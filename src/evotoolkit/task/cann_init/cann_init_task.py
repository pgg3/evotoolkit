# Copyright (c) 2025 Ping Guo
# Licensed under the MIT License

"""
CANN Init task class for Ascend C operator generation.

This module contains the task class for generating Ascend C operators
from Python reference implementations.
"""

import os
import tempfile
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

from evotoolkit.core import BaseTask, EvaluationResult, Solution

from .evaluator import AscendCEvaluator
from .assembler import AscendCCodeAssembler
from .parser import OperatorSignatureParser


@dataclass
class CANNInitTaskData:
    """CANNInit task input data"""

    op_name: str  # Operator name (e.g., "Add", "LayerNorm")
    python_reference: str  # Python reference implementation
    npu_type: str = "Ascend910B"  # NPU model
    cann_version: str = "8.0"  # CANN version


class CANNInitTask(BaseTask):
    """
    Ascend C operator generation task.

    Responsibilities:
    1. Parse Python Reference to extract operator signature
    2. Assemble LLM output into complete operator code (6 components)
    3. Compile, deploy, and verify operator correctness
    4. Return evaluation result

    LLM Output Format:
    {
        "kernel_src": "...",           # Core kernel code (LLM must generate)
        "tiling_fields": [             # Tiling data field definitions
            {"name": "totalLength", "type": "uint32_t"},
            {"name": "tileNum", "type": "uint32_t"}
        ],
        "tiling_func_body": "...",     # TilingFunc function body
        "block_dim": 8                 # Number of parallel cores
    }

    The remaining 5 components are generated by template engine:
    - project_json_src: From Python signature
    - host_tiling_src: Template + tiling_fields
    - host_operator_src: Template + tiling_func_body
    - python_bind_src: Pure template
    - model_src: Pure template
    """

    def __init__(
        self,
        data: Dict[str, Any],
        project_path: Optional[str] = None,
        fake_mode: bool = False,
    ):
        """
        Initialize the CANN Init task.

        Args:
            data: Task data (CANNInitTaskData as dict)
            project_path: Operator project directory
            fake_mode: Skip actual evaluation (for testing)
        """
        self.project_path = project_path or tempfile.mkdtemp()
        self.fake_mode = fake_mode
        super().__init__(data)

        # Initialize components
        self.parser = OperatorSignatureParser()
        self.assembler = AscendCCodeAssembler(self.signature)
        self.evaluator = AscendCEvaluator(self.project_path)

    def _process_data(self, data: Dict[str, Any]):
        """Process input data"""
        self.op_name = data["op_name"]
        self.python_reference = data["python_reference"]
        self.npu_type = data.get("npu_type", "Ascend910B")
        self.cann_version = data.get("cann_version", "8.0")

        # Parse Python signature
        self.signature = self.parser.parse(self.python_reference, self.op_name)

    def get_task_type(self) -> str:
        return "CANNInit"

    def get_base_task_description(self) -> str:
        return f"""You are an Ascend C operator development expert.
Convert Python operator implementation to Ascend C code.
The operator will run on {self.npu_type} NPU with CANN {self.cann_version}.
Ensure the implementation is functionally equivalent to Python Reference.
"""

    def evaluate_code(self, llm_output: Dict[str, Any]) -> EvaluationResult:
        """
        Evaluate LLM generated code.

        Args:
            llm_output: LLM output containing:
                - kernel_src: Kernel code
                - tiling_fields: Tiling field definitions
                - tiling_func_body: TilingFunc function body
                - block_dim: Number of parallel cores

        Returns:
            EvaluationResult: Evaluation result
        """
        if self.fake_mode:
            return EvaluationResult(
                valid=True, score=1.0, additional_info={"fake_mode": True}
            )

        try:
            # Step 1: Assemble complete code (template + LLM output)
            full_code = self.assembler.assemble(llm_output)

            # Step 2: Compile
            compile_result = self.evaluator.compile(full_code, self.op_name)
            if not compile_result["success"]:
                return EvaluationResult(
                    valid=False,
                    score=None,
                    additional_info={
                        "stage": "compile",
                        "error": compile_result["error"],
                        "kernel_src": llm_output.get("kernel_src", ""),
                    },
                )

            # Step 3: Deploy
            deploy_result = self.evaluator.deploy(self.op_name)
            if not deploy_result["success"]:
                return EvaluationResult(
                    valid=False,
                    score=None,
                    additional_info={
                        "stage": "deploy",
                        "error": deploy_result["error"],
                    },
                )

            # Step 4: Verify correctness
            correctness_result = self.evaluator.verify_correctness(
                self.python_reference, self.op_name
            )
            if not correctness_result["pass"]:
                return EvaluationResult(
                    valid=False,
                    score=None,
                    additional_info={
                        "stage": "correctness",
                        "error": correctness_result["error"],
                        "python_output": correctness_result.get("python_output"),
                        "ascend_output": correctness_result.get("ascend_output"),
                        "max_diff": correctness_result.get("max_diff"),
                    },
                )

            # Step 5: Performance measurement (optional)
            perf_result = self.evaluator.measure_performance(self.op_name)

            return EvaluationResult(
                valid=True,
                score=1.0,  # Pass = 1.0, or use -runtime as score
                additional_info={
                    "stage": "success",
                    "runtime": perf_result.get("runtime"),
                    "kernel_src": llm_output.get("kernel_src", ""),
                },
            )

        except Exception as e:
            return EvaluationResult(
                valid=False,
                score=None,
                additional_info={
                    "stage": "exception",
                    "error": str(e),
                },
            )

    def make_init_sol_wo_other_info(self) -> Solution:
        """Create initial solution (empty, as this is a generation task)"""
        return Solution("")
