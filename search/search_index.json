{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"EvoToolkit","text":"<p>LLM-driven solution evolutionary optimization toolkit</p> <p>EvoToolkit is a Python library that leverages Large Language Models (LLMs) to evolve solutions for optimization problems. It combines the power of evolutionary algorithms with LLM-based solution generation and refinement, supporting code, text, and other evaluable representations.</p>"},{"location":"#key-features","title":"\u2728 Key Features","text":"<ul> <li>\ud83e\udd16 LLM-Driven Evolution: Use state-of-the-art language models to generate and evolve solutions</li> <li>\ud83d\udd2c Multiple Algorithms: Support for EoH, EvoEngineer, and FunSearch evolutionary methods</li> <li>\ud83c\udf0d Task-Agnostic: Supports any evaluable optimization task (code, text, math expressions, etc.)</li> <li>\ud83c\udfaf Extensible Framework: Easy-to-extend task system for custom optimization problems</li> <li>\ud83d\udd0c Simple API: High-level <code>evotoolkit.solve()</code> function for quick prototyping</li> <li>\ud83d\udee0\ufe0f Advanced Customization: Low-level API for fine-grained control</li> </ul>"},{"location":"#built-in-task-types","title":"Built-in Task Types","text":"Task Type Description Details \ud83d\udd2c Scientific Regression Symbolic regression on real scientific datasets Scientific Regression Tutorial \ud83d\udcac Prompt Engineering Optimize LLM prompts for downstream tasks Prompt Engineering Tutorial \ud83d\udee1\ufe0f Adversarial Attacks Evolve adversarial attack algorithms Adversarial Attack Tutorial \u26a1 CUDA Code Evolution Evolve and optimize CUDA kernels CUDA Task Tutorial"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install evotoolkit\n\n# Or install with all dependencies\npip install evotoolkit[all]\n</code></pre> <p>For detailed installation instructions, see the Installation Guide.</p>"},{"location":"#your-first-optimization","title":"Your First Optimization","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools import HttpsApi\n\n# 1. Create a task\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\n\n# 2. Create an interface\ninterface = EvoEngineerPythonInterface(task)\n\n# 3. Solve with LLM\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"your-api-key-here\",\n    model=\"gpt-4o\"\n)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre> <p>That's it! EvoToolkit will use the LLM to evolve mathematical equations to fit your scientific data.</p> <p>For a complete walkthrough, check out the Getting Started Guide.</p>"},{"location":"#available-algorithms","title":"\ud83d\udcda Available Algorithms","text":"Algorithm Description EvoEngineer Main LLM-driven evolutionary algorithm FunSearch Function search optimization method EoH Evolution of Heuristics <p>See the Tutorials section for more usage examples.</p>"},{"location":"#documentation","title":"\ud83d\udcd6 Documentation","text":"<ul> <li>Installation: Installation instructions and setup</li> <li>Getting Started: Quick start guide and basic usage</li> <li>Tutorials: Step-by-step tutorials for common tasks</li> <li>API Reference: Detailed API documentation</li> <li>Development: Contributing guidelines and architecture</li> </ul>"},{"location":"#links","title":"\ud83d\udd17 Links","text":"<ul> <li>GitHub: https://github.com/pgg3/evotoolkit</li> <li>PyPI: https://pypi.org/project/evotoolkit/</li> <li>Paper: arXiv (submitted)</li> </ul>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>EvoToolkit is dual-licensed:</p> <ul> <li>Academic &amp; Open Source Use: Free for academic research, education, and open source projects. Citation required for academic publications.</li> <li>Commercial Use: Requires a separate commercial license. Contact pguo6680@gmail.com for licensing.</li> </ul> <p>See LICENSE for full terms.</p>"},{"location":"#citation","title":"\ud83d\ude4f Citation","text":"<p>If you use EvoToolkit in your research, please cite:</p> <pre><code>@article{guo2025evotoolkit,\n  title={evotoolkit: A Unified LLM-Driven Evolutionary Framework for Generalized Solution Search},\n  author={Guo, Ping and Zhang, Qingfu},\n  journal={arXiv preprint arXiv:XXXX.XXXXX},\n  year={2025},\n  note={Submitted to arXiv}\n}\n</code></pre>"},{"location":"#getting-help","title":"\ud83d\udcac Getting Help","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>Email: pguo6680@gmail.com</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will walk you through your first optimization task using EvoToolkit.</p>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<p>Create a new project and run your first optimization in minutes:</p> <pre><code>mkdir my-evotool-project\ncd my-evotool-project\n</code></pre> <p>Then follow the guide below to create your first optimization script.</p>"},{"location":"getting-started/#topics","title":"Topics","text":"<ul> <li>Your First Optimization: Your First Optimization: Scientific Symbolic Regression</li> <li>Understanding the Code: Understanding the Code</li> <li>Exploring the Results: Exploring the Results</li> <li>Try Different Algorithms: Try Different Algorithms</li> <li>Next Steps: Next Steps</li> </ul> <p>Next, see Tutorials: Tutorials</p>"},{"location":"installation/","title":"Installation","text":"<p>This section helps you install EvoToolkit and set up your environment.</p>"},{"location":"installation/#quick-install","title":"Quick Install","text":"<pre><code>pip install evotoolkit\n</code></pre>"},{"location":"installation/#topics","title":"Topics","text":"<ul> <li>Requirements: Requirements</li> <li>Install from PyPI: Install from PyPI</li> <li>Install from Source: Install from Source</li> <li>Environments &amp; Package Managers: Environments &amp; Package Managers</li> <li>LLM Setup &amp; Verify: LLM Setup &amp; Verify</li> <li>Troubleshooting: Troubleshooting</li> </ul> <p>Next, see Getting Started: Getting Started</p>"},{"location":"api/","title":"API Reference","text":"<p>Welcome to the EvoToolkit API reference documentation. This section provides detailed information about all public APIs, classes, and functions.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>EvoToolkit is organized into several main modules:</p> <ul> <li>Core API: Core functionality including <code>evotoolkit.solve()</code>, <code>Solution</code>, <code>Task</code>, and base classes</li> <li>Tasks: Built-in optimization tasks (Python and CUDA)</li> <li>Methods: Evolutionary algorithms (EoH, EvoEngineer, FunSearch)</li> <li>Interfaces: Method interfaces that connect tasks to algorithms</li> <li>Tools: Utilities and LLM API clients</li> </ul>"},{"location":"api/#quick-api-reference","title":"Quick API Reference","text":""},{"location":"api/#high-level-api","title":"High-Level API","text":"<p>The simplest way to use EvoToolkit:</p> <pre><code>import evotoolkit\n\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre> <p>See Core API: evotoolkit.solve() for details.</p>"},{"location":"api/#core-classes","title":"Core Classes","text":"Class Description Documentation <code>Solution</code> Represents a candidate solution Core API <code>Task</code> Base class for optimization tasks Core API <code>MethodInterface</code> Base class for algorithm interfaces Interfaces"},{"location":"api/#built-in-tasks","title":"Built-in Tasks","text":"Task Description Documentation <code>ScientificRegressionTask</code> Scientific symbolic regression task Tasks <code>PythonTask</code> Generic Python task Tasks <code>CudaTask</code> GPU kernel optimization task Tasks"},{"location":"api/#evolutionary-algorithms","title":"Evolutionary Algorithms","text":"Algorithm Description Documentation <code>EvoEngineer</code> Main LLM-driven evolutionary algorithm Methods <code>FunSearch</code> Function search optimization Methods <code>EoH</code> Evolution of Heuristics Methods"},{"location":"api/#api-design-philosophy","title":"API Design Philosophy","text":"<p>EvoToolkit provides two levels of API:</p>"},{"location":"api/#1-high-level-api-recommended","title":"1. High-Level API (Recommended)","text":"<p>The high-level API through <code>evotoolkit.solve()</code> handles most complexity automatically:</p> <pre><code># Create task and interface\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = EvoEngineerPythonInterface(task)\n\n# Solve\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre> <p>Advantages: - Simple and concise - Automatic configuration - Best for most use cases</p>"},{"location":"api/#2-low-level-api-advanced","title":"2. Low-Level API (Advanced)","text":"<p>The low-level API provides fine-grained control:</p> <pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\n# Create custom configuration\nconfig = EvoEngineerConfig(\n    task=task,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    pop_size=10,\n    # ... more custom settings\n)\n\n# Create and run algorithm\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# Get best solution\nbest_solution = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n</code></pre> <p>Advantages: - Full customization - Access to internal state - Advanced debugging</p> <p>See Advanced Usage Tutorial for details.</p>"},{"location":"api/#module-organization","title":"Module Organization","text":"<pre><code>evotool/\n\u251c\u2500\u2500 __init__.py              # High-level API (solve function)\n\u251c\u2500\u2500 core/                    # Core abstractions\n\u2502   \u251c\u2500\u2500 base_task.py        # Task base class\n\u2502   \u251c\u2500\u2500 solution.py         # Solution class\n\u2502   \u251c\u2500\u2500 base_method.py      # Algorithm base class\n\u2502   \u251c\u2500\u2500 base_config.py      # Configuration base class\n\u2502   \u2514\u2500\u2500 method_interface/   # Algorithm interfaces\n\u251c\u2500\u2500 evo_method/             # Evolutionary algorithms\n\u2502   \u251c\u2500\u2500 eoh/               # EoH implementation\n\u2502   \u251c\u2500\u2500 evoengineer/       # EvoEngineer implementation\n\u2502   \u2514\u2500\u2500 funsearch/         # FunSearch implementation\n\u251c\u2500\u2500 task/                   # Task implementations\n\u2502   \u251c\u2500\u2500 python_task/       # Python task framework\n\u2502   \u251c\u2500\u2500 cuda_engineering/  # CUDA task framework\n\u2502   \u2514\u2500\u2500 string_optimization/ # String optimization tasks\n\u251c\u2500\u2500 tools/                  # Utilities\n\u2502   \u2514\u2500\u2500 llm.py             # LLM API client (HttpsApi)\n\u2514\u2500\u2500 data/                   # Data management utilities\n</code></pre>"},{"location":"api/#common-patterns","title":"Common Patterns","text":""},{"location":"api/#pattern-1-basic-optimization","title":"Pattern 1: Basic Optimization","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\n\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface, './results', llm_api, max_generations=5)\n</code></pre>"},{"location":"api/#pattern-2-custom-task","title":"Pattern 2: Custom Task","text":"<pre><code>from evotoolkit.core import BaseTask, Solution\n\nclass MyTask(BaseTask):\n    def evaluate(self, solution: Solution) -&gt; float:\n        # Your evaluation logic\n        return fitness_value\n\ntask = MyTask()\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface, './results', llm_api)\n</code></pre>"},{"location":"api/#pattern-3-algorithm-comparison","title":"Pattern 3: Algorithm Comparison","text":"<pre><code>algorithms = [\n    ('EoH', EoHPythonInterface(task)),\n    ('EvoEngineer', EvoEngineerPythonInterface(task)),\n    ('FunSearch', FunSearchPythonInterface(task))\n]\n\nfor name, interface in algorithms:\n    result = evotoolkit.solve(interface, f'./results/{name}', llm_api)\n    print(f\"{name}: {result.fitness}\")\n</code></pre>"},{"location":"api/#api-versioning","title":"API Versioning","text":"<p>EvoToolkit follows Semantic Versioning:</p> <ul> <li>Major version (1.x.x): Breaking API changes</li> <li>Minor version (x.1.x): New features, backward compatible</li> <li>Patch version (x.x.1): Bug fixes, backward compatible</li> </ul> <p>Check the current version:</p> <pre><code>import evotoolkit\nprint(evotoolkit.__version__)  # e.g., \"1.0.0\"\n</code></pre>"},{"location":"api/#type-hints","title":"Type Hints","text":"<p>EvoToolkit uses type hints throughout the codebase. Use a type checker like <code>mypy</code> for static analysis:</p> <pre><code>pip install mypy\nmypy your_script.py\n</code></pre>"},{"location":"api/#next-steps","title":"Next Steps","text":"<ul> <li>Browse the Core API documentation</li> <li>Explore Tasks API for built-in tasks</li> <li>Check Methods API for evolutionary algorithms</li> <li>Learn about Interfaces API for algorithm integration</li> </ul>"},{"location":"api/core/","title":"Core API Overview","text":"<p>This section documents EvoToolkit\u2019s core building blocks. Each topic has a dedicated page to keep content focused and easy to scan.</p>"},{"location":"api/core/#functions","title":"Functions","text":"<ul> <li>evotoolkit.solve()</li> <li>evotoolkit.list_algorithms()</li> <li>evotoolkit.list_tasks()</li> </ul>"},{"location":"api/core/#classes","title":"Classes","text":"<ul> <li>Solution</li> <li>BaseTask</li> <li>Method</li> <li>BaseConfig</li> <li>HistoryManager</li> <li>Operator</li> <li>BaseRunStateDict</li> </ul>"},{"location":"api/core/#related","title":"Related","text":"<ul> <li>See Interfaces for adapters connecting tasks to methods.</li> </ul>"},{"location":"api/interfaces/","title":"Interfaces API","text":"<p>Interfaces connect optimization tasks to evolutionary algorithms, handling algorithm-specific adaptations.</p>"},{"location":"api/interfaces/#what-are-interfaces","title":"What are Interfaces?","text":"<p>An Interface is a bridge between a Task (what you want to optimize) and a Method (how to optimize it).</p> <pre><code>Task (Problem) \u2192 Interface (Adapter) \u2192 Method (Algorithm)\n</code></pre> <p>Interfaces handle: - Algorithm-specific prompt generation for LLM - Task-specific operators (mutation, crossover, etc.) - Solution format conversion - Evaluation orchestration</p>"},{"location":"api/interfaces/#python-task-interfaces","title":"Python Task Interfaces","text":""},{"location":"api/interfaces/#python-interfaces","title":"Python Interfaces","text":"<p>See the dedicated pages:</p> <ul> <li>EvoEngineerPythonInterface</li> <li>FunSearchPythonInterface</li> <li>EoHPythonInterface</li> </ul>"},{"location":"api/interfaces/#cuda-task-interfaces","title":"CUDA Task Interfaces","text":"<p>See the dedicated pages:</p> <ul> <li>EvoEngineerFullCudaInterface</li> <li>EvoEngineerFreeCudaInterface</li> <li>EvoEngineerInsightCudaInterface</li> <li>FunSearchCudaInterface</li> <li>EoHCudaInterface</li> </ul> <p>See CUDA Task Tutorial for details.</p>"},{"location":"api/interfaces/#base-interface-class","title":"Base Interface Class","text":""},{"location":"api/interfaces/#basemethodinterface","title":"BaseMethodInterface","text":"<p>Base class for all method interfaces. See the reference page: BaseMethodInterface.</p> <p>Key Methods:</p> <ul> <li><code>generate_prompt(generation, population)</code>: Creates LLM prompts</li> <li><code>parse_llm_response(response)</code>: Parses LLM output into solutions</li> <li><code>mutate(solution)</code>: Applies mutation operator</li> <li><code>crossover(parent1, parent2)</code>: Applies crossover operator</li> </ul> <p>Creating Custom Interfaces:</p> <pre><code>from evotoolkit.core.method_interface import BaseMethodInterface\nfrom evotoolkit.core import Solution\n\nclass MyCustomInterface(BaseMethodInterface):\n    def generate_prompt(self, generation, population):\n        # Your custom prompt generation\n        return prompt_string\n\n    def parse_llm_response(self, response):\n        # Parse LLM response\n        code = self.extract_code(response)\n        return Solution(code=code)\n\n    def mutate(self, solution):\n        # Your custom mutation logic\n        return mutated_solution\n</code></pre>"},{"location":"api/interfaces/#interface-selection-guide","title":"Interface Selection Guide","text":""},{"location":"api/interfaces/#for-python-tasks","title":"For Python Tasks","text":"Task Type Recommended Interface Alternative Scientific Regression <code>EvoEngineerPythonInterface</code> <code>FunSearchPythonInterface</code> General Optimization <code>EvoEngineerPythonInterface</code> <code>EoHPythonInterface</code> Quick Prototyping <code>EoHPythonInterface</code> <code>EvoEngineerPythonInterface</code>"},{"location":"api/interfaces/#for-cuda-tasks","title":"For CUDA Tasks","text":"Task Type Recommended Interface Kernel Optimization <code>EvoEngineerCudaInterface</code> GPU Algorithm Discovery <code>FunSearchCudaInterface</code>"},{"location":"api/interfaces/#how-interfaces-work","title":"How Interfaces Work","text":""},{"location":"api/interfaces/#1-prompt-generation","title":"1. Prompt Generation","text":"<p>Interfaces create algorithm-specific prompts for the LLM:</p> <pre><code># EvoEngineer prompt example\nprompt = \"\"\"\nYou are evolving a Python function to approximate data.\n\nPrevious generation best solution:\n{previous_best_code}\n\nCurrent fitness: {fitness}\n\nPlease improve this solution or create a new one.\n\"\"\"\n</code></pre>"},{"location":"api/interfaces/#2-response-parsing","title":"2. Response Parsing","text":"<p>Interfaces extract code from LLM responses:</p> <pre><code>response = llm_api.call(prompt)\nsolution = interface.parse_llm_response(response)\n# solution.sol_string now contains the extracted Python/CUDA code\n</code></pre>"},{"location":"api/interfaces/#3-operator-application","title":"3. Operator Application","text":"<p>Interfaces apply evolutionary operators:</p> <pre><code># Mutation\nmutated = interface.mutate(solution)\n\n# Crossover\noffspring = interface.crossover(parent1, parent2)\n</code></pre>"},{"location":"api/interfaces/#advanced-custom-interfaces","title":"Advanced: Custom Interfaces","text":"<p>Create a custom interface for specialized algorithms or tasks:</p> <pre><code>from evotoolkit.core.method_interface import BaseMethodInterface\nfrom evotoolkit.core import Solution\n\nclass MySpecializedInterface(BaseMethodInterface):\n    def __init__(self, task):\n        super().__init__(task)\n        self.custom_config = self.load_custom_config()\n\n    def generate_prompt(self, generation, population):\n        # Custom prompt with domain-specific instructions\n        best_sol = max(population, key=lambda s: s.evaluation_res.score if s.evaluation_res.valid else float('-inf'))\n\n        prompt = f\"\"\"\n        Domain-specific context: {self.custom_config['context']}\n\n        Evolve a solution that improves upon:\n        {best_sol.sol_string}\n\n        Current best score: {best_sol.evaluation_res.score}\n        Generation: {generation}\n        \"\"\"\n        return prompt\n\n    def parse_llm_response(self, response):\n        # Custom parsing logic\n        code = self.extract_code_with_custom_markers(response)\n        return Solution(code=code)\n\n    def load_custom_config(self):\n        # Load domain-specific configuration\n        return {\"context\": \"Custom domain knowledge\"}\n</code></pre> <p>Usage:</p> <pre><code>task = MyCustomTask()\ninterface = MySpecializedInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre>"},{"location":"api/interfaces/#comparison-interface-vs-direct-method-call","title":"Comparison: Interface vs Direct Method Call","text":""},{"location":"api/interfaces/#using-interface-high-level-api-recommended","title":"Using Interface (High-Level API) \u2705 Recommended","text":"<pre><code>interface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre> <p>Advantages: - Simple and concise - Automatic configuration - Algorithm is inferred from interface</p>"},{"location":"api/interfaces/#direct-method-call-low-level-api-advanced","title":"Direct Method Call (Low-Level API) \u2699\ufe0f Advanced","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nconfig = EvoEngineerConfig(interface=interface, ...)\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n</code></pre> <p>Advantages: - Full control over configuration - Access to internal state - Custom post-processing</p>"},{"location":"api/interfaces/#next-steps","title":"Next Steps","text":"<ul> <li>See Tasks API for available optimization tasks</li> <li>Check Methods API for evolutionary algorithms</li> <li>Try the Advanced Usage Tutorial for low-level API</li> </ul>"},{"location":"api/methods/","title":"Methods API","text":"<p>Evolutionary methods are the core algorithms that drive the optimization process.</p>"},{"location":"api/methods/#available-algorithms","title":"Available Algorithms","text":"<p>EvoToolkit provides three main evolutionary algorithms:</p> Algorithm Best For Characteristics EvoEngineer General optimization Versatile, robust, good default choice FunSearch Function discovery Specialized for function approximation EoH Heuristic optimization Fast, efficient for simple problems"},{"location":"api/methods/#evoengineer","title":"EvoEngineer","text":"<p>See the dedicated page: EvoEngineer.</p>"},{"location":"api/methods/#funsearch","title":"FunSearch","text":"<p>See the dedicated page: FunSearch.</p>"},{"location":"api/methods/#eoh-evolution-of-heuristics","title":"EoH (Evolution of Heuristics)","text":"<p>See the dedicated page: EoH.</p>"},{"location":"api/methods/#algorithm-comparison","title":"Algorithm Comparison","text":""},{"location":"api/methods/#when-to-use-each-algorithm","title":"When to Use Each Algorithm","text":"<p>Use EvoEngineer when: - You have a general optimization problem - You want a robust, well-tested algorithm - You need good default behavior</p> <p>Use FunSearch when: - You're specifically looking for novel functions - Function discovery is the primary goal - You want to explore a diverse function space</p> <p>Use EoH when: - You need fast iterations - Your problem has simple heuristics - You want efficient resource usage</p>"},{"location":"api/methods/#performance-characteristics","title":"Performance Characteristics","text":"Algorithm Speed Exploration Exploitation Best Fitness EvoEngineer Medium High High \u2b50\u2b50\u2b50\u2b50\u2b50 FunSearch Slow Very High Medium \u2b50\u2b50\u2b50\u2b50 EoH Fast Medium High \u2b50\u2b50\u2b50"},{"location":"api/methods/#advanced-custom-algorithms","title":"Advanced: Custom Algorithms","text":"<p>You can implement custom evolutionary algorithms by extending <code>BaseMethod</code>:</p> <pre><code>from evotoolkit.core import BaseMethod, BaseConfig\n\nclass MyCustomAlgorithm(BaseMethod):\n    def run(self):\n        for generation in range(self.config.max_generations):\n            # 1. Generate solutions\n            solutions = self.generate_solutions()\n\n            # 2. Evaluate solutions\n            for solution in solutions:\n                eval_res = self.config.interface.task.evaluate_code(solution.sol_string)\n                solution.evaluation_res = eval_res\n\n            # 3. Select best solutions\n            self.select_and_update_population(solutions)\n\n    def generate_solutions(self):\n        # Your custom generation logic\n        pass\n\n    def select_and_update_population(self, solutions):\n        # Your custom selection logic\n        pass\n</code></pre> <p>See Advanced Usage Tutorial for details.</p>"},{"location":"api/methods/#next-steps","title":"Next Steps","text":"<ul> <li>Try different algorithms with the Tutorials</li> <li>Learn about Interfaces for connecting tasks to algorithms</li> <li>Explore Core API for the high-level <code>solve()</code> function</li> </ul>"},{"location":"api/tasks/","title":"Tasks API","text":"<p>Tasks define optimization problems and how to evaluate candidate solutions.</p>"},{"location":"api/tasks/#overview","title":"Overview","text":"<p>EvoToolkit provides three categories of tasks:</p> <ul> <li>Python Tasks - Optimize Python code functions</li> <li>String Tasks - Optimize text/string solutions (e.g., prompts)</li> <li>CUDA Tasks - Optimize GPU kernel code</li> </ul>"},{"location":"api/tasks/#python-tasks","title":"Python Tasks","text":""},{"location":"api/tasks/#pythontask","title":"PythonTask","text":"<p>Base class for Python code optimization tasks.</p> <p>See the dedicated page: PythonTask.</p>"},{"location":"api/tasks/#scientificregressiontask","title":"ScientificRegressionTask","text":"<p>Scientific symbolic regression for discovering mathematical equations from data.</p> <p>See the dedicated page: ScientificRegressionTask.</p>"},{"location":"api/tasks/#adversarialattacktask","title":"AdversarialAttackTask","text":"<p>Evolve adversarial attack algorithms for black-box models.</p> <p>Usage:</p> <pre><code>from evotoolkit.task.python_task.adversarial_attack import AdversarialAttackTask\n\n# Create task with mock evaluation\ntask = AdversarialAttackTask(\n    model=None,  # Optional: PyTorch model\n    test_loader=None,  # Optional: test data loader\n    attack_steps=1000,\n    n_test_samples=10,\n    timeout_seconds=300.0,\n    use_mock=True  # Use mock evaluation for testing\n)\n\n# Evaluate attack code\ncode = '''\ndef draw_proposals(x, num_proposals, step_size):\n    # Generate adversarial proposal samples\n    proposals = ...\n    return proposals\n'''\n\nresult = task.evaluate_code(code)\nprint(f\"Score: {result.score}\")  # Negative L2 distance (higher is better)\n</code></pre> <p>Parameters:</p> <ul> <li><code>model</code> (<code>any</code>, optional): Target model to attack. If None, uses mock evaluation.</li> <li><code>test_loader</code> (<code>any</code>, optional): DataLoader with test samples. If None, uses mock evaluation.</li> <li><code>attack_steps</code> (<code>int</code>): Number of attack iterations per sample (default: 1000)</li> <li><code>n_test_samples</code> (<code>int</code>): Number of test samples to evaluate (default: 10)</li> <li><code>timeout_seconds</code> (<code>float</code>): Execution timeout (default: 300.0)</li> <li><code>use_mock</code> (<code>bool</code>): Use mock evaluation instead of real attack (default: False)</li> </ul> <p>Methods:</p> <ul> <li><code>evaluate_code(code: str) -&gt; EvaluationResult</code>: Evaluate attack algorithm code</li> </ul> <p>See Adversarial Attack Tutorial for details.</p>"},{"location":"api/tasks/#string-tasks","title":"String Tasks","text":""},{"location":"api/tasks/#stringtask","title":"StringTask","text":"<p>Base class for string-based optimization tasks (e.g., prompt optimization).</p> <p>Usage:</p> <pre><code>from evotoolkit.task.string_optimization.string_task import StringTask\nfrom evotoolkit.core import EvaluationResult, Solution\n\nclass MyStringTask(StringTask):\n    def _evaluate_string_impl(self, candidate_string: str) -&gt; EvaluationResult:\n        # Evaluate string solution\n        score = self.compute_score(candidate_string)\n        return EvaluationResult(\n            valid=True,\n            score=score,\n            additional_info={}\n        )\n\n    def get_base_task_description(self) -&gt; str:\n        return \"Optimize a string solution...\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        return Solution(\"initial string\")\n</code></pre> <p>Constructor:</p> <pre><code>def __init__(self, data, timeout_seconds: float = 30.0)\n</code></pre> <p>Abstract Methods:</p> <ul> <li><code>_evaluate_string_impl(candidate_string: str) -&gt; EvaluationResult</code></li> <li><code>get_base_task_description() -&gt; str</code></li> <li><code>make_init_sol_wo_other_info() -&gt; Solution</code></li> </ul>"},{"location":"api/tasks/#promptoptimizationtask","title":"PromptOptimizationTask","text":"<p>Optimize LLM prompt templates to improve task performance.</p> <p>Usage:</p> <pre><code>from evotoolkit.task.string_optimization.prompt_optimization import PromptOptimizationTask\n\n# Define test cases\ntest_cases = [\n    {\"question\": \"What is 2+2?\", \"expected\": \"4\"},\n    {\"question\": \"What is 5*3?\", \"expected\": \"15\"}\n]\n\n# Create task\ntask = PromptOptimizationTask(\n    test_cases=test_cases,\n    llm_api=my_llm_api,  # Optional if use_mock=True\n    timeout_seconds=30.0,\n    use_mock=True  # Use mock LLM for testing\n)\n\n# Evaluate prompt template\nprompt_template = \"Solve this math problem: {question}\\nGive only the number.\"\nresult = task.evaluate_code(prompt_template)\nprint(f\"Accuracy: {result.score}\")  # Correctness rate (0.0 to 1.0)\n</code></pre> <p>Parameters:</p> <ul> <li><code>test_cases</code> (<code>List[Dict[str, str]]</code>): Test cases with 'question' and 'expected' keys</li> <li><code>llm_api</code> (optional): LLM API instance for testing prompts (required if <code>use_mock=False</code>)</li> <li><code>timeout_seconds</code> (<code>float</code>): Evaluation timeout (default: 30.0)</li> <li><code>use_mock</code> (<code>bool</code>): Use mock LLM responses for testing (default: False)</li> </ul> <p>Template Format:</p> <p>Prompt templates must contain <code>{question}</code> placeholder:</p> <pre><code># Valid templates\n\"Answer the question: {question}\"\n\"Q: {question}\\nA:\"\n\n# Invalid - missing placeholder\n\"Answer the question\"  # ERROR!\n</code></pre> <p>Methods:</p> <ul> <li><code>evaluate_code(prompt_template: str) -&gt; EvaluationResult</code>: Evaluate prompt template</li> </ul> <p>See Prompt Engineering Tutorial for details.</p>"},{"location":"api/tasks/#cuda-tasks","title":"CUDA Tasks","text":""},{"location":"api/tasks/#cudatask","title":"CudaTask","text":"<p>Base class for CUDA kernel optimization tasks.</p> <p>Usage:</p> <pre><code>from evotoolkit.task.cuda_engineering import CudaTask, CudaTaskInfoMaker, Evaluator\n\n# Create evaluator\nevaluator = Evaluator(temp_path='./temp')\n\n# Create task info\ntask_info = CudaTaskInfoMaker.make_task_info(\n    evaluator=evaluator,\n    gpu_type=\"RTX 4090\",\n    cuda_version=\"12.4\",\n    org_py_code=original_python_code,\n    func_py_code=function_python_code,\n    cuda_code=baseline_cuda_code\n)\n\n# Create task\ntask = CudaTask(data=task_info, temp_path='./temp')\n\n# Evaluate CUDA code\neval_res = task.evaluate_code(candidate_cuda_code)\nprint(f\"Runtime: {-eval_res.score:.4f}s\")  # Score is negative runtime\n</code></pre> <p>Constructor:</p> <pre><code>def __init__(self, data, temp_path=None, fake_mode: bool = False)\n</code></pre> <p>Parameters:</p> <ul> <li><code>data</code> (<code>dict</code>): Task info from <code>CudaTaskInfoMaker.make_task_info()</code></li> <li><code>temp_path</code> (<code>str</code>, optional): Temporary path for CUDA compilation</li> <li><code>fake_mode</code> (<code>bool</code>): Skip actual CUDA evaluation (default: False)</li> </ul> <p>Methods:</p> <ul> <li><code>evaluate_code(code: str) -&gt; EvaluationResult</code>: Evaluate CUDA kernel code and return result with negative runtime as score (higher score = faster kernel)</li> </ul> <p>Note: CUDA tasks require the <code>cuda_engineering</code> extra:</p> <pre><code>pip install evotoolkit[cuda_engineering]\n</code></pre> <p>See CUDA Task Tutorial for a complete example.</p>"},{"location":"api/tasks/#data-management","title":"Data Management","text":"<p>Datasets are automatically downloaded from GitHub releases when first accessed.</p>"},{"location":"api/tasks/#python-api","title":"Python API","text":"<pre><code>from evotoolkit.data import get_dataset_path, list_available_datasets\n\n# Get dataset path (auto-downloads if not present)\nbase_dir = get_dataset_path('scientific_regression')\n\n# Access specific dataset\nbactgrow_path = base_dir / 'bactgrow'\ntrain_csv = bactgrow_path / 'train.csv'\n\n# Use custom directory\nbase_dir = get_dataset_path('scientific_regression', data_dir='./my_data')\n\n# List available datasets in a category\ndatasets = list_available_datasets('scientific_regression')\nprint(datasets.keys())  # dict_keys(['bactgrow', 'oscillator1', 'oscillator2', 'stressstrain'])\n</code></pre> <p>Available Functions:</p> <ul> <li><code>get_dataset_path(category, data_dir=None)</code> - Get dataset path, auto-download if needed</li> <li><code>list_available_datasets(category)</code> - List all datasets in a category</li> </ul> <p>Default Location: <code>~/.evotool/data/</code></p>"},{"location":"api/tasks/#creating-custom-tasks","title":"Creating Custom Tasks","text":""},{"location":"api/tasks/#python-task-example","title":"Python Task Example","text":"<pre><code>from evotoolkit.task.python_task import PythonTask\nfrom evotoolkit.core import EvaluationResult, Solution\n\nclass MyOptimizationTask(PythonTask):\n    \"\"\"Custom optimization task\"\"\"\n\n    def __init__(self, data, target):\n        self.data = data\n        self.target = target\n        super().__init__(data={'data': data, 'target': target}, timeout_seconds=30.0)\n\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"Evaluate solution and return result (higher score is better)\"\"\"\n        # 1. Execute solution code\n        namespace = {}\n        try:\n            exec(candidate_code, namespace)\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': str(e)}\n            )\n\n        # 2. Extract function\n        if 'my_function' not in namespace:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': 'Function \"my_function\" not found'}\n            )\n\n        func = namespace['my_function']\n\n        # 3. Compute fitness (negative MSE so higher is better)\n        try:\n            predictions = [func(x) for x in self.data]\n            mse = sum((p - t)**2 for p, t in zip(predictions, self.target)) / len(self.data)\n            score = -mse\n            return EvaluationResult(\n                valid=True,\n                score=score,\n                additional_info={'mse': mse}\n            )\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': str(e)}\n            )\n\n    def get_base_task_description(self) -&gt; str:\n        return \"Optimize a function to fit the data...\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        return Solution(\"def my_function(x): return x\")\n</code></pre> <p>See Custom Task Tutorial for details.</p>"},{"location":"api/tasks/#task-selection-guide","title":"Task Selection Guide","text":"Task Type Recommended Class Use Case Scientific equation discovery <code>ScientificRegressionTask</code> Discover mathematical models from data Adversarial attacks <code>AdversarialAttackTask</code> Evolve attack algorithms Prompt optimization <code>PromptOptimizationTask</code> Optimize LLM prompts Python code <code>PythonTask</code> General Python optimization String optimization <code>StringTask</code> Text/configuration optimization GPU kernels <code>CudaTask</code> CUDA performance optimization Custom problems <code>BaseTask</code> Any other optimization problem"},{"location":"api/tasks/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Methods API for evolutionary algorithms</li> <li>Check Interfaces API for task-method connections</li> <li>Try Scientific Regression Tutorial</li> <li>Learn to create Custom Tasks</li> </ul>"},{"location":"api/tools/","title":"Tools API","text":"<p>Utilities and helpers for EvoToolkit, including LLM API clients.</p>"},{"location":"api/tools/#httpsapi","title":"HttpsApi","text":"<p>See the dedicated page: HttpsApi.</p> <p>Purpose:</p> <ul> <li>Connect to LLM chat APIs</li> <li>Send prompts and receive responses</li> <li>Handle authentication and retries automatically</li> </ul> <p>Usage Example:</p> <pre><code>from evotoolkit.tools import HttpsApi\nimport os\n\n# Create LLM API client\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=os.environ[\"OPENAI_API_KEY\"],\n    model=\"gpt-4o\",\n    temperature=1.0\n)\n\n# Send a prompt\nmessages = [{\"role\": \"user\", \"content\": \"Write a Python function to compute fibonacci\"}]\nresponse, usage = llm_api.get_response(messages)\n\nprint(response)\nprint(f\"Tokens used: {usage['total_tokens']}\")\n</code></pre> <p>Using with evotoolkit.solve():</p> <pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import ScientificRegressionTask, EvoEngineerPythonInterface\nfrom evotoolkit.tools import HttpsApi\n\n# Configure LLM\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=os.environ[\"OPENAI_API_KEY\"],\n    model=\"gpt-4o\"\n)\n\n# Create task and interface\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = EvoEngineerPythonInterface(task)\n\n# Solve with the LLM\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre>"},{"location":"api/tools/#constructor-examples","title":"Constructor &amp; Examples","text":"<p>See the HttpsApi page for the full constructor, parameters, and usage examples.</p>"},{"location":"api/tools/#methods","title":"Methods","text":"<ul> <li>get_response()</li> <li>get_embedding()</li> </ul>"},{"location":"api/tools/#environment-variables","title":"Environment Variables","text":""},{"location":"api/tools/#openai_api_key","title":"OPENAI_API_KEY","text":"<p>Store your OpenAI API key:</p> <pre><code>export OPENAI_API_KEY=\"sk-...\"\n</code></pre> <p>Then use in Python:</p> <pre><code>import os\nfrom evotoolkit.tools import HttpsApi\n\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=os.environ[\"OPENAI_API_KEY\"],\n    model=\"gpt-4o\"\n)\n</code></pre>"},{"location":"api/tools/#llm_api_url-llm_api_key","title":"LLM_API_URL / LLM_API_KEY","text":"<p>For custom configurations:</p> <pre><code>export LLM_API_URL=\"https://your-api.com/v1/chat/completions\"\nexport LLM_API_KEY=\"your-key\"\nexport LLM_MODEL=\"gpt-4o\"\n</code></pre>"},{"location":"api/tools/#best-practices","title":"Best Practices","text":""},{"location":"api/tools/#dos","title":"Do's \u2705","text":"<ul> <li>Store API keys in environment variables (never hardcode)</li> <li>Use appropriate timeout values for your use case</li> <li>Handle rate limits gracefully</li> <li>Monitor token usage to control costs</li> <li>Use lower temperatures (0.0-0.5) for deterministic outputs</li> <li>Use higher temperatures (0.7-1.5) for creative outputs</li> </ul>"},{"location":"api/tools/#donts","title":"Don'ts \u274c","text":"<ul> <li>Don't commit API keys to git</li> <li>Don't use excessively low timeouts (&lt; 30s)</li> <li>Don't ignore token usage metrics</li> <li>Don't disable retries for production code</li> </ul>"},{"location":"api/tools/#provider-specific-notes","title":"Provider-Specific Notes","text":""},{"location":"api/tools/#openai","title":"OpenAI","text":"<pre><code>llm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=os.environ[\"OPENAI_API_KEY\"],\n    model=\"gpt-4o\"\n)\n</code></pre> <ul> <li>Models: <code>gpt-4o</code>, <code>gpt-4o-mini</code>, <code>gpt-3.5-turbo</code></li> <li>Rate limits: Check your account tier</li> <li>Docs: https://platform.openai.com/docs/api-reference</li> </ul>"},{"location":"api/tools/#anthropic-claude","title":"Anthropic Claude","text":"<p>Requires a compatible proxy or API gateway:</p> <pre><code>llm_api = HttpsApi(\n    api_url=\"https://your-gateway.com/v1/chat/completions\",\n    key=os.environ[\"ANTHROPIC_API_KEY\"],\n    model=\"claude-3-5-sonnet-20241022\"\n)\n</code></pre> <ul> <li>Models: <code>claude-3-5-sonnet-20241022</code>, <code>claude-3-opus-20240229</code></li> <li>Note: Requires OpenAI-compatible API format</li> <li>Docs: https://docs.anthropic.com/</li> </ul>"},{"location":"api/tools/#custom-providers","title":"Custom Providers","text":"<p>Many LLM providers offer OpenAI-compatible APIs:</p> <pre><code>llm_api = HttpsApi(\n    api_url=\"api.custom-provider.com\",  # Hostname only\n    key=\"your-key\",\n    model=\"provider-model-name\"\n)\n</code></pre> <p>Check your provider's documentation for: - API endpoint URL - Authentication method - Supported models - Request/response format</p>"},{"location":"api/tools/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api/tools/#connection-errors","title":"Connection Errors","text":"<p>Problem: <code>RuntimeError: Model Response Error!</code></p> <p>Solutions: - Check your API URL is correct - Verify your API key is valid - Ensure network connectivity - Check provider status page</p>"},{"location":"api/tools/#timeout-errors","title":"Timeout Errors","text":"<p>Problem: Requests timing out</p> <p>Solutions: - Increase <code>timeout</code> parameter - Check network latency - Try a smaller model - Reduce prompt complexity</p>"},{"location":"api/tools/#rate-limiting","title":"Rate Limiting","text":"<p>Problem: Too many requests</p> <p>Solutions: - Add delays between requests - Reduce parallelism - Upgrade API tier - Implement exponential backoff</p>"},{"location":"api/tools/#next-steps","title":"Next Steps","text":"<ul> <li>See Core API for using LLMs with <code>evotoolkit.solve()</code></li> <li>Check Methods API for evolutionary algorithms</li> <li>Try the Scientific Regression Tutorial</li> </ul>"},{"location":"api/core/base-config/","title":"BaseConfig","text":"<p>Common parameters include:</p> <ul> <li><code>interface</code> (<code>BaseMethodInterface</code>): Task interface</li> <li><code>output_path</code> (<code>str</code>): Where to save results</li> <li><code>running_llm</code> (<code>HttpsApi</code>): LLM API instance</li> <li><code>max_generations</code> (<code>int</code>): Maximum generations</li> <li><code>pop_size</code> (<code>int</code>): Population size</li> </ul>"},{"location":"api/core/base-config/#evotoolkit.core.BaseConfig","title":"evotoolkit.core.BaseConfig","text":"<p>Base configuration class for evolutionary methods.</p> <p>Note: task is accessed via interface.task to avoid data redundancy.</p> Source code in <code>src/evotoolkit/core/base_config.py</code> <pre><code>class BaseConfig:\n    \"\"\"\n    Base configuration class for evolutionary methods.\n\n    Note: task is accessed via interface.task to avoid data redundancy.\n    \"\"\"\n\n    def __init__(self, interface: \"BaseMethodInterface\", output_path: str, verbose: bool = True):\n        self.interface = interface\n        self.output_path = output_path\n        self.verbose = verbose\n\n    @property\n    def task(self) -&gt; \"BaseTask\":\n        \"\"\"Access task through interface to avoid redundancy.\"\"\"\n        return self.interface.task\n</code></pre>"},{"location":"api/core/base-config/#evotoolkit.core.BaseConfig.task","title":"task  <code>property</code>","text":"<pre><code>task: BaseTask\n</code></pre> <p>Access task through interface to avoid redundancy.</p>"},{"location":"api/core/base-run-state-dict/","title":"BaseRunStateDict","text":""},{"location":"api/core/base-run-state-dict/#evotoolkit.core.BaseRunStateDict","title":"evotoolkit.core.BaseRunStateDict","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>src/evotoolkit/core/base_run_state_dict.py</code> <pre><code>class BaseRunStateDict(ABC):\n    def __init__(self, task_info: dict):\n        self.task_info = task_info\n        self._history_manager: Optional[HistoryManager] = None\n\n    @staticmethod\n    def _serialize_value(value):\n        \"\"\"Convert numpy arrays and other types to JSON-serializable format\"\"\"\n        if isinstance(value, np.ndarray):\n            return {\n                \"__numpy_array__\": True,\n                \"dtype\": str(value.dtype),\n                \"shape\": list(value.shape),\n                \"data\": value.tolist(),\n            }\n        elif isinstance(value, dict):\n            return {k: BaseRunStateDict._serialize_value(v) for k, v in value.items()}\n        elif isinstance(value, (list, tuple)):\n            return [BaseRunStateDict._serialize_value(item) for item in value]\n        elif isinstance(value, (np.integer, np.floating)):\n            return value.item()\n        else:\n            # Basic types (str, int, float, bool, None) pass through\n            # User-defined types will fail here - that's their responsibility\n            return value\n\n    @staticmethod\n    def _deserialize_value(value):\n        \"\"\"Convert serialized numpy arrays back to original format\"\"\"\n        if isinstance(value, dict):\n            if value.get(\"__numpy_array__\"):\n                return np.array(value[\"data\"], dtype=value[\"dtype\"]).reshape(value[\"shape\"])\n            else:\n                return {k: BaseRunStateDict._deserialize_value(v) for k, v in value.items()}\n        elif isinstance(value, list):\n            return [BaseRunStateDict._deserialize_value(item) for item in value]\n        else:\n            return value\n\n    @abstractmethod\n    def to_json(self) -&gt; dict:\n        \"\"\"Convert the run state to JSON-serializable dictionary\"\"\"\n        pass\n\n    @classmethod\n    @abstractmethod\n    def from_json(cls, data: dict) -&gt; \"BaseRunStateDict\":\n        \"\"\"Create instance from JSON data\"\"\"\n        pass\n\n    def to_json_file(self, file_path: str) -&gt; None:\n        \"\"\"Save the run state to a JSON file\"\"\"\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(self.to_json(), f, indent=2, ensure_ascii=False)\n\n    @classmethod\n    def from_json_file(cls, file_path: str) -&gt; \"BaseRunStateDict\":\n        \"\"\"Load instance from JSON file\"\"\"\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            data = json.load(f)\n        return cls.from_json(data)\n\n    def init_history_manager(self, output_path: str) -&gt; None:\n        \"\"\"\u521d\u59cb\u5316\u5386\u53f2\u7ba1\u7406\u5668\"\"\"\n        self._history_manager = HistoryManager(output_path)\n\n    @abstractmethod\n    def save_current_history(self) -&gt; None:\n        \"\"\"\u4fdd\u5b58\u5f53\u524d\u8fdb\u5ea6\u7684\u5386\u53f2\u8bb0\u5f55\uff08\u7531\u5b50\u7c7b\u5b9e\u73b0\u5177\u4f53\u903b\u8f91\uff09\"\"\"\n        pass\n</code></pre>"},{"location":"api/core/base-run-state-dict/#evotoolkit.core.BaseRunStateDict.to_json","title":"to_json  <code>abstractmethod</code>","text":"<pre><code>to_json() -&gt; dict\n</code></pre> <p>Convert the run state to JSON-serializable dictionary</p> Source code in <code>src/evotoolkit/core/base_run_state_dict.py</code> <pre><code>@abstractmethod\ndef to_json(self) -&gt; dict:\n    \"\"\"Convert the run state to JSON-serializable dictionary\"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base-run-state-dict/#evotoolkit.core.BaseRunStateDict.from_json","title":"from_json  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>from_json(data: dict) -&gt; BaseRunStateDict\n</code></pre> <p>Create instance from JSON data</p> Source code in <code>src/evotoolkit/core/base_run_state_dict.py</code> <pre><code>@classmethod\n@abstractmethod\ndef from_json(cls, data: dict) -&gt; \"BaseRunStateDict\":\n    \"\"\"Create instance from JSON data\"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base-run-state-dict/#evotoolkit.core.BaseRunStateDict.to_json_file","title":"to_json_file","text":"<pre><code>to_json_file(file_path: str) -&gt; None\n</code></pre> <p>Save the run state to a JSON file</p> Source code in <code>src/evotoolkit/core/base_run_state_dict.py</code> <pre><code>def to_json_file(self, file_path: str) -&gt; None:\n    \"\"\"Save the run state to a JSON file\"\"\"\n    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(self.to_json(), f, indent=2, ensure_ascii=False)\n</code></pre>"},{"location":"api/core/base-run-state-dict/#evotoolkit.core.BaseRunStateDict.from_json_file","title":"from_json_file  <code>classmethod</code>","text":"<pre><code>from_json_file(file_path: str) -&gt; BaseRunStateDict\n</code></pre> <p>Load instance from JSON file</p> Source code in <code>src/evotoolkit/core/base_run_state_dict.py</code> <pre><code>@classmethod\ndef from_json_file(cls, file_path: str) -&gt; \"BaseRunStateDict\":\n    \"\"\"Load instance from JSON file\"\"\"\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return cls.from_json(data)\n</code></pre>"},{"location":"api/core/base-run-state-dict/#evotoolkit.core.BaseRunStateDict.init_history_manager","title":"init_history_manager","text":"<pre><code>init_history_manager(output_path: str) -&gt; None\n</code></pre> <p>\u521d\u59cb\u5316\u5386\u53f2\u7ba1\u7406\u5668</p> Source code in <code>src/evotoolkit/core/base_run_state_dict.py</code> <pre><code>def init_history_manager(self, output_path: str) -&gt; None:\n    \"\"\"\u521d\u59cb\u5316\u5386\u53f2\u7ba1\u7406\u5668\"\"\"\n    self._history_manager = HistoryManager(output_path)\n</code></pre>"},{"location":"api/core/base-run-state-dict/#evotoolkit.core.BaseRunStateDict.save_current_history","title":"save_current_history  <code>abstractmethod</code>","text":"<pre><code>save_current_history() -&gt; None\n</code></pre> <p>\u4fdd\u5b58\u5f53\u524d\u8fdb\u5ea6\u7684\u5386\u53f2\u8bb0\u5f55\uff08\u7531\u5b50\u7c7b\u5b9e\u73b0\u5177\u4f53\u903b\u8f91\uff09</p> Source code in <code>src/evotoolkit/core/base_run_state_dict.py</code> <pre><code>@abstractmethod\ndef save_current_history(self) -&gt; None:\n    \"\"\"\u4fdd\u5b58\u5f53\u524d\u8fdb\u5ea6\u7684\u5386\u53f2\u8bb0\u5f55\uff08\u7531\u5b50\u7c7b\u5b9e\u73b0\u5177\u4f53\u903b\u8f91\uff09\"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base-task/","title":"BaseTask","text":"<p>See the Custom Task Tutorial for a complete guide.</p>"},{"location":"api/core/base-task/#evotoolkit.core.BaseTask","title":"evotoolkit.core.BaseTask","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for evolutionary optimization tasks.</p> <p>This class unifies the functionality of BaseEvaluator and BaseTaskConfig into a single concept, providing both evaluation capabilities and task configuration in one place.</p> Source code in <code>src/evotoolkit/core/base_task.py</code> <pre><code>class BaseTask(ABC):\n    \"\"\"\n    Abstract base class for evolutionary optimization tasks.\n\n    This class unifies the functionality of BaseEvaluator and BaseTaskConfig\n    into a single concept, providing both evaluation capabilities and task\n    configuration in one place.\n    \"\"\"\n\n    def __init__(self, data):\n        \"\"\"\n        Initialize the task with input data.\n\n        Args:\n            data (Any): Task-specific input data (format varies by task type).\n        \"\"\"\n        self._process_data(data)\n\n    def _process_data(self, data):\n        \"\"\"\n        Process input data and set up task_info.\n\n        This method should be overridden by subclasses to handle\n        task-specific data processing and create the task_info dict.\n\n        Args:\n            data (Any): Task-specific input data.\n        \"\"\"\n        self.data = data\n        self.task_info = {}  # Subclasses should populate this\n\n    # === Abstract methods from BaseEvaluator ===\n\n    @abstractmethod\n    def evaluate_code(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"\n        Evaluate a candidate code solution and return evaluation result.\n\n        This is the simple interface for tasks that only need a code string.\n        For tasks requiring additional information, override evaluate_solution().\n\n        Args:\n            candidate_code: The code to evaluate\n\n        Returns:\n            EvaluationResult: Result of the evaluation\n        \"\"\"\n        pass\n\n    def evaluate_solution(self, solution: Solution) -&gt; EvaluationResult:\n        \"\"\"\n        Evaluate a Solution object and return evaluation result.\n\n        This method provides a richer interface for complex tasks that need\n        additional information beyond just code. The Solution object can carry:\n        - sol_string: The main code (e.g., kernel source)\n        - other_info: Additional metadata (e.g., tiling config, block_dim)\n\n        Default implementation simply calls evaluate_code(solution.sol_string).\n        Complex tasks (e.g., CANN) should override this method to extract\n        additional information from solution.other_info.\n\n        Args:\n            solution: Solution object containing code and optional metadata\n\n        Returns:\n            EvaluationResult: Result of the evaluation\n        \"\"\"\n        return self.evaluate_code(solution.sol_string)\n\n    # === Abstract methods from BaseTaskConfig ===\n\n    @abstractmethod\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"\n        Get the base task description for prompt generation.\n\n        Returns:\n            str: Task description text\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"\n        Create initial solution from task info without other_info.\n\n        Returns:\n            Solution: Initial solution for this task\n        \"\"\"\n        pass\n\n    # === Optional methods that subclasses can override ===\n\n    def get_task_type(self) -&gt; str:\n        \"\"\"\n        Get the type of this task (e.g., 'Python', 'Cuda').\n\n        Default implementation returns 'Python'. Subclasses should\n        override if they represent different task types.\n\n        Returns:\n            str: Task type identifier\n        \"\"\"\n        return \"Python\"\n\n    def get_task_info(self) -&gt; dict:\n        \"\"\"\n        Get the task_info dictionary.\n\n        Returns:\n            dict: Task information dictionary\n        \"\"\"\n        return self.task_info\n</code></pre>"},{"location":"api/core/base-task/#evotoolkit.core.BaseTask.__init__","title":"__init__","text":"<pre><code>__init__(data)\n</code></pre> <p>Initialize the task with input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Task-specific input data (format varies by task type).</p> required Source code in <code>src/evotoolkit/core/base_task.py</code> <pre><code>def __init__(self, data):\n    \"\"\"\n    Initialize the task with input data.\n\n    Args:\n        data (Any): Task-specific input data (format varies by task type).\n    \"\"\"\n    self._process_data(data)\n</code></pre>"},{"location":"api/core/base-task/#evotoolkit.core.BaseTask.evaluate_code","title":"evaluate_code  <code>abstractmethod</code>","text":"<pre><code>evaluate_code(candidate_code: str) -&gt; EvaluationResult\n</code></pre> <p>Evaluate a candidate code solution and return evaluation result.</p> <p>This is the simple interface for tasks that only need a code string. For tasks requiring additional information, override evaluate_solution().</p> <p>Parameters:</p> Name Type Description Default <code>candidate_code</code> <code>str</code> <p>The code to evaluate</p> required <p>Returns:</p> Name Type Description <code>EvaluationResult</code> <code>EvaluationResult</code> <p>Result of the evaluation</p> Source code in <code>src/evotoolkit/core/base_task.py</code> <pre><code>@abstractmethod\ndef evaluate_code(self, candidate_code: str) -&gt; EvaluationResult:\n    \"\"\"\n    Evaluate a candidate code solution and return evaluation result.\n\n    This is the simple interface for tasks that only need a code string.\n    For tasks requiring additional information, override evaluate_solution().\n\n    Args:\n        candidate_code: The code to evaluate\n\n    Returns:\n        EvaluationResult: Result of the evaluation\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base-task/#evotoolkit.core.BaseTask.evaluate_solution","title":"evaluate_solution","text":"<pre><code>evaluate_solution(solution: Solution) -&gt; EvaluationResult\n</code></pre> <p>Evaluate a Solution object and return evaluation result.</p> <p>This method provides a richer interface for complex tasks that need additional information beyond just code. The Solution object can carry: - sol_string: The main code (e.g., kernel source) - other_info: Additional metadata (e.g., tiling config, block_dim)</p> <p>Default implementation simply calls evaluate_code(solution.sol_string). Complex tasks (e.g., CANN) should override this method to extract additional information from solution.other_info.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>Solution object containing code and optional metadata</p> required <p>Returns:</p> Name Type Description <code>EvaluationResult</code> <code>EvaluationResult</code> <p>Result of the evaluation</p> Source code in <code>src/evotoolkit/core/base_task.py</code> <pre><code>def evaluate_solution(self, solution: Solution) -&gt; EvaluationResult:\n    \"\"\"\n    Evaluate a Solution object and return evaluation result.\n\n    This method provides a richer interface for complex tasks that need\n    additional information beyond just code. The Solution object can carry:\n    - sol_string: The main code (e.g., kernel source)\n    - other_info: Additional metadata (e.g., tiling config, block_dim)\n\n    Default implementation simply calls evaluate_code(solution.sol_string).\n    Complex tasks (e.g., CANN) should override this method to extract\n    additional information from solution.other_info.\n\n    Args:\n        solution: Solution object containing code and optional metadata\n\n    Returns:\n        EvaluationResult: Result of the evaluation\n    \"\"\"\n    return self.evaluate_code(solution.sol_string)\n</code></pre>"},{"location":"api/core/base-task/#evotoolkit.core.BaseTask.get_base_task_description","title":"get_base_task_description  <code>abstractmethod</code>","text":"<pre><code>get_base_task_description() -&gt; str\n</code></pre> <p>Get the base task description for prompt generation.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Task description text</p> Source code in <code>src/evotoolkit/core/base_task.py</code> <pre><code>@abstractmethod\ndef get_base_task_description(self) -&gt; str:\n    \"\"\"\n    Get the base task description for prompt generation.\n\n    Returns:\n        str: Task description text\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base-task/#evotoolkit.core.BaseTask.make_init_sol_wo_other_info","title":"make_init_sol_wo_other_info  <code>abstractmethod</code>","text":"<pre><code>make_init_sol_wo_other_info() -&gt; Solution\n</code></pre> <p>Create initial solution from task info without other_info.</p> <p>Returns:</p> Name Type Description <code>Solution</code> <code>Solution</code> <p>Initial solution for this task</p> Source code in <code>src/evotoolkit/core/base_task.py</code> <pre><code>@abstractmethod\ndef make_init_sol_wo_other_info(self) -&gt; Solution:\n    \"\"\"\n    Create initial solution from task info without other_info.\n\n    Returns:\n        Solution: Initial solution for this task\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base-task/#evotoolkit.core.BaseTask.get_task_type","title":"get_task_type","text":"<pre><code>get_task_type() -&gt; str\n</code></pre> <p>Get the type of this task (e.g., 'Python', 'Cuda').</p> <p>Default implementation returns 'Python'. Subclasses should override if they represent different task types.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Task type identifier</p> Source code in <code>src/evotoolkit/core/base_task.py</code> <pre><code>def get_task_type(self) -&gt; str:\n    \"\"\"\n    Get the type of this task (e.g., 'Python', 'Cuda').\n\n    Default implementation returns 'Python'. Subclasses should\n    override if they represent different task types.\n\n    Returns:\n        str: Task type identifier\n    \"\"\"\n    return \"Python\"\n</code></pre>"},{"location":"api/core/base-task/#evotoolkit.core.BaseTask.get_task_info","title":"get_task_info","text":"<pre><code>get_task_info() -&gt; dict\n</code></pre> <p>Get the task_info dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Task information dictionary</p> Source code in <code>src/evotoolkit/core/base_task.py</code> <pre><code>def get_task_info(self) -&gt; dict:\n    \"\"\"\n    Get the task_info dictionary.\n\n    Returns:\n        dict: Task information dictionary\n    \"\"\"\n    return self.task_info\n</code></pre>"},{"location":"api/core/history-manager/","title":"HistoryManager","text":""},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager","title":"evotoolkit.core.HistoryManager","text":"<p>\u7ba1\u7406\u8fdb\u5316\u7b97\u6cd5\u8fd0\u884c\u5386\u53f2\u7684\u4fdd\u5b58\u548c\u52a0\u8f7d</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>class HistoryManager:\n    \"\"\"\u7ba1\u7406\u8fdb\u5316\u7b97\u6cd5\u8fd0\u884c\u5386\u53f2\u7684\u4fdd\u5b58\u548c\u52a0\u8f7d\"\"\"\n\n    def __init__(self, output_path: str):\n        self.output_path = output_path\n        self.history_dir = os.path.join(output_path, \"history\")\n        self.summary_dir = os.path.join(output_path, \"summary\")\n\n        # \u786e\u4fdd\u76ee\u5f55\u5b58\u5728\n        os.makedirs(self.history_dir, exist_ok=True)\n        os.makedirs(self.summary_dir, exist_ok=True)\n\n    # ========== By-Generation Methods ==========\n\n    def save_generation_history(\n        self,\n        generation: int,\n        solutions: List[Solution],\n        usage: List[Dict],\n        statistics: Optional[Dict] = None,\n    ) -&gt; None:\n        \"\"\"\u4fdd\u5b58\u67d0\u4e00\u4ee3\u7684\u5386\u53f2\u8bb0\u5f55\"\"\"\n        gen_file = os.path.join(self.history_dir, f\"gen_{generation}.json\")\n\n        # \u8f6c\u6362Solution\u5bf9\u8c61\u4e3a\u5b57\u5178\n        solutions_json = []\n        for sol in solutions:\n            sol_dict = {\n                \"sol_string\": sol.sol_string,\n                \"other_info\": sol.other_info,\n                \"evaluation_res\": None,\n            }\n            if sol.evaluation_res:\n                sol_dict[\"evaluation_res\"] = {\n                    \"valid\": sol.evaluation_res.valid,\n                    \"score\": sol.evaluation_res.score,\n                    \"additional_info\": sol.evaluation_res.additional_info,\n                }\n            solutions_json.append(sol_dict)\n\n        data = {\n            \"generation\": generation,\n            \"solutions\": solutions_json,\n            \"usage\": usage,\n            \"statistics\": statistics or {},\n        }\n\n        with open(gen_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(data, f, indent=2, ensure_ascii=False)\n\n    def load_generation_history(self, generation: int) -&gt; Optional[Dict]:\n        \"\"\"\u52a0\u8f7d\u67d0\u4e00\u4ee3\u7684\u5386\u53f2\u8bb0\u5f55\"\"\"\n        gen_file = os.path.join(self.history_dir, f\"gen_{generation}.json\")\n        if not os.path.exists(gen_file):\n            return None\n\n        with open(gen_file, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n\n    def get_all_generations(self) -&gt; List[int]:\n        \"\"\"\u83b7\u53d6\u6240\u6709\u5df2\u4fdd\u5b58\u7684\u4ee3\u6570\"\"\"\n        generations = []\n        if not os.path.exists(self.history_dir):\n            return generations\n\n        for filename in os.listdir(self.history_dir):\n            if filename.startswith(\"gen_\") and filename.endswith(\".json\"):\n                try:\n                    gen = int(filename.replace(\"gen_\", \"\").replace(\".json\", \"\"))\n                    generations.append(gen)\n                except ValueError:\n                    continue\n\n        return sorted(generations)\n\n    # ========== By-Batch Methods ==========\n\n    def save_batch_history(\n        self,\n        batch_id: int,\n        sample_range: tuple,\n        solutions: List[Solution],\n        usage: List[Dict],\n        metadata: Optional[Dict] = None,\n    ) -&gt; None:\n        \"\"\"\u4fdd\u5b58\u6279\u6b21\u5386\u53f2\u8bb0\u5f55\uff08\u7528\u4e8eFunSearch\u7b49\uff09\"\"\"\n        batch_file = os.path.join(self.history_dir, f\"batch_{batch_id:04d}.json\")\n\n        # \u8f6c\u6362Solution\u5bf9\u8c61\u4e3a\u5b57\u5178\n        solutions_json = []\n        for sol in solutions:\n            sol_dict = {\n                \"sol_string\": sol.sol_string,\n                \"other_info\": sol.other_info,\n                \"evaluation_res\": None,\n            }\n            if sol.evaluation_res:\n                sol_dict[\"evaluation_res\"] = {\n                    \"valid\": sol.evaluation_res.valid,\n                    \"score\": sol.evaluation_res.score,\n                    \"additional_info\": sol.evaluation_res.additional_info,\n                }\n            solutions_json.append(sol_dict)\n\n        data = {\n            \"batch_id\": batch_id,\n            \"sample_range\": sample_range,\n            \"solutions\": solutions_json,\n            \"usage\": usage,\n            \"metadata\": metadata or {},\n        }\n\n        with open(batch_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(data, f, indent=2, ensure_ascii=False)\n\n    def load_batch_history(self, batch_id: int) -&gt; Optional[Dict]:\n        \"\"\"\u52a0\u8f7d\u6279\u6b21\u5386\u53f2\u8bb0\u5f55\"\"\"\n        batch_file = os.path.join(self.history_dir, f\"batch_{batch_id:04d}.json\")\n        if not os.path.exists(batch_file):\n            return None\n\n        with open(batch_file, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n\n    def get_all_batches(self) -&gt; List[int]:\n        \"\"\"\u83b7\u53d6\u6240\u6709\u5df2\u4fdd\u5b58\u7684\u6279\u6b21\"\"\"\n        batches = []\n        if not os.path.exists(self.history_dir):\n            return batches\n\n        for filename in os.listdir(self.history_dir):\n            if filename.startswith(\"batch_\") and filename.endswith(\".json\"):\n                try:\n                    batch = int(filename.replace(\"batch_\", \"\").replace(\".json\", \"\"))\n                    batches.append(batch)\n                except ValueError:\n                    continue\n\n        return sorted(batches)\n\n    # ========== Summary Methods ==========\n\n    def save_usage_history(self, usage_history: Dict) -&gt; None:\n        \"\"\"\u4fdd\u5b58\u5b8c\u6574\u7684usage\u5386\u53f2\"\"\"\n        usage_file = os.path.join(self.summary_dir, \"usage_history.json\")\n        with open(usage_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(usage_history, f, indent=2, ensure_ascii=False)\n\n    def load_usage_history(self) -&gt; Dict:\n        \"\"\"\u52a0\u8f7dusage\u5386\u53f2\"\"\"\n        usage_file = os.path.join(self.summary_dir, \"usage_history.json\")\n        if not os.path.exists(usage_file):\n            return {}\n\n        with open(usage_file, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n\n    def save_best_per_generation(self, best_solutions: List[Dict]) -&gt; None:\n        \"\"\"\u4fdd\u5b58\u6bcf\u4ee3\u6700\u4f18\u89e3\u6458\u8981\"\"\"\n        best_file = os.path.join(self.summary_dir, \"best_per_generation.json\")\n        with open(best_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(best_solutions, f, indent=2, ensure_ascii=False)\n\n    def load_best_per_generation(self) -&gt; List[Dict]:\n        \"\"\"\u52a0\u8f7d\u6bcf\u4ee3\u6700\u4f18\u89e3\u6458\u8981\"\"\"\n        best_file = os.path.join(self.summary_dir, \"best_per_generation.json\")\n        if not os.path.exists(best_file):\n            return []\n\n        with open(best_file, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.save_generation_history","title":"save_generation_history","text":"<pre><code>save_generation_history(\n    generation: int,\n    solutions: List[Solution],\n    usage: List[Dict],\n    statistics: Optional[Dict] = None,\n) -&gt; None\n</code></pre> <p>\u4fdd\u5b58\u67d0\u4e00\u4ee3\u7684\u5386\u53f2\u8bb0\u5f55</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def save_generation_history(\n    self,\n    generation: int,\n    solutions: List[Solution],\n    usage: List[Dict],\n    statistics: Optional[Dict] = None,\n) -&gt; None:\n    \"\"\"\u4fdd\u5b58\u67d0\u4e00\u4ee3\u7684\u5386\u53f2\u8bb0\u5f55\"\"\"\n    gen_file = os.path.join(self.history_dir, f\"gen_{generation}.json\")\n\n    # \u8f6c\u6362Solution\u5bf9\u8c61\u4e3a\u5b57\u5178\n    solutions_json = []\n    for sol in solutions:\n        sol_dict = {\n            \"sol_string\": sol.sol_string,\n            \"other_info\": sol.other_info,\n            \"evaluation_res\": None,\n        }\n        if sol.evaluation_res:\n            sol_dict[\"evaluation_res\"] = {\n                \"valid\": sol.evaluation_res.valid,\n                \"score\": sol.evaluation_res.score,\n                \"additional_info\": sol.evaluation_res.additional_info,\n            }\n        solutions_json.append(sol_dict)\n\n    data = {\n        \"generation\": generation,\n        \"solutions\": solutions_json,\n        \"usage\": usage,\n        \"statistics\": statistics or {},\n    }\n\n    with open(gen_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(data, f, indent=2, ensure_ascii=False)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.load_generation_history","title":"load_generation_history","text":"<pre><code>load_generation_history(generation: int) -&gt; Optional[Dict]\n</code></pre> <p>\u52a0\u8f7d\u67d0\u4e00\u4ee3\u7684\u5386\u53f2\u8bb0\u5f55</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def load_generation_history(self, generation: int) -&gt; Optional[Dict]:\n    \"\"\"\u52a0\u8f7d\u67d0\u4e00\u4ee3\u7684\u5386\u53f2\u8bb0\u5f55\"\"\"\n    gen_file = os.path.join(self.history_dir, f\"gen_{generation}.json\")\n    if not os.path.exists(gen_file):\n        return None\n\n    with open(gen_file, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.get_all_generations","title":"get_all_generations","text":"<pre><code>get_all_generations() -&gt; List[int]\n</code></pre> <p>\u83b7\u53d6\u6240\u6709\u5df2\u4fdd\u5b58\u7684\u4ee3\u6570</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def get_all_generations(self) -&gt; List[int]:\n    \"\"\"\u83b7\u53d6\u6240\u6709\u5df2\u4fdd\u5b58\u7684\u4ee3\u6570\"\"\"\n    generations = []\n    if not os.path.exists(self.history_dir):\n        return generations\n\n    for filename in os.listdir(self.history_dir):\n        if filename.startswith(\"gen_\") and filename.endswith(\".json\"):\n            try:\n                gen = int(filename.replace(\"gen_\", \"\").replace(\".json\", \"\"))\n                generations.append(gen)\n            except ValueError:\n                continue\n\n    return sorted(generations)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.save_batch_history","title":"save_batch_history","text":"<pre><code>save_batch_history(\n    batch_id: int,\n    sample_range: tuple,\n    solutions: List[Solution],\n    usage: List[Dict],\n    metadata: Optional[Dict] = None,\n) -&gt; None\n</code></pre> <p>\u4fdd\u5b58\u6279\u6b21\u5386\u53f2\u8bb0\u5f55\uff08\u7528\u4e8eFunSearch\u7b49\uff09</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def save_batch_history(\n    self,\n    batch_id: int,\n    sample_range: tuple,\n    solutions: List[Solution],\n    usage: List[Dict],\n    metadata: Optional[Dict] = None,\n) -&gt; None:\n    \"\"\"\u4fdd\u5b58\u6279\u6b21\u5386\u53f2\u8bb0\u5f55\uff08\u7528\u4e8eFunSearch\u7b49\uff09\"\"\"\n    batch_file = os.path.join(self.history_dir, f\"batch_{batch_id:04d}.json\")\n\n    # \u8f6c\u6362Solution\u5bf9\u8c61\u4e3a\u5b57\u5178\n    solutions_json = []\n    for sol in solutions:\n        sol_dict = {\n            \"sol_string\": sol.sol_string,\n            \"other_info\": sol.other_info,\n            \"evaluation_res\": None,\n        }\n        if sol.evaluation_res:\n            sol_dict[\"evaluation_res\"] = {\n                \"valid\": sol.evaluation_res.valid,\n                \"score\": sol.evaluation_res.score,\n                \"additional_info\": sol.evaluation_res.additional_info,\n            }\n        solutions_json.append(sol_dict)\n\n    data = {\n        \"batch_id\": batch_id,\n        \"sample_range\": sample_range,\n        \"solutions\": solutions_json,\n        \"usage\": usage,\n        \"metadata\": metadata or {},\n    }\n\n    with open(batch_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(data, f, indent=2, ensure_ascii=False)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.load_batch_history","title":"load_batch_history","text":"<pre><code>load_batch_history(batch_id: int) -&gt; Optional[Dict]\n</code></pre> <p>\u52a0\u8f7d\u6279\u6b21\u5386\u53f2\u8bb0\u5f55</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def load_batch_history(self, batch_id: int) -&gt; Optional[Dict]:\n    \"\"\"\u52a0\u8f7d\u6279\u6b21\u5386\u53f2\u8bb0\u5f55\"\"\"\n    batch_file = os.path.join(self.history_dir, f\"batch_{batch_id:04d}.json\")\n    if not os.path.exists(batch_file):\n        return None\n\n    with open(batch_file, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.get_all_batches","title":"get_all_batches","text":"<pre><code>get_all_batches() -&gt; List[int]\n</code></pre> <p>\u83b7\u53d6\u6240\u6709\u5df2\u4fdd\u5b58\u7684\u6279\u6b21</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def get_all_batches(self) -&gt; List[int]:\n    \"\"\"\u83b7\u53d6\u6240\u6709\u5df2\u4fdd\u5b58\u7684\u6279\u6b21\"\"\"\n    batches = []\n    if not os.path.exists(self.history_dir):\n        return batches\n\n    for filename in os.listdir(self.history_dir):\n        if filename.startswith(\"batch_\") and filename.endswith(\".json\"):\n            try:\n                batch = int(filename.replace(\"batch_\", \"\").replace(\".json\", \"\"))\n                batches.append(batch)\n            except ValueError:\n                continue\n\n    return sorted(batches)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.save_usage_history","title":"save_usage_history","text":"<pre><code>save_usage_history(usage_history: Dict) -&gt; None\n</code></pre> <p>\u4fdd\u5b58\u5b8c\u6574\u7684usage\u5386\u53f2</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def save_usage_history(self, usage_history: Dict) -&gt; None:\n    \"\"\"\u4fdd\u5b58\u5b8c\u6574\u7684usage\u5386\u53f2\"\"\"\n    usage_file = os.path.join(self.summary_dir, \"usage_history.json\")\n    with open(usage_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(usage_history, f, indent=2, ensure_ascii=False)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.load_usage_history","title":"load_usage_history","text":"<pre><code>load_usage_history() -&gt; Dict\n</code></pre> <p>\u52a0\u8f7dusage\u5386\u53f2</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def load_usage_history(self) -&gt; Dict:\n    \"\"\"\u52a0\u8f7dusage\u5386\u53f2\"\"\"\n    usage_file = os.path.join(self.summary_dir, \"usage_history.json\")\n    if not os.path.exists(usage_file):\n        return {}\n\n    with open(usage_file, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.save_best_per_generation","title":"save_best_per_generation","text":"<pre><code>save_best_per_generation(\n    best_solutions: List[Dict],\n) -&gt; None\n</code></pre> <p>\u4fdd\u5b58\u6bcf\u4ee3\u6700\u4f18\u89e3\u6458\u8981</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def save_best_per_generation(self, best_solutions: List[Dict]) -&gt; None:\n    \"\"\"\u4fdd\u5b58\u6bcf\u4ee3\u6700\u4f18\u89e3\u6458\u8981\"\"\"\n    best_file = os.path.join(self.summary_dir, \"best_per_generation.json\")\n    with open(best_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(best_solutions, f, indent=2, ensure_ascii=False)\n</code></pre>"},{"location":"api/core/history-manager/#evotoolkit.core.HistoryManager.load_best_per_generation","title":"load_best_per_generation","text":"<pre><code>load_best_per_generation() -&gt; List[Dict]\n</code></pre> <p>\u52a0\u8f7d\u6bcf\u4ee3\u6700\u4f18\u89e3\u6458\u8981</p> Source code in <code>src/evotoolkit/core/history_manager.py</code> <pre><code>def load_best_per_generation(self) -&gt; List[Dict]:\n    \"\"\"\u52a0\u8f7d\u6bcf\u4ee3\u6700\u4f18\u89e3\u6458\u8981\"\"\"\n    best_file = os.path.join(self.summary_dir, \"best_per_generation.json\")\n    if not os.path.exists(best_file):\n        return []\n\n    with open(best_file, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"api/core/list-algorithms/","title":"evotoolkit.list_algorithms()","text":""},{"location":"api/core/list-algorithms/#evotoolkit.list_algorithms","title":"evotoolkit.list_algorithms","text":"<pre><code>list_algorithms() -&gt; list[str]\n</code></pre> <p>List all registered algorithm names.</p> Source code in <code>src/evotoolkit/registry.py</code> <pre><code>def list_algorithms() -&gt; list[str]:\n    \"\"\"List all registered algorithm names.\"\"\"\n    return list(_ALGORITHM_REGISTRY.keys())\n</code></pre>"},{"location":"api/core/list-algorithms/#example","title":"Example","text":"<pre><code>import evotoolkit\n\nalgorithms = evotoolkit.list_algorithms()\nfor algo in algorithms:\n    print(f\"- {algo}\")\n</code></pre>"},{"location":"api/core/list-tasks/","title":"evotoolkit.list_tasks()","text":""},{"location":"api/core/list-tasks/#evotoolkit.list_tasks","title":"evotoolkit.list_tasks","text":"<pre><code>list_tasks() -&gt; list[str]\n</code></pre> <p>List all registered task names.</p> Source code in <code>src/evotoolkit/registry.py</code> <pre><code>def list_tasks() -&gt; list[str]:\n    \"\"\"List all registered task names.\"\"\"\n    return list(_TASK_REGISTRY.keys())\n</code></pre>"},{"location":"api/core/list-tasks/#example","title":"Example","text":"<pre><code>import evotoolkit\n\ntasks = evotoolkit.list_tasks()\nfor task in tasks:\n    print(f\"- {task}\")\n</code></pre>"},{"location":"api/core/method/","title":"Method","text":"<p>If you're implementing a custom evolutionary algorithm, extend <code>Method</code>:</p> <pre><code>from evotoolkit.core import Method, BaseConfig\n\nclass MyCustomAlgorithm(Method):\n    def run(self):\n        for generation in range(self.config.max_generations):\n            # Generate, evaluate, select\n            pass\n</code></pre>"},{"location":"api/core/method/#evotoolkit.core.Method","title":"evotoolkit.core.Method","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>src/evotoolkit/core/base_method.py</code> <pre><code>class Method(ABC):\n    def __init__(self, config: BaseConfig):\n        self.config = config\n        self.run_state_dict = self._load_run_state_dict()\n        # \u521d\u59cb\u5316\u5386\u53f2\u7ba1\u7406\u5668\n        self.run_state_dict.init_history_manager(self.config.output_path)\n        self._save_run_state_dict()\n\n    def _get_init_sol(self):\n        # Try to create and evaluate initial solution up to 3 times\n        initial_sol = None\n        for attempt in range(3):\n            try:\n                candidate_sol = self.config.interface.make_init_sol()\n                if candidate_sol.evaluation_res is None:\n                    candidate_sol.evaluation_res = self.config.task.evaluate_code(candidate_sol.sol_string)\n\n                if candidate_sol.evaluation_res is not None and candidate_sol.evaluation_res.valid:\n                    if (not np.isinf(candidate_sol.evaluation_res.score)) and (candidate_sol.evaluation_res.score &gt; -np.inf):\n                        initial_sol = candidate_sol\n                        break\n                else:\n                    self.verbose_info(f\"Initial solution attempt {attempt + 1} failed: invalid evaluation result\")\n            except Exception as e:\n                self.verbose_info(f\"Initial solution attempt {attempt + 1} failed with exception: {e}\")\n\n        if initial_sol is None:\n            print(\"Warning: Failed to create valid initial solution after 3 attempts. Exiting.\")\n        return initial_sol\n\n    @abstractmethod\n    def run(self, *args):\n        raise NotImplementedError()\n\n    def verbose_info(self, message: str):\n        if self.config.verbose:\n            print(message)\n\n    def verbose_title(self, text: str, total_width: int = 60):\n        \"\"\"Display a centered title with equal signs above and below\"\"\"\n        if self.config.verbose:\n            print(\"=\" * total_width)\n            print(text.center(total_width))\n            print(\"=\" * total_width)\n\n    def verbose_stage(self, text: str, total_width: int = 60):\n        \"\"\"Display a stage separator with dashes\"\"\"\n        if self.config.verbose:\n            print(\"-\" * total_width)\n            print(text.center(total_width))\n            print(\"-\" * total_width)\n\n    def verbose_gen(self, text: str, total_width: int = 60):\n        \"\"\"Display text centered with dashes on both sides\"\"\"\n        if self.config.verbose:\n            padding = (total_width - len(text)) // 2\n            left_dashes = \"-\" * padding\n            right_dashes = \"-\" * (total_width - len(text) - padding)\n            print(left_dashes + text + right_dashes)\n\n    def _save_run_state_dict(self):\n        \"\"\"Save run state to file and history\"\"\"\n        # \u5148\u4fdd\u5b58\u5386\u53f2\n        self.run_state_dict.save_current_history()\n        # \u518d\u4fdd\u5b58\u5f53\u524d\u72b6\u6001\n        self.run_state_dict.to_json_file(os.path.join(self.config.output_path, \"run_state.json\"))\n\n    def _load_run_state_dict(self) -&gt; BaseRunStateDict | None:\n        \"\"\"Load run state from file\"\"\"\n        run_state_class = self._get_run_state_class()\n        if os.path.exists(os.path.join(self.config.output_path, \"run_state.json\")):\n            self.verbose_info(f\"Loading run state from file {os.path.join(self.config.output_path, 'run_state.json')}\")\n            return run_state_class.from_json_file(os.path.join(self.config.output_path, \"run_state.json\"))\n        else:\n            run_state_dict = run_state_class(self.config.task.task_info)\n            self.verbose_info(\"Initialized run state dict.\")\n            return run_state_dict\n\n    @staticmethod\n    def _get_best_valid_sol(sol_list: List[Solution]):\n        valid_sols = []\n        for sol in sol_list:\n            if sol.evaluation_res is not None:\n                if sol.evaluation_res.valid:\n                    valid_sols.append(sol)\n\n        # Return the kernel with minimum runtime\n        best_kernel = max(valid_sols, key=lambda x: x.evaluation_res.score)\n        return best_kernel\n\n    @staticmethod\n    def _get_best_sol(sol_list: List[Solution]):\n        best_valid_sol = Method._get_best_valid_sol(sol_list)\n        if best_valid_sol is not None:\n            best_sol = best_valid_sol\n        else:\n            best_sol = sol_list[0]\n        return best_sol\n\n    @abstractmethod\n    def _get_run_state_class(self) -&gt; Type[BaseRunStateDict]:\n        \"\"\"Return the algorithm-specific RunStateDict class\"\"\"\n        pass\n</code></pre>"},{"location":"api/core/method/#evotoolkit.core.Method.verbose_title","title":"verbose_title","text":"<pre><code>verbose_title(text: str, total_width: int = 60)\n</code></pre> <p>Display a centered title with equal signs above and below</p> Source code in <code>src/evotoolkit/core/base_method.py</code> <pre><code>def verbose_title(self, text: str, total_width: int = 60):\n    \"\"\"Display a centered title with equal signs above and below\"\"\"\n    if self.config.verbose:\n        print(\"=\" * total_width)\n        print(text.center(total_width))\n        print(\"=\" * total_width)\n</code></pre>"},{"location":"api/core/method/#evotoolkit.core.Method.verbose_stage","title":"verbose_stage","text":"<pre><code>verbose_stage(text: str, total_width: int = 60)\n</code></pre> <p>Display a stage separator with dashes</p> Source code in <code>src/evotoolkit/core/base_method.py</code> <pre><code>def verbose_stage(self, text: str, total_width: int = 60):\n    \"\"\"Display a stage separator with dashes\"\"\"\n    if self.config.verbose:\n        print(\"-\" * total_width)\n        print(text.center(total_width))\n        print(\"-\" * total_width)\n</code></pre>"},{"location":"api/core/method/#evotoolkit.core.Method.verbose_gen","title":"verbose_gen","text":"<pre><code>verbose_gen(text: str, total_width: int = 60)\n</code></pre> <p>Display text centered with dashes on both sides</p> Source code in <code>src/evotoolkit/core/base_method.py</code> <pre><code>def verbose_gen(self, text: str, total_width: int = 60):\n    \"\"\"Display text centered with dashes on both sides\"\"\"\n    if self.config.verbose:\n        padding = (total_width - len(text)) // 2\n        left_dashes = \"-\" * padding\n        right_dashes = \"-\" * (total_width - len(text) - padding)\n        print(left_dashes + text + right_dashes)\n</code></pre>"},{"location":"api/core/operators/","title":"Operator","text":""},{"location":"api/core/operators/#evotoolkit.core.Operator","title":"evotoolkit.core.Operator","text":"<p>Simple operator class with name and selection size.</p> Source code in <code>src/evotoolkit/core/operator.py</code> <pre><code>class Operator:\n    \"\"\"Simple operator class with name and selection size.\"\"\"\n\n    def __init__(self, name: str, selection_size: int = 0):\n        self.name = name\n        self.selection_size = selection_size\n</code></pre>"},{"location":"api/core/solution/","title":"Solution","text":""},{"location":"api/core/solution/#evotoolkit.core.Solution","title":"evotoolkit.core.Solution","text":"<p>Represents a candidate solution in the evolutionary process.</p> Source code in <code>src/evotoolkit/core/solution.py</code> <pre><code>class Solution:\n    \"\"\"Represents a candidate solution in the evolutionary process.\"\"\"\n\n    def __init__(\n        self,\n        sol_string,\n        other_info: dict = None,\n        evaluation_res: EvaluationResult = None,\n    ):\n        self.sol_string = sol_string\n        self.other_info = other_info\n        self.evaluation_res = evaluation_res\n</code></pre>"},{"location":"api/core/solution/#example","title":"Example","text":"<pre><code>from evotoolkit.core import Solution, EvaluationResult\n\neval_res = EvaluationResult(valid=True, score=0.95, additional_info={\"generation\": 3})\nsolution = Solution(\n    sol_string=\"def f(x): return x**2\",\n    evaluation_res=eval_res,\n    other_info={\"method\": \"mutation\"}\n)\n\nprint(solution.sol_string)\nprint(f\"Score: {solution.evaluation_res.score}\")\n</code></pre>"},{"location":"api/core/solve/","title":"evotoolkit.solve()","text":""},{"location":"api/core/solve/#evotoolkit.solve","title":"evotoolkit.solve","text":"<pre><code>solve(\n    interface: BaseMethodInterface,\n    output_path: str = \"./results\",\n    **kwargs,\n) -&gt; Any\n</code></pre> <p>Factory method to create and run an evolutionary optimization workflow.</p> <p>This is the main entry point for using evotool with an explicit, unambiguous API. Users must explicitly create task and interface instances before calling solve().</p> <p>Parameters:</p> Name Type Description Default <code>interface</code> <code>BaseMethodInterface</code> <p>Interface instance (e.g., <code>EoHPythonInterface</code>, <code>EvoEngineerPythonInterface</code>). Must be explicitly created with a task instance. The algorithm is automatically inferred from the interface type.</p> required <code>output_path</code> <code>str</code> <p>Path to save results.</p> <code>'./results'</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters passed to algorithm config (e.g., <code>max_generations</code>, <code>max_sample_nums</code>, <code>pop_size</code>, <code>running_llm</code>).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Best solution found during the evolutionary optimization run.</p> Example Source code in <code>src/evotoolkit/__init__.py</code> <pre><code>def solve(\n    interface: BaseMethodInterface, output_path: str = \"./results\", **kwargs\n) -&gt; Any:\n    \"\"\"\n    Factory method to create and run an evolutionary optimization workflow.\n\n    This is the main entry point for using evotool with an explicit, unambiguous API.\n    Users must explicitly create task and interface instances before calling solve().\n\n    Args:\n        interface (BaseMethodInterface): Interface instance (e.g.,\n            `EoHPythonInterface`, `EvoEngineerPythonInterface`). Must be\n            explicitly created with a task instance. The algorithm is\n            automatically inferred from the interface type.\n        output_path (str): Path to save results.\n        **kwargs (Any): Additional parameters passed to algorithm config\n            (e.g., `max_generations`, `max_sample_nums`, `pop_size`,\n            `running_llm`).\n\n    Returns:\n        Any: Best solution found during the evolutionary optimization run.\n\n    Example:\n        # Create task instance explicitly\n        task = FuncApproxTask(x_data, y_noisy, y_true)\n\n        # Create interface instance explicitly\n        interface = EoHPythonInterface(task)\n\n        # Call solve with explicit interface\n        result = evotool.solve(\n            interface=interface,\n            output_path='./results',\n            running_llm=llm_api,\n            max_generations=5,\n            max_sample_nums=10\n        )\n    \"\"\"\n    # Step 1: Infer algorithm from interface\n    algorithm_name = infer_algorithm_from_interface(interface)\n\n    # Step 2: Get algorithm info from registry\n    algo_info = get_algorithm_info(algorithm_name)\n    algorithm_class = algo_info[\"class\"]\n    config_class = algo_info[\"config\"]\n\n    # Step 3: Create config with all parameters\n    # Note: task is accessed via interface.task\n    config = config_class(interface=interface, output_path=output_path, **kwargs)\n\n    # Step 4: Create and run algorithm\n    algorithm_instance = algorithm_class(config)\n    algorithm_instance.run()\n\n    # Step 5: Get the best solution from the run\n    best_solution = algorithm_instance._get_best_sol(\n        algorithm_instance.run_state_dict.sol_history\n    )\n\n    return best_solution\n</code></pre>"},{"location":"api/core/solve/#evotoolkit.solve--create-task-instance-explicitly","title":"Create task instance explicitly","text":"<p>task = FuncApproxTask(x_data, y_noisy, y_true)</p>"},{"location":"api/core/solve/#evotoolkit.solve--create-interface-instance-explicitly","title":"Create interface instance explicitly","text":"<p>interface = EoHPythonInterface(task)</p>"},{"location":"api/core/solve/#evotoolkit.solve--call-solve-with-explicit-interface","title":"Call solve with explicit interface","text":"<p>result = evotool.solve(     interface=interface,     output_path='./results',     running_llm=llm_api,     max_generations=5,     max_sample_nums=10 )</p>"},{"location":"api/core/solve/#example","title":"Example","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools import HttpsApi\n\n# Create task\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\n\n# Create interface\ninterface = EvoEngineerPythonInterface(task)\n\n# Configure LLM\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"your-api-key\",\n    model=\"gpt-4o\"\n)\n\n# Solve\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    max_sample_nums=10,\n    pop_size=5\n)\n\nprint(f\"Best score: {result.evaluation_res.score}\")\n</code></pre>"},{"location":"api/interfaces/base-method-interface/","title":"BaseMethodInterface","text":"<p>Base class for all method interfaces. See Python and CUDA interface implementations:</p> <ul> <li>Python Interfaces</li> <li>CUDA Interfaces</li> </ul>"},{"location":"api/interfaces/base-method-interface/#evotoolkit.core.BaseMethodInterface","title":"evotoolkit.core.BaseMethodInterface","text":"<p>               Bases: <code>ABC</code></p> <p>Base Adapter</p> Source code in <code>src/evotoolkit/core/method_interface/base_method_interface.py</code> <pre><code>class BaseMethodInterface(abc.ABC):\n    \"\"\"Base Adapter\"\"\"\n\n    def __init__(self, task: BaseTask):\n        self.task = task\n\n    @abstractmethod\n    def make_init_sol(self) -&gt; Solution:\n        \"\"\"Create initial solution from task info.\"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def parse_response(self, response_str: str) -&gt; Solution:\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/interfaces/base-method-interface/#evotoolkit.core.BaseMethodInterface.make_init_sol","title":"make_init_sol  <code>abstractmethod</code>","text":"<pre><code>make_init_sol() -&gt; Solution\n</code></pre> <p>Create initial solution from task info.</p> Source code in <code>src/evotoolkit/core/method_interface/base_method_interface.py</code> <pre><code>@abstractmethod\ndef make_init_sol(self) -&gt; Solution:\n    \"\"\"Create initial solution from task info.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/interfaces/cuda/","title":"CUDA Interfaces","text":"<p>Interfaces for CUDA kernel optimization tasks.</p> <ul> <li>EvoEngineerFullCudaInterface</li> <li>EvoEngineerFreeCudaInterface</li> <li>EvoEngineerInsightCudaInterface</li> <li>FunSearchCudaInterface</li> <li>EoHCudaInterface</li> </ul>"},{"location":"api/interfaces/cuda/eoh-cuda-interface/","title":"EoHCudaInterface","text":""},{"location":"api/interfaces/cuda/eoh-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EoHCudaInterface","title":"evotoolkit.task.cuda_engineering.method_interface.EoHCudaInterface","text":"<p>               Bases: <code>EoHInterface</code></p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/eoh_interface.py</code> <pre><code>class EoHCudaInterface(EoHInterface):\n    def __init__(self, task: CudaTask):\n        super().__init__(task)\n\n    def _get_base_task_description(self) -&gt; str:\n        base_task_description = self.task.get_base_task_description()\n        baseline_code = self.task.task_info.get(\"cuda_code\", \"\")\n\n        return f\"\"\"\n{base_task_description}\n\nHere is the CUDA kernel code example you need to optimize:\n```cpp\n{baseline_code}\n```\n\"\"\"\n\n    def get_prompt_i1(self) -&gt; List[dict]:\n        \"\"\"Generate initialization prompt (I1 operator)\"\"\"\n        task_description = self._get_base_task_description()\n\n        prompt = f\"\"\"\n{task_description}\n\n1. First, describe your new implementation and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, give the optimized kernel implementation:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def get_prompt_e1(self, selected_individuals: List[Solution]) -&gt; List[dict]:\n        \"\"\"Generate E1 (crossover) prompt\"\"\"\n        task_description = self._get_base_task_description()\n\n        # Create prompt content for all individuals\n        indivs_prompt = \"\"\n        for i, indi in enumerate(selected_individuals):\n            if \"algorithm\" in indi.other_info and indi.other_info[\"algorithm\"]:\n                algorithm_desc = indi.other_info[\"algorithm\"]\n            else:\n                algorithm_desc = f\"Kernel implementation {i + 1}\"\n            indivs_prompt += f\"No. {i + 1} kernel implementation and the corresponding code are:\\n{algorithm_desc}\\n{indi.sol_string}\\n\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have {len(selected_individuals)} existing kernel implementations with their codes as follows:\n{indivs_prompt}\n\nPlease help me create a new kernel implementation that has a totally different form from the given ones.\n1. First, describe your new kernel implementation and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def get_prompt_e2(self, selected_individuals: List[Solution]) -&gt; List[dict]:\n        \"\"\"Generate E2 (guided crossover) prompt\"\"\"\n        task_description = self._get_base_task_description()\n\n        # Create prompt content for all individuals\n        indivs_prompt = \"\"\n        for i, indi in enumerate(selected_individuals):\n            if \"algorithm\" in indi.other_info and indi.other_info[\"algorithm\"]:\n                algorithm_desc = indi.other_info[\"algorithm\"]\n            else:\n                algorithm_desc = f\"Kernel implementation {i + 1}\"\n            indivs_prompt += f\"No. {i + 1} kernel implementation and the corresponding code are:\\n{algorithm_desc}\\n{indi.sol_string}\\n\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have {len(selected_individuals)} existing kernel implementations with their codes as follows:\n{indivs_prompt}\n\nPlease help me create a new kernel implementation that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided kernel implementations.\n2. Secondly, based on the backbone idea describe your new kernel implementation in one sentence. The description must be inside within boxed {{}}.\n3. Thirdly, implement the kernel:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def get_prompt_m1(self, individual: Solution) -&gt; List[dict]:\n        \"\"\"Generate M1 (mutation) prompt\"\"\"\n        task_description = self._get_base_task_description()\n\n        if \"algorithm\" in individual.other_info and individual.other_info[\"algorithm\"]:\n            algorithm_desc = individual.other_info[\"algorithm\"]\n        else:\n            algorithm_desc = \"Current kernel implementation\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have one kernel implementation with its code as follows. Kernel implementation description:\n{algorithm_desc}\nCode:\n{individual.sol_string}\n\nPlease assist me in creating a new kernel implementation that has a different form but can be a modified version of the kernel implementation provided.\n1. First, describe your new kernel implementation and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def get_prompt_m2(self, individual: Solution) -&gt; List[dict]:\n        \"\"\"Generate M2 (parameter mutation) prompt\"\"\"\n        task_description = self._get_base_task_description()\n\n        if \"algorithm\" in individual.other_info and individual.other_info[\"algorithm\"]:\n            algorithm_desc = individual.other_info[\"algorithm\"]\n        else:\n            algorithm_desc = \"Current kernel implementation\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have one kernel implementation with its code as follows. Kernel implementation description:\n{algorithm_desc}\nCode:\n{individual.sol_string}\n\nPlease identify the main kernel implementation parameters and assist me in creating a new kernel implementation that has a different parameter settings of the kernel implementation provided.\n1. First, describe your new kernel implementation and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"Parse LLM response to extract solution string and algorithm description\"\"\"\n        # Extract algorithm/thought from response using pattern matching\n        try:\n            pattern = r\"\\{.*?\\}\"\n            bracketed_texts = re.findall(pattern, response_str, re.DOTALL)\n            algorithm = bracketed_texts[0] if bracketed_texts else None\n        except Exception:\n            algorithm = None\n\n        # Remove only the algorithm part from response before code extraction\n        response_without_algorithm = response_str\n        if algorithm:\n            # Remove only the specific algorithm part from the response\n            response_without_algorithm = response_str.replace(algorithm, \"\", 1)\n\n        # Try different code block patterns in order of preference\n        patterns = [\n            r\"```cpp\\s*\\n(.*?)\\n```\",  # cpp\n            r\"```c\\+\\+\\s*\\n(.*?)\\n```\",  # c++\n            r\"```cuda\\s*\\n(.*?)\\n```\",  # cuda\n            r\"```c\\s*\\n(.*?)\\n```\",  # c\n            r\"```\\s*\\n(.*?)\\n```\",  # generic code block\n        ]\n\n        # Find all matches using case insensitive search\n        code = \"\"\n        for pattern in patterns:\n            matches = re.findall(\n                pattern, response_without_algorithm, re.DOTALL | re.IGNORECASE\n            )\n            if matches:\n                # Return the longest match (likely the most complete implementation)\n                code = max(matches, key=len).strip()\n                break\n\n        if not code:\n            # Last resort: return stripped response without algorithm\n            code = response_without_algorithm.strip()\n\n        # Store algorithm description in the solution (this would need to be handled elsewhere)\n        # For now, we just return the code\n        other_info = {\"algorithm\": algorithm}\n        return Solution(code, other_info=other_info)\n</code></pre>"},{"location":"api/interfaces/cuda/eoh-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EoHCudaInterface.get_prompt_i1","title":"get_prompt_i1","text":"<pre><code>get_prompt_i1() -&gt; List[dict]\n</code></pre> <p>Generate initialization prompt (I1 operator)</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/eoh_interface.py</code> <pre><code>    def get_prompt_i1(self) -&gt; List[dict]:\n        \"\"\"Generate initialization prompt (I1 operator)\"\"\"\n        task_description = self._get_base_task_description()\n\n        prompt = f\"\"\"\n{task_description}\n\n1. First, describe your new implementation and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, give the optimized kernel implementation:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre>"},{"location":"api/interfaces/cuda/eoh-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EoHCudaInterface.get_prompt_e1","title":"get_prompt_e1","text":"<pre><code>get_prompt_e1(\n    selected_individuals: List[Solution],\n) -&gt; List[dict]\n</code></pre> <p>Generate E1 (crossover) prompt</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/eoh_interface.py</code> <pre><code>    def get_prompt_e1(self, selected_individuals: List[Solution]) -&gt; List[dict]:\n        \"\"\"Generate E1 (crossover) prompt\"\"\"\n        task_description = self._get_base_task_description()\n\n        # Create prompt content for all individuals\n        indivs_prompt = \"\"\n        for i, indi in enumerate(selected_individuals):\n            if \"algorithm\" in indi.other_info and indi.other_info[\"algorithm\"]:\n                algorithm_desc = indi.other_info[\"algorithm\"]\n            else:\n                algorithm_desc = f\"Kernel implementation {i + 1}\"\n            indivs_prompt += f\"No. {i + 1} kernel implementation and the corresponding code are:\\n{algorithm_desc}\\n{indi.sol_string}\\n\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have {len(selected_individuals)} existing kernel implementations with their codes as follows:\n{indivs_prompt}\n\nPlease help me create a new kernel implementation that has a totally different form from the given ones.\n1. First, describe your new kernel implementation and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre>"},{"location":"api/interfaces/cuda/eoh-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EoHCudaInterface.get_prompt_e2","title":"get_prompt_e2","text":"<pre><code>get_prompt_e2(\n    selected_individuals: List[Solution],\n) -&gt; List[dict]\n</code></pre> <p>Generate E2 (guided crossover) prompt</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/eoh_interface.py</code> <pre><code>    def get_prompt_e2(self, selected_individuals: List[Solution]) -&gt; List[dict]:\n        \"\"\"Generate E2 (guided crossover) prompt\"\"\"\n        task_description = self._get_base_task_description()\n\n        # Create prompt content for all individuals\n        indivs_prompt = \"\"\n        for i, indi in enumerate(selected_individuals):\n            if \"algorithm\" in indi.other_info and indi.other_info[\"algorithm\"]:\n                algorithm_desc = indi.other_info[\"algorithm\"]\n            else:\n                algorithm_desc = f\"Kernel implementation {i + 1}\"\n            indivs_prompt += f\"No. {i + 1} kernel implementation and the corresponding code are:\\n{algorithm_desc}\\n{indi.sol_string}\\n\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have {len(selected_individuals)} existing kernel implementations with their codes as follows:\n{indivs_prompt}\n\nPlease help me create a new kernel implementation that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided kernel implementations.\n2. Secondly, based on the backbone idea describe your new kernel implementation in one sentence. The description must be inside within boxed {{}}.\n3. Thirdly, implement the kernel:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre>"},{"location":"api/interfaces/cuda/eoh-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EoHCudaInterface.get_prompt_m1","title":"get_prompt_m1","text":"<pre><code>get_prompt_m1(individual: Solution) -&gt; List[dict]\n</code></pre> <p>Generate M1 (mutation) prompt</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/eoh_interface.py</code> <pre><code>    def get_prompt_m1(self, individual: Solution) -&gt; List[dict]:\n        \"\"\"Generate M1 (mutation) prompt\"\"\"\n        task_description = self._get_base_task_description()\n\n        if \"algorithm\" in individual.other_info and individual.other_info[\"algorithm\"]:\n            algorithm_desc = individual.other_info[\"algorithm\"]\n        else:\n            algorithm_desc = \"Current kernel implementation\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have one kernel implementation with its code as follows. Kernel implementation description:\n{algorithm_desc}\nCode:\n{individual.sol_string}\n\nPlease assist me in creating a new kernel implementation that has a different form but can be a modified version of the kernel implementation provided.\n1. First, describe your new kernel implementation and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre>"},{"location":"api/interfaces/cuda/eoh-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EoHCudaInterface.get_prompt_m2","title":"get_prompt_m2","text":"<pre><code>get_prompt_m2(individual: Solution) -&gt; List[dict]\n</code></pre> <p>Generate M2 (parameter mutation) prompt</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/eoh_interface.py</code> <pre><code>    def get_prompt_m2(self, individual: Solution) -&gt; List[dict]:\n        \"\"\"Generate M2 (parameter mutation) prompt\"\"\"\n        task_description = self._get_base_task_description()\n\n        if \"algorithm\" in individual.other_info and individual.other_info[\"algorithm\"]:\n            algorithm_desc = individual.other_info[\"algorithm\"]\n        else:\n            algorithm_desc = \"Current kernel implementation\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have one kernel implementation with its code as follows. Kernel implementation description:\n{algorithm_desc}\nCode:\n{individual.sol_string}\n\nPlease identify the main kernel implementation parameters and assist me in creating a new kernel implementation that has a different parameter settings of the kernel implementation provided.\n1. First, describe your new kernel implementation and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```cpp\n[Your kernel implementation]\n```\nDo not give additional explanations.\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre>"},{"location":"api/interfaces/cuda/eoh-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EoHCudaInterface.parse_response","title":"parse_response","text":"<pre><code>parse_response(response_str: str) -&gt; Solution\n</code></pre> <p>Parse LLM response to extract solution string and algorithm description</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/eoh_interface.py</code> <pre><code>def parse_response(self, response_str: str) -&gt; Solution:\n    \"\"\"Parse LLM response to extract solution string and algorithm description\"\"\"\n    # Extract algorithm/thought from response using pattern matching\n    try:\n        pattern = r\"\\{.*?\\}\"\n        bracketed_texts = re.findall(pattern, response_str, re.DOTALL)\n        algorithm = bracketed_texts[0] if bracketed_texts else None\n    except Exception:\n        algorithm = None\n\n    # Remove only the algorithm part from response before code extraction\n    response_without_algorithm = response_str\n    if algorithm:\n        # Remove only the specific algorithm part from the response\n        response_without_algorithm = response_str.replace(algorithm, \"\", 1)\n\n    # Try different code block patterns in order of preference\n    patterns = [\n        r\"```cpp\\s*\\n(.*?)\\n```\",  # cpp\n        r\"```c\\+\\+\\s*\\n(.*?)\\n```\",  # c++\n        r\"```cuda\\s*\\n(.*?)\\n```\",  # cuda\n        r\"```c\\s*\\n(.*?)\\n```\",  # c\n        r\"```\\s*\\n(.*?)\\n```\",  # generic code block\n    ]\n\n    # Find all matches using case insensitive search\n    code = \"\"\n    for pattern in patterns:\n        matches = re.findall(\n            pattern, response_without_algorithm, re.DOTALL | re.IGNORECASE\n        )\n        if matches:\n            # Return the longest match (likely the most complete implementation)\n            code = max(matches, key=len).strip()\n            break\n\n    if not code:\n        # Last resort: return stripped response without algorithm\n        code = response_without_algorithm.strip()\n\n    # Store algorithm description in the solution (this would need to be handled elsewhere)\n    # For now, we just return the code\n    other_info = {\"algorithm\": algorithm}\n    return Solution(code, other_info=other_info)\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-free-cuda-interface/","title":"EvoEngineerFreeCudaInterface","text":""},{"location":"api/interfaces/cuda/evoengineer-free-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFreeCudaInterface","title":"evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFreeCudaInterface","text":"<p>               Bases: <code>EvoEngineerFullCudaInterface</code></p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_free_interface.py</code> <pre><code>class EvoEngineerFreeCudaInterface(EvoEngineerFullCudaInterface):\n    def __init__(self, task: CudaTask):\n        super().__init__(task)\n        self.valid_require = 0\n\n    def get_init_operators(self) -&gt; List[Operator]:\n        \"\"\"Get initialization operators for CUDA optimization\"\"\"\n        return [Operator(\"init\", 0)]\n\n    def get_offspring_operators(self) -&gt; List[Operator]:\n        \"\"\"Get offspring operators for CUDA optimization\"\"\"\n        return [Operator(\"init\", 0)]\n\n    def get_operator_prompt(\n        self,\n        operator_name: str,\n        selected_individuals: List[Solution],\n        current_best_sol: Solution,\n        random_thoughts: List[str],\n        **kwargs,\n    ) -&gt; List[dict]:\n        \"\"\"Generate prompt for any operator\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        if current_best_sol is None:\n            current_best_sol = self.make_init_sol()\n\n        if operator_name == \"init\":\n            prompt = f\"\"\"# CUDA KERNEL OPTIMIZATION TASK\n{task_description}\n\n## BASELINE CODE\n```cpp\n{current_best_sol.sol_string}\n```\n\n## OPTIMIZATION STRATEGY\nPropose a new CUDA kernel code which aims to reduce the runtime of the operation, while ensuring the kernel returns the correct result.\n\n## RESPONSE FORMAT:\n\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\n\n## FORMAT REQUIREMENTS:\n1. MAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\n2. The PYBIND11_MODULE inside the code has to be the same as ## BASELINE CODE.\n3. The code MUST be wrapped in ```cpp and ``` markers.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        else:\n            raise ValueError(f\"Unknown operator: {operator_name}\")\n\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"Parse response with multiple fallback strategies for free format\"\"\"\n        if not response_str or not response_str.strip():\n            return Solution(\n                \"\", other_info={\"name\": \"raw\", \"thought\": \"Failed to parse\"}\n            )\n\n        content = response_str.strip()\n\n        # Strategy 1: Look for code: block format (expected format)\n        code_pattern = r\"code:\\s*\\n*```(?:cpp|c\\+\\+|cuda)?\\s*\\n(.*?)```\"\n        code_match = re.search(code_pattern, content, re.DOTALL | re.IGNORECASE)\n        if code_match:\n            code = code_match.group(1).strip()\n            if code:\n                return Solution(\n                    code,\n                    other_info={\"name\": \"code_block\", \"thought\": \"Standard format\"},\n                )\n\n        # Strategy 2: Look for any cpp/cuda code block\n        code = self._extract_any_code_block(content)\n        if code:\n            return Solution(\n                code, other_info={\"name\": \"extracted\", \"thought\": \"Code block fallback\"}\n            )\n\n        # Strategy 3: Raw content (last resort)\n        return Solution(\n            content, other_info={\"name\": \"raw\", \"thought\": \"Failed to parse\"}\n        )\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-free-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFreeCudaInterface.get_init_operators","title":"get_init_operators","text":"<pre><code>get_init_operators() -&gt; List[Operator]\n</code></pre> <p>Get initialization operators for CUDA optimization</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_free_interface.py</code> <pre><code>def get_init_operators(self) -&gt; List[Operator]:\n    \"\"\"Get initialization operators for CUDA optimization\"\"\"\n    return [Operator(\"init\", 0)]\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-free-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFreeCudaInterface.get_offspring_operators","title":"get_offspring_operators","text":"<pre><code>get_offspring_operators() -&gt; List[Operator]\n</code></pre> <p>Get offspring operators for CUDA optimization</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_free_interface.py</code> <pre><code>def get_offspring_operators(self) -&gt; List[Operator]:\n    \"\"\"Get offspring operators for CUDA optimization\"\"\"\n    return [Operator(\"init\", 0)]\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-free-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFreeCudaInterface.get_operator_prompt","title":"get_operator_prompt","text":"<pre><code>get_operator_prompt(\n    operator_name: str,\n    selected_individuals: List[Solution],\n    current_best_sol: Solution,\n    random_thoughts: List[str],\n    **kwargs,\n) -&gt; List[dict]\n</code></pre> <p>Generate prompt for any operator</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_free_interface.py</code> <pre><code>    def get_operator_prompt(\n        self,\n        operator_name: str,\n        selected_individuals: List[Solution],\n        current_best_sol: Solution,\n        random_thoughts: List[str],\n        **kwargs,\n    ) -&gt; List[dict]:\n        \"\"\"Generate prompt for any operator\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        if current_best_sol is None:\n            current_best_sol = self.make_init_sol()\n\n        if operator_name == \"init\":\n            prompt = f\"\"\"# CUDA KERNEL OPTIMIZATION TASK\n{task_description}\n\n## BASELINE CODE\n```cpp\n{current_best_sol.sol_string}\n```\n\n## OPTIMIZATION STRATEGY\nPropose a new CUDA kernel code which aims to reduce the runtime of the operation, while ensuring the kernel returns the correct result.\n\n## RESPONSE FORMAT:\n\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\n\n## FORMAT REQUIREMENTS:\n1. MAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\n2. The PYBIND11_MODULE inside the code has to be the same as ## BASELINE CODE.\n3. The code MUST be wrapped in ```cpp and ``` markers.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        else:\n            raise ValueError(f\"Unknown operator: {operator_name}\")\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-free-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFreeCudaInterface.parse_response","title":"parse_response","text":"<pre><code>parse_response(response_str: str) -&gt; Solution\n</code></pre> <p>Parse response with multiple fallback strategies for free format</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_free_interface.py</code> <pre><code>def parse_response(self, response_str: str) -&gt; Solution:\n    \"\"\"Parse response with multiple fallback strategies for free format\"\"\"\n    if not response_str or not response_str.strip():\n        return Solution(\n            \"\", other_info={\"name\": \"raw\", \"thought\": \"Failed to parse\"}\n        )\n\n    content = response_str.strip()\n\n    # Strategy 1: Look for code: block format (expected format)\n    code_pattern = r\"code:\\s*\\n*```(?:cpp|c\\+\\+|cuda)?\\s*\\n(.*?)```\"\n    code_match = re.search(code_pattern, content, re.DOTALL | re.IGNORECASE)\n    if code_match:\n        code = code_match.group(1).strip()\n        if code:\n            return Solution(\n                code,\n                other_info={\"name\": \"code_block\", \"thought\": \"Standard format\"},\n            )\n\n    # Strategy 2: Look for any cpp/cuda code block\n    code = self._extract_any_code_block(content)\n    if code:\n        return Solution(\n            code, other_info={\"name\": \"extracted\", \"thought\": \"Code block fallback\"}\n        )\n\n    # Strategy 3: Raw content (last resort)\n    return Solution(\n        content, other_info={\"name\": \"raw\", \"thought\": \"Failed to parse\"}\n    )\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-full-cuda-interface/","title":"EvoEngineerFullCudaInterface","text":""},{"location":"api/interfaces/cuda/evoengineer-full-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFullCudaInterface","title":"evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFullCudaInterface","text":"<p>               Bases: <code>EvoEngineerInterface</code></p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_full_interface.py</code> <pre><code>class EvoEngineerFullCudaInterface(EvoEngineerInterface):\n    def __init__(self, task: CudaTask):\n        super().__init__(task)\n\n    def get_init_operators(self) -&gt; List[Operator]:\n        \"\"\"Get initialization operators for CUDA optimization\"\"\"\n        return [Operator(\"init\", 0)]\n\n    def get_offspring_operators(self) -&gt; List[Operator]:\n        \"\"\"Get offspring operators for CUDA optimization\"\"\"\n        return [Operator(\"crossover\", 2), Operator(\"mutation\", 1)]\n\n    def get_operator_prompt(\n        self,\n        operator_name: str,\n        selected_individuals: List[Solution],\n        current_best_sol: Solution,\n        random_thoughts: List[str],\n        **kwargs,\n    ) -&gt; List[dict]:\n        \"\"\"Generate prompt for any operator\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        if current_best_sol is None:\n            current_best_sol = self.make_init_sol()\n\n        if operator_name == \"init\":\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"\n{thoughts_list}\n\"\"\"\n\n            prompt = f\"\"\"# CUDA KERNEL OPTIMIZATION TASK\n{task_description}\n\n## BASELINE CODE\n**Name:** {current_best_sol.other_info[\"name\"]}\n**Runtime:** {-current_best_sol.evaluation_res.score:.5f} milliseconds\n**Current Approach:** {current_best_sol.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{current_best_sol.sol_string}\n```\n**Performance Profile:**\n{current_best_sol.evaluation_res.additional_info[\"prof_string\"]}\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## OPTIMIZATION STRATEGY\n{\"Use the insights above if relevant as optimization guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\nPropose a new CUDA kernel code which aims to reduce the runtime of the operation, while ensuring the kernel returns the correct result.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```cpp and ``` markers\n2. The PYBIND11_MODULE inside the code has to be the same as in the ## BASELINE CODE.\n3. MAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"crossover\":\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"\n{thoughts_list}\n\"\"\"\n            # Build parent kernels info\n            parents_info = \"\"\n            for i, parent in enumerate(selected_individuals, 1):\n                parents_info += f\"\"\"\n**Parent {i}:**\n**Name:** {parent.other_info[\"name\"]} \n**Runtime:** {-parent.evaluation_res.score:.5f} milliseconds\n**Parent Approach:** {parent.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{parent.sol_string}\n```\n\"\"\"\n            prompt = f\"\"\"# CUDA KERNEL CROSSOVER TASK\n{task_description}\n\n## BASELINE CODE\n**Name:** {current_best_sol.other_info[\"name\"]}\n**Runtime:** {-current_best_sol.evaluation_res.score:.5f} milliseconds\n**Current Approach:** {current_best_sol.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{current_best_sol.sol_string}\n```\n**Performance Profile:**\n{current_best_sol.evaluation_res.additional_info[\"prof_string\"]}\n\n## PARENTS TO COMBINE\n\n{parents_info}\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## CROSSOVER STRATEGY\nCombine the best features from both parent kernels:\n{\"Use the insights above if relevant as crossover guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\n\nCreate a hybrid CUDA kernel that combines the strengths of both parents.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```cpp and ``` markers\n2. The PYBIND11_MODULE inside the code has to be the same as in the ## BASELINE CODE.\n3. MAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        elif operator_name == \"mutation\":\n            individual = selected_individuals[0]\n\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"\n{thoughts_list}\n\"\"\"\n            prompt = f\"\"\"# CUDA KERNEL MUTATION TASK\n{task_description}\n\n## CURRENT BEST\n**Name:** {current_best_sol.other_info[\"name\"]}\n**Runtime:** {-current_best_sol.evaluation_res.score:.5f} milliseconds\n**Previous Approach:** {current_best_sol.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{current_best_sol.sol_string}\n```\n**Performance Profile:**\n{current_best_sol.evaluation_res.additional_info[\"prof_string\"]}\n\n## SOURCE TO MUTATE\n**Name:** {individual.other_info[\"name\"]}\n**Runtime:** {-individual.evaluation_res.score:.5f} milliseconds\n**Target Approach:** {individual.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{individual.sol_string}\n```\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## MUTATION STRATEGY\nApply significant changes to the target kernel:\n{\"Use the insights above if relevant as mutation guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\nCreate a substantially modified version that explores new optimization directions.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```cpp and ``` markers\n2. The PYBIND11_MODULE inside the code has to be the same as in the ## BASELINE CODE.\n3. MAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        else:\n            raise ValueError(f\"Unknown operator: {operator_name}\")\n\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"Improved parser with multiple fallback strategies\"\"\"\n        if not response_str or not response_str.strip():\n            return Solution(\"\")\n\n        content = response_str.strip()\n\n        # Strategy 1: Standard format parsing (most reliable)\n        result = self._parse_standard_format(content)\n        if result and result[1]:  # Ensure we have code\n            return Solution(\n                result[1], other_info={\"name\": result[0], \"thought\": result[2]}\n            )\n\n        # Strategy 2: Flexible format parsing\n        result = self._parse_flexible_format(content)\n        if result and result[1]:\n            return Solution(\n                result[1], other_info={\"name\": result[0], \"thought\": result[2]}\n            )\n\n        # Strategy 3: Code block fallback\n        code = self._extract_any_code_block(content)\n        if code:\n            return Solution(\n                code, other_info={\"name\": \"extracted\", \"thought\": \"Fallback parsing\"}\n            )\n\n        # Strategy 4: Raw content (last resort)\n        return Solution(\n            content, other_info={\"name\": \"raw\", \"thought\": \"Failed to parse\"}\n        )\n\n    def _parse_standard_format(self, content: str) -&gt; tuple:\n        \"\"\"Parse standard format: name -&gt; code -&gt; thought order\"\"\"\n        # Extract name (independent pattern)\n        name_pattern = r\"^name:\\s*([^\\n\\r]+?)(?:\\n|\\r|$)\"\n        name_match = re.search(name_pattern, content, re.MULTILINE | re.IGNORECASE)\n        name = name_match.group(1).strip() if name_match else \"\"\n\n        # Extract code block (independent pattern)\n        code_pattern = r\"code:\\s*\\n*```(?:cpp|c\\+\\+|cuda)?\\n(.*?)```\"\n        code_match = re.search(code_pattern, content, re.DOTALL | re.IGNORECASE)\n        code = code_match.group(1).strip() if code_match else \"\"\n\n        # Extract thought (independent pattern)\n        thought_pattern = r\"thought:\\s*(.*?)$\"\n        thought_match = re.search(thought_pattern, content, re.DOTALL | re.IGNORECASE)\n        thought = thought_match.group(1).strip() if thought_match else \"\"\n\n        return (name, code, thought)\n\n    def _parse_flexible_format(self, content: str) -&gt; tuple:\n        \"\"\"More flexible parsing for variations in format\"\"\"\n        # Try to extract name anywhere in the text\n        name_pattern = r\"(?:name|Name|NAME)\\s*:?\\s*([^\\n\\r]+)\"\n        name_match = re.search(name_pattern, content, re.IGNORECASE)\n        name = name_match.group(1).strip() if name_match else \"\"\n\n        # Try to extract any code block\n        code = self._extract_any_code_block(content)\n\n        # Try to extract thought\n        thought_pattern = (\n            r\"(?:thought|Thought|THOUGHT)\\s*:?\\s*(.*?)(?=\\n(?:name|code)|$)\"\n        )\n        thought_match = re.search(thought_pattern, content, re.DOTALL | re.IGNORECASE)\n        thought = thought_match.group(1).strip() if thought_match else \"\"\n\n        return (name, code, thought)\n\n    def _extract_any_code_block(self, content: str) -&gt; str:\n        \"\"\"Extract any code block from the content\"\"\"\n        # Priority 1: Look for ```cpp or ```c++ blocks\n        cpp_pattern = r\"```(?:cpp|c\\+\\+|cuda)\\n(.*?)```\"\n        match = re.search(cpp_pattern, content, re.DOTALL | re.IGNORECASE)\n        if match:\n            return match.group(1).strip()\n\n        # Priority 2: Look for any ``` blocks\n        generic_pattern = r\"```[^\\n]*\\n(.*?)```\"\n        match = re.search(generic_pattern, content, re.DOTALL)\n        if match:\n            return match.group(1).strip()\n\n        # Priority 3: Look for code: section without proper markers\n        code_pattern = r\"code:\\s*\\n*(.*?)(?=\\n(?:thought|$))\"\n        match = re.search(code_pattern, content, re.DOTALL | re.IGNORECASE)\n        if match:\n            code_content = match.group(1).strip()\n            # Remove any remaining ``` markers\n            code_content = re.sub(r\"^```[^\\n]*\\n?\", \"\", code_content)\n            code_content = re.sub(r\"\\n?```\\s*$\", \"\", code_content)\n            return code_content.strip()\n\n        return \"\"\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-full-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFullCudaInterface.get_init_operators","title":"get_init_operators","text":"<pre><code>get_init_operators() -&gt; List[Operator]\n</code></pre> <p>Get initialization operators for CUDA optimization</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_full_interface.py</code> <pre><code>def get_init_operators(self) -&gt; List[Operator]:\n    \"\"\"Get initialization operators for CUDA optimization\"\"\"\n    return [Operator(\"init\", 0)]\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-full-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFullCudaInterface.get_offspring_operators","title":"get_offspring_operators","text":"<pre><code>get_offspring_operators() -&gt; List[Operator]\n</code></pre> <p>Get offspring operators for CUDA optimization</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_full_interface.py</code> <pre><code>def get_offspring_operators(self) -&gt; List[Operator]:\n    \"\"\"Get offspring operators for CUDA optimization\"\"\"\n    return [Operator(\"crossover\", 2), Operator(\"mutation\", 1)]\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-full-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFullCudaInterface.get_operator_prompt","title":"get_operator_prompt","text":"<pre><code>get_operator_prompt(\n    operator_name: str,\n    selected_individuals: List[Solution],\n    current_best_sol: Solution,\n    random_thoughts: List[str],\n    **kwargs,\n) -&gt; List[dict]\n</code></pre> <p>Generate prompt for any operator</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_full_interface.py</code> <pre><code>    def get_operator_prompt(\n        self,\n        operator_name: str,\n        selected_individuals: List[Solution],\n        current_best_sol: Solution,\n        random_thoughts: List[str],\n        **kwargs,\n    ) -&gt; List[dict]:\n        \"\"\"Generate prompt for any operator\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        if current_best_sol is None:\n            current_best_sol = self.make_init_sol()\n\n        if operator_name == \"init\":\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"\n{thoughts_list}\n\"\"\"\n\n            prompt = f\"\"\"# CUDA KERNEL OPTIMIZATION TASK\n{task_description}\n\n## BASELINE CODE\n**Name:** {current_best_sol.other_info[\"name\"]}\n**Runtime:** {-current_best_sol.evaluation_res.score:.5f} milliseconds\n**Current Approach:** {current_best_sol.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{current_best_sol.sol_string}\n```\n**Performance Profile:**\n{current_best_sol.evaluation_res.additional_info[\"prof_string\"]}\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## OPTIMIZATION STRATEGY\n{\"Use the insights above if relevant as optimization guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\nPropose a new CUDA kernel code which aims to reduce the runtime of the operation, while ensuring the kernel returns the correct result.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```cpp and ``` markers\n2. The PYBIND11_MODULE inside the code has to be the same as in the ## BASELINE CODE.\n3. MAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"crossover\":\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"\n{thoughts_list}\n\"\"\"\n            # Build parent kernels info\n            parents_info = \"\"\n            for i, parent in enumerate(selected_individuals, 1):\n                parents_info += f\"\"\"\n**Parent {i}:**\n**Name:** {parent.other_info[\"name\"]} \n**Runtime:** {-parent.evaluation_res.score:.5f} milliseconds\n**Parent Approach:** {parent.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{parent.sol_string}\n```\n\"\"\"\n            prompt = f\"\"\"# CUDA KERNEL CROSSOVER TASK\n{task_description}\n\n## BASELINE CODE\n**Name:** {current_best_sol.other_info[\"name\"]}\n**Runtime:** {-current_best_sol.evaluation_res.score:.5f} milliseconds\n**Current Approach:** {current_best_sol.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{current_best_sol.sol_string}\n```\n**Performance Profile:**\n{current_best_sol.evaluation_res.additional_info[\"prof_string\"]}\n\n## PARENTS TO COMBINE\n\n{parents_info}\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## CROSSOVER STRATEGY\nCombine the best features from both parent kernels:\n{\"Use the insights above if relevant as crossover guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\n\nCreate a hybrid CUDA kernel that combines the strengths of both parents.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```cpp and ``` markers\n2. The PYBIND11_MODULE inside the code has to be the same as in the ## BASELINE CODE.\n3. MAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        elif operator_name == \"mutation\":\n            individual = selected_individuals[0]\n\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"\n{thoughts_list}\n\"\"\"\n            prompt = f\"\"\"# CUDA KERNEL MUTATION TASK\n{task_description}\n\n## CURRENT BEST\n**Name:** {current_best_sol.other_info[\"name\"]}\n**Runtime:** {-current_best_sol.evaluation_res.score:.5f} milliseconds\n**Previous Approach:** {current_best_sol.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{current_best_sol.sol_string}\n```\n**Performance Profile:**\n{current_best_sol.evaluation_res.additional_info[\"prof_string\"]}\n\n## SOURCE TO MUTATE\n**Name:** {individual.other_info[\"name\"]}\n**Runtime:** {-individual.evaluation_res.score:.5f} milliseconds\n**Target Approach:** {individual.other_info[\"thought\"]}\n**Kernel Code:**\n```cpp\n{individual.sol_string}\n```\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## MUTATION STRATEGY\nApply significant changes to the target kernel:\n{\"Use the insights above if relevant as mutation guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\nCreate a substantially modified version that explores new optimization directions.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```cpp and ``` markers\n2. The PYBIND11_MODULE inside the code has to be the same as in the ## BASELINE CODE.\n3. MAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        else:\n            raise ValueError(f\"Unknown operator: {operator_name}\")\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-full-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerFullCudaInterface.parse_response","title":"parse_response","text":"<pre><code>parse_response(response_str: str) -&gt; Solution\n</code></pre> <p>Improved parser with multiple fallback strategies</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_full_interface.py</code> <pre><code>def parse_response(self, response_str: str) -&gt; Solution:\n    \"\"\"Improved parser with multiple fallback strategies\"\"\"\n    if not response_str or not response_str.strip():\n        return Solution(\"\")\n\n    content = response_str.strip()\n\n    # Strategy 1: Standard format parsing (most reliable)\n    result = self._parse_standard_format(content)\n    if result and result[1]:  # Ensure we have code\n        return Solution(\n            result[1], other_info={\"name\": result[0], \"thought\": result[2]}\n        )\n\n    # Strategy 2: Flexible format parsing\n    result = self._parse_flexible_format(content)\n    if result and result[1]:\n        return Solution(\n            result[1], other_info={\"name\": result[0], \"thought\": result[2]}\n        )\n\n    # Strategy 3: Code block fallback\n    code = self._extract_any_code_block(content)\n    if code:\n        return Solution(\n            code, other_info={\"name\": \"extracted\", \"thought\": \"Fallback parsing\"}\n        )\n\n    # Strategy 4: Raw content (last resort)\n    return Solution(\n        content, other_info={\"name\": \"raw\", \"thought\": \"Failed to parse\"}\n    )\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-insight-cuda-interface/","title":"EvoEngineerInsightCudaInterface","text":""},{"location":"api/interfaces/cuda/evoengineer-insight-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerInsightCudaInterface","title":"evotoolkit.task.cuda_engineering.method_interface.EvoEngineerInsightCudaInterface","text":"<p>               Bases: <code>EvoEngineerFullCudaInterface</code></p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_insight_interface.py</code> <pre><code>class EvoEngineerInsightCudaInterface(EvoEngineerFullCudaInterface):\n    def __init__(self, task_config: CudaTask):\n        super().__init__(task_config)\n        self.valid_require = 0\n\n    def get_init_operators(self) -&gt; List[Operator]:\n        \"\"\"Get initialization operators for CUDA optimization\"\"\"\n        return [Operator(\"init\", 0)]\n\n    def get_offspring_operators(self) -&gt; List[Operator]:\n        \"\"\"Get offspring operators for CUDA optimization\"\"\"\n        return [Operator(\"init\", 0)]\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-insight-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerInsightCudaInterface.get_init_operators","title":"get_init_operators","text":"<pre><code>get_init_operators() -&gt; List[Operator]\n</code></pre> <p>Get initialization operators for CUDA optimization</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_insight_interface.py</code> <pre><code>def get_init_operators(self) -&gt; List[Operator]:\n    \"\"\"Get initialization operators for CUDA optimization\"\"\"\n    return [Operator(\"init\", 0)]\n</code></pre>"},{"location":"api/interfaces/cuda/evoengineer-insight-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.EvoEngineerInsightCudaInterface.get_offspring_operators","title":"get_offspring_operators","text":"<pre><code>get_offspring_operators() -&gt; List[Operator]\n</code></pre> <p>Get offspring operators for CUDA optimization</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/evoengineer_insight_interface.py</code> <pre><code>def get_offspring_operators(self) -&gt; List[Operator]:\n    \"\"\"Get offspring operators for CUDA optimization\"\"\"\n    return [Operator(\"init\", 0)]\n</code></pre>"},{"location":"api/interfaces/cuda/funsearch-cuda-interface/","title":"FunSearchCudaInterface","text":""},{"location":"api/interfaces/cuda/funsearch-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.FunSearchCudaInterface","title":"evotoolkit.task.cuda_engineering.method_interface.FunSearchCudaInterface","text":"<p>               Bases: <code>FunSearchInterface</code></p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/funsearch_interface.py</code> <pre><code>class FunSearchCudaInterface(FunSearchInterface):\n    def __init__(self, task: CudaTask):\n        super().__init__(task)\n\n    def get_prompt(self, solutions: List[Solution]) -&gt; List[dict]:\n        base_task_description = self.task.get_base_task_description()\n        if len(solutions) == 1:\n            prompt = f\"\"\"\n{base_task_description}\n\nHere is the CUDA kernel code example you need to optimize:\n```cpp\n{solutions[0].sol_string}\n```\n\nPropose a new CUDA kernel code which aims to reduce the runtime of the operation, while ensuring the kernel returns the correct result.\n\nAnswer using the following schema:\n\n```cpp\n[Your kernel implementation]\n```\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        elif len(solutions) &gt;= 2:\n            prompt = f\"\"\"\n{base_task_description}\n\nHere is a CUDA kernel code example:\n```cpp\n{solutions[0].sol_string}\n```\n\nA better version of the CUDA kernel code example is as follows:\n```cpp\n{solutions[1].sol_string}\n```\n\nPropose a new CUDA kernel code which aims to reduce the runtime of the operation, while ensuring the kernel returns the correct result.\n\nAnswer using the following schema:\n\n```cpp\n[Your kernel implementation]\n```\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        else:\n            # Fallback if no solutions provided\n            prompt = f\"\"\"\n{base_task_description}\n\nHere is the original CUDA kernel code:\n```cpp\n{self.task.task_info[\"cuda_code\"]}\n```\n\nPropose an optimized CUDA kernel code which aims to reduce the runtime of the operation, while ensuring the kernel returns the correct result.\n\nAnswer using the following schema:\n\n```cpp\n[Your kernel implementation]\n```\n\nThe pybind11 cuda module name has to be the same as in the example.\nMAKE SURE THE PROPOSAL CODE IS VALID CUDA CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n\n        prompt_content = [{\"role\": \"user\", \"content\": prompt}]\n        return prompt_content\n\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"Parse LLM response to extract CUDA code\"\"\"\n        # Try different code block patterns in order of preference\n        patterns = [\n            r\"```cpp\\s*\\n(.*?)\\n```\",  # cpp\n            r\"```c\\+\\+\\s*\\n(.*?)\\n```\",  # c++\n            r\"```cuda\\s*\\n(.*?)\\n```\",  # cuda\n            r\"```c\\s*\\n(.*?)\\n```\",  # c\n            r\"```\\s*\\n(.*?)\\n```\",  # generic code block\n        ]\n\n        # Find all matches using case insensitive search\n        for pattern in patterns:\n            matches = re.findall(pattern, response_str, re.DOTALL | re.IGNORECASE)\n            if matches:\n                # Return the longest match (likely the most complete implementation)\n                return Solution(max(matches, key=len).strip())\n\n        # Last resort: return stripped response\n        return Solution(response_str.strip())\n</code></pre>"},{"location":"api/interfaces/cuda/funsearch-cuda-interface/#evotoolkit.task.cuda_engineering.method_interface.FunSearchCudaInterface.parse_response","title":"parse_response","text":"<pre><code>parse_response(response_str: str) -&gt; Solution\n</code></pre> <p>Parse LLM response to extract CUDA code</p> Source code in <code>src/evotoolkit/task/cuda_engineering/method_interface/funsearch_interface.py</code> <pre><code>def parse_response(self, response_str: str) -&gt; Solution:\n    \"\"\"Parse LLM response to extract CUDA code\"\"\"\n    # Try different code block patterns in order of preference\n    patterns = [\n        r\"```cpp\\s*\\n(.*?)\\n```\",  # cpp\n        r\"```c\\+\\+\\s*\\n(.*?)\\n```\",  # c++\n        r\"```cuda\\s*\\n(.*?)\\n```\",  # cuda\n        r\"```c\\s*\\n(.*?)\\n```\",  # c\n        r\"```\\s*\\n(.*?)\\n```\",  # generic code block\n    ]\n\n    # Find all matches using case insensitive search\n    for pattern in patterns:\n        matches = re.findall(pattern, response_str, re.DOTALL | re.IGNORECASE)\n        if matches:\n            # Return the longest match (likely the most complete implementation)\n            return Solution(max(matches, key=len).strip())\n\n    # Last resort: return stripped response\n    return Solution(response_str.strip())\n</code></pre>"},{"location":"api/interfaces/python/","title":"Python Interfaces","text":"<p>Interfaces connecting Python tasks to evolutionary methods.</p> <ul> <li>EvoEngineerPythonInterface</li> <li>FunSearchPythonInterface</li> <li>EoHPythonInterface</li> </ul>"},{"location":"api/interfaces/python/eoh-python-interface/","title":"EoHPythonInterface","text":""},{"location":"api/interfaces/python/eoh-python-interface/#evotoolkit.task.python_task.method_interface.EoHPythonInterface","title":"evotoolkit.task.python_task.method_interface.EoHPythonInterface","text":"<p>               Bases: <code>EoHInterface</code></p> <p>EOH Adapter for Python code optimization tasks.</p> <p>This class provides common operator logic for Python tasks. Subclasses only need to implement _get_system_prompt() to define task-specific instructions.</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/eoh_interface.py</code> <pre><code>class EoHPythonInterface(EoHInterface):\n    \"\"\"EOH Adapter for Python code optimization tasks.\n\n    This class provides common operator logic for Python tasks.\n    Subclasses only need to implement _get_system_prompt() to define task-specific instructions.\n    \"\"\"\n\n    def __init__(self, task: PythonTask):\n        super().__init__(task)\n\n    def get_prompt_i1(self) -&gt; List[dict]:\n        \"\"\"Generate initialization prompt (I1 operator).\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        prompt = f\"\"\"\n{task_description}\n\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {{}}. \n2. Next, implement the following Python function:\n```python\n[Your implementation code]\n```\n\nDo not give additional explanations.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def get_prompt_e1(self, selected_individuals: List[Solution]) -&gt; List[dict]:\n        task_description = self.task.get_base_task_description()\n\n        # Create prompt content for all individuals\n        indivs_prompt = \"\"\n        for i, indi in enumerate(selected_individuals):\n            if \"algorithm\" in indi.other_info and indi.other_info[\"algorithm\"]:\n                algorithm_desc = indi.other_info[\"algorithm\"]\n            else:\n                algorithm_desc = f\"Python Code {i + 1}\"\n            indivs_prompt += f\"No. {i + 1} algorithm and the corresponding code are:\\n{algorithm_desc}\\n{indi.sol_string}\\n\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have {len(selected_individuals)} existing algorithms with their codes as follows:\n{indivs_prompt}\n\nPlease help me create a new algorithm that has a totally different form from the given ones.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```python\n[Your implementation code]\n```\nDo not give additional explanations.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def get_prompt_e2(self, selected_individuals: List[Solution]) -&gt; List[dict]:\n        \"\"\"Generate E2 (guided crossover) prompt.\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        # Create prompt content for all individuals\n        indivs_prompt = \"\"\n        for i, indi in enumerate(selected_individuals):\n            if \"algorithm\" in indi.other_info and indi.other_info[\"algorithm\"]:\n                algorithm_desc = indi.other_info[\"algorithm\"]\n            else:\n                algorithm_desc = f\"Python code {i + 1}\"\n            indivs_prompt += f\"No. {i + 1} algorithm and the corresponding code are:\\n{algorithm_desc}\\n{indi.sol_string}\\n\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have {len(selected_individuals)} existing algorithms with their codes as follows:\n{indivs_prompt}\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms.\n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {{}}.\n3. Thirdly, implement the kernel:\n```python\n[Your implementation code]\n```\nDo not give additional explanations.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def get_prompt_m1(self, individual: Solution) -&gt; List[dict]:\n        task_description = self.task.get_base_task_description()\n\n        if \"algorithm\" in individual.other_info and individual.other_info[\"algorithm\"]:\n            algorithm_desc = individual.other_info[\"algorithm\"]\n        else:\n            algorithm_desc = \"Current algorithm\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have one algorithm with its code as follows. algorithm description:\n{algorithm_desc}\nCode:\n{individual.sol_string}\n\nPlease assist me in creating a new algorithm that has a different form but can be a modified version of the algorithm provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```python\n[Your implementation code]\n```\nDo not give additional explanations.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def get_prompt_m2(self, individual: Solution) -&gt; List[dict]:\n        task_description = self.task.get_base_task_description()\n\n        if \"algorithm\" in individual.other_info and individual.other_info[\"algorithm\"]:\n            algorithm_desc = individual.other_info[\"algorithm\"]\n        else:\n            algorithm_desc = \"Current algorithm\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have one algorithm with its code as follows. algorithm description:\n{algorithm_desc}\nCode:\n{individual.sol_string}\n\nPlease identify the main algorithm parameters and assist me in creating a new algorithm that has a different parameter settings of the algorithm provided.\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {{}}.\n2. Next, implement the kernel:\n```python\n[Your implementation code]\n```\nDo not give additional explanations.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"Parse LLM response to extract solution string and algorithm description\"\"\"\n        # Extract algorithm/thought from response using pattern matching\n        try:\n            pattern = r\"\\{.*?\\}\"\n            bracketed_texts = re.findall(pattern, response_str, re.DOTALL)\n            algorithm = bracketed_texts[0] if bracketed_texts else None\n        except Exception:\n            algorithm = None\n\n        # Remove only the algorithm part from response before code extraction\n        response_without_algorithm = response_str\n        if algorithm:\n            # Remove only the specific algorithm part from the response\n            response_without_algorithm = response_str.replace(algorithm, \"\", 1)\n\n        # Extract Python code block\n        patterns = [\n            r\"```python\\s*\\n(.*?)\\n```\",\n            r\"```Python\\s*\\n(.*?)\\n```\",\n            r\"```\\s*\\n(.*?)\\n```\",\n        ]\n\n        # Find all matches using case insensitive search\n        code = \"\"\n        for pattern in patterns:\n            matches = re.findall(\n                pattern, response_without_algorithm, re.DOTALL | re.IGNORECASE\n            )\n            if matches:\n                # Return the longest match (likely the most complete implementation)\n                code = max(matches, key=len).strip()\n                break\n\n        if not code:\n            # Last resort: return stripped response without algorithm\n            code = response_without_algorithm.strip()\n\n        # Store algorithm description in the solution (this would need to be handled elsewhere)\n        # For now, we just return the code\n        other_info = {\"algorithm\": algorithm}\n        return Solution(code, other_info=other_info)\n</code></pre>"},{"location":"api/interfaces/python/eoh-python-interface/#evotoolkit.task.python_task.method_interface.EoHPythonInterface.get_prompt_i1","title":"get_prompt_i1","text":"<pre><code>get_prompt_i1() -&gt; List[dict]\n</code></pre> <p>Generate initialization prompt (I1 operator).</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/eoh_interface.py</code> <pre><code>    def get_prompt_i1(self) -&gt; List[dict]:\n        \"\"\"Generate initialization prompt (I1 operator).\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        prompt = f\"\"\"\n{task_description}\n\n1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {{}}. \n2. Next, implement the following Python function:\n```python\n[Your implementation code]\n```\n\nDo not give additional explanations.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre>"},{"location":"api/interfaces/python/eoh-python-interface/#evotoolkit.task.python_task.method_interface.EoHPythonInterface.get_prompt_e2","title":"get_prompt_e2","text":"<pre><code>get_prompt_e2(\n    selected_individuals: List[Solution],\n) -&gt; List[dict]\n</code></pre> <p>Generate E2 (guided crossover) prompt.</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/eoh_interface.py</code> <pre><code>    def get_prompt_e2(self, selected_individuals: List[Solution]) -&gt; List[dict]:\n        \"\"\"Generate E2 (guided crossover) prompt.\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        # Create prompt content for all individuals\n        indivs_prompt = \"\"\n        for i, indi in enumerate(selected_individuals):\n            if \"algorithm\" in indi.other_info and indi.other_info[\"algorithm\"]:\n                algorithm_desc = indi.other_info[\"algorithm\"]\n            else:\n                algorithm_desc = f\"Python code {i + 1}\"\n            indivs_prompt += f\"No. {i + 1} algorithm and the corresponding code are:\\n{algorithm_desc}\\n{indi.sol_string}\\n\"\n\n        prompt = f\"\"\"\n{task_description}\n\nI have {len(selected_individuals)} existing algorithms with their codes as follows:\n{indivs_prompt}\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms.\n2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be inside within boxed {{}}.\n3. Thirdly, implement the kernel:\n```python\n[Your implementation code]\n```\nDo not give additional explanations.\n\"\"\"\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre>"},{"location":"api/interfaces/python/eoh-python-interface/#evotoolkit.task.python_task.method_interface.EoHPythonInterface.parse_response","title":"parse_response","text":"<pre><code>parse_response(response_str: str) -&gt; Solution\n</code></pre> <p>Parse LLM response to extract solution string and algorithm description</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/eoh_interface.py</code> <pre><code>def parse_response(self, response_str: str) -&gt; Solution:\n    \"\"\"Parse LLM response to extract solution string and algorithm description\"\"\"\n    # Extract algorithm/thought from response using pattern matching\n    try:\n        pattern = r\"\\{.*?\\}\"\n        bracketed_texts = re.findall(pattern, response_str, re.DOTALL)\n        algorithm = bracketed_texts[0] if bracketed_texts else None\n    except Exception:\n        algorithm = None\n\n    # Remove only the algorithm part from response before code extraction\n    response_without_algorithm = response_str\n    if algorithm:\n        # Remove only the specific algorithm part from the response\n        response_without_algorithm = response_str.replace(algorithm, \"\", 1)\n\n    # Extract Python code block\n    patterns = [\n        r\"```python\\s*\\n(.*?)\\n```\",\n        r\"```Python\\s*\\n(.*?)\\n```\",\n        r\"```\\s*\\n(.*?)\\n```\",\n    ]\n\n    # Find all matches using case insensitive search\n    code = \"\"\n    for pattern in patterns:\n        matches = re.findall(\n            pattern, response_without_algorithm, re.DOTALL | re.IGNORECASE\n        )\n        if matches:\n            # Return the longest match (likely the most complete implementation)\n            code = max(matches, key=len).strip()\n            break\n\n    if not code:\n        # Last resort: return stripped response without algorithm\n        code = response_without_algorithm.strip()\n\n    # Store algorithm description in the solution (this would need to be handled elsewhere)\n    # For now, we just return the code\n    other_info = {\"algorithm\": algorithm}\n    return Solution(code, other_info=other_info)\n</code></pre>"},{"location":"api/interfaces/python/evoengineer-python-interface/","title":"EvoEngineerPythonInterface","text":""},{"location":"api/interfaces/python/evoengineer-python-interface/#evotoolkit.task.python_task.method_interface.EvoEngineerPythonInterface","title":"evotoolkit.task.python_task.method_interface.EvoEngineerPythonInterface","text":"<p>               Bases: <code>EvoEngineerInterface</code></p> <p>EvoEngineer Adapter for Python code optimization tasks.</p> <p>This class provides EvoEngineer algorithm logic for Python tasks. Subclasses should implement _get_base_task_description() to define task-specific instructions.</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/evoengineer_interface.py</code> <pre><code>class EvoEngineerPythonInterface(EvoEngineerInterface):\n    \"\"\"EvoEngineer Adapter for Python code optimization tasks.\n\n    This class provides EvoEngineer algorithm logic for Python tasks.\n    Subclasses should implement _get_base_task_description() to define task-specific instructions.\n    \"\"\"\n\n    def __init__(self, task: PythonTask):\n        super().__init__(task)\n\n    def get_init_operators(self) -&gt; List[Operator]:\n        \"\"\"Get initialization operators for Python optimization\"\"\"\n        return [Operator(\"init\", 0)]\n\n    def get_offspring_operators(self) -&gt; List[Operator]:\n        \"\"\"Get offspring operators for Python optimization\"\"\"\n        return [Operator(\"crossover\", 2), Operator(\"mutation\", 1)]\n\n    def get_operator_prompt(\n        self,\n        operator_name: str,\n        selected_individuals: List[Solution],\n        current_best_sol: Solution,\n        random_thoughts: List[str],\n        **kwargs,\n    ) -&gt; List[dict]:\n        \"\"\"Generate prompt for any operator\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        if current_best_sol is None:\n            current_best_sol = self.make_init_sol()\n\n        if operator_name == \"init\":\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"{thoughts_list}\"\"\"\n\n            prompt = f\"\"\"# PYTHON FUNCTION OPTIMIZATION TASK\n{task_description}\n\n## BASELINE CODE\n**Name:** {current_best_sol.other_info[\"name\"]}\n**Score:** {current_best_sol.evaluation_res.score:.5f}\n**Current Approach:** {current_best_sol.other_info[\"thought\"]}\n**Function Code:**\n```python\n{current_best_sol.sol_string}\n```\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## OPTIMIZATION STRATEGY\n{\"Use the insights above if relevant as optimization guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\nPropose a new Python function that aims to improve the score while ensuring it returns the correct result.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```python\n[Your Python implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```python and ``` markers\n2. MAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"crossover\":\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"{thoughts_list}\"\"\"\n\n            # Build parent functions info\n            parents_info = \"\"\n            for i, parent in enumerate(selected_individuals, 1):\n                parents_info += f\"\"\"\n**Parent {i}:**\n**Name:** {parent.other_info.get(\"name\", f\"function_{i}\")}\n**Score:** {parent.evaluation_res.score if parent.evaluation_res else 0:.5f}\n**Parent Approach:** {parent.other_info.get(\"thought\", \"No thought provided\")}\n**Function Code:**\n```python\n{parent.sol_string}\n```\n\"\"\"\n\n            prompt = f\"\"\"# PYTHON FUNCTION CROSSOVER TASK\n{task_description}\n\n## BASELINE CODE\n**Name:** {current_best_sol.other_info.get(\"name\", \"current_best\")}\n**Score:** {current_best_sol.evaluation_res.score:.5f}\n**Current Approach:** {current_best_sol.other_info.get(\"thought\", \"Current best implementation\")}\n**Function Code:**\n```python\n{current_best_sol.sol_string}\n```\n\n## PARENTS TO COMBINE\n{parents_info}\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## CROSSOVER STRATEGY\nCombine the best features from both parent functions:\n{\"Use the insights above if relevant as crossover guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\n\nCreate a hybrid Python function that combines the strengths of both parents.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```python\n[Your Python implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```python and ``` markers\n2. MAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"mutation\":\n            individual = selected_individuals[0]\n\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"{thoughts_list}\"\"\"\n\n            prompt = f\"\"\"# PYTHON FUNCTION MUTATION TASK\n{task_description}\n\n## CURRENT BEST\n**Name:** {current_best_sol.other_info.get(\"name\", \"current_best\")}\n**Score:** {current_best_sol.evaluation_res.score:.5f}\n**Previous Approach:** {current_best_sol.other_info.get(\"thought\", \"Current best implementation\")}\n**Function Code:**\n```python\n{current_best_sol.sol_string}\n```\n\n## SOURCE TO MUTATE\n**Name:** {individual.other_info.get(\"name\", \"mutation_base\")}\n**Score:** {individual.evaluation_res.score if individual.evaluation_res else 0:.5f}\n**Target Approach:** {individual.other_info.get(\"thought\", \"No thought provided\")}\n**Function Code:**\n```python\n{individual.sol_string}\n```\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## MUTATION STRATEGY\nApply significant changes to the target function:\n{\"Use the insights above if relevant as mutation guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\nCreate a substantially modified version that explores new optimization directions.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```python\n[Your Python implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```python and ``` markers\n2. MAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        else:\n            raise ValueError(f\"Unknown operator: {operator_name}\")\n\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"Improved parser with multiple fallback strategies\"\"\"\n        if not response_str or not response_str.strip():\n            return Solution(\"\")\n\n        content = response_str.strip()\n\n        # Strategy 1: Standard format parsing (most reliable)\n        result = self._parse_standard_format(content)\n        if result and result[1]:  # Ensure we have code\n            return Solution(\n                result[1], other_info={\"name\": result[0], \"thought\": result[2]}\n            )\n\n        # Strategy 2: Flexible format parsing\n        result = self._parse_flexible_format(content)\n        if result and result[1]:\n            return Solution(\n                result[1], other_info={\"name\": result[0], \"thought\": result[2]}\n            )\n\n        # Strategy 3: Code block fallback\n        code = self._extract_any_code_block(content)\n        if code:\n            return Solution(\n                code, other_info={\"name\": \"extracted\", \"thought\": \"Fallback parsing\"}\n            )\n\n        # Strategy 4: Raw content (last resort)\n        return Solution(\n            content, other_info={\"name\": \"raw\", \"thought\": \"Failed to parse\"}\n        )\n\n    def _parse_standard_format(self, content: str) -&gt; tuple:\n        \"\"\"Parse standard format: name -&gt; code -&gt; thought order\"\"\"\n        # Extract name (independent pattern)\n        name_pattern = r\"^name:\\s*([^\\n\\r]+?)(?:\\n|\\r|$)\"\n        name_match = re.search(name_pattern, content, re.MULTILINE | re.IGNORECASE)\n        name = name_match.group(1).strip() if name_match else \"\"\n\n        # Extract code block (independent pattern)\n        code_pattern = r\"code:\\s*\\n*```(?:python|py)?\\\\n(.*?)```\"\n        code_match = re.search(code_pattern, content, re.DOTALL | re.IGNORECASE)\n        code = code_match.group(1).strip() if code_match else \"\"\n\n        # Extract thought (independent pattern)\n        thought_pattern = r\"thought:\\s*(.*?)$\"\n        thought_match = re.search(thought_pattern, content, re.DOTALL | re.IGNORECASE)\n        thought = thought_match.group(1).strip() if thought_match else \"\"\n\n        return (name, code, thought)\n\n    def _parse_flexible_format(self, content: str) -&gt; tuple:\n        \"\"\"More flexible parsing for variations in format\"\"\"\n        # Try to extract name anywhere in the text\n        name_pattern = r\"(?:name|Name|NAME)\\s*:?\\s*([^\\n\\r]+)\"\n        name_match = re.search(name_pattern, content, re.IGNORECASE)\n        name = name_match.group(1).strip() if name_match else \"\"\n\n        # Try to extract any code block\n        code = self._extract_any_code_block(content)\n\n        # Try to extract thought\n        thought_pattern = (\n            r\"(?:thought|Thought|THOUGHT)\\s*:?\\s*(.*?)(?=\\n(?:name|code)|$)\"\n        )\n        thought_match = re.search(thought_pattern, content, re.DOTALL | re.IGNORECASE)\n        thought = thought_match.group(1).strip() if thought_match else \"\"\n\n        return (name, code, thought)\n\n    def _extract_any_code_block(self, content: str) -&gt; str:\n        \"\"\"Extract any code block from the content\"\"\"\n        # Priority 1: Look for ```python or ```py blocks\n        python_pattern = r\"```(?:python|py)\\n(.*?)```\"\n        match = re.search(python_pattern, content, re.DOTALL | re.IGNORECASE)\n        if match:\n            return match.group(1).strip()\n\n        # Priority 2: Look for any ``` blocks\n        generic_pattern = r\"```[^\\n]*\\n(.*?)```\"\n        match = re.search(generic_pattern, content, re.DOTALL)\n        if match:\n            return match.group(1).strip()\n\n        # Priority 3: Look for code: section without proper markers\n        code_pattern = r\"code:\\s*\\n*(.*?)(?=\\n(?:thought|$))\"\n        match = re.search(code_pattern, content, re.DOTALL | re.IGNORECASE)\n        if match:\n            code_content = match.group(1).strip()\n            # Remove any remaining ``` markers\n            code_content = re.sub(r\"^```[^\\n]*\\n?\", \"\", code_content)\n            code_content = re.sub(r\"\\n?```\\s*$\", \"\", code_content)\n            return code_content.strip()\n\n        return \"\"\n</code></pre>"},{"location":"api/interfaces/python/evoengineer-python-interface/#evotoolkit.task.python_task.method_interface.EvoEngineerPythonInterface.get_init_operators","title":"get_init_operators","text":"<pre><code>get_init_operators() -&gt; List[Operator]\n</code></pre> <p>Get initialization operators for Python optimization</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/evoengineer_interface.py</code> <pre><code>def get_init_operators(self) -&gt; List[Operator]:\n    \"\"\"Get initialization operators for Python optimization\"\"\"\n    return [Operator(\"init\", 0)]\n</code></pre>"},{"location":"api/interfaces/python/evoengineer-python-interface/#evotoolkit.task.python_task.method_interface.EvoEngineerPythonInterface.get_offspring_operators","title":"get_offspring_operators","text":"<pre><code>get_offspring_operators() -&gt; List[Operator]\n</code></pre> <p>Get offspring operators for Python optimization</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/evoengineer_interface.py</code> <pre><code>def get_offspring_operators(self) -&gt; List[Operator]:\n    \"\"\"Get offspring operators for Python optimization\"\"\"\n    return [Operator(\"crossover\", 2), Operator(\"mutation\", 1)]\n</code></pre>"},{"location":"api/interfaces/python/evoengineer-python-interface/#evotoolkit.task.python_task.method_interface.EvoEngineerPythonInterface.get_operator_prompt","title":"get_operator_prompt","text":"<pre><code>get_operator_prompt(\n    operator_name: str,\n    selected_individuals: List[Solution],\n    current_best_sol: Solution,\n    random_thoughts: List[str],\n    **kwargs,\n) -&gt; List[dict]\n</code></pre> <p>Generate prompt for any operator</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/evoengineer_interface.py</code> <pre><code>    def get_operator_prompt(\n        self,\n        operator_name: str,\n        selected_individuals: List[Solution],\n        current_best_sol: Solution,\n        random_thoughts: List[str],\n        **kwargs,\n    ) -&gt; List[dict]:\n        \"\"\"Generate prompt for any operator\"\"\"\n        task_description = self.task.get_base_task_description()\n\n        if current_best_sol is None:\n            current_best_sol = self.make_init_sol()\n\n        if operator_name == \"init\":\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"{thoughts_list}\"\"\"\n\n            prompt = f\"\"\"# PYTHON FUNCTION OPTIMIZATION TASK\n{task_description}\n\n## BASELINE CODE\n**Name:** {current_best_sol.other_info[\"name\"]}\n**Score:** {current_best_sol.evaluation_res.score:.5f}\n**Current Approach:** {current_best_sol.other_info[\"thought\"]}\n**Function Code:**\n```python\n{current_best_sol.sol_string}\n```\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## OPTIMIZATION STRATEGY\n{\"Use the insights above if relevant as optimization guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\nPropose a new Python function that aims to improve the score while ensuring it returns the correct result.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```python\n[Your Python implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```python and ``` markers\n2. MAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"crossover\":\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"{thoughts_list}\"\"\"\n\n            # Build parent functions info\n            parents_info = \"\"\n            for i, parent in enumerate(selected_individuals, 1):\n                parents_info += f\"\"\"\n**Parent {i}:**\n**Name:** {parent.other_info.get(\"name\", f\"function_{i}\")}\n**Score:** {parent.evaluation_res.score if parent.evaluation_res else 0:.5f}\n**Parent Approach:** {parent.other_info.get(\"thought\", \"No thought provided\")}\n**Function Code:**\n```python\n{parent.sol_string}\n```\n\"\"\"\n\n            prompt = f\"\"\"# PYTHON FUNCTION CROSSOVER TASK\n{task_description}\n\n## BASELINE CODE\n**Name:** {current_best_sol.other_info.get(\"name\", \"current_best\")}\n**Score:** {current_best_sol.evaluation_res.score:.5f}\n**Current Approach:** {current_best_sol.other_info.get(\"thought\", \"Current best implementation\")}\n**Function Code:**\n```python\n{current_best_sol.sol_string}\n```\n\n## PARENTS TO COMBINE\n{parents_info}\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## CROSSOVER STRATEGY\nCombine the best features from both parent functions:\n{\"Use the insights above if relevant as crossover guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\n\nCreate a hybrid Python function that combines the strengths of both parents.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```python\n[Your Python implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```python and ``` markers\n2. MAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"mutation\":\n            individual = selected_individuals[0]\n\n            # Build the thoughts section if available\n            thoughts_section = \"\"\n            if random_thoughts and len(random_thoughts) &gt; 0:\n                thoughts_list = \"\\n\".join(\n                    [f\"- {thought}\" for thought in random_thoughts]\n                )\n                thoughts_section = f\"\"\"{thoughts_list}\"\"\"\n\n            prompt = f\"\"\"# PYTHON FUNCTION MUTATION TASK\n{task_description}\n\n## CURRENT BEST\n**Name:** {current_best_sol.other_info.get(\"name\", \"current_best\")}\n**Score:** {current_best_sol.evaluation_res.score:.5f}\n**Previous Approach:** {current_best_sol.other_info.get(\"thought\", \"Current best implementation\")}\n**Function Code:**\n```python\n{current_best_sol.sol_string}\n```\n\n## SOURCE TO MUTATE\n**Name:** {individual.other_info.get(\"name\", \"mutation_base\")}\n**Score:** {individual.evaluation_res.score if individual.evaluation_res else 0:.5f}\n**Target Approach:** {individual.other_info.get(\"thought\", \"No thought provided\")}\n**Function Code:**\n```python\n{individual.sol_string}\n```\n\n## OPTIMIZATION INSIGHTS\n{thoughts_section}\n\n## MUTATION STRATEGY\nApply significant changes to the target function:\n{\"Use the insights above if relevant as mutation guidance.\" if random_thoughts and len(random_thoughts) &gt; 0 else \"\"}\nCreate a substantially modified version that explores new optimization directions.\n\n## RESPONSE FORMAT:\nname: [descriptive_name_with_underscores]\ncode:\n```python\n[Your Python implementation]\n```\nthought: [The rationale for the improvement idea.]\n\n## FORMAT REQUIREMENTS:\n1. The code MUST be wrapped in ```python and ``` markers\n2. MAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        else:\n            raise ValueError(f\"Unknown operator: {operator_name}\")\n</code></pre>"},{"location":"api/interfaces/python/evoengineer-python-interface/#evotoolkit.task.python_task.method_interface.EvoEngineerPythonInterface.parse_response","title":"parse_response","text":"<pre><code>parse_response(response_str: str) -&gt; Solution\n</code></pre> <p>Improved parser with multiple fallback strategies</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/evoengineer_interface.py</code> <pre><code>def parse_response(self, response_str: str) -&gt; Solution:\n    \"\"\"Improved parser with multiple fallback strategies\"\"\"\n    if not response_str or not response_str.strip():\n        return Solution(\"\")\n\n    content = response_str.strip()\n\n    # Strategy 1: Standard format parsing (most reliable)\n    result = self._parse_standard_format(content)\n    if result and result[1]:  # Ensure we have code\n        return Solution(\n            result[1], other_info={\"name\": result[0], \"thought\": result[2]}\n        )\n\n    # Strategy 2: Flexible format parsing\n    result = self._parse_flexible_format(content)\n    if result and result[1]:\n        return Solution(\n            result[1], other_info={\"name\": result[0], \"thought\": result[2]}\n        )\n\n    # Strategy 3: Code block fallback\n    code = self._extract_any_code_block(content)\n    if code:\n        return Solution(\n            code, other_info={\"name\": \"extracted\", \"thought\": \"Fallback parsing\"}\n        )\n\n    # Strategy 4: Raw content (last resort)\n    return Solution(\n        content, other_info={\"name\": \"raw\", \"thought\": \"Failed to parse\"}\n    )\n</code></pre>"},{"location":"api/interfaces/python/funsearch-python-interface/","title":"FunSearchPythonInterface","text":""},{"location":"api/interfaces/python/funsearch-python-interface/#evotoolkit.task.python_task.method_interface.FunSearchPythonInterface","title":"evotoolkit.task.python_task.method_interface.FunSearchPythonInterface","text":"<p>               Bases: <code>FunSearchInterface</code></p> <p>FunSearch Adapter for Python code optimization tasks.</p> <p>This class provides common FunSearch logic for Python tasks. Subclasses only need to implement _get_system_prompt() to define task-specific instructions.</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/funsearch_interface.py</code> <pre><code>class FunSearchPythonInterface(FunSearchInterface):\n    \"\"\"FunSearch Adapter for Python code optimization tasks.\n\n    This class provides common FunSearch logic for Python tasks.\n    Subclasses only need to implement _get_system_prompt() to define task-specific instructions.\n    \"\"\"\n\n    def __init__(self, task: PythonTask):\n        super().__init__(task)\n\n    def get_prompt(self, solutions: List[Solution]) -&gt; List[dict]:\n        \"\"\"Generate prompt based on multiple solutions (similar to CUDA implementation)\"\"\"\n        task_description = self.task.get_base_task_description()\n        if len(solutions) == 1:\n            prompt = f\"\"\"\n{task_description}\n\nHere is the Python code example you need to optimize:\n```python\n{solutions[0].sol_string}\n```\n\nPropose a new Python code which performs better than the above code.\n\nAnswer using the following schema:\n\n```python\n[Your Python implementation]\n```\n\nMAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        elif len(solutions) &gt;= 2:\n            prompt = f\"\"\"\n{task_description}\n\nHere is a Python code example:\n```python\n{solutions[0].sol_string}\n```\n\nA better version of the Python code example is as follows:\n```python\n{solutions[1].sol_string}\n```\n\nPropose a new Python code which performs better than the above code.\n\nAnswer using the following schema:\n\n```python\n[Your Python implementation]\n```\n\nMAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        else:\n            # Fallback if no solutions provided\n            prompt = f\"\"\"\n{task_description}\n\nPropose a new Python code which performs better than the above code.\n\nAnswer using the following schema:\n\n```python\n[Your Python implementation]\n```\nMAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n\n        prompt_content = [{\"role\": \"user\", \"content\": prompt}]\n        return prompt_content\n\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"Parse LLM response to extract CUDA code\"\"\"\n        # Try different code block patterns in order of preference\n        patterns = [\n            r\"```python\\s*\\n(.*?)\\n```\",\n            r\"```Python\\s*\\n(.*?)\\n```\",\n            r\"```\\s*\\n(.*?)\\n```\",  # generic code block\n        ]\n\n        # Find all matches using case insensitive search\n        for pattern in patterns:\n            matches = re.findall(pattern, response_str, re.DOTALL | re.IGNORECASE)\n            if matches:\n                # Return the longest match (likely the most complete implementation)\n                return Solution(max(matches, key=len).strip())\n\n        # Last resort: return stripped response\n        return Solution(response_str.strip())\n</code></pre>"},{"location":"api/interfaces/python/funsearch-python-interface/#evotoolkit.task.python_task.method_interface.FunSearchPythonInterface.get_prompt","title":"get_prompt","text":"<pre><code>get_prompt(solutions: List[Solution]) -&gt; List[dict]\n</code></pre> <p>Generate prompt based on multiple solutions (similar to CUDA implementation)</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/funsearch_interface.py</code> <pre><code>    def get_prompt(self, solutions: List[Solution]) -&gt; List[dict]:\n        \"\"\"Generate prompt based on multiple solutions (similar to CUDA implementation)\"\"\"\n        task_description = self.task.get_base_task_description()\n        if len(solutions) == 1:\n            prompt = f\"\"\"\n{task_description}\n\nHere is the Python code example you need to optimize:\n```python\n{solutions[0].sol_string}\n```\n\nPropose a new Python code which performs better than the above code.\n\nAnswer using the following schema:\n\n```python\n[Your Python implementation]\n```\n\nMAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        elif len(solutions) &gt;= 2:\n            prompt = f\"\"\"\n{task_description}\n\nHere is a Python code example:\n```python\n{solutions[0].sol_string}\n```\n\nA better version of the Python code example is as follows:\n```python\n{solutions[1].sol_string}\n```\n\nPropose a new Python code which performs better than the above code.\n\nAnswer using the following schema:\n\n```python\n[Your Python implementation]\n```\n\nMAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n        else:\n            # Fallback if no solutions provided\n            prompt = f\"\"\"\n{task_description}\n\nPropose a new Python code which performs better than the above code.\n\nAnswer using the following schema:\n\n```python\n[Your Python implementation]\n```\nMAKE SURE THE PROPOSAL CODE IS VALID PYTHON CODE.\nFOLLOW EXACTLY THIS FORMAT. DO NOT ADD ANYTHING ELSE.\n\"\"\"\n\n        prompt_content = [{\"role\": \"user\", \"content\": prompt}]\n        return prompt_content\n</code></pre>"},{"location":"api/interfaces/python/funsearch-python-interface/#evotoolkit.task.python_task.method_interface.FunSearchPythonInterface.parse_response","title":"parse_response","text":"<pre><code>parse_response(response_str: str) -&gt; Solution\n</code></pre> <p>Parse LLM response to extract CUDA code</p> Source code in <code>src/evotoolkit/task/python_task/method_interface/funsearch_interface.py</code> <pre><code>def parse_response(self, response_str: str) -&gt; Solution:\n    \"\"\"Parse LLM response to extract CUDA code\"\"\"\n    # Try different code block patterns in order of preference\n    patterns = [\n        r\"```python\\s*\\n(.*?)\\n```\",\n        r\"```Python\\s*\\n(.*?)\\n```\",\n        r\"```\\s*\\n(.*?)\\n```\",  # generic code block\n    ]\n\n    # Find all matches using case insensitive search\n    for pattern in patterns:\n        matches = re.findall(pattern, response_str, re.DOTALL | re.IGNORECASE)\n        if matches:\n            # Return the longest match (likely the most complete implementation)\n            return Solution(max(matches, key=len).strip())\n\n    # Last resort: return stripped response\n    return Solution(response_str.strip())\n</code></pre>"},{"location":"api/methods/eoh/","title":"EoH (Evolution of Heuristics)","text":""},{"location":"api/methods/eoh/#evotoolkit.evo_method.eoh.EoH","title":"evotoolkit.evo_method.eoh.EoH","text":"<p>               Bases: <code>Method</code></p> Source code in <code>src/evotoolkit/evo_method/eoh/eoh.py</code> <pre><code>@register_algorithm(\"eoh\", config=EoHConfig)\nclass EoH(Method):\n    def __init__(self, config: EoHConfig):\n        super().__init__(config)\n        self.config = config\n\n    def run(self):\n        \"\"\"Main EoH algorithm execution\"\"\"\n        self.verbose_title(\"EOH ALGORITHM STARTED\")\n\n        if \"sample\" not in self.run_state_dict.usage_history:\n            self.run_state_dict.usage_history[\"sample\"] = []\n\n        # Initialize with seed solution if sol_history is empty\n        if len(self.run_state_dict.sol_history) == 0:\n            init_sol = self._get_init_sol()\n            if init_sol is None:\n                exit()\n            self.run_state_dict.sol_history.append(init_sol)\n            self.run_state_dict.population.append(init_sol)\n            self._save_run_state_dict()\n            self.verbose_info(\n                f\"Initialized with baseline solution (score: {init_sol.evaluation_res.score if init_sol.evaluation_res else 'None'})\"\n            )\n\n        # Initialize population if starting from scratch\n        if self.run_state_dict.generation == 0:\n            self._initialize_population()\n\n        # Check if we have enough individuals for selection\n        valid_population = self._get_valid_population(self.run_state_dict.population)\n        if len(valid_population) &lt; self.config.selection_num:\n            self.verbose_info(\n                f\"The search is terminated since EoH unable to obtain {self.config.selection_num} feasible algorithms during initialization.\"\n            )\n            return\n\n        # Main evolution loop - moved loop control logic here\n        while (self.run_state_dict.generation &lt; self.config.max_generations) and (\n            self.run_state_dict.tot_sample_nums &lt; self.config.max_sample_nums\n        ):\n            try:\n                self.verbose_info(\n                    f\"Generation {self.run_state_dict.generation} - Sample {self.run_state_dict.tot_sample_nums + 1} - {self.run_state_dict.tot_sample_nums + self.config.num_samplers} / {self.config.max_sample_nums or 'unlimited'}\"\n                )\n\n                # Apply operators in parallel for this generation\n                new_solutions = self._apply_operators_parallel()\n\n                # Add new solutions to both sol_history and population\n                for sol in new_solutions:\n                    self.run_state_dict.sol_history.append(sol)\n                    self.run_state_dict.population.append(sol)\n                    self.run_state_dict.current_gen_solutions.append(\n                        sol\n                    )  # \u6dfb\u52a0\u5230\u5f53\u524d\u4ee3\u5386\u53f2\n                    self.run_state_dict.tot_sample_nums += 1\n\n                # Manage population size - keep only the best pop_size individuals\n                self._manage_population_size()\n\n                self.run_state_dict.generation += 1\n                self._save_run_state_dict()\n\n            except KeyboardInterrupt:\n                self.verbose_info(\"Evolution interrupted by user\")\n                break\n            except Exception as e:\n                self.verbose_info(f\"Evolution error: {str(e)}\")\n                continue\n\n        # Mark as done and save final state\n        self.run_state_dict.is_done = True\n        self._save_run_state_dict()\n\n    def _initialize_population(self):\n        \"\"\"Initialize population using i1 prompt - keep generating until we have enough valid solutions\"\"\"\n        self.verbose_info(\"Initializing population...\")\n\n        initial_sample_limit = self.config.max_sample_nums  # Reasonable limit\n\n        # Keep generating until we have pop_size valid solutions or hit sample limit\n        while (\n            len(self._get_valid_population(self.run_state_dict.population))\n            &lt; self.config.pop_size\n            and self.run_state_dict.tot_sample_nums &lt; initial_sample_limit\n        ):\n            # Generate and immediately evaluate solutions in parallel\n            evaluated_solutions = self._generate_and_evaluate_initial_solutions()\n\n            # Add all solutions to both sol_history and population\n            for sol in evaluated_solutions:\n                self.run_state_dict.sol_history.append(sol)\n                self.run_state_dict.population.append(sol)\n                self.run_state_dict.current_gen_solutions.append(\n                    sol\n                )  # \u6dfb\u52a0\u5230\u5f53\u524d\u4ee3\u5386\u53f2\n                self.run_state_dict.tot_sample_nums += 1\n\n                score_str = (\n                    \"None\"\n                    if not sol.evaluation_res or sol.evaluation_res.score is None\n                    else f\"{sol.evaluation_res.score}\"\n                )\n                valid_str = (\n                    \"Valid\"\n                    if sol.evaluation_res and sol.evaluation_res.valid\n                    else \"Invalid\"\n                )\n                self.verbose_info(\n                    f\"Initial sample {self.run_state_dict.tot_sample_nums} - Score: {score_str} ({valid_str})\"\n                )\n\n            valid_count = len(\n                self._get_valid_population(self.run_state_dict.population)\n            )\n            self.verbose_info(f\"Valid solutions: {valid_count}/{self.config.pop_size}\")\n\n            self._save_run_state_dict()\n\n        valid_population = self._get_valid_population(self.run_state_dict.population)\n        if len(valid_population) &gt;= self.config.selection_num:\n            self.run_state_dict.generation = 1\n            self._save_run_state_dict()\n            self.verbose_info(\n                f\"Initialization completed with {len(valid_population)} valid solutions\"\n            )\n        else:\n            self.verbose_info(\n                f\"Warning: Only {len(valid_population)} valid solutions obtained, need at least {self.config.selection_num}\"\n            )\n\n    def _generate_and_evaluate_initial_solutions(self) -&gt; List[Solution]:\n        \"\"\"Generate and immediately evaluate initial solutions using single executor\"\"\"\n        evaluated_solutions = []\n\n        # Single executor for both generation and evaluation\n        with concurrent.futures.ThreadPoolExecutor(\n            max_workers=self.config.num_samplers + self.config.num_evaluators\n        ) as executor:\n            # Submit all generation tasks\n            generate_futures = []\n            eval_futures = []\n\n            for sampler_id in range(self.config.num_samplers):\n                future = executor.submit(\n                    self._generate_single_initial_solution, sampler_id\n                )\n                generate_futures.append(future)\n\n            # Process generations as they complete and immediately submit for evaluation\n            for future in concurrent.futures.as_completed(generate_futures):\n                try:\n                    new_sol, usage = future.result()\n                    self.run_state_dict.usage_history[\"sample\"].append(usage)\n                    self.run_state_dict.current_gen_usage.append(\n                        usage\n                    )  # \u6dfb\u52a0\u5230\u5f53\u524d\u4ee3usage\u5386\u53f2\n\n                    # Immediately submit for evaluation without waiting\n                    if new_sol.sol_string.strip():  # Only evaluate non-empty solutions\n                        eval_future = executor.submit(\n                            self.config.task.evaluate_code, new_sol.sol_string\n                        )\n                        eval_futures.append((eval_future, new_sol))\n                    else:\n                        evaluated_solutions.append(new_sol)\n                except Exception as e:\n                    self.verbose_info(f\"Initial solution generation failed: {str(e)}\")\n                    continue\n\n            # Collect evaluation results\n            for eval_future, solution in eval_futures:\n                try:\n                    evaluation_res = eval_future.result()\n                    solution.evaluation_res = evaluation_res\n                    evaluated_solutions.append(solution)\n                except Exception as e:\n                    self.verbose_info(f\"Evaluation failed: {str(e)}\")\n                    evaluated_solutions.append(\n                        solution\n                    )  # Add with no evaluation result\n                    continue\n\n        return evaluated_solutions\n\n    def _generate_single_initial_solution(\n        self, sampler_id: int\n    ) -&gt; tuple[Solution, dict]:\n        \"\"\"Generate a single initial solution\"\"\"\n        try:\n            prompt_content = self.config.interface.get_prompt_i1()\n            response, usage = self.config.running_llm.get_response(prompt_content)\n            new_sol = self.config.interface.parse_response(response)\n            self.verbose_info(f\"Sampler {sampler_id}: Generated initial solution\")\n            return new_sol, usage\n        except Exception as e:\n            self.verbose_info(\n                f\"Sampler {sampler_id}: Failed to generate initial solution - {str(e)}\"\n            )\n            return Solution(\"\"), {}\n\n    def _evaluate_solutions(self, solutions: List[Solution]) -&gt; List[Solution]:\n        \"\"\"Evaluate solutions using multithreading\"\"\"\n        with concurrent.futures.ThreadPoolExecutor(\n            max_workers=self.config.num_evaluators\n        ) as executor:\n            futures = []\n            for i, solution in enumerate(solutions):\n                if solution.sol_string.strip():  # Only evaluate non-empty solutions\n                    future = executor.submit(\n                        self.config.task.evaluate_code, solution.sol_string\n                    )\n                    futures.append((future, i))\n\n            # Collect results\n            for future, i in futures:\n                try:\n                    evaluation_res = future.result()\n                    solutions[i].evaluation_res = evaluation_res\n                except Exception as e:\n                    self.verbose_info(f\"Evaluation failed: {str(e)}\")\n                    continue\n\n        return solutions\n\n    def _get_valid_population(self, population: List[Solution]) -&gt; List[Solution]:\n        \"\"\"Get valid solutions from population\"\"\"\n        return [\n            sol for sol in population if sol.evaluation_res and sol.evaluation_res.valid\n        ]\n\n    def _get_best_valid_sol(self, sol_history: List[Solution]) -&gt; Solution:\n        \"\"\"Get the best valid solution from sol_history\"\"\"\n        valid_sols = [\n            sol\n            for sol in sol_history\n            if sol.evaluation_res\n            and sol.evaluation_res.valid\n            and sol.evaluation_res.score is not None\n        ]\n        if valid_sols:\n            return max(valid_sols, key=lambda x: x.evaluation_res.score)\n        return sol_history[-1] if sol_history else None\n\n    def _apply_operators_parallel(self) -&gt; List[Solution]:\n        \"\"\"Apply all operators in parallel and return new solutions\"\"\"\n        new_solutions = []\n\n        # Prepare operator tasks\n        operator_tasks = []\n\n        # E1 operator - crossover\n        selected_individuals = self._select_individuals(self.config.selection_num)\n        if selected_individuals:\n            prompt_content = self.config.interface.get_prompt_e1(selected_individuals)\n            operator_tasks.append((\"E1\", prompt_content))\n\n        # E2 operator - guided crossover\n        if self.config.use_e2_operator:\n            selected_individuals = self._select_individuals(self.config.selection_num)\n            if selected_individuals:\n                prompt_content = self.config.interface.get_prompt_e2(\n                    selected_individuals\n                )\n                operator_tasks.append((\"E2\", prompt_content))\n\n        # M1 operator - mutation\n        if self.config.use_m1_operator:\n            selected_individuals = self._select_individuals(1)\n            if selected_individuals:\n                selected_individual = selected_individuals[0]\n                prompt_content = self.config.interface.get_prompt_m1(\n                    selected_individual\n                )\n                operator_tasks.append((\"M1\", prompt_content))\n\n        # M2 operator - parameter mutation\n        if self.config.use_m2_operator:\n            selected_individuals = self._select_individuals(1)\n            if selected_individuals:\n                selected_individual = selected_individuals[0]\n                prompt_content = self.config.interface.get_prompt_m2(\n                    selected_individual\n                )\n                operator_tasks.append((\"M2\", prompt_content))\n\n        # Execute operators and evaluate in parallel using single executor\n        if operator_tasks:\n            # Single executor for both generation and evaluation\n            with concurrent.futures.ThreadPoolExecutor(\n                max_workers=self.config.num_samplers + self.config.num_evaluators\n            ) as executor:\n                generate_futures = []\n                eval_futures = []\n\n                # Calculate samples per operator to maintain balanced distribution\n                num_operators = len(operator_tasks)\n\n                # Calculate target samples: multiple of num_operators, not exceeding num_samplers\n                max_multiplier = self.config.num_samplers // num_operators\n                target_samples = (\n                    max_multiplier * num_operators\n                )  # Largest multiple of num_operators &lt;= num_samplers\n                samples_per_operator = (\n                    target_samples // num_operators\n                )  # This equals max_multiplier\n\n                # Generate samples: each operator gets exactly samples_per_operator samples\n                sample_id = 0\n                for operator_name, prompt_content in operator_tasks:\n                    for _ in range(samples_per_operator):\n                        future = executor.submit(\n                            self._generate_single_operator_solution,\n                            prompt_content,\n                            operator_name,\n                            sample_id,\n                        )\n                        generate_futures.append((operator_name, future))\n                        sample_id += 1\n\n                # Process generations as they complete and immediately submit for evaluation\n                future_to_operator = {\n                    future: operator_name for operator_name, future in generate_futures\n                }\n                for future in concurrent.futures.as_completed(\n                    [f for _, f in generate_futures]\n                ):\n                    operator_name = future_to_operator[future]\n                    try:\n                        solution, usage = future.result()\n\n                        # Add usage history\n                        self.run_state_dict.usage_history[\"sample\"].append(usage)\n                        self.run_state_dict.current_gen_usage.append(\n                            usage\n                        )  # \u6dfb\u52a0\u5230\u5f53\u524d\u4ee3usage\u5386\u53f2\n\n                        # Immediately submit for evaluation without waiting\n                        if solution.sol_string.strip():\n                            eval_future = executor.submit(\n                                self.config.task.evaluate_code, solution.sol_string\n                            )\n                            eval_futures.append((eval_future, solution, operator_name))\n                        else:\n                            new_solutions.append(solution)\n                            # Log result for empty solution\n                            self.verbose_info(\n                                f\"{operator_name} Gen {self.run_state_dict.generation} - Score: None (Invalid)\"\n                            )\n\n                    except Exception as e:\n                        self.verbose_info(f\"Error generating {operator_name}: {str(e)}\")\n                        continue\n\n                # Collect evaluation results\n                for eval_future, solution, operator_name in eval_futures:\n                    try:\n                        evaluation_res = eval_future.result()\n                        solution.evaluation_res = evaluation_res\n                        new_solutions.append(solution)\n\n                        # Log result\n                        score_str = (\n                            \"None\"\n                            if not solution.evaluation_res\n                            or solution.evaluation_res.score is None\n                            else f\"{solution.evaluation_res.score}\"\n                        )\n                        valid_str = (\n                            \"Valid\"\n                            if solution.evaluation_res and solution.evaluation_res.valid\n                            else \"Invalid\"\n                        )\n                        self.verbose_info(\n                            f\"{operator_name} Gen {self.run_state_dict.generation} - Score: {score_str} ({valid_str})\"\n                        )\n\n                    except Exception as e:\n                        self.verbose_info(f\"Error evaluating {operator_name}: {str(e)}\")\n                        new_solutions.append(solution)  # Add with no evaluation result\n                        continue\n\n        return new_solutions\n\n    def _manage_population_size(self):\n        \"\"\"Manage population size - keep only the best pop_size individuals\"\"\"\n        if len(self.run_state_dict.population) &lt;= self.config.pop_size:\n            return\n\n        # Separate valid and invalid solutions\n        valid_solutions = self._get_valid_population(self.run_state_dict.population)\n        invalid_solutions = [\n            sol for sol in self.run_state_dict.population if sol not in valid_solutions\n        ]\n\n        # Sort valid solutions by score (descending - higher is better)\n        valid_solutions.sort(\n            key=lambda x: x.evaluation_res.score\n            if x.evaluation_res and x.evaluation_res.score is not None\n            else float(\"-inf\"),\n            reverse=True,\n        )\n\n        # Keep the best valid solutions + some invalid ones if needed\n        new_population = []\n\n        # First, add the best valid solutions\n        valid_to_keep = min(len(valid_solutions), self.config.pop_size)\n        new_population.extend(valid_solutions[:valid_to_keep])\n\n        # If we need more individuals, add some invalid ones (most recent)\n        remaining_slots = self.config.pop_size - len(new_population)\n        if remaining_slots &gt; 0 and invalid_solutions:\n            new_population.extend(\n                invalid_solutions[-remaining_slots:]\n            )  # Keep most recent invalid ones\n\n        self.run_state_dict.population = new_population\n\n        valid_count = len(self._get_valid_population(new_population))\n        self.verbose_info(\n            f\"Population managed: {len(new_population)} total ({valid_count} valid, {len(new_population) - valid_count} invalid)\"\n        )\n\n    def _select_individuals(self, num_select: int) -&gt; List[Solution]:\n        \"\"\"Select individuals from population using rank-based probability selection\"\"\"\n        import math\n\n        import numpy as np\n\n        # Handle edge cases\n        if num_select &lt;= 0:\n            return []\n\n        # Filter valid solutions with finite scores (including NaN check)\n        funcs = [\n            sol\n            for sol in self.run_state_dict.population\n            if sol.evaluation_res\n            and sol.evaluation_res.valid\n            and sol.evaluation_res.score is not None\n            and not math.isinf(sol.evaluation_res.score)\n            and not math.isnan(sol.evaluation_res.score)\n        ]\n\n        if len(funcs) == 0:\n            # Fallback to any available solutions\n            return (\n                self.run_state_dict.population[:num_select]\n                if self.run_state_dict.population\n                else []\n            )\n\n        # Sort by score (assuming higher is better)\n        func = sorted(funcs, key=lambda f: f.evaluation_res.score, reverse=True)\n\n        # Create rank-based probability distribution\n        p = [1 / (r + len(func)) for r in range(len(func))]\n        p = np.array(p)\n        p = p / np.sum(p)\n\n        # Select individuals based on probability\n        selected = []\n        for _ in range(\n            min(num_select, len(func))\n        ):  # Ensure we don't select more than available\n            chosen = np.random.choice(func, p=p)\n            selected.append(chosen)\n\n        return selected\n\n    def _generate_single_operator_solution(\n        self, prompt_content: List[dict], operator_type: str, sampler_id: int\n    ) -&gt; tuple[Solution, dict]:\n        \"\"\"Generate a single solution for an operator\"\"\"\n        try:\n            response, usage = self.config.running_llm.get_response(prompt_content)\n            new_sol = self.config.interface.parse_response(response)\n            self.verbose_info(\n                f\"Sampler {sampler_id}: Generated {operator_type} solution\"\n            )\n            return new_sol, usage\n        except Exception as e:\n            self.verbose_info(\n                f\"Sampler {sampler_id}: Failed to generate {operator_type} solution - {str(e)}\"\n            )\n            return Solution(\"\"), {}\n\n    def _get_run_state_class(self) -&gt; Type[BaseRunStateDict]:\n        return EoHRunStateDict\n</code></pre>"},{"location":"api/methods/eoh/#evotoolkit.evo_method.eoh.EoH.run","title":"run","text":"<pre><code>run()\n</code></pre> <p>Main EoH algorithm execution</p> Source code in <code>src/evotoolkit/evo_method/eoh/eoh.py</code> <pre><code>def run(self):\n    \"\"\"Main EoH algorithm execution\"\"\"\n    self.verbose_title(\"EOH ALGORITHM STARTED\")\n\n    if \"sample\" not in self.run_state_dict.usage_history:\n        self.run_state_dict.usage_history[\"sample\"] = []\n\n    # Initialize with seed solution if sol_history is empty\n    if len(self.run_state_dict.sol_history) == 0:\n        init_sol = self._get_init_sol()\n        if init_sol is None:\n            exit()\n        self.run_state_dict.sol_history.append(init_sol)\n        self.run_state_dict.population.append(init_sol)\n        self._save_run_state_dict()\n        self.verbose_info(\n            f\"Initialized with baseline solution (score: {init_sol.evaluation_res.score if init_sol.evaluation_res else 'None'})\"\n        )\n\n    # Initialize population if starting from scratch\n    if self.run_state_dict.generation == 0:\n        self._initialize_population()\n\n    # Check if we have enough individuals for selection\n    valid_population = self._get_valid_population(self.run_state_dict.population)\n    if len(valid_population) &lt; self.config.selection_num:\n        self.verbose_info(\n            f\"The search is terminated since EoH unable to obtain {self.config.selection_num} feasible algorithms during initialization.\"\n        )\n        return\n\n    # Main evolution loop - moved loop control logic here\n    while (self.run_state_dict.generation &lt; self.config.max_generations) and (\n        self.run_state_dict.tot_sample_nums &lt; self.config.max_sample_nums\n    ):\n        try:\n            self.verbose_info(\n                f\"Generation {self.run_state_dict.generation} - Sample {self.run_state_dict.tot_sample_nums + 1} - {self.run_state_dict.tot_sample_nums + self.config.num_samplers} / {self.config.max_sample_nums or 'unlimited'}\"\n            )\n\n            # Apply operators in parallel for this generation\n            new_solutions = self._apply_operators_parallel()\n\n            # Add new solutions to both sol_history and population\n            for sol in new_solutions:\n                self.run_state_dict.sol_history.append(sol)\n                self.run_state_dict.population.append(sol)\n                self.run_state_dict.current_gen_solutions.append(\n                    sol\n                )  # \u6dfb\u52a0\u5230\u5f53\u524d\u4ee3\u5386\u53f2\n                self.run_state_dict.tot_sample_nums += 1\n\n            # Manage population size - keep only the best pop_size individuals\n            self._manage_population_size()\n\n            self.run_state_dict.generation += 1\n            self._save_run_state_dict()\n\n        except KeyboardInterrupt:\n            self.verbose_info(\"Evolution interrupted by user\")\n            break\n        except Exception as e:\n            self.verbose_info(f\"Evolution error: {str(e)}\")\n            continue\n\n    # Mark as done and save final state\n    self.run_state_dict.is_done = True\n    self._save_run_state_dict()\n</code></pre>"},{"location":"api/methods/eoh/#configuration","title":"Configuration","text":""},{"location":"api/methods/eoh/#evotoolkit.evo_method.eoh.EoHConfig","title":"evotoolkit.evo_method.eoh.EoHConfig","text":"<p>               Bases: <code>BaseConfig</code></p> Source code in <code>src/evotoolkit/evo_method/eoh/run_config.py</code> <pre><code>class EoHConfig(BaseConfig):\n    def __init__(\n        self,\n        interface: EoHInterface,\n        output_path: str,\n        running_llm: HttpsApi,\n        verbose: bool = True,\n        max_generations: int = 10,\n        max_sample_nums: int = 45,\n        pop_size: int = 5,\n        selection_num: int = 2,\n        use_e2_operator: bool = True,\n        use_m1_operator: bool = True,\n        use_m2_operator: bool = True,\n        num_samplers: int = 5,\n        num_evaluators: int = 5,\n    ):\n        super().__init__(interface, output_path, verbose)\n        self.running_llm = running_llm\n        self.max_generations = max_generations\n        self.max_sample_nums = max_sample_nums\n        self.pop_size = pop_size\n        self.selection_num = selection_num\n        self.use_e2_operator = use_e2_operator\n        self.use_m1_operator = use_m1_operator\n        self.use_m2_operator = use_m2_operator\n        self.num_samplers = num_samplers\n        self.num_evaluators = num_evaluators\n</code></pre>"},{"location":"api/methods/eoh/#usage","title":"Usage","text":"<pre><code>from evotoolkit.task.python_task import EoHPythonInterface\nimport evotoolkit\n\ninterface = EoHPythonInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    max_sample_nums=15\n)\n</code></pre>"},{"location":"api/methods/evoengineer/","title":"EvoEngineer","text":""},{"location":"api/methods/evoengineer/#evotoolkit.evo_method.evoengineer.EvoEngineer","title":"evotoolkit.evo_method.evoengineer.EvoEngineer","text":"<p>               Bases: <code>Method</code></p> Source code in <code>src/evotoolkit/evo_method/evoengineer/evoengineer.py</code> <pre><code>@register_algorithm(\"evoengineer\", config=EvoEngineerConfig)\nclass EvoEngineer(Method):\n    def __init__(self, config: EvoEngineerConfig):\n        super().__init__(config)\n        self.config = config\n\n    def run(self):\n        \"\"\"Main EvoEngineer algorithm execution\"\"\"\n        self.verbose_title(\"EvoEngineer ALGORITHM STARTED\")\n\n        if \"sample\" not in self.run_state_dict.usage_history:\n            self.run_state_dict.usage_history[\"sample\"] = []\n\n        # Initialize with seed solution if sol_history is empty\n        if len(self.run_state_dict.sol_history) == 0:\n            init_sol = self._get_init_sol()\n            if init_sol is None:\n                exit()\n            # Don't use _register_solution as this doesn't consume samples\n            self.run_state_dict.sol_history.append(init_sol)\n            self.run_state_dict.population.append(init_sol)\n            self._save_run_state_dict()\n            self.verbose_info(\n                f\"Initialized with baseline solution (score: {init_sol.evaluation_res.score if init_sol.evaluation_res else 'None'})\"\n            )\n\n        # Initialize population if starting from scratch\n        if self.run_state_dict.generation == 0:\n            self._initialize_population()\n\n        # Check if we have enough individuals for selection\n        valid_population = self._get_valid_population(self.run_state_dict.population)\n        if len(valid_population) &lt; self.config.interface.valid_require:\n            self.verbose_info(\n                f\"The search is terminated since EvoEngineer unable to obtain {self.config.interface.valid_require} feasible algorithms during initialization.\"\n            )\n            return\n\n        # Main evolution loop - moved loop control logic here\n        while (self.run_state_dict.generation &lt; self.config.max_generations) and (\n            self.run_state_dict.tot_sample_nums &lt; self.config.max_sample_nums\n        ):\n            try:\n                self.verbose_info(\n                    f\"Generation {self.run_state_dict.generation} - Sample {self.run_state_dict.tot_sample_nums + 1} - {self.run_state_dict.tot_sample_nums + self.config.num_samplers} / {self.config.max_sample_nums or 'unlimited'}\"\n                )\n\n                # Apply offspring operators in parallel for this generation\n                self._apply_operators_parallel(\n                    self.config.get_offspring_operators(),\n                    f\"Gen {self.run_state_dict.generation}\",\n                )\n\n                # Manage population size - keep only the best pop_size individuals\n                self._manage_population_size()\n\n                self.run_state_dict.generation += 1\n                self._save_run_state_dict()\n\n            except KeyboardInterrupt:\n                self.verbose_info(\"Evolution interrupted by user\")\n                break\n            except Exception as e:\n                self.verbose_info(f\"Evolution error: {str(e)}\")\n                continue\n\n        # Mark as done and save final state\n        self.run_state_dict.is_done = True\n        self._save_run_state_dict()\n\n    def _initialize_population(self):\n        \"\"\"Initialize population using init operators - keep generating until we have enough valid solutions\"\"\"\n        self.verbose_info(\"Initializing population...\")\n\n        initial_sample_limit = self.config.max_sample_nums  # Reasonable limit\n\n        # Keep generating until we have pop_size valid solutions or hit sample limit\n        while self.run_state_dict.tot_sample_nums &lt; initial_sample_limit:\n            # Apply init operators in parallel\n            self._apply_operators_parallel(self.config.get_init_operators(), \"Init\")\n\n            valid_count = len(\n                self._get_valid_population(self.run_state_dict.population)\n            )\n            self.verbose_info(f\"Valid solutions: {valid_count}/{self.config.pop_size}\")\n\n            self._save_run_state_dict()\n\n            if valid_count &gt;= self.config.interface.valid_require:\n                break\n\n        valid_population = self._get_valid_population(self.run_state_dict.population)\n        if len(valid_population) &gt;= self.config.interface.valid_require:\n            self.run_state_dict.generation = 1\n            self._save_run_state_dict()\n            self.verbose_info(\n                f\"Initialization completed with {len(valid_population)} valid solutions\"\n            )\n        else:\n            self.verbose_info(\n                f\"Warning: Only {len(valid_population)} valid solutions obtained, need at least {self.config.interface.valid_require}\"\n            )\n\n    def _get_valid_population(self, population: List[Solution]) -&gt; List[Solution]:\n        \"\"\"Get valid solutions from population\"\"\"\n        return [\n            sol for sol in population if sol.evaluation_res and sol.evaluation_res.valid\n        ]\n\n    def _get_best_valid_sol(self, sol_history: List[Solution]) -&gt; Solution | None:\n        \"\"\"Get the best valid solution from sol_history\"\"\"\n        valid_sols = [\n            sol\n            for sol in sol_history\n            if sol.evaluation_res\n            and sol.evaluation_res.valid\n            and sol.evaluation_res.score is not None\n        ]\n        if valid_sols:\n            return max(valid_sols, key=lambda x: x.evaluation_res.score)\n        return None\n\n    def _register_solution(self, solution: Solution):\n        \"\"\"Register a new solution to both sol_history and population\"\"\"\n        self.run_state_dict.sol_history.append(solution)\n        self.run_state_dict.population.append(solution)\n        self.run_state_dict.current_gen_solutions.append(solution)  # \u6dfb\u52a0\u5230\u5f53\u524d\u4ee3\u5386\u53f2\n        self.run_state_dict.tot_sample_nums += 1\n\n    def _apply_operators_parallel(self, operators: List, generation_label: str = \"\"):\n        \"\"\"Apply operators in parallel and register solutions\"\"\"\n        if not operators:\n            return\n\n        # Single executor for both generation and evaluation\n        with concurrent.futures.ThreadPoolExecutor(\n            max_workers=self.config.num_samplers + self.config.num_evaluators\n        ) as executor:\n            generate_futures = []\n            eval_futures = []\n\n            # Calculate target samples: multiple of num_operators, not exceeding num_samplers\n            num_operators = len(operators)\n\n            max_multiplier = self.config.num_samplers // num_operators\n            target_samples = (\n                max_multiplier * num_operators\n            )  # Largest multiple of num_operators &lt;= num_samplers\n            samples_per_operator = (\n                target_samples // num_operators\n            )  # This equals max_multiplier\n\n            # Generate samples: each operator gets exactly samples_per_operator samples\n            sample_id = 0\n            for operator in operators:\n                for _ in range(samples_per_operator):\n                    selected_individuals = self._select_individuals_for_operator(\n                        operator\n                    )\n                    future = executor.submit(\n                        self._generate_single_solution,\n                        operator,\n                        selected_individuals,\n                        sample_id,\n                    )\n                    generate_futures.append((operator.name, future))\n                    sample_id += 1\n\n            # Process generations as they complete and immediately submit for evaluation\n            future_to_operator = {\n                future: operator_name for operator_name, future in generate_futures\n            }\n            for future in concurrent.futures.as_completed(\n                [f for _, f in generate_futures]\n            ):\n                operator_name = future_to_operator[future]\n                try:\n                    solution, usage = future.result()\n\n                    # Add usage history\n                    self.run_state_dict.usage_history[\"sample\"].append(usage)\n                    self.run_state_dict.current_gen_usage.append(\n                        usage\n                    )  # \u6dfb\u52a0\u5230\u5f53\u524d\u4ee3usage\u5386\u53f2\n\n                    # Immediately submit for evaluation without waiting\n                    if solution.sol_string.strip():\n                        eval_future = executor.submit(\n                            self.config.task.evaluate_code, solution.sol_string\n                        )\n                        eval_futures.append((eval_future, solution, operator_name))\n                    else:\n                        self._register_solution(solution)\n                        # Log result for empty solution\n                        self.verbose_info(\n                            f\"{operator_name} {generation_label} - Score: None (Invalid)\"\n                        )\n\n                except Exception as e:\n                    self.verbose_info(f\"Error generating {operator_name}: {str(e)}\")\n                    continue\n\n            # Collect evaluation results\n            eval_future_to_info = {\n                eval_future: (solution, operator_name)\n                for eval_future, solution, operator_name in eval_futures\n            }\n            for eval_future in concurrent.futures.as_completed(\n                [ef for ef, _, _ in eval_futures]\n            ):\n                solution, operator_name = eval_future_to_info[eval_future]\n                try:\n                    evaluation_res = eval_future.result()\n                    solution.evaluation_res = evaluation_res\n                    self._register_solution(solution)\n\n                    # Log result\n                    score_str = (\n                        \"None\"\n                        if not solution.evaluation_res\n                        or solution.evaluation_res.score is None\n                        else f\"{solution.evaluation_res.score}\"\n                    )\n                    valid_str = (\n                        \"Valid\"\n                        if solution.evaluation_res and solution.evaluation_res.valid\n                        else \"Invalid\"\n                    )\n                    self.verbose_info(\n                        f\"{operator_name} {generation_label} - Score: {score_str} ({valid_str})\"\n                    )\n\n                except Exception as e:\n                    self.verbose_info(f\"Error evaluating {operator_name}: {str(e)}\")\n                    self._register_solution(solution)  # Add with no evaluation result\n                    continue\n\n    def _manage_population_size(self):\n        \"\"\"Manage population size - keep only the best pop_size individuals\"\"\"\n        if len(self.run_state_dict.population) &lt;= self.config.pop_size:\n            return\n\n        # Separate valid and invalid solutions\n        valid_solutions = self._get_valid_population(self.run_state_dict.population)\n        invalid_solutions = [\n            sol for sol in self.run_state_dict.population if sol not in valid_solutions\n        ]\n\n        # Sort valid solutions by score (descending - higher is better)\n        valid_solutions.sort(\n            key=lambda x: x.evaluation_res.score\n            if x.evaluation_res and x.evaluation_res.score is not None\n            else float(\"-inf\"),\n            reverse=True,\n        )\n\n        # Keep the best valid solutions + some invalid ones if needed\n        new_population = []\n\n        # First, add the best valid solutions\n        valid_to_keep = min(len(valid_solutions), self.config.pop_size)\n        new_population.extend(valid_solutions[:valid_to_keep])\n\n        # If we need more individuals, add some invalid ones (most recent)\n        remaining_slots = self.config.pop_size - len(new_population)\n        if remaining_slots &gt; 0 and invalid_solutions:\n            new_population.extend(\n                invalid_solutions[-remaining_slots:]\n            )  # Keep most recent invalid ones\n\n        self.run_state_dict.population = new_population\n\n        valid_count = len(self._get_valid_population(new_population))\n        self.verbose_info(\n            f\"Population managed: {len(new_population)} total ({valid_count} valid, {len(new_population) - valid_count} invalid)\"\n        )\n\n    def _select_individuals_for_operator(self, operator) -&gt; List[Solution]:\n        \"\"\"Select individuals for an operator using rank-based probability selection\"\"\"\n        import math\n\n        import numpy as np\n\n        if operator.selection_size &lt;= 0:\n            return []  # Init operators or invalid selection size\n\n        # Filter valid solutions with finite scores (including NaN check)\n        funcs = [\n            sol\n            for sol in self.run_state_dict.population\n            if sol.evaluation_res\n            and sol.evaluation_res.valid\n            and sol.evaluation_res.score is not None\n            and not math.isinf(sol.evaluation_res.score)\n            and not math.isnan(sol.evaluation_res.score)\n        ]\n\n        if len(funcs) == 0:\n            # Fallback to any available solutions\n            return (\n                self.run_state_dict.population[: operator.selection_size]\n                if self.run_state_dict.population\n                else []\n            )\n\n        # Sort by score (assuming higher is better)\n        func = sorted(funcs, key=lambda f: f.evaluation_res.score, reverse=True)\n\n        # Create rank-based probability distribution\n        p = [1 / (r + len(func)) for r in range(len(func))]\n        p = np.array(p)\n        p = p / np.sum(p)\n\n        # Select individuals based on probability\n        selected = []\n        for _ in range(\n            min(operator.selection_size, len(func))\n        ):  # Ensure we don't select more than available\n            chosen = np.random.choice(func, p=p)\n            selected.append(chosen)\n\n        return selected\n\n    def _generate_single_solution(\n        self, operator, selected_individuals: List[Solution], sampler_id: int\n    ) -&gt; tuple[Solution, dict]:\n        \"\"\"Generate a single solution using an operator\"\"\"\n        try:\n            current_best_sol = self._get_best_sol(self.run_state_dict.population)\n            random_3_thought = self._get_n_random_thought(3)\n            prompt_content = self.config.interface.get_operator_prompt(\n                operator.name, selected_individuals, current_best_sol, random_3_thought\n            )\n            response, usage = self.config.running_llm.get_response(prompt_content)\n            new_sol = self.config.interface.parse_response(response)\n            self.verbose_info(\n                f\"Sampler {sampler_id}: Generated {operator.name} solution\"\n            )\n            return new_sol, usage\n        except Exception as e:\n            self.verbose_info(\n                f\"Sampler {sampler_id}: Failed to generate {operator.name} solution - {str(e)}\"\n            )\n            return Solution(\"\"), {}\n\n    def _get_n_random_thought(self, n: int) -&gt; List[str]:\n        \"\"\"Get n random thoughts from solutions in the current population\"\"\"\n        import random\n\n        # Get all thoughts from current population\n        thoughts = []\n        for sol in self.run_state_dict.population:\n            if sol.other_info and \"thought\" in sol.other_info:\n                thought = sol.other_info[\"thought\"]\n                if thought:  # Only add non-empty thoughts\n                    thoughts.append(thought)\n\n        # If we don't have enough thoughts, return all available ones\n        if len(thoughts) &lt;= n:\n            return thoughts\n\n        # Randomly sample n thoughts without replacement\n        return random.sample(thoughts, n)\n\n    def _get_run_state_class(self) -&gt; Type[BaseRunStateDict]:\n        return EvoEngineerRunStateDict\n</code></pre>"},{"location":"api/methods/evoengineer/#evotoolkit.evo_method.evoengineer.EvoEngineer.run","title":"run","text":"<pre><code>run()\n</code></pre> <p>Main EvoEngineer algorithm execution</p> Source code in <code>src/evotoolkit/evo_method/evoengineer/evoengineer.py</code> <pre><code>def run(self):\n    \"\"\"Main EvoEngineer algorithm execution\"\"\"\n    self.verbose_title(\"EvoEngineer ALGORITHM STARTED\")\n\n    if \"sample\" not in self.run_state_dict.usage_history:\n        self.run_state_dict.usage_history[\"sample\"] = []\n\n    # Initialize with seed solution if sol_history is empty\n    if len(self.run_state_dict.sol_history) == 0:\n        init_sol = self._get_init_sol()\n        if init_sol is None:\n            exit()\n        # Don't use _register_solution as this doesn't consume samples\n        self.run_state_dict.sol_history.append(init_sol)\n        self.run_state_dict.population.append(init_sol)\n        self._save_run_state_dict()\n        self.verbose_info(\n            f\"Initialized with baseline solution (score: {init_sol.evaluation_res.score if init_sol.evaluation_res else 'None'})\"\n        )\n\n    # Initialize population if starting from scratch\n    if self.run_state_dict.generation == 0:\n        self._initialize_population()\n\n    # Check if we have enough individuals for selection\n    valid_population = self._get_valid_population(self.run_state_dict.population)\n    if len(valid_population) &lt; self.config.interface.valid_require:\n        self.verbose_info(\n            f\"The search is terminated since EvoEngineer unable to obtain {self.config.interface.valid_require} feasible algorithms during initialization.\"\n        )\n        return\n\n    # Main evolution loop - moved loop control logic here\n    while (self.run_state_dict.generation &lt; self.config.max_generations) and (\n        self.run_state_dict.tot_sample_nums &lt; self.config.max_sample_nums\n    ):\n        try:\n            self.verbose_info(\n                f\"Generation {self.run_state_dict.generation} - Sample {self.run_state_dict.tot_sample_nums + 1} - {self.run_state_dict.tot_sample_nums + self.config.num_samplers} / {self.config.max_sample_nums or 'unlimited'}\"\n            )\n\n            # Apply offspring operators in parallel for this generation\n            self._apply_operators_parallel(\n                self.config.get_offspring_operators(),\n                f\"Gen {self.run_state_dict.generation}\",\n            )\n\n            # Manage population size - keep only the best pop_size individuals\n            self._manage_population_size()\n\n            self.run_state_dict.generation += 1\n            self._save_run_state_dict()\n\n        except KeyboardInterrupt:\n            self.verbose_info(\"Evolution interrupted by user\")\n            break\n        except Exception as e:\n            self.verbose_info(f\"Evolution error: {str(e)}\")\n            continue\n\n    # Mark as done and save final state\n    self.run_state_dict.is_done = True\n    self._save_run_state_dict()\n</code></pre>"},{"location":"api/methods/evoengineer/#configuration","title":"Configuration","text":""},{"location":"api/methods/evoengineer/#evotoolkit.evo_method.evoengineer.EvoEngineerConfig","title":"evotoolkit.evo_method.evoengineer.EvoEngineerConfig","text":"<p>               Bases: <code>BaseConfig</code></p> Source code in <code>src/evotoolkit/evo_method/evoengineer/run_config.py</code> <pre><code>class EvoEngineerConfig(BaseConfig):\n    def __init__(\n        self,\n        interface: EvoEngineerInterface,\n        output_path: str,\n        running_llm: HttpsApi,\n        verbose: bool = True,\n        max_generations: int = 10,\n        max_sample_nums: int = 45,\n        pop_size: int = 5,\n        num_samplers: int = 4,\n        num_evaluators: int = 4,\n        **kwargs,\n    ):\n        super().__init__(interface, output_path, verbose)\n        self.running_llm = running_llm\n\n        self.max_generations = max_generations\n        self.max_sample_nums = max_sample_nums\n        self.pop_size = pop_size\n        self.num_samplers = num_samplers\n        self.num_evaluators = num_evaluators\n\n        # Get operators from adapter\n        self.init_operators = interface.get_init_operators()\n        self.offspring_operators = interface.get_offspring_operators()\n\n        # Validate required operators\n        if not self.init_operators:\n            raise ValueError(\"Adapter must provide at least one init operator\")\n        if not self.offspring_operators:\n            raise ValueError(\"Adapter must provide at least one offspring operator\")\n\n        # Validate init operators have selection_size=0\n        for op in self.init_operators:\n            if op.selection_size != 0:\n                raise ValueError(\n                    f\"Init operator '{op.name}' must have selection_size=0, got {op.selection_size}\"\n                )\n\n    def get_init_operators(self) -&gt; List[Operator]:\n        \"\"\"Get initialization operators\"\"\"\n        return self.init_operators\n\n    def get_offspring_operators(self) -&gt; List[Operator]:\n        \"\"\"Get offspring operators\"\"\"\n        return self.offspring_operators\n\n    def get_all_operators(self) -&gt; List[Operator]:\n        \"\"\"Get all operators\"\"\"\n        return self.init_operators + self.offspring_operators\n</code></pre>"},{"location":"api/methods/evoengineer/#evotoolkit.evo_method.evoengineer.EvoEngineerConfig.get_init_operators","title":"get_init_operators","text":"<pre><code>get_init_operators() -&gt; List[Operator]\n</code></pre> <p>Get initialization operators</p> Source code in <code>src/evotoolkit/evo_method/evoengineer/run_config.py</code> <pre><code>def get_init_operators(self) -&gt; List[Operator]:\n    \"\"\"Get initialization operators\"\"\"\n    return self.init_operators\n</code></pre>"},{"location":"api/methods/evoengineer/#evotoolkit.evo_method.evoengineer.EvoEngineerConfig.get_offspring_operators","title":"get_offspring_operators","text":"<pre><code>get_offspring_operators() -&gt; List[Operator]\n</code></pre> <p>Get offspring operators</p> Source code in <code>src/evotoolkit/evo_method/evoengineer/run_config.py</code> <pre><code>def get_offspring_operators(self) -&gt; List[Operator]:\n    \"\"\"Get offspring operators\"\"\"\n    return self.offspring_operators\n</code></pre>"},{"location":"api/methods/evoengineer/#evotoolkit.evo_method.evoengineer.EvoEngineerConfig.get_all_operators","title":"get_all_operators","text":"<pre><code>get_all_operators() -&gt; List[Operator]\n</code></pre> <p>Get all operators</p> Source code in <code>src/evotoolkit/evo_method/evoengineer/run_config.py</code> <pre><code>def get_all_operators(self) -&gt; List[Operator]:\n    \"\"\"Get all operators\"\"\"\n    return self.init_operators + self.offspring_operators\n</code></pre>"},{"location":"api/methods/evoengineer/#usage","title":"Usage","text":"<pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\nimport evotoolkit\n\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=8\n)\n</code></pre>"},{"location":"api/methods/funsearch/","title":"FunSearch","text":""},{"location":"api/methods/funsearch/#evotoolkit.evo_method.funsearch.FunSearch","title":"evotoolkit.evo_method.funsearch.FunSearch","text":"<p>               Bases: <code>Method</code></p> Source code in <code>src/evotoolkit/evo_method/funsearch/funsearch.py</code> <pre><code>@register_algorithm(\"funsearch\", config=FunSearchConfig)\nclass FunSearch(Method):\n    def __init__(self, config: FunSearchConfig):\n        super().__init__(config)\n        self.config = config\n\n    def run(self):\n        \"\"\"Main FunSearch algorithm execution\"\"\"\n        self.verbose_title(\"FUNSEARCH ALGORITHM STARTED\")\n\n        # Initialize usage history\n        if \"sample\" not in self.run_state_dict.usage_history:\n            self.run_state_dict.usage_history[\"sample\"] = []\n\n        # Initialize or restore programs database\n        if self.run_state_dict.has_database_state(self.config.output_path):\n            # Restore from saved database file\n            database_dict = self.run_state_dict.load_database_state(\n                self.config.output_path\n            )\n            if database_dict:\n                programs_db = ProgramsDatabase.from_dict(database_dict)\n                self.verbose_info(\"Restored programs database from saved state\")\n            else:\n                # Failed to load, create new database\n                programs_db = ProgramsDatabase(\n                    num_islands=self.config.num_islands,\n                    solutions_per_prompt=self.config.programs_per_prompt,\n                    reset_period=4 * 60 * 60,  # 4 hours\n                )\n                self.verbose_info(\"Failed to restore database, initialized new one\")\n        else:\n            # Initialize new database\n            programs_db = ProgramsDatabase(\n                num_islands=self.config.num_islands,\n                solutions_per_prompt=self.config.programs_per_prompt,\n                reset_period=4 * 60 * 60,  # 4 hours\n            )\n            self.verbose_info(\"Initialized new programs database\")\n\n        # Initialize with seed program if sol_history is empty\n        if len(self.run_state_dict.sol_history) == 0:\n            init_sol = self._get_init_sol()\n            if init_sol is None:\n                exit()\n\n            programs_db.register_solution(init_sol)  # Register to all islands\n            self.run_state_dict.sol_history.append(\n                init_sol\n            )  # Add to sol_history but don't count in sample_nums\n\n            self._save_run_state_dict_with_database(programs_db)\n\n            self.verbose_info(\n                f\"Initialized with seed program (score: {init_sol.evaluation_res.score if init_sol.evaluation_res else 'None'})\"\n            )\n        else:\n            self.verbose_info(\n                f\"Continuing from sample {self.run_state_dict.tot_sample_nums} with {len(self.run_state_dict.sol_history)} solutions in history\"\n            )\n\n            # Rebuild database from sol_history if needed\n            if not self.run_state_dict.has_database_state(self.config.output_path):\n                self.verbose_info(\"Rebuilding database from solution history...\")\n                for solution in self.run_state_dict.sol_history:\n                    if solution.evaluation_res and solution.evaluation_res.valid:\n                        programs_db.register_solution(solution)\n\n        # Main sampling loop\n        while self.run_state_dict.tot_sample_nums &lt; self.config.max_sample_nums:\n            try:\n                start_sample = self.run_state_dict.tot_sample_nums + 1\n                end_sample = (\n                    self.run_state_dict.tot_sample_nums + self.config.num_samplers\n                )\n                self.verbose_info(\n                    f\"Samples {start_sample} - {end_sample} / {self.config.max_sample_nums or 'unlimited'}\"\n                )\n\n                # Get prompt solutions from random island\n                prompt_solutions, island_id = programs_db.get_prompt_solutions()\n                if not prompt_solutions:\n                    self.verbose_info(\"No solutions available for prompting\")\n                    continue\n\n                self.verbose_info(\n                    f\"Selected {len(prompt_solutions)} solutions from island {island_id}\"\n                )\n\n                # Async generate and evaluate programs - single executor for both\n                with concurrent.futures.ThreadPoolExecutor(\n                    max_workers=self.config.num_samplers + self.config.num_evaluators\n                ) as executor:\n                    # Submit all generate tasks\n                    generate_futures = []\n                    eval_futures = []\n\n                    for sampler_id in range(self.config.num_samplers):\n                        future = executor.submit(\n                            self._generate_single_program, prompt_solutions, sampler_id\n                        )\n                        generate_futures.append(future)\n\n                    # Process generated programs as they complete and immediately submit for evaluation\n                    for future in concurrent.futures.as_completed(generate_futures):\n                        try:\n                            new_program, usage = future.result()\n                            self.run_state_dict.usage_history[\"sample\"].append(usage)\n                            self.run_state_dict.current_batch_usage.append(\n                                usage\n                            )  # \u6dfb\u52a0\u5230\u5f53\u524d\u6279\u6b21usage\u5386\u53f2\n\n                            # Immediately submit for evaluation without waiting\n                            eval_future = executor.submit(\n                                self.config.task.evaluate_code, new_program.sol_string\n                            )\n                            eval_futures.append((eval_future, new_program))\n                        except Exception as e:\n                            self.verbose_info(f\"Program generation failed: {str(e)}\")\n                            continue\n\n                    # Collect evaluation results as they complete\n                    for eval_future, program in eval_futures:\n                        try:\n                            evaluation_res = eval_future.result()\n                            program.evaluation_res = evaluation_res\n                            score_str = (\n                                \"None\"\n                                if evaluation_res.score is None\n                                else f\"{evaluation_res.score}\"\n                            )\n                            self.verbose_info(f\"Program evaluated - Score: {score_str}\")\n                        except Exception as e:\n                            self.verbose_info(f\"Program evaluation failed: {str(e)}\")\n                            continue\n\n                        # Process each evaluated program immediately\n                        # Add ALL programs (valid/invalid) to sol_history\n                        self.run_state_dict.sol_history.append(program)\n                        self.run_state_dict.current_batch_solutions.append(\n                            program\n                        )  # \u6dfb\u52a0\u5230\u5f53\u524d\u6279\u6b21\u5386\u53f2\n                        self.run_state_dict.tot_sample_nums += 1\n\n                        # Only register valid programs to the database/island\n                        if program.evaluation_res and program.evaluation_res.valid:\n                            programs_db.register_solution(program, island_id)\n\n                            score_str = (\n                                f\"{program.evaluation_res.score:.6f}\"\n                                if program.evaluation_res.score is not None\n                                else \"None\"\n                            )\n                            self.verbose_info(\n                                f\"Registered valid program to island {island_id} (score: {score_str})\"\n                            )\n                        else:\n                            self.verbose_info(\n                                f\"Added invalid program to history (sample {self.run_state_dict.tot_sample_nums})\"\n                            )\n\n                # Log current best\n                best_solution = programs_db.get_best_solution()\n                if best_solution and best_solution.evaluation_res:\n                    best_score_str = (\n                        f\"{best_solution.evaluation_res.score:.6f}\"\n                        if best_solution.evaluation_res.score is not None\n                        else \"None\"\n                    )\n                    self.verbose_info(f\"Current best score: {best_score_str}\")\n\n                # Show database statistics periodically\n                if self.run_state_dict.tot_sample_nums % 50 == 0:\n                    stats = programs_db.get_statistics()\n                    self.verbose_info(\n                        f\"Database stats: {stats['total_programs']} total programs, {stats['num_islands']} islands, best score: {stats['global_best_score']:.6f}\"\n                    )\n\n                self._save_run_state_dict_with_database(programs_db)\n\n            except KeyboardInterrupt:\n                self.verbose_info(\"Interrupted by user\")\n                break\n            except Exception as e:\n                self.verbose_info(f\"Sampling error: {str(e)}\")\n                continue\n\n        # Mark as done and save final state with database\n        self.run_state_dict.is_done = True\n        self._save_run_state_dict_with_database(programs_db)\n\n        # Log final statistics\n        final_stats = programs_db.get_statistics()\n        self.verbose_info(\n            f\"Final stats: {final_stats['total_programs']} programs, best score: {final_stats['global_best_score']:.6f}\"\n        )\n\n    def _save_run_state_dict_with_database(self, programs_db):\n        \"\"\"Override base method to also save database state\"\"\"\n        # Save database state first\n        self.run_state_dict.save_database_state(\n            programs_db.to_dict(), self.config.output_path\n        )\n        # Then save run state as usual\n        super()._save_run_state_dict()\n\n        # Show database file location\n        self.verbose_info(\n            f\"Programs database saved to: {self.run_state_dict.database_file}\"\n        )\n\n    def _generate_single_program(\n        self, prompt_solutions: list[Solution], sampler_id: int\n    ) -&gt; tuple[Solution, dict]:\n        \"\"\"Generate single program variant using LLM based on prompt solutions\"\"\"\n        try:\n            # Get prompt from adapter based on selected solutions\n            prompt_content = self.config.interface.get_prompt(prompt_solutions)\n\n            response, usage = self.config.running_llm.get_response(prompt_content)\n\n            new_sol = self.config.interface.parse_response(response)\n            self.verbose_info(f\"Sampler {sampler_id}: Generated a program variant.\")\n            return new_sol, usage\n        except Exception as e:\n            self.verbose_info(\n                f\"Sampler {sampler_id}: Failed to generate program - {str(e)}\"\n            )\n            return Solution(\"\"), {}  # Return usage even if failed\n\n    def _get_run_state_class(self) -&gt; Type[BaseRunStateDict]:\n        return FunSearchRunStateDict\n</code></pre>"},{"location":"api/methods/funsearch/#evotoolkit.evo_method.funsearch.FunSearch.run","title":"run","text":"<pre><code>run()\n</code></pre> <p>Main FunSearch algorithm execution</p> Source code in <code>src/evotoolkit/evo_method/funsearch/funsearch.py</code> <pre><code>def run(self):\n    \"\"\"Main FunSearch algorithm execution\"\"\"\n    self.verbose_title(\"FUNSEARCH ALGORITHM STARTED\")\n\n    # Initialize usage history\n    if \"sample\" not in self.run_state_dict.usage_history:\n        self.run_state_dict.usage_history[\"sample\"] = []\n\n    # Initialize or restore programs database\n    if self.run_state_dict.has_database_state(self.config.output_path):\n        # Restore from saved database file\n        database_dict = self.run_state_dict.load_database_state(\n            self.config.output_path\n        )\n        if database_dict:\n            programs_db = ProgramsDatabase.from_dict(database_dict)\n            self.verbose_info(\"Restored programs database from saved state\")\n        else:\n            # Failed to load, create new database\n            programs_db = ProgramsDatabase(\n                num_islands=self.config.num_islands,\n                solutions_per_prompt=self.config.programs_per_prompt,\n                reset_period=4 * 60 * 60,  # 4 hours\n            )\n            self.verbose_info(\"Failed to restore database, initialized new one\")\n    else:\n        # Initialize new database\n        programs_db = ProgramsDatabase(\n            num_islands=self.config.num_islands,\n            solutions_per_prompt=self.config.programs_per_prompt,\n            reset_period=4 * 60 * 60,  # 4 hours\n        )\n        self.verbose_info(\"Initialized new programs database\")\n\n    # Initialize with seed program if sol_history is empty\n    if len(self.run_state_dict.sol_history) == 0:\n        init_sol = self._get_init_sol()\n        if init_sol is None:\n            exit()\n\n        programs_db.register_solution(init_sol)  # Register to all islands\n        self.run_state_dict.sol_history.append(\n            init_sol\n        )  # Add to sol_history but don't count in sample_nums\n\n        self._save_run_state_dict_with_database(programs_db)\n\n        self.verbose_info(\n            f\"Initialized with seed program (score: {init_sol.evaluation_res.score if init_sol.evaluation_res else 'None'})\"\n        )\n    else:\n        self.verbose_info(\n            f\"Continuing from sample {self.run_state_dict.tot_sample_nums} with {len(self.run_state_dict.sol_history)} solutions in history\"\n        )\n\n        # Rebuild database from sol_history if needed\n        if not self.run_state_dict.has_database_state(self.config.output_path):\n            self.verbose_info(\"Rebuilding database from solution history...\")\n            for solution in self.run_state_dict.sol_history:\n                if solution.evaluation_res and solution.evaluation_res.valid:\n                    programs_db.register_solution(solution)\n\n    # Main sampling loop\n    while self.run_state_dict.tot_sample_nums &lt; self.config.max_sample_nums:\n        try:\n            start_sample = self.run_state_dict.tot_sample_nums + 1\n            end_sample = (\n                self.run_state_dict.tot_sample_nums + self.config.num_samplers\n            )\n            self.verbose_info(\n                f\"Samples {start_sample} - {end_sample} / {self.config.max_sample_nums or 'unlimited'}\"\n            )\n\n            # Get prompt solutions from random island\n            prompt_solutions, island_id = programs_db.get_prompt_solutions()\n            if not prompt_solutions:\n                self.verbose_info(\"No solutions available for prompting\")\n                continue\n\n            self.verbose_info(\n                f\"Selected {len(prompt_solutions)} solutions from island {island_id}\"\n            )\n\n            # Async generate and evaluate programs - single executor for both\n            with concurrent.futures.ThreadPoolExecutor(\n                max_workers=self.config.num_samplers + self.config.num_evaluators\n            ) as executor:\n                # Submit all generate tasks\n                generate_futures = []\n                eval_futures = []\n\n                for sampler_id in range(self.config.num_samplers):\n                    future = executor.submit(\n                        self._generate_single_program, prompt_solutions, sampler_id\n                    )\n                    generate_futures.append(future)\n\n                # Process generated programs as they complete and immediately submit for evaluation\n                for future in concurrent.futures.as_completed(generate_futures):\n                    try:\n                        new_program, usage = future.result()\n                        self.run_state_dict.usage_history[\"sample\"].append(usage)\n                        self.run_state_dict.current_batch_usage.append(\n                            usage\n                        )  # \u6dfb\u52a0\u5230\u5f53\u524d\u6279\u6b21usage\u5386\u53f2\n\n                        # Immediately submit for evaluation without waiting\n                        eval_future = executor.submit(\n                            self.config.task.evaluate_code, new_program.sol_string\n                        )\n                        eval_futures.append((eval_future, new_program))\n                    except Exception as e:\n                        self.verbose_info(f\"Program generation failed: {str(e)}\")\n                        continue\n\n                # Collect evaluation results as they complete\n                for eval_future, program in eval_futures:\n                    try:\n                        evaluation_res = eval_future.result()\n                        program.evaluation_res = evaluation_res\n                        score_str = (\n                            \"None\"\n                            if evaluation_res.score is None\n                            else f\"{evaluation_res.score}\"\n                        )\n                        self.verbose_info(f\"Program evaluated - Score: {score_str}\")\n                    except Exception as e:\n                        self.verbose_info(f\"Program evaluation failed: {str(e)}\")\n                        continue\n\n                    # Process each evaluated program immediately\n                    # Add ALL programs (valid/invalid) to sol_history\n                    self.run_state_dict.sol_history.append(program)\n                    self.run_state_dict.current_batch_solutions.append(\n                        program\n                    )  # \u6dfb\u52a0\u5230\u5f53\u524d\u6279\u6b21\u5386\u53f2\n                    self.run_state_dict.tot_sample_nums += 1\n\n                    # Only register valid programs to the database/island\n                    if program.evaluation_res and program.evaluation_res.valid:\n                        programs_db.register_solution(program, island_id)\n\n                        score_str = (\n                            f\"{program.evaluation_res.score:.6f}\"\n                            if program.evaluation_res.score is not None\n                            else \"None\"\n                        )\n                        self.verbose_info(\n                            f\"Registered valid program to island {island_id} (score: {score_str})\"\n                        )\n                    else:\n                        self.verbose_info(\n                            f\"Added invalid program to history (sample {self.run_state_dict.tot_sample_nums})\"\n                        )\n\n            # Log current best\n            best_solution = programs_db.get_best_solution()\n            if best_solution and best_solution.evaluation_res:\n                best_score_str = (\n                    f\"{best_solution.evaluation_res.score:.6f}\"\n                    if best_solution.evaluation_res.score is not None\n                    else \"None\"\n                )\n                self.verbose_info(f\"Current best score: {best_score_str}\")\n\n            # Show database statistics periodically\n            if self.run_state_dict.tot_sample_nums % 50 == 0:\n                stats = programs_db.get_statistics()\n                self.verbose_info(\n                    f\"Database stats: {stats['total_programs']} total programs, {stats['num_islands']} islands, best score: {stats['global_best_score']:.6f}\"\n                )\n\n            self._save_run_state_dict_with_database(programs_db)\n\n        except KeyboardInterrupt:\n            self.verbose_info(\"Interrupted by user\")\n            break\n        except Exception as e:\n            self.verbose_info(f\"Sampling error: {str(e)}\")\n            continue\n\n    # Mark as done and save final state with database\n    self.run_state_dict.is_done = True\n    self._save_run_state_dict_with_database(programs_db)\n\n    # Log final statistics\n    final_stats = programs_db.get_statistics()\n    self.verbose_info(\n        f\"Final stats: {final_stats['total_programs']} programs, best score: {final_stats['global_best_score']:.6f}\"\n    )\n</code></pre>"},{"location":"api/methods/funsearch/#configuration","title":"Configuration","text":""},{"location":"api/methods/funsearch/#evotoolkit.evo_method.funsearch.FunSearchConfig","title":"evotoolkit.evo_method.funsearch.FunSearchConfig","text":"<p>               Bases: <code>BaseConfig</code></p> Source code in <code>src/evotoolkit/evo_method/funsearch/run_config.py</code> <pre><code>class FunSearchConfig(BaseConfig):\n    def __init__(\n        self,\n        interface: FunSearchInterface,\n        output_path: str,\n        running_llm: HttpsApi,\n        verbose: bool = True,\n        max_sample_nums: int = 45,\n        num_islands: int = 5,\n        max_population_size: int = 1000,\n        num_samplers: int = 5,\n        num_evaluators: int = 5,\n        programs_per_prompt: int = 2,\n        **kwargs,  # Ignore extra arguments like max_generations, pop_size\n    ):\n        super().__init__(interface, output_path, verbose)\n        self.running_llm = running_llm\n\n        self.max_sample_nums = max_sample_nums\n        self.num_islands = num_islands\n        self.max_population_size = max_population_size\n        self.num_samplers = num_samplers\n        self.num_evaluators = num_evaluators\n        self.programs_per_prompt = programs_per_prompt\n\n        # Optionally log ignored parameters\n        if kwargs and verbose:\n            ignored = \", \".join(kwargs.keys())\n            # Silently ignore, or uncomment to log:\n            print(f\"FunSearchConfig: Ignoring parameters: {ignored}\")\n</code></pre>"},{"location":"api/methods/funsearch/#usage","title":"Usage","text":"<pre><code>from evotoolkit.task.python_task import FunSearchPythonInterface\nimport evotoolkit\n\ninterface = FunSearchPythonInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=15\n)\n</code></pre>"},{"location":"api/tasks/cuda/cuda-task/","title":"CudaTask","text":""},{"location":"api/tasks/cuda/cuda-task/#evotoolkit.task.cuda_engineering.cuda_task.CudaTask","title":"evotoolkit.task.cuda_engineering.cuda_task.CudaTask","text":"<p>               Bases: <code>BaseTask</code></p> <p>Base class for CUDA-based evolutionary optimization tasks.</p> <p>This class unifies CudaEvaluator and CudaTaskConfig functionality, providing a common base for CUDA kernel optimization tasks.</p> Source code in <code>src/evotoolkit/task/cuda_engineering/cuda_task.py</code> <pre><code>class CudaTask(BaseTask):\n    \"\"\"\n    Base class for CUDA-based evolutionary optimization tasks.\n\n    This class unifies CudaEvaluator and CudaTaskConfig functionality,\n    providing a common base for CUDA kernel optimization tasks.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: Dict[str, Any],\n        temp_path: Optional[str] = None,\n        fake_mode: bool = False,\n    ):\n        \"\"\"\n        Initialize the CUDA task with input data.\n\n        Args:\n            data: Task-specific input data (task_info dict)\n            temp_path: Temporary path for CUDA compilation\n            fake_mode: If True, skip actual CUDA evaluation\n        \"\"\"\n        self.temp_path = temp_path or tempfile.mkdtemp()\n        self.fake_mode = fake_mode\n        super().__init__(data)\n\n        self.evaluator = Evaluator(self.temp_path)\n\n    def _process_data(self, data):\n        \"\"\"Process CUDA task data.\"\"\"\n        self.task_info = data\n        self.org_py_code = data[\"org_py_code\"]\n        self.func_py_code = data[\"func_py_code\"]\n        self.cuda_code = data[\"cuda_code\"]\n\n    def get_task_type(self) -&gt; str:\n        \"\"\"Get task type as 'Cuda'.\"\"\"\n        return \"Cuda\"\n\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get the base task description using task info\"\"\"\n        gpu_type = self.task_info.get(\"gpu_type\", \"RTX 4090\")\n        cuda_version = self.task_info.get(\"cuda_version\", \"12.4.1\")\n        return f\"\"\"You are a Machine Learning Engineer trying to reduce the runtime of a CUDA kernel. Make sure the kernel returns the correct result. Do not use any alternative precision that could result in an incorrect result. The kernel will be run on a {gpu_type} GPU with CUDA {cuda_version}.\n\"\"\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"Create initial solution from task info.\"\"\"\n        init_sol = Solution(self.task_info[\"cuda_code\"])\n        evaluation_res = EvaluationResult(\n            valid=True,\n            score=-self.task_info[\"cuda_info\"][\"runtime\"],\n            additional_info={\n                \"code\": self.task_info[\"cuda_code\"],\n                \"temp_str\": None,\n                \"runtime\": self.task_info[\"cuda_info\"][\"runtime\"],\n                \"prof_string\": self.task_info[\"cuda_info\"][\"prof_string\"],\n                \"compilation_error\": False,\n                \"comparison_error\": False,\n                \"error_msg\": None,\n                \"exception\": None,\n            },\n        )\n        init_sol.evaluation_res = evaluation_res\n        return init_sol\n\n    def evaluate_code(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"Evaluate CUDA kernel code.\"\"\"\n\n        try:\n            if self.fake_mode:\n                return EvaluationResult(\n                    valid=True,\n                    score=-0.1,\n                    additional_info={\n                        \"code\": candidate_code,\n                        \"temp_str\": None,\n                        \"runtime\": 0.1,\n                        \"prof_string\": None,\n                        \"compilation_error\": False,\n                        \"comparison_error\": False,\n                        \"error_msg\": None,\n                        \"exception\": None,\n                    },\n                )\n\n            cuda_comparison_result = self.evaluator.compare_func_cuda_sandbox(\n                self.func_py_code, candidate_code\n            )\n\n            additional_info = {\n                \"code\": candidate_code,\n                \"temp_str\": cuda_comparison_result.get(\"temp_str\"),\n                \"runtime\": None,\n                \"prof_string\": None,\n                \"compilation_error\": cuda_comparison_result.get(\n                    \"compilation_error\", False\n                ),\n                \"comparison_error\": not cuda_comparison_result.get(\n                    \"correctness\", False\n                ),\n                \"error_msg\": cuda_comparison_result.get(\"error_msg\", None),\n            }\n\n            if cuda_comparison_result.get(\"correctness\", False):\n                cuda_runtime_result = self.evaluator.get_cuda_runtime_sandbox(\n                    self.func_py_code,\n                    candidate_code,\n                    cuda_comparison_result.get(\"temp_str\"),\n                )\n                additional_info[\"runtime\"] = cuda_runtime_result.get(\"runtime\")\n                additional_info[\"prof_string\"] = cuda_runtime_result.get(\"prof_string\")\n\n                score = -cuda_runtime_result.get(\"runtime\")\n                valid = True\n                additional_info[\"error_msg\"] = cuda_runtime_result.get(\n                    \"error_msg\", None\n                )\n            else:\n                score = None\n                valid = False\n\n            return EvaluationResult(\n                valid=valid, score=score, additional_info=additional_info\n            )\n\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=None,\n                additional_info={\n                    \"code\": candidate_code,\n                    \"temp_str\": None,\n                    \"runtime\": None,\n                    \"prof_string\": None,\n                    \"compilation_error\": True,\n                    \"comparison_error\": True,\n                    \"error_msg\": str(e),\n                    \"exception\": True,\n                },\n            )\n</code></pre>"},{"location":"api/tasks/cuda/cuda-task/#evotoolkit.task.cuda_engineering.cuda_task.CudaTask.__init__","title":"__init__","text":"<pre><code>__init__(\n    data: Dict[str, Any],\n    temp_path: Optional[str] = None,\n    fake_mode: bool = False,\n)\n</code></pre> <p>Initialize the CUDA task with input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>Task-specific input data (task_info dict)</p> required <code>temp_path</code> <code>Optional[str]</code> <p>Temporary path for CUDA compilation</p> <code>None</code> <code>fake_mode</code> <code>bool</code> <p>If True, skip actual CUDA evaluation</p> <code>False</code> Source code in <code>src/evotoolkit/task/cuda_engineering/cuda_task.py</code> <pre><code>def __init__(\n    self,\n    data: Dict[str, Any],\n    temp_path: Optional[str] = None,\n    fake_mode: bool = False,\n):\n    \"\"\"\n    Initialize the CUDA task with input data.\n\n    Args:\n        data: Task-specific input data (task_info dict)\n        temp_path: Temporary path for CUDA compilation\n        fake_mode: If True, skip actual CUDA evaluation\n    \"\"\"\n    self.temp_path = temp_path or tempfile.mkdtemp()\n    self.fake_mode = fake_mode\n    super().__init__(data)\n\n    self.evaluator = Evaluator(self.temp_path)\n</code></pre>"},{"location":"api/tasks/cuda/cuda-task/#evotoolkit.task.cuda_engineering.cuda_task.CudaTask.get_task_type","title":"get_task_type","text":"<pre><code>get_task_type() -&gt; str\n</code></pre> <p>Get task type as 'Cuda'.</p> Source code in <code>src/evotoolkit/task/cuda_engineering/cuda_task.py</code> <pre><code>def get_task_type(self) -&gt; str:\n    \"\"\"Get task type as 'Cuda'.\"\"\"\n    return \"Cuda\"\n</code></pre>"},{"location":"api/tasks/cuda/cuda-task/#evotoolkit.task.cuda_engineering.cuda_task.CudaTask.get_base_task_description","title":"get_base_task_description","text":"<pre><code>get_base_task_description() -&gt; str\n</code></pre> <p>Get the base task description using task info</p> Source code in <code>src/evotoolkit/task/cuda_engineering/cuda_task.py</code> <pre><code>    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get the base task description using task info\"\"\"\n        gpu_type = self.task_info.get(\"gpu_type\", \"RTX 4090\")\n        cuda_version = self.task_info.get(\"cuda_version\", \"12.4.1\")\n        return f\"\"\"You are a Machine Learning Engineer trying to reduce the runtime of a CUDA kernel. Make sure the kernel returns the correct result. Do not use any alternative precision that could result in an incorrect result. The kernel will be run on a {gpu_type} GPU with CUDA {cuda_version}.\n\"\"\"\n</code></pre>"},{"location":"api/tasks/cuda/cuda-task/#evotoolkit.task.cuda_engineering.cuda_task.CudaTask.make_init_sol_wo_other_info","title":"make_init_sol_wo_other_info","text":"<pre><code>make_init_sol_wo_other_info() -&gt; Solution\n</code></pre> <p>Create initial solution from task info.</p> Source code in <code>src/evotoolkit/task/cuda_engineering/cuda_task.py</code> <pre><code>def make_init_sol_wo_other_info(self) -&gt; Solution:\n    \"\"\"Create initial solution from task info.\"\"\"\n    init_sol = Solution(self.task_info[\"cuda_code\"])\n    evaluation_res = EvaluationResult(\n        valid=True,\n        score=-self.task_info[\"cuda_info\"][\"runtime\"],\n        additional_info={\n            \"code\": self.task_info[\"cuda_code\"],\n            \"temp_str\": None,\n            \"runtime\": self.task_info[\"cuda_info\"][\"runtime\"],\n            \"prof_string\": self.task_info[\"cuda_info\"][\"prof_string\"],\n            \"compilation_error\": False,\n            \"comparison_error\": False,\n            \"error_msg\": None,\n            \"exception\": None,\n        },\n    )\n    init_sol.evaluation_res = evaluation_res\n    return init_sol\n</code></pre>"},{"location":"api/tasks/cuda/cuda-task/#evotoolkit.task.cuda_engineering.cuda_task.CudaTask.evaluate_code","title":"evaluate_code","text":"<pre><code>evaluate_code(candidate_code: str) -&gt; EvaluationResult\n</code></pre> <p>Evaluate CUDA kernel code.</p> Source code in <code>src/evotoolkit/task/cuda_engineering/cuda_task.py</code> <pre><code>def evaluate_code(self, candidate_code: str) -&gt; EvaluationResult:\n    \"\"\"Evaluate CUDA kernel code.\"\"\"\n\n    try:\n        if self.fake_mode:\n            return EvaluationResult(\n                valid=True,\n                score=-0.1,\n                additional_info={\n                    \"code\": candidate_code,\n                    \"temp_str\": None,\n                    \"runtime\": 0.1,\n                    \"prof_string\": None,\n                    \"compilation_error\": False,\n                    \"comparison_error\": False,\n                    \"error_msg\": None,\n                    \"exception\": None,\n                },\n            )\n\n        cuda_comparison_result = self.evaluator.compare_func_cuda_sandbox(\n            self.func_py_code, candidate_code\n        )\n\n        additional_info = {\n            \"code\": candidate_code,\n            \"temp_str\": cuda_comparison_result.get(\"temp_str\"),\n            \"runtime\": None,\n            \"prof_string\": None,\n            \"compilation_error\": cuda_comparison_result.get(\n                \"compilation_error\", False\n            ),\n            \"comparison_error\": not cuda_comparison_result.get(\n                \"correctness\", False\n            ),\n            \"error_msg\": cuda_comparison_result.get(\"error_msg\", None),\n        }\n\n        if cuda_comparison_result.get(\"correctness\", False):\n            cuda_runtime_result = self.evaluator.get_cuda_runtime_sandbox(\n                self.func_py_code,\n                candidate_code,\n                cuda_comparison_result.get(\"temp_str\"),\n            )\n            additional_info[\"runtime\"] = cuda_runtime_result.get(\"runtime\")\n            additional_info[\"prof_string\"] = cuda_runtime_result.get(\"prof_string\")\n\n            score = -cuda_runtime_result.get(\"runtime\")\n            valid = True\n            additional_info[\"error_msg\"] = cuda_runtime_result.get(\n                \"error_msg\", None\n            )\n        else:\n            score = None\n            valid = False\n\n        return EvaluationResult(\n            valid=valid, score=score, additional_info=additional_info\n        )\n\n    except Exception as e:\n        return EvaluationResult(\n            valid=False,\n            score=None,\n            additional_info={\n                \"code\": candidate_code,\n                \"temp_str\": None,\n                \"runtime\": None,\n                \"prof_string\": None,\n                \"compilation_error\": True,\n                \"comparison_error\": True,\n                \"error_msg\": str(e),\n                \"exception\": True,\n            },\n        )\n</code></pre>"},{"location":"api/tasks/python/adversarial-attack/","title":"AdversarialAttackTask","text":""},{"location":"api/tasks/python/adversarial-attack/#evotoolkit.task.python_task.adversarial_attack.AdversarialAttackTask","title":"evotoolkit.task.python_task.adversarial_attack.AdversarialAttackTask","text":"<p>               Bases: <code>PythonTask</code></p> <p>Adversarial attack task for evolving proposal generation algorithms.</p> <p>This task evaluates Python code that defines a <code>draw_proposals</code> function used in black-box adversarial attacks to generate candidate adversarial examples.</p> <p>The evolved function should effectively balance exploration and exploitation to find adversarial examples with minimal distortion.</p> Source code in <code>src/evotoolkit/task/python_task/adversarial_attack/adversarial_attack_task.py</code> <pre><code>@register_task(\"AdversarialAttack\")\nclass AdversarialAttackTask(PythonTask):\n    \"\"\"\n    Adversarial attack task for evolving proposal generation algorithms.\n\n    This task evaluates Python code that defines a `draw_proposals` function\n    used in black-box adversarial attacks to generate candidate adversarial examples.\n\n    The evolved function should effectively balance exploration and exploitation\n    to find adversarial examples with minimal distortion.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Optional[any] = None,\n        test_loader: Optional[any] = None,\n        attack_steps: int = 1000,\n        n_test_samples: int = 10,\n        timeout_seconds: float = 300.0,\n        use_mock: bool = False,\n    ):\n        \"\"\"\n        Initialize adversarial attack task.\n\n        Args:\n            model: Target model to attack (PyTorch model). If None or use_mock=True,\n                   uses mock evaluation for testing.\n            test_loader: DataLoader with test samples. If None or use_mock=True,\n                        uses mock evaluation. Data preprocessing/normalization should\n                        be handled externally (e.g., in model wrapper or transform).\n            attack_steps: Number of attack iterations per sample\n            n_test_samples: Number of test samples to evaluate\n            timeout_seconds: Execution timeout\n            use_mock: If True, uses mock evaluation (returns random fitness)\n        \"\"\"\n        self.model = model\n        self.test_loader = test_loader\n        self.attack_steps = attack_steps\n        self.n_test_samples = n_test_samples\n        self.use_mock = use_mock\n\n        # Initialize data\n        data = {\n            \"attack_steps\": attack_steps,\n            \"n_test_samples\": n_test_samples,\n            \"use_mock\": use_mock,\n        }\n\n        super().__init__(data=data, timeout_seconds=timeout_seconds)\n\n    def _process_data(self, data):\n        \"\"\"Process input data and create task_info.\"\"\"\n        self.data = data\n        self.task_info = {\n            \"attack_steps\": data[\"attack_steps\"],\n            \"n_test_samples\": data[\"n_test_samples\"],\n            \"use_mock\": data[\"use_mock\"],\n        }\n\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"\n        Evaluate Python code for adversarial attack.\n\n        The code must define a `draw_proposals` function.\n        \"\"\"\n        # If using mock mode, return random fitness\n        if self.use_mock:\n            return EvaluationResult(\n                valid=True,\n                score=float(np.random.uniform(1.0, 5.0)),  # Random L2 distance\n                additional_info={\n                    \"avg_distance\": float(np.random.uniform(1.0, 5.0)),\n                    \"mock\": True,\n                },\n            )\n\n        # Create namespace with required modules\n        namespace = {\n            \"__builtins__\": {\n                \"len\": len,\n                \"range\": range,\n                \"enumerate\": enumerate,\n                \"zip\": zip,\n                \"map\": map,\n                \"filter\": filter,\n                \"sum\": sum,\n                \"min\": min,\n                \"max\": max,\n                \"abs\": abs,\n                \"print\": print,\n                \"str\": str,\n                \"int\": int,\n                \"float\": float,\n                \"list\": list,\n                \"dict\": dict,\n                \"tuple\": tuple,\n                \"set\": set,\n                \"__import__\": __import__,\n            },\n            \"np\": np,\n        }\n\n        # Execute the code\n        try:\n            exec(candidate_code, namespace)\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float(\"-inf\"),\n                additional_info={\"error\": f\"Code execution error: {str(e)}\"},\n            )\n\n        # Check if draw_proposals function exists\n        if \"draw_proposals\" not in namespace:\n            return EvaluationResult(\n                valid=False,\n                score=float(\"-inf\"),\n                additional_info={\n                    \"error\": 'Function \"draw_proposals\" not found in code'\n                },\n            )\n\n        draw_proposals_func = namespace[\"draw_proposals\"]\n\n        # Evaluate the attack\n        try:\n            avg_distance = self._evaluate_attack(draw_proposals_func)\n\n            if avg_distance is None or np.isnan(avg_distance) or np.isinf(avg_distance):\n                return EvaluationResult(\n                    valid=False,\n                    score=float(\"-inf\"),\n                    additional_info={\n                        \"error\": \"Attack evaluation returned None/NaN/Inf\"\n                    },\n                )\n\n            # Lower distance is better - negate for maximization\n            score = -float(avg_distance)\n\n            return EvaluationResult(\n                valid=True,\n                score=score,\n                additional_info={\n                    \"avg_distance\": float(avg_distance),\n                    \"attack_steps\": self.attack_steps,\n                },\n            )\n\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float(\"-inf\"),\n                additional_info={\"error\": f\"Attack evaluation error: {str(e)}\"},\n            )\n\n    def _evaluate_attack(self, draw_proposals_func: Callable) -&gt; Optional[float]:\n        \"\"\"\n        Evaluate attack with evolved draw_proposals function.\n\n        Returns:\n            float: Average L2 distance, or None if failed\n        \"\"\"\n        import eagerpy as ep\n        import foolbox as fb\n        import torch\n\n        # Create module with draw_proposals\n        heuristic_module = types.ModuleType(\"heuristic_module\")\n        heuristic_module.draw_proposals = draw_proposals_func\n        sys.modules[heuristic_module.__name__] = heuristic_module\n\n        # Import EvoAttack\n        from .evo_attack import EvoAttack\n\n        # Setup model\n        if torch.cuda.is_available():\n            self.model.cuda()\n\n        # Create foolbox model without preprocessing\n        # User should handle normalization externally (in model wrapper or transform)\n        fmodel = fb.PyTorchModel(self.model, bounds=(0, 1))\n\n        # Let EvoAttack use its default initial attack (LinearSearchBlendedUniformNoiseAttack)\n        # which is a MinimizationAttack. Our improved error handling in evo_attack.py\n        # will handle cases where initial attack fails.\n        attack = EvoAttack(heuristic_module, init_attack=None, steps=self.attack_steps)\n\n        # Evaluate on test samples\n        distances = []\n        sample_count = 0\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n\n            for x, y in self.test_loader:\n                if sample_count &gt;= self.n_test_samples:\n                    break\n\n                if torch.cuda.is_available():\n                    x = x.cuda()\n                    y = y.cuda()\n\n                # Clip to [0, 1] using eagerpy\n                x_ep = ep.astensor(x)\n                min_, max_ = fmodel.bounds\n                x_ep = ep.clip(x_ep, min_, max_)\n                x = x_ep.raw\n\n                try:\n                    # Run attack with foolbox criterion\n                    img_adv = attack.run(fmodel, x, fb.criteria.Misclassification(y))\n\n                    # Calculate L2 distance\n                    distance = torch.linalg.norm(\n                        (x - img_adv).flatten(start_dim=1), axis=1\n                    )\n                    distance = distance.mean()\n\n                    # Check if distance is valid\n                    dist_value = float(distance.cpu().numpy())\n                    if np.isnan(dist_value) or np.isinf(dist_value):\n                        print(\n                            f\"Warning: Invalid distance for sample {sample_count}, using penalty value\"\n                        )\n                        distances.append(10.0)  # Penalty for invalid result\n                    else:\n                        distances.append(dist_value)\n\n                except Exception as e:\n                    # If attack fails, use a penalty value instead of failing completely\n                    print(f\"Warning: Attack failed on sample {sample_count}: {str(e)}\")\n                    distances.append(10.0)  # Penalty distance for failed attack\n\n                sample_count += 1\n\n        if not distances:\n            return None\n\n        return float(np.mean(distances))\n\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get task description.\"\"\"\n        return \"\"\"You are an expert in adversarial machine learning and optimization algorithms.\n\nTask: Design an effective proposal generation algorithm for black-box adversarial attacks\n\nYour goal is to evolve a `draw_proposals` function that generates high-quality candidate\nadversarial examples to fool a neural network classifier with minimal distortion.\n\nFunction Signature:\n```python\ndef draw_proposals(\n    org_img: np.ndarray,\n    best_adv_img: np.ndarray,\n    std_normal_noise: np.ndarray,\n    hyperparams: np.ndarray\n) -&gt; np.ndarray:\n    \\\"\\\"\\\"\n    Generate a new candidate adversarial example.\n\n    Args:\n        org_img: Original clean image, shape (3, H, W), values in [0, 1]\n        best_adv_img: Current best adversarial example, shape (3, H, W), values in [0, 1]\n        std_normal_noise: Random normal noise, shape (3, H, W)\n        hyperparams: Step size parameter, shape (1,), range [0.5, 1.5]\n                    Gets larger when algorithm finds more adversarial examples\n\n    Returns:\n        np.ndarray: New candidate adversarial example, shape (3, H, W)\n    \\\"\\\"\\\"\n```\n\nRequirements:\n- All inputs and outputs are numpy arrays\n- Output must have same shape as org_img: (3, H, W)\n- Output values should stay in [0, 1] (will be clipped automatically)\n- Use numpy operations (np.linalg.norm, np.dot, etc.)\n\nAvailable Operations:\n- Arithmetic: +, -, *, /\n- Linear algebra: np.dot, np.linalg.norm, np.matmul\n- Array operations: .reshape(), .flatten(), etc.\n\nStrategy Guidelines:\n1. **Direction**: Move from best_adv_img towards the decision boundary\n2. **Step size**: Use hyperparams to control exploration vs exploitation\n3. **Noise**: Incorporate std_normal_noise for exploration\n4. **Distance**: Consider the vector from org_img to best_adv_img\n\nKey Insights:\n- Smaller L2 distance from org_img is better\n- The candidate should be adversarial (fool the model)\n- Balance between exploitation (refining best_adv_img) and exploration (using noise)\n- hyperparams adapts: increases when finding adversarials, decreases otherwise\n\nExample Structure:\n```python\nimport numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    # Reshape to vectors\n    org = org_img.flatten()\n    best = best_adv_img.flatten()\n    noise = std_normal_noise.flatten()\n\n    # Compute direction from org to best\n    direction = org - best\n\n    # Your algorithm here: combine direction, noise, and hyperparams\n    # ...\n\n    # Reshape back to image\n    return candidate.reshape(org_img.shape)\n```\n\nFitness: Your function will be evaluated by running attacks and measuring the average L2\ndistance of adversarial examples from original images. Lower distance = better score.\n\"\"\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"Create initial solution with baseline algorithm.\"\"\"\n        initial_code = '''import numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    \"\"\"\n    Baseline proposal generation using parallel and perpendicular components.\n\n    This is a simple baseline that combines:\n    1. Movement along the direction from org to best (parallel)\n    2. Random exploration perpendicular to that direction\n    \"\"\"\n    # Reshape to flat vectors\n    original_shape = org_img.shape\n    org = org_img.flatten()\n    best = best_adv_img.flatten()\n    noise = std_normal_noise.flatten()\n\n    # Compute norms and direction\n    noise_norm = np.linalg.norm(noise)\n    direction = org - best\n    direction_norm = np.linalg.norm(direction)\n\n    # Parallel component (along org-&gt;best direction)\n    step_size = (noise_norm * hyperparams[0]) ** 2\n    d_parallel = step_size * direction\n\n    # Perpendicular component (exploration)\n    if direction_norm &gt; 1e-8:\n        # Project noise onto direction\n        dot_product = np.dot(direction, noise)\n        projection = (dot_product / direction_norm) * direction\n        # Perpendicular = noise - projection\n        d_perpendicular = (projection / direction_norm - direction_norm * noise) * hyperparams[0]\n    else:\n        d_perpendicular = noise * hyperparams[0]\n\n    # Combine components\n    candidate = best + d_parallel + d_perpendicular\n\n    # Reshape back\n    return candidate.reshape(original_shape)\n'''\n        # Evaluate the initial solution\n        eval_res = self.evaluate_code(initial_code)\n\n        return Solution(sol_string=initial_code, evaluation_res=eval_res, other_info={})\n</code></pre>"},{"location":"api/tasks/python/adversarial-attack/#evotoolkit.task.python_task.adversarial_attack.AdversarialAttackTask.__init__","title":"__init__","text":"<pre><code>__init__(\n    model: Optional[any] = None,\n    test_loader: Optional[any] = None,\n    attack_steps: int = 1000,\n    n_test_samples: int = 10,\n    timeout_seconds: float = 300.0,\n    use_mock: bool = False,\n)\n</code></pre> <p>Initialize adversarial attack task.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[any]</code> <p>Target model to attack (PyTorch model). If None or use_mock=True,    uses mock evaluation for testing.</p> <code>None</code> <code>test_loader</code> <code>Optional[any]</code> <p>DataLoader with test samples. If None or use_mock=True,         uses mock evaluation. Data preprocessing/normalization should         be handled externally (e.g., in model wrapper or transform).</p> <code>None</code> <code>attack_steps</code> <code>int</code> <p>Number of attack iterations per sample</p> <code>1000</code> <code>n_test_samples</code> <code>int</code> <p>Number of test samples to evaluate</p> <code>10</code> <code>timeout_seconds</code> <code>float</code> <p>Execution timeout</p> <code>300.0</code> <code>use_mock</code> <code>bool</code> <p>If True, uses mock evaluation (returns random fitness)</p> <code>False</code> Source code in <code>src/evotoolkit/task/python_task/adversarial_attack/adversarial_attack_task.py</code> <pre><code>def __init__(\n    self,\n    model: Optional[any] = None,\n    test_loader: Optional[any] = None,\n    attack_steps: int = 1000,\n    n_test_samples: int = 10,\n    timeout_seconds: float = 300.0,\n    use_mock: bool = False,\n):\n    \"\"\"\n    Initialize adversarial attack task.\n\n    Args:\n        model: Target model to attack (PyTorch model). If None or use_mock=True,\n               uses mock evaluation for testing.\n        test_loader: DataLoader with test samples. If None or use_mock=True,\n                    uses mock evaluation. Data preprocessing/normalization should\n                    be handled externally (e.g., in model wrapper or transform).\n        attack_steps: Number of attack iterations per sample\n        n_test_samples: Number of test samples to evaluate\n        timeout_seconds: Execution timeout\n        use_mock: If True, uses mock evaluation (returns random fitness)\n    \"\"\"\n    self.model = model\n    self.test_loader = test_loader\n    self.attack_steps = attack_steps\n    self.n_test_samples = n_test_samples\n    self.use_mock = use_mock\n\n    # Initialize data\n    data = {\n        \"attack_steps\": attack_steps,\n        \"n_test_samples\": n_test_samples,\n        \"use_mock\": use_mock,\n    }\n\n    super().__init__(data=data, timeout_seconds=timeout_seconds)\n</code></pre>"},{"location":"api/tasks/python/adversarial-attack/#evotoolkit.task.python_task.adversarial_attack.AdversarialAttackTask.get_base_task_description","title":"get_base_task_description","text":"<pre><code>get_base_task_description() -&gt; str\n</code></pre> <p>Get task description.</p> Source code in <code>src/evotoolkit/task/python_task/adversarial_attack/adversarial_attack_task.py</code> <pre><code>    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get task description.\"\"\"\n        return \"\"\"You are an expert in adversarial machine learning and optimization algorithms.\n\nTask: Design an effective proposal generation algorithm for black-box adversarial attacks\n\nYour goal is to evolve a `draw_proposals` function that generates high-quality candidate\nadversarial examples to fool a neural network classifier with minimal distortion.\n\nFunction Signature:\n```python\ndef draw_proposals(\n    org_img: np.ndarray,\n    best_adv_img: np.ndarray,\n    std_normal_noise: np.ndarray,\n    hyperparams: np.ndarray\n) -&gt; np.ndarray:\n    \\\"\\\"\\\"\n    Generate a new candidate adversarial example.\n\n    Args:\n        org_img: Original clean image, shape (3, H, W), values in [0, 1]\n        best_adv_img: Current best adversarial example, shape (3, H, W), values in [0, 1]\n        std_normal_noise: Random normal noise, shape (3, H, W)\n        hyperparams: Step size parameter, shape (1,), range [0.5, 1.5]\n                    Gets larger when algorithm finds more adversarial examples\n\n    Returns:\n        np.ndarray: New candidate adversarial example, shape (3, H, W)\n    \\\"\\\"\\\"\n```\n\nRequirements:\n- All inputs and outputs are numpy arrays\n- Output must have same shape as org_img: (3, H, W)\n- Output values should stay in [0, 1] (will be clipped automatically)\n- Use numpy operations (np.linalg.norm, np.dot, etc.)\n\nAvailable Operations:\n- Arithmetic: +, -, *, /\n- Linear algebra: np.dot, np.linalg.norm, np.matmul\n- Array operations: .reshape(), .flatten(), etc.\n\nStrategy Guidelines:\n1. **Direction**: Move from best_adv_img towards the decision boundary\n2. **Step size**: Use hyperparams to control exploration vs exploitation\n3. **Noise**: Incorporate std_normal_noise for exploration\n4. **Distance**: Consider the vector from org_img to best_adv_img\n\nKey Insights:\n- Smaller L2 distance from org_img is better\n- The candidate should be adversarial (fool the model)\n- Balance between exploitation (refining best_adv_img) and exploration (using noise)\n- hyperparams adapts: increases when finding adversarials, decreases otherwise\n\nExample Structure:\n```python\nimport numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    # Reshape to vectors\n    org = org_img.flatten()\n    best = best_adv_img.flatten()\n    noise = std_normal_noise.flatten()\n\n    # Compute direction from org to best\n    direction = org - best\n\n    # Your algorithm here: combine direction, noise, and hyperparams\n    # ...\n\n    # Reshape back to image\n    return candidate.reshape(org_img.shape)\n```\n\nFitness: Your function will be evaluated by running attacks and measuring the average L2\ndistance of adversarial examples from original images. Lower distance = better score.\n\"\"\"\n</code></pre>"},{"location":"api/tasks/python/adversarial-attack/#evotoolkit.task.python_task.adversarial_attack.AdversarialAttackTask.make_init_sol_wo_other_info","title":"make_init_sol_wo_other_info","text":"<pre><code>make_init_sol_wo_other_info() -&gt; Solution\n</code></pre> <p>Create initial solution with baseline algorithm.</p> Source code in <code>src/evotoolkit/task/python_task/adversarial_attack/adversarial_attack_task.py</code> <pre><code>    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"Create initial solution with baseline algorithm.\"\"\"\n        initial_code = '''import numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    \"\"\"\n    Baseline proposal generation using parallel and perpendicular components.\n\n    This is a simple baseline that combines:\n    1. Movement along the direction from org to best (parallel)\n    2. Random exploration perpendicular to that direction\n    \"\"\"\n    # Reshape to flat vectors\n    original_shape = org_img.shape\n    org = org_img.flatten()\n    best = best_adv_img.flatten()\n    noise = std_normal_noise.flatten()\n\n    # Compute norms and direction\n    noise_norm = np.linalg.norm(noise)\n    direction = org - best\n    direction_norm = np.linalg.norm(direction)\n\n    # Parallel component (along org-&gt;best direction)\n    step_size = (noise_norm * hyperparams[0]) ** 2\n    d_parallel = step_size * direction\n\n    # Perpendicular component (exploration)\n    if direction_norm &gt; 1e-8:\n        # Project noise onto direction\n        dot_product = np.dot(direction, noise)\n        projection = (dot_product / direction_norm) * direction\n        # Perpendicular = noise - projection\n        d_perpendicular = (projection / direction_norm - direction_norm * noise) * hyperparams[0]\n    else:\n        d_perpendicular = noise * hyperparams[0]\n\n    # Combine components\n    candidate = best + d_parallel + d_perpendicular\n\n    # Reshape back\n    return candidate.reshape(original_shape)\n'''\n        # Evaluate the initial solution\n        eval_res = self.evaluate_code(initial_code)\n\n        return Solution(sol_string=initial_code, evaluation_res=eval_res, other_info={})\n</code></pre>"},{"location":"api/tasks/python/python-task/","title":"PythonTask","text":""},{"location":"api/tasks/python/python-task/#evotoolkit.task.python_task.python_task.PythonTask","title":"evotoolkit.task.python_task.python_task.PythonTask","text":"<p>               Bases: <code>BaseTask</code></p> <p>Abstract base class for Python-based evolutionary optimization tasks.</p> <p>This class unifies PythonEvaluator and PythonTaskConfig functionality, providing a common base for Python code evaluation tasks.</p> Source code in <code>src/evotoolkit/task/python_task/python_task.py</code> <pre><code>class PythonTask(BaseTask):\n    \"\"\"\n    Abstract base class for Python-based evolutionary optimization tasks.\n\n    This class unifies PythonEvaluator and PythonTaskConfig functionality,\n    providing a common base for Python code evaluation tasks.\n    \"\"\"\n\n    def __init__(self, data, timeout_seconds: float = 30.0):\n        \"\"\"\n        Initialize the Python task with input data.\n\n        Args:\n            data (Any): Task-specific input data.\n            timeout_seconds (float): Execution timeout for code evaluation.\n        \"\"\"\n        self.timeout_seconds = timeout_seconds\n        super().__init__(data)\n\n    def get_task_type(self) -&gt; str:\n        \"\"\"Get task type as 'Python'.\"\"\"\n        return \"Python\"\n\n    def evaluate_code(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"\n        Evaluate Python code.\n\n        Default implementation provides basic error handling framework.\n        Subclasses should override this method with specific evaluation logic.\n\n        Args:\n            candidate_code: Python code to evaluate\n\n        Returns:\n            EvaluationResult: Result of the evaluation\n        \"\"\"\n        try:\n            return self._evaluate_code_impl(candidate_code)\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float(\"-inf\"),\n                additional_info={\n                    \"error\": f\"Evaluation error: {str(e)}\",\n                    \"traceback\": traceback.format_exc(),\n                },\n            )\n\n    @abstractmethod\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"\n        Implement specific code evaluation logic.\n\n        Subclasses must implement this method with their specific\n        evaluation logic. This method is called by evaluate_code\n        within a try-catch block.\n\n        Args:\n            candidate_code: Python code to evaluate\n\n        Returns:\n            EvaluationResult: Result of the evaluation\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/tasks/python/python-task/#evotoolkit.task.python_task.python_task.PythonTask.__init__","title":"__init__","text":"<pre><code>__init__(data, timeout_seconds: float = 30.0)\n</code></pre> <p>Initialize the Python task with input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Task-specific input data.</p> required <code>timeout_seconds</code> <code>float</code> <p>Execution timeout for code evaluation.</p> <code>30.0</code> Source code in <code>src/evotoolkit/task/python_task/python_task.py</code> <pre><code>def __init__(self, data, timeout_seconds: float = 30.0):\n    \"\"\"\n    Initialize the Python task with input data.\n\n    Args:\n        data (Any): Task-specific input data.\n        timeout_seconds (float): Execution timeout for code evaluation.\n    \"\"\"\n    self.timeout_seconds = timeout_seconds\n    super().__init__(data)\n</code></pre>"},{"location":"api/tasks/python/python-task/#evotoolkit.task.python_task.python_task.PythonTask.get_task_type","title":"get_task_type","text":"<pre><code>get_task_type() -&gt; str\n</code></pre> <p>Get task type as 'Python'.</p> Source code in <code>src/evotoolkit/task/python_task/python_task.py</code> <pre><code>def get_task_type(self) -&gt; str:\n    \"\"\"Get task type as 'Python'.\"\"\"\n    return \"Python\"\n</code></pre>"},{"location":"api/tasks/python/python-task/#evotoolkit.task.python_task.python_task.PythonTask.evaluate_code","title":"evaluate_code","text":"<pre><code>evaluate_code(candidate_code: str) -&gt; EvaluationResult\n</code></pre> <p>Evaluate Python code.</p> <p>Default implementation provides basic error handling framework. Subclasses should override this method with specific evaluation logic.</p> <p>Parameters:</p> Name Type Description Default <code>candidate_code</code> <code>str</code> <p>Python code to evaluate</p> required <p>Returns:</p> Name Type Description <code>EvaluationResult</code> <code>EvaluationResult</code> <p>Result of the evaluation</p> Source code in <code>src/evotoolkit/task/python_task/python_task.py</code> <pre><code>def evaluate_code(self, candidate_code: str) -&gt; EvaluationResult:\n    \"\"\"\n    Evaluate Python code.\n\n    Default implementation provides basic error handling framework.\n    Subclasses should override this method with specific evaluation logic.\n\n    Args:\n        candidate_code: Python code to evaluate\n\n    Returns:\n        EvaluationResult: Result of the evaluation\n    \"\"\"\n    try:\n        return self._evaluate_code_impl(candidate_code)\n    except Exception as e:\n        return EvaluationResult(\n            valid=False,\n            score=float(\"-inf\"),\n            additional_info={\n                \"error\": f\"Evaluation error: {str(e)}\",\n                \"traceback\": traceback.format_exc(),\n            },\n        )\n</code></pre>"},{"location":"api/tasks/python/scientific-regression/","title":"ScientificRegressionTask","text":""},{"location":"api/tasks/python/scientific-regression/#evotoolkit.task.python_task.scientific_regression.ScientificRegressionTask","title":"evotoolkit.task.python_task.scientific_regression.ScientificRegressionTask","text":"<p>               Bases: <code>PythonTask</code></p> <p>Scientific symbolic regression task for discovering mathematical equations.</p> <p>This task evaluates Python code that defines an <code>equation</code> function, optimizes its parameters using scipy, and returns fitness based on MSE.</p> Source code in <code>src/evotoolkit/task/python_task/scientific_regression/scientific_regression_task.py</code> <pre><code>@register_task(\"ScientificRegression\")\nclass ScientificRegressionTask(PythonTask):\n    \"\"\"\n    Scientific symbolic regression task for discovering mathematical equations.\n\n    This task evaluates Python code that defines an `equation` function,\n    optimizes its parameters using scipy, and returns fitness based on MSE.\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset_name: Literal[\"bactgrow\", \"oscillator1\", \"oscillator2\", \"stressstrain\"],\n        data_dir: str | Path | None = None,\n        max_params: int = 10,\n        timeout_seconds: float = 60.0,\n    ):\n        \"\"\"\n        Initialize scientific regression task.\n\n        Args:\n            dataset_name: Name of the scientific dataset\n            data_dir: Custom data directory (optional, defaults to ~/.evotool/data/)\n            max_params: Maximum number of optimizable parameters\n            timeout_seconds: Execution timeout\n        \"\"\"\n        if dataset_name not in DATASET_INFO:\n            raise ValueError(\n                f\"Unknown dataset: {dataset_name}. \"\n                f\"Available: {list(DATASET_INFO.keys())}\"\n            )\n\n        self.dataset_name = dataset_name\n        self.max_params = max_params\n        self.dataset_info = DATASET_INFO[dataset_name]\n\n        # Load data\n        train_data, test_data = self._load_dataset(dataset_name, data_dir)\n\n        # Store data\n        self.train_inputs = train_data[\"inputs\"]\n        self.train_outputs = train_data[\"outputs\"]\n        self.test_inputs = test_data[\"inputs\"]\n        self.test_outputs = test_data[\"outputs\"]\n\n        # Pass to parent\n        super().__init__(\n            data={\"train\": train_data, \"test\": test_data},\n            timeout_seconds=timeout_seconds,\n        )\n\n    def _load_dataset(self, dataset_name: str, data_dir: str | Path | None):\n        \"\"\"\n        Load dataset, automatically downloading from GitHub release if needed.\n\n        Returns:\n            tuple: (train_data, test_data) dictionaries with 'inputs' and 'outputs'\n        \"\"\"\n        from evotoolkit.data import DownloadError, get_dataset_path\n\n        try:\n            # Get dataset path, will auto-download if needed\n            base_dir = get_dataset_path(\n                \"scientific_regression\", data_dir=data_dir)\n            dataset_path = base_dir / dataset_name\n        except DownloadError as e:\n            raise FileNotFoundError(\n                f\"Failed to download dataset '{dataset_name}': {str(e)}\"\n            ) from e\n\n        # Verify dataset exists\n        if not dataset_path.exists():\n            raise FileNotFoundError(\n                f\"Dataset '{dataset_name}' not found after download. \"\n                f\"This might be a bug - please report it at: \"\n                f\"https://github.com/pgg3/evotoolkit/issues\"\n            )\n\n        # Load CSV files\n        info = self.dataset_info\n        train_df = pd.read_csv(dataset_path / \"train.csv\")\n        # Use in-distribution test\n        test_df = pd.read_csv(dataset_path / \"test_id.csv\")\n\n        # Extract inputs and outputs\n        train_data = {\n            \"inputs\": train_df[info[\"input_cols\"]].values,\n            \"outputs\": train_df[info[\"output_col\"]].values,\n        }\n        test_data = {\n            \"inputs\": test_df[info[\"input_cols\"]].values,\n            \"outputs\": test_df[info[\"output_col\"]].values,\n        }\n\n        return train_data, test_data\n\n    def _process_data(self, data):\n        \"\"\"Process input data and create task_info.\"\"\"\n        self.data = data\n        self.task_info = {\n            \"dataset_name\": self.dataset_name,\n            \"train_size\": len(data[\"train\"][\"inputs\"]),\n            \"test_size\": len(data[\"test\"][\"inputs\"]),\n            \"n_inputs\": data[\"train\"][\"inputs\"].shape[1],\n            \"max_params\": self.max_params,\n        }\n\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"\n        Evaluate Python code for scientific symbolic regression.\n\n        The code must define an `equation` function that will be optimized.\n        \"\"\"\n        # Create namespace with required modules\n        namespace = {\n            \"__builtins__\": {\n                \"len\": len,\n                \"range\": range,\n                \"enumerate\": enumerate,\n                \"zip\": zip,\n                \"map\": map,\n                \"filter\": filter,\n                \"sum\": sum,\n                \"min\": min,\n                \"max\": max,\n                \"abs\": abs,\n                \"print\": print,\n                \"str\": str,\n                \"int\": int,\n                \"float\": float,\n                \"list\": list,\n                \"dict\": dict,\n                \"tuple\": tuple,\n                \"set\": set,\n                \"__import__\": __import__,\n            },\n            \"np\": np,\n        }\n\n        # Execute the code\n        exec(candidate_code, namespace)\n\n        # Check if equation function exists\n        if \"equation\" not in namespace:\n            return EvaluationResult(\n                valid=False,\n                score=float(\"-inf\"),\n                additional_info={\n                    \"error\": 'Function \"equation\" not found in code'},\n            )\n\n        equation_func = namespace[\"equation\"]\n\n        # Evaluate on training data\n        try:\n            train_score, train_warnings = self._evaluate_equation(\n                equation_func, self.train_inputs, self.train_outputs\n            )\n\n            # Evaluate on test data\n            test_score, test_warnings = self._evaluate_equation(\n                equation_func, self.test_inputs, self.test_outputs\n            )\n\n            # Combine all warnings\n            all_warnings = list(set(train_warnings + test_warnings))\n\n            if train_score is None or test_score is None:\n                return EvaluationResult(\n                    valid=False,\n                    score=float(\"-inf\"),\n                    additional_info={\n                        \"error\": \"Optimization failed or returned NaN/Inf\",\n                        \"warnings\": all_warnings,\n                    },\n                )\n\n            # Use train_score as fitness (already -MSE, higher is better)\n            # Test score is only for final evaluation, not for optimization\n            score = train_score\n\n            return EvaluationResult(\n                valid=True,\n                score=score,\n                additional_info={\n                    \"train_mse\": -train_score,  # Convert -MSE back to MSE for logging\n                    \"test_mse\": -test_score,  # Convert -MSE back to MSE for logging\n                    \"n_params\": self.max_params,\n                    \"warnings\": all_warnings if all_warnings else [],\n                },\n            )\n\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float(\"-inf\"),\n                additional_info={\"error\": f\"Evaluation error: {str(e)}\"},\n            )\n\n    def _evaluate_equation(self, equation_func, inputs, outputs):\n        \"\"\"\n        Evaluate equation with parameter optimization.\n\n        Returns:\n            tuple: (score, warnings_list) where score is -MSE (higher is better), or (None, warnings) if failed\n        \"\"\"\n        from scipy.optimize import minimize\n\n        captured_warnings = []\n\n        # Define loss function\n        def loss(params):\n            try:\n                # Call equation with unpacked inputs and params\n                if inputs.shape[1] == 2:\n                    y_pred = equation_func(inputs[:, 0], inputs[:, 1], params)\n                elif inputs.shape[1] == 4:\n                    y_pred = equation_func(\n                        inputs[:, 0], inputs[:, 1], inputs[:,\n                                                           2], inputs[:, 3], params\n                    )\n                else:\n                    # Generic case\n                    y_pred = equation_func(\n                        *[inputs[:, i] for i in range(inputs.shape[1])], params\n                    )\n\n                mse = np.mean((y_pred - outputs) ** 2)\n                return mse\n            except Exception:\n                return 1e10  # Large penalty for errors\n\n        # Optimize parameters with warning capture\n        try:\n            with warnings.catch_warnings(record=True) as w:\n                warnings.simplefilter(\"always\")\n\n                result = minimize(\n                    loss,\n                    x0=[1.0] * self.max_params,\n                    method=\"BFGS\",\n                    options={\"maxiter\": 1000},\n                )\n\n                # Collect warning messages\n                for warning in w:\n                    msg = f\"{warning.category.__name__}: {warning.message}\"\n                    if msg not in captured_warnings:  # Deduplicate\n                        captured_warnings.append(msg)\n\n            final_loss = result.fun\n\n            # Check for NaN or Inf\n            if np.isnan(final_loss) or np.isinf(final_loss):\n                return (None, captured_warnings)\n\n            # Return negative MSE (higher is better) and warnings\n            return (-final_loss, captured_warnings)\n\n        except Exception:\n            return (None, captured_warnings)\n\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get task description for the specific dataset.\"\"\"\n        info = self.dataset_info\n        input_names = info[\"input_cols\"]\n        output_name = info[\"output_col\"]\n\n        # Build input signature\n        if len(input_names) == 2:\n            signature = f\"{input_names[0]}: np.ndarray, {input_names[1]}: np.ndarray, params: np.ndarray\"\n        elif len(input_names) == 4:\n            signature = (\n                \", \".join([f\"{name}: np.ndarray\" for name in input_names])\n                + \", params: np.ndarray\"\n            )\n        else:\n            signature = (\n                \", \".join(\n                    [f\"input{i}: np.ndarray\" for i in range(len(input_names))])\n                + \", params: np.ndarray\"\n            )\n\n        return f\"\"\"You are an expert in scientific symbolic regression and mathematical modeling.\n\nTask: {info[\"description\"]}\n\nYour goal is to discover a mathematical equation that predicts {output_name} from:\n{chr(10).join(f\"  - {inp}\" for inp in info[\"inputs\"])}\n\nRequirements:\n- Define a function named 'equation' with signature: equation({signature}) -&gt; np.ndarray\n- Use numpy operations for vectorized computation\n- The 'params' array contains {self.max_params} optimizable constants (params[0] to params[{self.max_params - 1}])\n- Return predictions as a numpy array matching the shape of inputs\n- Focus on discovering the mathematical structure; parameters will be auto-optimized\n\nGuidelines:\n- Use mathematical operations: +, -, *, /, **, np.exp, np.log, np.sin, np.cos, etc.\n- Combine input variables in meaningful ways based on physical intuition\n- Keep equations reasonably simple to avoid overfitting\n- Ensure numerical stability (avoid division by very small numbers, etc.)\n- All operations must be vectorized (work on numpy arrays)\n\nExample structure:\n```python\nimport numpy as np\n\ndef equation({signature}) -&gt; np.ndarray:\n    # Example: linear combination\n    return params[0] * {input_names[0]} + params[1] * {input_names[1] if len(input_names) &gt; 1 else input_names[0]}\n```\n\nFitness: Your equation will be evaluated by optimizing parameters to minimize MSE on test data.\n\"\"\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"Create initial solution with simple linear equation.\"\"\"\n        info = self.dataset_info\n        input_names = info[\"input_cols\"]\n\n        # Build simple linear combination\n        if len(input_names) == 2:\n            equation_body = f\"    return params[0] * {input_names[0]} + params[1] * {input_names[1]} + params[2]\"\n            signature = f\"{input_names[0]}, {input_names[1]}, params\"\n        elif len(input_names) == 4:\n            terms = [f\"params[{i}] * {name}\" for i,\n                     name in enumerate(input_names)]\n            equation_body = (\n                f\"    return {' + '.join(terms)} + params[{len(input_names)}]\"\n            )\n            signature = \", \".join(input_names) + \", params\"\n        else:\n            terms = [\n                f\"params[{i}] * input{i}\" for i in range(len(input_names))]\n            equation_body = (\n                f\"    return {' + '.join(terms)} + params[{len(input_names)}]\"\n            )\n            signature = (\n                \", \".join([f\"input{i}\" for i in range(\n                    len(input_names))]) + \", params\"\n            )\n\n        initial_code = f'''import numpy as np\n\ndef equation({signature}):\n    \"\"\"Linear baseline model.\"\"\"\n{equation_body}\n'''\n\n        # Evaluate the initial solution\n        eval_res = self.evaluate_code(initial_code)\n\n        return Solution(sol_string=initial_code, evaluation_res=eval_res, other_info={})\n</code></pre>"},{"location":"api/tasks/python/scientific-regression/#evotoolkit.task.python_task.scientific_regression.ScientificRegressionTask.__init__","title":"__init__","text":"<pre><code>__init__(\n    dataset_name: Literal[\n        \"bactgrow\",\n        \"oscillator1\",\n        \"oscillator2\",\n        \"stressstrain\",\n    ],\n    data_dir: str | Path | None = None,\n    max_params: int = 10,\n    timeout_seconds: float = 60.0,\n)\n</code></pre> <p>Initialize scientific regression task.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>Literal['bactgrow', 'oscillator1', 'oscillator2', 'stressstrain']</code> <p>Name of the scientific dataset</p> required <code>data_dir</code> <code>str | Path | None</code> <p>Custom data directory (optional, defaults to ~/.evotool/data/)</p> <code>None</code> <code>max_params</code> <code>int</code> <p>Maximum number of optimizable parameters</p> <code>10</code> <code>timeout_seconds</code> <code>float</code> <p>Execution timeout</p> <code>60.0</code> Source code in <code>src/evotoolkit/task/python_task/scientific_regression/scientific_regression_task.py</code> <pre><code>def __init__(\n    self,\n    dataset_name: Literal[\"bactgrow\", \"oscillator1\", \"oscillator2\", \"stressstrain\"],\n    data_dir: str | Path | None = None,\n    max_params: int = 10,\n    timeout_seconds: float = 60.0,\n):\n    \"\"\"\n    Initialize scientific regression task.\n\n    Args:\n        dataset_name: Name of the scientific dataset\n        data_dir: Custom data directory (optional, defaults to ~/.evotool/data/)\n        max_params: Maximum number of optimizable parameters\n        timeout_seconds: Execution timeout\n    \"\"\"\n    if dataset_name not in DATASET_INFO:\n        raise ValueError(\n            f\"Unknown dataset: {dataset_name}. \"\n            f\"Available: {list(DATASET_INFO.keys())}\"\n        )\n\n    self.dataset_name = dataset_name\n    self.max_params = max_params\n    self.dataset_info = DATASET_INFO[dataset_name]\n\n    # Load data\n    train_data, test_data = self._load_dataset(dataset_name, data_dir)\n\n    # Store data\n    self.train_inputs = train_data[\"inputs\"]\n    self.train_outputs = train_data[\"outputs\"]\n    self.test_inputs = test_data[\"inputs\"]\n    self.test_outputs = test_data[\"outputs\"]\n\n    # Pass to parent\n    super().__init__(\n        data={\"train\": train_data, \"test\": test_data},\n        timeout_seconds=timeout_seconds,\n    )\n</code></pre>"},{"location":"api/tasks/python/scientific-regression/#evotoolkit.task.python_task.scientific_regression.ScientificRegressionTask.get_base_task_description","title":"get_base_task_description","text":"<pre><code>get_base_task_description() -&gt; str\n</code></pre> <p>Get task description for the specific dataset.</p> Source code in <code>src/evotoolkit/task/python_task/scientific_regression/scientific_regression_task.py</code> <pre><code>    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get task description for the specific dataset.\"\"\"\n        info = self.dataset_info\n        input_names = info[\"input_cols\"]\n        output_name = info[\"output_col\"]\n\n        # Build input signature\n        if len(input_names) == 2:\n            signature = f\"{input_names[0]}: np.ndarray, {input_names[1]}: np.ndarray, params: np.ndarray\"\n        elif len(input_names) == 4:\n            signature = (\n                \", \".join([f\"{name}: np.ndarray\" for name in input_names])\n                + \", params: np.ndarray\"\n            )\n        else:\n            signature = (\n                \", \".join(\n                    [f\"input{i}: np.ndarray\" for i in range(len(input_names))])\n                + \", params: np.ndarray\"\n            )\n\n        return f\"\"\"You are an expert in scientific symbolic regression and mathematical modeling.\n\nTask: {info[\"description\"]}\n\nYour goal is to discover a mathematical equation that predicts {output_name} from:\n{chr(10).join(f\"  - {inp}\" for inp in info[\"inputs\"])}\n\nRequirements:\n- Define a function named 'equation' with signature: equation({signature}) -&gt; np.ndarray\n- Use numpy operations for vectorized computation\n- The 'params' array contains {self.max_params} optimizable constants (params[0] to params[{self.max_params - 1}])\n- Return predictions as a numpy array matching the shape of inputs\n- Focus on discovering the mathematical structure; parameters will be auto-optimized\n\nGuidelines:\n- Use mathematical operations: +, -, *, /, **, np.exp, np.log, np.sin, np.cos, etc.\n- Combine input variables in meaningful ways based on physical intuition\n- Keep equations reasonably simple to avoid overfitting\n- Ensure numerical stability (avoid division by very small numbers, etc.)\n- All operations must be vectorized (work on numpy arrays)\n\nExample structure:\n```python\nimport numpy as np\n\ndef equation({signature}) -&gt; np.ndarray:\n    # Example: linear combination\n    return params[0] * {input_names[0]} + params[1] * {input_names[1] if len(input_names) &gt; 1 else input_names[0]}\n```\n\nFitness: Your equation will be evaluated by optimizing parameters to minimize MSE on test data.\n\"\"\"\n</code></pre>"},{"location":"api/tasks/python/scientific-regression/#evotoolkit.task.python_task.scientific_regression.ScientificRegressionTask.make_init_sol_wo_other_info","title":"make_init_sol_wo_other_info","text":"<pre><code>make_init_sol_wo_other_info() -&gt; Solution\n</code></pre> <p>Create initial solution with simple linear equation.</p> Source code in <code>src/evotoolkit/task/python_task/scientific_regression/scientific_regression_task.py</code> <pre><code>    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"Create initial solution with simple linear equation.\"\"\"\n        info = self.dataset_info\n        input_names = info[\"input_cols\"]\n\n        # Build simple linear combination\n        if len(input_names) == 2:\n            equation_body = f\"    return params[0] * {input_names[0]} + params[1] * {input_names[1]} + params[2]\"\n            signature = f\"{input_names[0]}, {input_names[1]}, params\"\n        elif len(input_names) == 4:\n            terms = [f\"params[{i}] * {name}\" for i,\n                     name in enumerate(input_names)]\n            equation_body = (\n                f\"    return {' + '.join(terms)} + params[{len(input_names)}]\"\n            )\n            signature = \", \".join(input_names) + \", params\"\n        else:\n            terms = [\n                f\"params[{i}] * input{i}\" for i in range(len(input_names))]\n            equation_body = (\n                f\"    return {' + '.join(terms)} + params[{len(input_names)}]\"\n            )\n            signature = (\n                \", \".join([f\"input{i}\" for i in range(\n                    len(input_names))]) + \", params\"\n            )\n\n        initial_code = f'''import numpy as np\n\ndef equation({signature}):\n    \"\"\"Linear baseline model.\"\"\"\n{equation_body}\n'''\n\n        # Evaluate the initial solution\n        eval_res = self.evaluate_code(initial_code)\n\n        return Solution(sol_string=initial_code, evaluation_res=eval_res, other_info={})\n</code></pre>"},{"location":"api/tasks/string/prompt-optimization/","title":"PromptOptimizationTask","text":""},{"location":"api/tasks/string/prompt-optimization/#evotoolkit.task.string_optimization.prompt_optimization.PromptOptimizationTask","title":"evotoolkit.task.string_optimization.prompt_optimization.PromptOptimizationTask","text":"<p>               Bases: <code>StringTask</code></p> <p>Task for optimizing LLM prompt templates.</p> <p>This task evaluates prompt templates by testing them on a set of test cases and measuring the quality of LLM responses.</p> <p>The prompt template is a string that can contain {question} placeholder.</p> Example Source code in <code>src/evotoolkit/task/string_optimization/prompt_optimization/prompt_optimization_task.py</code> <pre><code>class PromptOptimizationTask(StringTask):\n    \"\"\"\n    Task for optimizing LLM prompt templates.\n\n    This task evaluates prompt templates by testing them on a set of test cases\n    and measuring the quality of LLM responses.\n\n    The prompt template is a string that can contain {question} placeholder.\n\n    Example:\n        &gt;&gt;&gt; # Define test cases\n        &gt;&gt;&gt; test_cases = [\n        ...     {\"question\": \"What is 2+2?\", \"expected\": \"4\"},\n        ...     {\"question\": \"What is 5*3?\", \"expected\": \"15\"}\n        ... ]\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create task\n        &gt;&gt;&gt; task = PromptOptimizationTask(\n        ...     test_cases=test_cases,\n        ...     llm_api=my_llm_api\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Evaluate a prompt template\n        &gt;&gt;&gt; prompt_template = \"Solve this math problem: {question}\\\\nGive only the number.\"\n        &gt;&gt;&gt; result = task.evaluate_code(prompt_template)\n    \"\"\"\n\n    def __init__(\n        self,\n        test_cases: List[Dict[str, str]],\n        llm_api: Optional[Any] = None,\n        timeout_seconds: float = 30.0,\n        use_mock: bool = False,\n    ):\n        \"\"\"\n        Initialize the prompt optimization task.\n\n        Args:\n            test_cases: List of test cases with 'question' and 'expected' keys\n            llm_api: LLM API instance for testing prompts (optional if use_mock=True)\n            timeout_seconds: Timeout for evaluation\n            use_mock: If True, use mock LLM responses for testing (default: False)\n        \"\"\"\n        self.test_cases = test_cases\n        self.llm_api = llm_api\n        self.use_mock = use_mock\n\n        if not use_mock and llm_api is None:\n            raise ValueError(\"llm_api must be provided when use_mock=False\")\n\n        data = {\"test_cases\": test_cases, \"num_cases\": len(test_cases)}\n\n        super().__init__(data, timeout_seconds)\n\n    def _process_data(self, data):\n        \"\"\"Process task data and set up task_info.\"\"\"\n        super()._process_data(data)\n        self.task_info = {\n            \"num_test_cases\": data[\"num_cases\"],\n            \"task_type\": \"prompt_optimization\",\n        }\n\n    def _evaluate_string_impl(self, prompt_template: str) -&gt; EvaluationResult:\n        \"\"\"\n        Evaluate a prompt template string.\n\n        The prompt template should contain {question} placeholder.\n\n        Args:\n            prompt_template: Prompt template string with {question} placeholder\n\n        Returns:\n            EvaluationResult with score based on correctness rate\n        \"\"\"\n        # Validate template has {question} placeholder\n        if \"{question}\" not in prompt_template:\n            return EvaluationResult(\n                valid=False,\n                score=float(\"-inf\"),\n                additional_info={\n                    \"error\": \"Prompt template must contain {question} placeholder\"\n                },\n            )\n\n        # Test the prompt on all test cases\n        correct = 0\n        total = len(self.test_cases)\n        results = []\n\n        for case in self.test_cases:\n            question = case[\"question\"]\n            expected = case[\"expected\"]\n\n            try:\n                # Generate prompt from template\n                prompt = prompt_template.format(question=question)\n\n                # Get LLM response\n                if self.use_mock:\n                    # Mock response: extract number from question for testing\n                    response = self._mock_llm_response(question, prompt)\n                else:\n                    # Real LLM call\n                    response = self._call_llm(prompt)\n\n                # Check if answer is correct\n                is_correct = self._check_answer(response, expected)\n\n                if is_correct:\n                    correct += 1\n\n                results.append(\n                    {\n                        \"question\": question,\n                        \"prompt\": prompt,\n                        \"response\": response,\n                        \"expected\": expected,\n                        \"correct\": is_correct,\n                    }\n                )\n\n            except Exception as e:\n                results.append(\n                    {\"question\": question, \"error\": str(e), \"correct\": False}\n                )\n\n        # Calculate score as correctness rate\n        score = correct / total if total &gt; 0 else 0.0\n\n        return EvaluationResult(\n            valid=True,\n            score=score,\n            additional_info={\n                \"correct\": correct,\n                \"total\": total,\n                \"accuracy\": score,\n                \"results\": results,\n            },\n        )\n\n    def _mock_llm_response(self, question: str, prompt: str) -&gt; str:\n        \"\"\"\n        Generate mock LLM response for testing without actual LLM calls.\n\n        Extracts the answer from the question for simple math problems.\n        \"\"\"\n        # Simple pattern matching for testing\n        # Extract numbers and operators from question\n        match = re.search(r\"(\\d+)\\s*([+\\-*/])\\s*(\\d+)\", question)\n        if match:\n            num1, op, num2 = match.groups()\n            num1, num2 = int(num1), int(num2)\n\n            ops = {\n                \"+\": num1 + num2,\n                \"-\": num1 - num2,\n                \"*\": num1 * num2,\n                \"/\": num1 // num2,\n            }\n            result = ops.get(op, 0)\n\n            # Return in a format that simulates LLM output\n            return f\"The answer is {result}\"\n\n        return \"I don't know\"\n\n    def _call_llm(self, prompt: str) -&gt; str:\n        \"\"\"Call the real LLM API with the generated prompt.\"\"\"\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        response, usage = self.llm_api.get_response(messages)\n        return response\n\n    def _check_answer(self, response: str, expected: str) -&gt; bool:\n        \"\"\"\n        Check if LLM response contains the expected answer.\n\n        Args:\n            response: LLM response text\n            expected: Expected answer string\n\n        Returns:\n            True if answer is correct, False otherwise\n        \"\"\"\n        # Extract numbers from response\n        numbers = re.findall(r\"\\d+\", response)\n        return expected in numbers or expected in response\n\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get task description for prompt generation.\"\"\"\n        case_desc = \"\\n\".join(\n            [\n                f\"  - Question: {case['question']} | Expected: {case['expected']}\"\n                for case in self.test_cases[:3]  # Show first 3 examples\n            ]\n        )\n\n        return f\"\"\"# Prompt Optimization Task\n\n**Objective:** Create a prompt template that generates effective prompts for an LLM\nto answer questions correctly.\n\n**Test Cases** ({len(self.test_cases)} total, showing first 3):\n{case_desc}\n\n**Prompt Template Format:**\nYour solution should be a string template with {{question}} placeholder.\n\nExample:\n```\nSolve this math problem: {{question}}\nGive only the number as your answer.\n```\n\n**Evaluation:** Your prompt template will be tested on {len(self.test_cases)} questions.\nScore = (number of correct answers) / (total questions)\n\n**Tips:**\n- Make prompts clear and specific\n- Use the {{question}} placeholder to insert the question\n- Consider instructing the LLM to output only the answer\n- Test different prompt formats for better accuracy\n\"\"\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"Create an initial solution with a simple prompt template.\"\"\"\n        init_template = \"Answer this question: {question}\"\n\n        eval_res = self.evaluate_code(init_template)\n\n        return Solution(\n            sol_string=init_template, evaluation_res=eval_res, other_info={}\n        )\n</code></pre>"},{"location":"api/tasks/string/prompt-optimization/#evotoolkit.task.string_optimization.prompt_optimization.PromptOptimizationTask--define-test-cases","title":"Define test cases","text":"<p>test_cases = [ ...     {\"question\": \"What is 2+2?\", \"expected\": \"4\"}, ...     {\"question\": \"What is 5*3?\", \"expected\": \"15\"} ... ]</p>"},{"location":"api/tasks/string/prompt-optimization/#evotoolkit.task.string_optimization.prompt_optimization.PromptOptimizationTask--create-task","title":"Create task","text":"<p>task = PromptOptimizationTask( ...     test_cases=test_cases, ...     llm_api=my_llm_api ... )</p>"},{"location":"api/tasks/string/prompt-optimization/#evotoolkit.task.string_optimization.prompt_optimization.PromptOptimizationTask--evaluate-a-prompt-template","title":"Evaluate a prompt template","text":"<p>prompt_template = \"Solve this math problem: {question}\\nGive only the number.\" result = task.evaluate_code(prompt_template)</p>"},{"location":"api/tasks/string/prompt-optimization/#evotoolkit.task.string_optimization.prompt_optimization.PromptOptimizationTask.__init__","title":"__init__","text":"<pre><code>__init__(\n    test_cases: List[Dict[str, str]],\n    llm_api: Optional[Any] = None,\n    timeout_seconds: float = 30.0,\n    use_mock: bool = False,\n)\n</code></pre> <p>Initialize the prompt optimization task.</p> <p>Parameters:</p> Name Type Description Default <code>test_cases</code> <code>List[Dict[str, str]]</code> <p>List of test cases with 'question' and 'expected' keys</p> required <code>llm_api</code> <code>Optional[Any]</code> <p>LLM API instance for testing prompts (optional if use_mock=True)</p> <code>None</code> <code>timeout_seconds</code> <code>float</code> <p>Timeout for evaluation</p> <code>30.0</code> <code>use_mock</code> <code>bool</code> <p>If True, use mock LLM responses for testing (default: False)</p> <code>False</code> Source code in <code>src/evotoolkit/task/string_optimization/prompt_optimization/prompt_optimization_task.py</code> <pre><code>def __init__(\n    self,\n    test_cases: List[Dict[str, str]],\n    llm_api: Optional[Any] = None,\n    timeout_seconds: float = 30.0,\n    use_mock: bool = False,\n):\n    \"\"\"\n    Initialize the prompt optimization task.\n\n    Args:\n        test_cases: List of test cases with 'question' and 'expected' keys\n        llm_api: LLM API instance for testing prompts (optional if use_mock=True)\n        timeout_seconds: Timeout for evaluation\n        use_mock: If True, use mock LLM responses for testing (default: False)\n    \"\"\"\n    self.test_cases = test_cases\n    self.llm_api = llm_api\n    self.use_mock = use_mock\n\n    if not use_mock and llm_api is None:\n        raise ValueError(\"llm_api must be provided when use_mock=False\")\n\n    data = {\"test_cases\": test_cases, \"num_cases\": len(test_cases)}\n\n    super().__init__(data, timeout_seconds)\n</code></pre>"},{"location":"api/tasks/string/prompt-optimization/#evotoolkit.task.string_optimization.prompt_optimization.PromptOptimizationTask.get_base_task_description","title":"get_base_task_description","text":"<pre><code>get_base_task_description() -&gt; str\n</code></pre> <p>Get task description for prompt generation.</p> Source code in <code>src/evotoolkit/task/string_optimization/prompt_optimization/prompt_optimization_task.py</code> <pre><code>    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get task description for prompt generation.\"\"\"\n        case_desc = \"\\n\".join(\n            [\n                f\"  - Question: {case['question']} | Expected: {case['expected']}\"\n                for case in self.test_cases[:3]  # Show first 3 examples\n            ]\n        )\n\n        return f\"\"\"# Prompt Optimization Task\n\n**Objective:** Create a prompt template that generates effective prompts for an LLM\nto answer questions correctly.\n\n**Test Cases** ({len(self.test_cases)} total, showing first 3):\n{case_desc}\n\n**Prompt Template Format:**\nYour solution should be a string template with {{question}} placeholder.\n\nExample:\n```\nSolve this math problem: {{question}}\nGive only the number as your answer.\n```\n\n**Evaluation:** Your prompt template will be tested on {len(self.test_cases)} questions.\nScore = (number of correct answers) / (total questions)\n\n**Tips:**\n- Make prompts clear and specific\n- Use the {{question}} placeholder to insert the question\n- Consider instructing the LLM to output only the answer\n- Test different prompt formats for better accuracy\n\"\"\"\n</code></pre>"},{"location":"api/tasks/string/prompt-optimization/#evotoolkit.task.string_optimization.prompt_optimization.PromptOptimizationTask.make_init_sol_wo_other_info","title":"make_init_sol_wo_other_info","text":"<pre><code>make_init_sol_wo_other_info() -&gt; Solution\n</code></pre> <p>Create an initial solution with a simple prompt template.</p> Source code in <code>src/evotoolkit/task/string_optimization/prompt_optimization/prompt_optimization_task.py</code> <pre><code>def make_init_sol_wo_other_info(self) -&gt; Solution:\n    \"\"\"Create an initial solution with a simple prompt template.\"\"\"\n    init_template = \"Answer this question: {question}\"\n\n    eval_res = self.evaluate_code(init_template)\n\n    return Solution(\n        sol_string=init_template, evaluation_res=eval_res, other_info={}\n    )\n</code></pre>"},{"location":"api/tasks/string/string-task/","title":"StringTask","text":""},{"location":"api/tasks/string/string-task/#evotoolkit.task.string_optimization.StringTask","title":"evotoolkit.task.string_optimization.StringTask","text":"<p>               Bases: <code>BaseTask</code></p> <p>Abstract base class for string-based evolutionary optimization tasks.</p> <p>Unlike PythonTask or CudaTask which evaluate code, StringTask directly evaluates string solutions (e.g., prompts, templates, configurations).</p> Source code in <code>src/evotoolkit/task/string_optimization/string_task.py</code> <pre><code>class StringTask(BaseTask):\n    \"\"\"\n    Abstract base class for string-based evolutionary optimization tasks.\n\n    Unlike PythonTask or CudaTask which evaluate code, StringTask directly\n    evaluates string solutions (e.g., prompts, templates, configurations).\n    \"\"\"\n\n    def __init__(self, data: Any, timeout_seconds: float = 30.0):\n        \"\"\"\n        Initialize the string task with input data.\n\n        Args:\n            data: Task-specific input data\n            timeout_seconds: Execution timeout for evaluation\n        \"\"\"\n        self.timeout_seconds = timeout_seconds\n        super().__init__(data)\n\n    def get_task_type(self) -&gt; str:\n        \"\"\"Get task type as 'String'.\"\"\"\n        return \"String\"\n\n    def evaluate_code(self, candidate_string: str) -&gt; EvaluationResult:\n        \"\"\"\n        Evaluate a candidate string solution.\n\n        Note: For compatibility with the framework, we keep the method name\n        'evaluate_code', but it actually evaluates strings, not code.\n\n        Args:\n            candidate_string: String solution to evaluate\n\n        Returns:\n            EvaluationResult: Result of the evaluation\n        \"\"\"\n        try:\n            return self._evaluate_string_impl(candidate_string)\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float(\"-inf\"),\n                additional_info={\n                    \"error\": f\"Evaluation error: {str(e)}\",\n                    \"traceback\": traceback.format_exc(),\n                },\n            )\n\n    @abstractmethod\n    def _evaluate_string_impl(self, candidate_string: str) -&gt; EvaluationResult:\n        \"\"\"\n        Implement specific string evaluation logic.\n\n        Subclasses must implement this method with their specific\n        evaluation logic. This method is called by evaluate_code\n        within a try-catch block.\n\n        Args:\n            candidate_string: String solution to evaluate\n\n        Returns:\n            EvaluationResult: Result of the evaluation\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/tasks/string/string-task/#evotoolkit.task.string_optimization.StringTask.__init__","title":"__init__","text":"<pre><code>__init__(data: Any, timeout_seconds: float = 30.0)\n</code></pre> <p>Initialize the string task with input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Task-specific input data</p> required <code>timeout_seconds</code> <code>float</code> <p>Execution timeout for evaluation</p> <code>30.0</code> Source code in <code>src/evotoolkit/task/string_optimization/string_task.py</code> <pre><code>def __init__(self, data: Any, timeout_seconds: float = 30.0):\n    \"\"\"\n    Initialize the string task with input data.\n\n    Args:\n        data: Task-specific input data\n        timeout_seconds: Execution timeout for evaluation\n    \"\"\"\n    self.timeout_seconds = timeout_seconds\n    super().__init__(data)\n</code></pre>"},{"location":"api/tasks/string/string-task/#evotoolkit.task.string_optimization.StringTask.get_task_type","title":"get_task_type","text":"<pre><code>get_task_type() -&gt; str\n</code></pre> <p>Get task type as 'String'.</p> Source code in <code>src/evotoolkit/task/string_optimization/string_task.py</code> <pre><code>def get_task_type(self) -&gt; str:\n    \"\"\"Get task type as 'String'.\"\"\"\n    return \"String\"\n</code></pre>"},{"location":"api/tasks/string/string-task/#evotoolkit.task.string_optimization.StringTask.evaluate_code","title":"evaluate_code","text":"<pre><code>evaluate_code(candidate_string: str) -&gt; EvaluationResult\n</code></pre> <p>Evaluate a candidate string solution.</p> <p>Note: For compatibility with the framework, we keep the method name 'evaluate_code', but it actually evaluates strings, not code.</p> <p>Parameters:</p> Name Type Description Default <code>candidate_string</code> <code>str</code> <p>String solution to evaluate</p> required <p>Returns:</p> Name Type Description <code>EvaluationResult</code> <code>EvaluationResult</code> <p>Result of the evaluation</p> Source code in <code>src/evotoolkit/task/string_optimization/string_task.py</code> <pre><code>def evaluate_code(self, candidate_string: str) -&gt; EvaluationResult:\n    \"\"\"\n    Evaluate a candidate string solution.\n\n    Note: For compatibility with the framework, we keep the method name\n    'evaluate_code', but it actually evaluates strings, not code.\n\n    Args:\n        candidate_string: String solution to evaluate\n\n    Returns:\n        EvaluationResult: Result of the evaluation\n    \"\"\"\n    try:\n        return self._evaluate_string_impl(candidate_string)\n    except Exception as e:\n        return EvaluationResult(\n            valid=False,\n            score=float(\"-inf\"),\n            additional_info={\n                \"error\": f\"Evaluation error: {str(e)}\",\n                \"traceback\": traceback.format_exc(),\n            },\n        )\n</code></pre>"},{"location":"api/tools/https-api/","title":"HttpsApi","text":""},{"location":"api/tools/https-api/#evotoolkit.tools.HttpsApi","title":"evotoolkit.tools.HttpsApi","text":"Source code in <code>src/evotoolkit/tools/llm.py</code> <pre><code>class HttpsApi:\n    def __init__(self, api_url, key, model, embed_url=None, timeout=60, **kwargs):\n        \"\"\"\n        Initialize the HttpsApi class.\n\n        Args:\n            api_url (str): API endpoint, supports multiple formats:\n                - Full URL: \"https://api.openai.com/v1/chat/completions\"\n                - Hostname only: \"api.openai.com\" (defaults to /v1/chat/completions)\n            key (str): API key for authentication.\n            model (str): Model name to use (e.g., \"gpt-4o\").\n            embed_url (str | None): Embedding API URL (optional), supports:\n                - Full URL: \"https://api.openai.com/v1/embeddings\"\n                - Path only: \"/v1/embeddings\"\n                - Auto-inferred if not provided\n            timeout (int): Request timeout in seconds (default: 60).\n            **kwargs (Any): Additional keyword arguments (e.g., temperature).\n\n        Example:\n            &gt;&gt;&gt; # Using full URL\n            &gt;&gt;&gt; api = HttpsApi(\n            ...     api_url=\"https://api.openai.com/v1/chat/completions\",\n            ...     key=\"sk-xxx\",\n            ...     model=\"gpt-4o\"\n            ... )\n            &gt;&gt;&gt; # Using hostname only\n            &gt;&gt;&gt; api = HttpsApi(\n            ...     api_url=\"api.openai.com\",\n            ...     key=\"sk-xxx\",\n            ...     model=\"gpt-4o\"\n            ... )\n        \"\"\"\n        # Parse the main API URL\n        if api_url.startswith((\"http://\", \"https://\")):\n            # Full URL with protocol\n            parsed = urlparse(api_url)\n            self._host = parsed.netloc\n            self._url = parsed.path or \"/v1/chat/completions\"\n\n            # Validate host\n            if not self._host:\n                raise ValueError(f\"Invalid API URL: missing hostname in '{api_url}'\")\n        else:\n            # Check if it looks like a URL without protocol (e.g., \"api.openai.com/v1/chat/completions\")\n            if \"/\" in api_url:\n                raise ValueError(\n                    f\"Invalid API URL: '{api_url}'\\n\"\n                    f\"Did you forget the protocol? Try: 'https://{api_url}'\"\n                )\n\n            # Plain hostname (e.g., \"api.openai.com\" or \"ai.api.xn--fiqs8s\")\n            self._host = api_url.strip()\n            self._url = \"/v1/chat/completions\"\n\n            # Basic hostname validation\n            if not self._host:\n                raise ValueError(\"API URL cannot be empty\")\n            if \" \" in self._host:\n                raise ValueError(f\"Invalid hostname: '{api_url}' contains spaces\")\n\n        # Handle embedding URL\n        if embed_url:\n            if embed_url.startswith((\"http://\", \"https://\")):\n                # Full URL with protocol\n                embed_parsed = urlparse(embed_url)\n                self._embed_url = embed_parsed.path or \"/v1/embeddings\"\n\n                # Validate path is not empty\n                if not self._embed_url or self._embed_url == \"/\":\n                    self._embed_url = \"/v1/embeddings\"\n            else:\n                # Plain path or potential mistake\n                embed_url = embed_url.strip()\n\n                # Validate not empty\n                if not embed_url:\n                    raise ValueError(\"Embedding URL cannot be empty\")\n\n                # Check if it looks like a hostname without protocol (e.g., \"api.openai.com/v1/embeddings\")\n                if not embed_url.startswith(\"/\") and \".\" in embed_url.split(\"/\")[0]:\n                    raise ValueError(\n                        f\"Invalid embedding URL: '{embed_url}'\\n\"\n                        f\"Did you forget the protocol? Try: 'https://{embed_url}'\\n\"\n                        f\"Or use path format: '/{embed_url}'\"\n                    )\n\n                # Plain path\n                self._embed_url = (\n                    embed_url if embed_url.startswith(\"/\") else f\"/{embed_url}\"\n                )\n        else:\n            # Auto-infer embedding URL\n            self._embed_url = \"/v1/embeddings\"\n\n        self._key = key\n        self._model = model\n        self._timeout = timeout\n        self._kwargs = kwargs\n        self._max_retry = 10\n\n    def get_response(self, prompt: str | Any, *args, **kwargs) -&gt; Tuple[str, dict]:\n        if isinstance(prompt, str):\n            prompt = [{\"role\": \"user\", \"content\": prompt.strip()}]\n\n        retry = 0\n        while True:\n            try:\n                if self._model.startswith(\"o1-preview\"):\n                    for p in prompt:\n                        if p[\"role\"] == \"system\":\n                            p[\"role\"] = \"user\"\n\n                conn = http.client.HTTPSConnection(self._host, timeout=self._timeout)\n                payload = json.dumps(\n                    {\n                        # 'max_tokens': self._kwargs.get('max_tokens', 4096),\n                        # 'top_p': self._kwargs.get('top_p', None),\n                        \"temperature\": self._kwargs.get(\"temperature\", 1.0),\n                        \"model\": self._model,\n                        \"messages\": prompt,\n                    }\n                )\n                headers = {\n                    \"Authorization\": f\"Bearer {self._key}\",\n                    \"User-Agent\": \"Apifox/1.0.0 (https://apifox.com)\",\n                    \"Content-Type\": \"application/json\",\n                }\n                conn.request(\"POST\", self._url, payload, headers)\n                res = conn.getresponse()\n                data = res.read().decode(\"utf-8\")\n                data = json.loads(data)\n                response = data[\"choices\"][0][\"message\"][\"content\"]\n                usage = data[\"usage\"]\n                # if self._model.startswith('claude'):\n                #     response = data['content'][0]['text']\n                # else:\n                #     response = data['choices'][0]['message']['content']\n                return response, usage\n            except Exception:\n                retry += 1\n                if retry &gt;= self._max_retry:\n                    raise RuntimeError(\n                        # f'{self.__class__.__name__} error: {traceback.format_exc()}.\\n'\n                        \"Model Response Error! You may check your API host and API key.\"\n                    )\n                else:\n                    print(\"Model Response Error! Retrying...\")\n                    # print(f'{self.__class__.__name__} error: {traceback.format_exc()}. Retrying...\\n')\n\n    def get_embedding(self, text: str | Any, *args, **kwargs) -&gt; str:\n        content_embedding = {\"input\": text, \"model\": self._model}\n\n        retry = 0\n        while True:\n            try:\n                conn = http.client.HTTPSConnection(self._host, timeout=self._timeout)\n                payload = json.dumps(content_embedding)\n                headers = {\n                    \"Authorization\": f\"Bearer {self._key}\",\n                    \"User-Agent\": \"Apifox/1.0.0 (https://apifox.com)\",\n                    \"Content-Type\": \"application/json\",\n                }\n                conn.request(\"POST\", self._embed_url, payload, headers)\n                res = conn.getresponse()\n                data = res.read().decode(\"utf-8\")\n                data = json.loads(data)\n                response = data[\"data\"][0][\"embedding\"]\n                # if self._model.startswith('claude'):\n                #     response = data['content'][0]['text']\n                # else:\n                #     response = data['choices'][0]['message']['content']\n                return response\n            except Exception:\n                retry += 1\n                if retry &gt;= self._max_retry:\n                    raise RuntimeError(\n                        f\"{self.__class__.__name__} error: {traceback.format_exc()}.\\n\"\n                        f\"You may check your API host and API key.\"\n                    )\n                else:\n                    print(\n                        f\"{self.__class__.__name__} error: {traceback.format_exc()}. Retrying...\\n\"\n                    )\n</code></pre>"},{"location":"api/tools/https-api/#evotoolkit.tools.HttpsApi.__init__","title":"__init__","text":"<pre><code>__init__(\n    api_url,\n    key,\n    model,\n    embed_url=None,\n    timeout=60,\n    **kwargs,\n)\n</code></pre> <p>Initialize the HttpsApi class.</p> <p>Parameters:</p> Name Type Description Default <code>api_url</code> <code>str</code> <p>API endpoint, supports multiple formats: - Full URL: \"https://api.openai.com/v1/chat/completions\" - Hostname only: \"api.openai.com\" (defaults to /v1/chat/completions)</p> required <code>key</code> <code>str</code> <p>API key for authentication.</p> required <code>model</code> <code>str</code> <p>Model name to use (e.g., \"gpt-4o\").</p> required <code>embed_url</code> <code>str | None</code> <p>Embedding API URL (optional), supports: - Full URL: \"https://api.openai.com/v1/embeddings\" - Path only: \"/v1/embeddings\" - Auto-inferred if not provided</p> <code>None</code> <code>timeout</code> <code>int</code> <p>Request timeout in seconds (default: 60).</p> <code>60</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (e.g., temperature).</p> <code>{}</code> Example Source code in <code>src/evotoolkit/tools/llm.py</code> <pre><code>def __init__(self, api_url, key, model, embed_url=None, timeout=60, **kwargs):\n    \"\"\"\n    Initialize the HttpsApi class.\n\n    Args:\n        api_url (str): API endpoint, supports multiple formats:\n            - Full URL: \"https://api.openai.com/v1/chat/completions\"\n            - Hostname only: \"api.openai.com\" (defaults to /v1/chat/completions)\n        key (str): API key for authentication.\n        model (str): Model name to use (e.g., \"gpt-4o\").\n        embed_url (str | None): Embedding API URL (optional), supports:\n            - Full URL: \"https://api.openai.com/v1/embeddings\"\n            - Path only: \"/v1/embeddings\"\n            - Auto-inferred if not provided\n        timeout (int): Request timeout in seconds (default: 60).\n        **kwargs (Any): Additional keyword arguments (e.g., temperature).\n\n    Example:\n        &gt;&gt;&gt; # Using full URL\n        &gt;&gt;&gt; api = HttpsApi(\n        ...     api_url=\"https://api.openai.com/v1/chat/completions\",\n        ...     key=\"sk-xxx\",\n        ...     model=\"gpt-4o\"\n        ... )\n        &gt;&gt;&gt; # Using hostname only\n        &gt;&gt;&gt; api = HttpsApi(\n        ...     api_url=\"api.openai.com\",\n        ...     key=\"sk-xxx\",\n        ...     model=\"gpt-4o\"\n        ... )\n    \"\"\"\n    # Parse the main API URL\n    if api_url.startswith((\"http://\", \"https://\")):\n        # Full URL with protocol\n        parsed = urlparse(api_url)\n        self._host = parsed.netloc\n        self._url = parsed.path or \"/v1/chat/completions\"\n\n        # Validate host\n        if not self._host:\n            raise ValueError(f\"Invalid API URL: missing hostname in '{api_url}'\")\n    else:\n        # Check if it looks like a URL without protocol (e.g., \"api.openai.com/v1/chat/completions\")\n        if \"/\" in api_url:\n            raise ValueError(\n                f\"Invalid API URL: '{api_url}'\\n\"\n                f\"Did you forget the protocol? Try: 'https://{api_url}'\"\n            )\n\n        # Plain hostname (e.g., \"api.openai.com\" or \"ai.api.xn--fiqs8s\")\n        self._host = api_url.strip()\n        self._url = \"/v1/chat/completions\"\n\n        # Basic hostname validation\n        if not self._host:\n            raise ValueError(\"API URL cannot be empty\")\n        if \" \" in self._host:\n            raise ValueError(f\"Invalid hostname: '{api_url}' contains spaces\")\n\n    # Handle embedding URL\n    if embed_url:\n        if embed_url.startswith((\"http://\", \"https://\")):\n            # Full URL with protocol\n            embed_parsed = urlparse(embed_url)\n            self._embed_url = embed_parsed.path or \"/v1/embeddings\"\n\n            # Validate path is not empty\n            if not self._embed_url or self._embed_url == \"/\":\n                self._embed_url = \"/v1/embeddings\"\n        else:\n            # Plain path or potential mistake\n            embed_url = embed_url.strip()\n\n            # Validate not empty\n            if not embed_url:\n                raise ValueError(\"Embedding URL cannot be empty\")\n\n            # Check if it looks like a hostname without protocol (e.g., \"api.openai.com/v1/embeddings\")\n            if not embed_url.startswith(\"/\") and \".\" in embed_url.split(\"/\")[0]:\n                raise ValueError(\n                    f\"Invalid embedding URL: '{embed_url}'\\n\"\n                    f\"Did you forget the protocol? Try: 'https://{embed_url}'\\n\"\n                    f\"Or use path format: '/{embed_url}'\"\n                )\n\n            # Plain path\n            self._embed_url = (\n                embed_url if embed_url.startswith(\"/\") else f\"/{embed_url}\"\n            )\n    else:\n        # Auto-infer embedding URL\n        self._embed_url = \"/v1/embeddings\"\n\n    self._key = key\n    self._model = model\n    self._timeout = timeout\n    self._kwargs = kwargs\n    self._max_retry = 10\n</code></pre>"},{"location":"api/tools/https-api/#evotoolkit.tools.HttpsApi.__init__--using-full-url","title":"Using full URL","text":"<p>api = HttpsApi( ...     api_url=\"https://api.openai.com/v1/chat/completions\", ...     key=\"sk-xxx\", ...     model=\"gpt-4o\" ... )</p>"},{"location":"api/tools/https-api/#evotoolkit.tools.HttpsApi.__init__--using-hostname-only","title":"Using hostname only","text":"<p>api = HttpsApi( ...     api_url=\"api.openai.com\", ...     key=\"sk-xxx\", ...     model=\"gpt-4o\" ... )</p>"},{"location":"development/architecture/","title":"Architecture","text":"<p>EvoToolkit is designed with modularity and extensibility in mind.</p>"},{"location":"development/architecture/#core-components","title":"Core Components","text":""},{"location":"development/architecture/#1-tasks-evotoolkittask","title":"1. Tasks (<code>evotoolkit.task</code>)","text":"<p>Define optimization problems and evaluation logic.</p>"},{"location":"development/architecture/#2-methods-evotoolkitevo_method","title":"2. Methods (<code>evotoolkit.evo_method</code>)","text":"<p>Implement evolutionary algorithms (EoH, EvoEngineer, FunSearch).</p>"},{"location":"development/architecture/#3-interfaces-evotoolkitcoremethod_interface","title":"3. Interfaces (<code>evotoolkit.core.method_interface</code>)","text":"<p>Bridge between tasks and methods, handling algorithm-specific adaptations.</p>"},{"location":"development/architecture/#4-registry-evotoolkitregistry","title":"4. Registry (<code>evotoolkit.registry</code>)","text":"<p>Automatic discovery and registration of tasks and algorithms.</p>"},{"location":"development/architecture/#design-patterns","title":"Design Patterns","text":"<ul> <li>Factory Pattern: <code>evotoolkit.solve()</code> creates algorithm instances</li> <li>Strategy Pattern: Interfaces provide algorithm-specific strategies</li> <li>Template Method: Base classes define workflow, subclasses customize</li> </ul>"},{"location":"development/architecture/#module-organization","title":"Module Organization","text":"<pre><code>evotool/\n\u251c\u2500\u2500 core/               # Base classes and abstractions\n\u251c\u2500\u2500 evo_method/         # Algorithm implementations\n\u251c\u2500\u2500 task/               # Task implementations\n\u251c\u2500\u2500 tools/              # Utilities (LLM API, etc.)\n\u2514\u2500\u2500 registry.py         # Component registration\n</code></pre> <p>For detailed implementation guides, see the source code documentation.</p>"},{"location":"development/contributing/","title":"Contributing to EvoToolkit","text":"<p>Thank you for your interest in contributing to EvoToolkit! This guide will help you get started.</p>"},{"location":"development/contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>\ud83d\udc1b Report bugs - Submit issues on GitHub</li> <li>\ud83d\udca1 Suggest features - Share your ideas</li> <li>\ud83d\udcdd Improve documentation - Fix typos, add examples</li> <li>\ud83d\udd27 Submit code - Fix bugs or add features</li> <li>\ud83c\udf93 Share examples - Contribute tutorials and use cases</li> </ul>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":""},{"location":"development/contributing/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code>git clone https://github.com/your-username/evotoolkit.git\ncd evotool\n</code></pre>"},{"location":"development/contributing/#2-install-development-dependencies","title":"2. Install Development Dependencies","text":"<pre><code># Install development dependencies\nuv sync --group dev\n\n# Optional: Install specific task dependencies\nuv sync --extra cuda_engineering       # For CUDA tasks\nuv sync --extra scientific_regression  # For scientific regression\nuv sync --extra adversarial_attack     # For adversarial attacks\nuv sync --extra all_tasks              # All task dependencies\n</code></pre>"},{"location":"development/contributing/#3-create-a-branch","title":"3. Create a Branch","text":"<pre><code>git checkout -b feature/your-feature-name\n</code></pre>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<p>EvoToolkit uses: - Black for code formatting - isort for import sorting - Type hints throughout the codebase</p> <p>Format your code:</p> <pre><code>uv run black .\nuv run isort .\n</code></pre>"},{"location":"development/contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Commit your changes with clear messages</li> <li>Push to your fork</li> <li>Open a Pull Request</li> <li>Respond to review feedback</li> </ol>"},{"location":"development/contributing/#questions","title":"Questions?","text":"<p>Join GitHub Discussions or email pguo6680@gmail.com</p>"},{"location":"getting-started/exploring-results/","title":"Exploring the Results","text":"<p>After running, check the <code>./results/</code> directory:</p>"},{"location":"getting-started/exploring-results/#results-directory-structure","title":"Results Directory Structure","text":"<pre><code>results/\n\u251c\u2500\u2500 run_state.json              # Run state and statistics\n\u251c\u2500\u2500 history/                    # Historical records\n\u2502   \u251c\u2500\u2500 gen_-1.json            # Initial population\n\u2502   \u251c\u2500\u2500 gen_1.json             # All solutions from generation 1\n\u2502   \u251c\u2500\u2500 gen_2.json             # All solutions from generation 2\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 summary/                    # Summary information\n    \u251c\u2500\u2500 usage_history.json     # LLM usage statistics\n    \u2514\u2500\u2500 best_per_generation.json  # Best solutions per generation (if any)\n</code></pre>"},{"location":"getting-started/exploring-results/#analyzing-results-programmatically","title":"Analyzing Results Programmatically","text":"<p>Each <code>gen_N.json</code> file contains all solutions, evaluation results, and statistics for that generation. You can load and analyze these results programmatically:</p> <pre><code>import json\n\n# Load history for a specific generation\nwith open('./results/history/gen_1.json', 'r') as f:\n    gen_1 = json.load(f)\n\n# View all solutions from that generation\nfor sol in gen_1['solutions']:\n    print(f\"Score: {sol['evaluation_res']['score']}\")\n    print(f\"Solution:\\n{sol['sol_string']}\\n\")\n</code></pre> <p>Next: Try Different Algorithms</p>"},{"location":"getting-started/first-optimization/","title":"Your First Optimization: Scientific Symbolic Regression","text":"<p>Let's use EvoToolkit to discover mathematical equations from real scientific data.</p> <p>Academic Citation</p> <p>The scientific regression task and datasets used in this guide are based on research from CoEvo. If you use this feature in academic work, please cite:</p> <pre><code>@misc{guo2024coevocontinualevolutionsymbolic,\n    title={CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models},\n    author={Ping Guo and Qingfu Zhang and Xi Lin},\n    year={2024},\n    eprint={2412.18890},\n    archivePrefix={arXiv},\n    primaryClass={cs.AI},\n    url={https://arxiv.org/abs/2412.18890}\n}\n</code></pre>"},{"location":"getting-started/first-optimization/#step-1-create-a-new-project","title":"Step 1: Create a New Project","text":"<pre><code>mkdir my-evotool-project\ncd my-evotool-project\n</code></pre>"},{"location":"getting-started/first-optimization/#step-2-write-your-first-script","title":"Step 2: Write Your First Script","text":"<p>Create a file named <code>first_optimization.py</code>:</p> <pre><code>import evotoolkit\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools import HttpsApi\n\n# Step 1: Create a task\nprint(\"Creating scientific regression task...\")\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\n\n# Step 2: Create an interface\nprint(\"Setting up EvoEngineer interface...\")\ninterface = EvoEngineerPythonInterface(task)\n\n# Step 3: Configure LLM API\nprint(\"Configuring LLM API...\")\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",  # Your API endpoint\n    key=\"your-api-key-here\",  # Your API key\n    model=\"gpt-4o\"\n)\n\n# Step 4: Run optimization\nprint(\"\\nStarting optimization with EvoEngineer...\")\nprint(\"This may take a few minutes...\\n\")\n\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    max_sample_nums=10,\n    pop_size=5\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Optimization completed!\")\nprint(\"=\"*60)\nprint(f\"\\nBest solution fitness: {result.evaluation_res.score}\")\nprint(f\"Results saved to: ./results/\")\n</code></pre>"},{"location":"getting-started/first-optimization/#step-3-run-the-script","title":"Step 3: Run the Script","text":"<pre><code>python first_optimization.py\n</code></pre> <p>You should see output similar to:</p> <pre><code>Creating scientific regression task...\nSetting up EvoEngineer interface...\nConfiguring LLM API...\n\nStarting optimization with EvoEngineer...\nThis may take a few minutes...\n\nGeneration 1/5: Best fitness = 0.245\nGeneration 2/5: Best fitness = 0.189\nGeneration 3/5: Best fitness = 0.134\nGeneration 4/5: Best fitness = 0.098\nGeneration 5/5: Best fitness = 0.067\n\n============================================================\nOptimization completed!\n============================================================\n\nBest solution fitness: 0.067\nResults saved to: ./results/\n</code></pre> <p>Next: Understanding the Code</p>"},{"location":"getting-started/next-steps/","title":"Next Steps","text":"<p>Congratulations! You've completed your first optimization with EvoToolkit. Here's what to explore next:</p>"},{"location":"getting-started/next-steps/#tutorials","title":"Tutorials","text":"<ul> <li>Scientific Regression Tutorial: Deep dive into scientific symbolic regression</li> <li>Custom Task Tutorial: Create your own optimization tasks</li> <li>API Reference: Detailed API documentation</li> <li>Advanced Usage: Low-level API and customization</li> </ul>"},{"location":"getting-started/next-steps/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ul> <li>Check the API Reference for detailed documentation</li> <li>Visit GitHub Issues</li> <li>Join GitHub Discussions</li> </ul>"},{"location":"getting-started/try-algorithms/","title":"Try Different Algorithms","text":"<p>EvoToolkit supports multiple evolutionary algorithms. Try them all:</p>"},{"location":"getting-started/try-algorithms/#eoh-evolution-of-heuristics","title":"EoH (Evolution of Heuristics)","text":"<pre><code>from evotoolkit.task.python_task import EoHPythonInterface\n\ninterface = EoHPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre>"},{"location":"getting-started/try-algorithms/#funsearch","title":"FunSearch","text":"<pre><code>from evotoolkit.task.python_task import FunSearchPythonInterface\n\ninterface = FunSearchPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre> <p>Next: Next Steps</p>"},{"location":"getting-started/understanding-code/","title":"Understanding the Code","text":"<p>Let's break down what each part does:</p>"},{"location":"getting-started/understanding-code/#1-task-creation","title":"1. Task Creation","text":"<pre><code>task = ScientificRegressionTask(dataset_name=\"bactgrow\")\n</code></pre> <p>A <code>Task</code> defines what problem you're solving and how to evaluate solutions. <code>ScientificRegressionTask</code> is a built-in task for discovering mathematical equations from real scientific datasets. The datasets are automatically downloaded on first use (lazy loading).</p>"},{"location":"getting-started/understanding-code/#2-interface-creation","title":"2. Interface Creation","text":"<pre><code>interface = EvoEngineerPythonInterface(task)\n</code></pre> <p>An <code>Interface</code> connects your task to a specific evolutionary algorithm. Here we use <code>EvoEngineerPythonInterface</code> for the EvoEngineer algorithm.</p>"},{"location":"getting-started/understanding-code/#3-llm-configuration","title":"3. LLM Configuration","text":"<pre><code>llm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"your-api-key-here\",\n    model=\"gpt-4o\"\n)\n</code></pre> <p>This sets up the LLM API client that will generate and improve code solutions. Replace <code>your-api-key-here</code> with your actual API key.</p>"},{"location":"getting-started/understanding-code/#4-solving-the-problem","title":"4. Solving the Problem","text":"<pre><code>result = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    max_sample_nums=10,\n    pop_size=5\n)\n</code></pre> <p>The <code>evotoolkit.solve()</code> function:</p> <ul> <li>Runs the evolutionary algorithm for 5 generations</li> <li>Uses a population size of 5</li> <li>Samples up to 10 LLM responses per generation</li> <li>Saves results to <code>./results/</code></li> </ul> <p>Next: Exploring the Results</p>"},{"location":"installation/env-managers/","title":"Environments &amp; Package Managers","text":"<p>Manage your Python environment with your preferred tool.</p>"},{"location":"installation/env-managers/#using-uv-recommended","title":"Using uv (Recommended)","text":"<pre><code># Install uv\npip install uv\n\n# Create a new project\nuv init my-evotool-project\ncd my-evotool-project\n\n# Add evotoolkit\nuv add evotoolkit\n\n# Run your script\nuv run python main.py\n</code></pre>"},{"location":"installation/env-managers/#using-pip","title":"Using pip","text":"<pre><code># Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install evotoolkit\npip install evotoolkit\n</code></pre>"},{"location":"installation/env-managers/#using-conda","title":"Using conda","text":"<pre><code># Create conda environment\nconda create -n evotool python=3.11\nconda activate evotool\n\n# Install evotoolkit\npip install evotoolkit\n</code></pre>"},{"location":"installation/from-source/","title":"Install from Source","text":"<p>For development or to get the latest features from the repository.</p>"},{"location":"installation/from-source/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/pgg3/evotoolkitkit.git\ncd evotool\n</code></pre>"},{"location":"installation/from-source/#install-with-uv-recommended","title":"Install with uv (Recommended)","text":"<pre><code>pip install uv\nuv sync\n</code></pre>"},{"location":"installation/from-source/#install-with-pip-editable","title":"Install with pip (Editable)","text":"<pre><code>pip install -e .\n</code></pre>"},{"location":"installation/llm-and-verify/","title":"LLM Setup &amp; Verify","text":"<p>Configure your LLM API and verify your installation.</p>"},{"location":"installation/llm-and-verify/#verify-installation","title":"Verify Installation","text":"<pre><code>import evotoolkit\nfrom evotoolkit.core import Solution\n\nprint(f\"EvoToolkit version: {evotoolkit.__version__}\")\nprint(\"\u2705 Installation successful!\")\n</code></pre>"},{"location":"installation/llm-and-verify/#llm-api-setup","title":"LLM API Setup","text":"<p>EvoToolkit uses an external LLM API (e.g., OpenAI GPT-4). Configure credentials in code:</p> <pre><code>from evotoolkit.tools import HttpsApi\n\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",  # Your API endpoint\n    key=\"your-api-key-here\",  # Your API key\n    model=\"gpt-4o\"\n)\n</code></pre> <p>You can obtain a key from OpenAI or use other OpenAI-compatible services.</p>"},{"location":"installation/pypi/","title":"Install from PyPI","text":"<p>The simplest way to install EvoToolkit is via pip.</p>"},{"location":"installation/pypi/#basic-installation","title":"Basic Installation","text":"<pre><code>pip install evotoolkit\n</code></pre>"},{"location":"installation/pypi/#optional-dependencies","title":"Optional Dependencies","text":"<p>EvoToolkit provides optional extras for specific tasks. For example, to enable CUDA kernel engineering tasks:</p> <pre><code>pip install evotoolkit[cuda_engineering]\n</code></pre>"},{"location":"installation/requirements/","title":"Requirements","text":"<p>EvoToolkit runs on modern Python and OS environments.</p>"},{"location":"installation/requirements/#supported-versions","title":"Supported Versions","text":"<ul> <li>Python: 3.11 or higher</li> <li>Operating Systems: Linux, macOS, or Windows</li> <li>Optional: CUDA-capable GPU (for CUDA engineering tasks)</li> </ul>"},{"location":"installation/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and quick fixes during installation and setup.</p>"},{"location":"installation/troubleshooting/#pip-cannot-find-evotoolkit","title":"pip cannot find evotoolkit","text":"<ul> <li>Ensure internet access and latest pip: <code>python -m pip install -U pip</code>.</li> <li>Confirm correct package name: <code>evotoolkit</code>.</li> </ul>"},{"location":"installation/troubleshooting/#importerror-cannot-import-name-solution","title":"ImportError: cannot import name 'Solution'","text":"<ul> <li>Check version: <code>python -c \"import evotoolkit, sys; print(evotoolkit.__version__)\"</code>.</li> <li>If multiple Python versions, ensure you run the interpreter from the same environment where you installed the package.</li> </ul>"},{"location":"installation/troubleshooting/#cuda-not-detected","title":"CUDA not detected","text":"<ul> <li>Install appropriate CUDA toolkit and drivers for your GPU and OS.</li> <li>Some tasks require the <code>cuda_engineering</code> extra: <code>pip install evotoolkit[cuda_engineering]</code>.</li> </ul>"},{"location":"installation/troubleshooting/#llm-api-errors-401403sslerror","title":"LLM API errors (401/403/SSLError)","text":"<ul> <li>Verify API key is set and valid.</li> <li>Check system time and certificate store.</li> <li>If using a proxy, ensure it allows HTTPS to the API endpoint.</li> </ul>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Welcome to the EvoToolkit tutorials! These step-by-step guides will help you master evolutionary optimization with LLMs.</p>"},{"location":"tutorials/#getting-started","title":"Getting Started","text":"<p>New to EvoToolkit? Start here:</p> <ol> <li>Installation - Set up your environment</li> <li>Getting Started - Run your first optimization in 5 minutes</li> <li>Scientific Regression Tutorial - Deep dive into a complete example</li> </ol>"},{"location":"tutorials/#tutorial-categories","title":"Tutorial Categories","text":""},{"location":"tutorials/#built-in-tasks","title":"Built-in Tasks","text":"<p>Learn how to use EvoToolkit's pre-built optimization tasks:</p> <ul> <li>Scientific Regression - Discover mathematical equations from data</li> <li>Prompt Engineering - Optimize LLM prompts for better performance</li> <li>Adversarial Attack - Generate adversarial examples</li> <li>CUDA Tasks - Optimize GPU kernels for performance</li> </ul>"},{"location":"tutorials/#customization","title":"Customization","text":"<p>Extend EvoToolkit for your specific needs:</p> <ul> <li>Custom Tasks - Create your own optimization problems</li> <li>Customizing Evolution - Modify prompts and algorithms</li> </ul>"},{"location":"tutorials/#advanced","title":"Advanced","text":"<p>Master the low-level APIs:</p> <ul> <li>Advanced Usage - Fine-grained control and debugging</li> </ul>"},{"location":"tutorials/#tutorial-overview","title":"Tutorial Overview","text":"Tutorial Level Time Topics Covered Scientific Regression Beginner 20 min High-level API, real datasets, equation evolution Prompt Engineering Beginner-Intermediate 20 min LLM prompt optimization, task performance Adversarial Attack Intermediate 25 min Evolving adversarial examples, attack algorithms CUDA Tasks Advanced 30 min GPU optimization, CUDA kernels, performance Custom Tasks Intermediate 20 min Creating tasks, evaluation, custom fitness Customizing Evolution Intermediate-Advanced 30 min Prompt engineering, custom algorithms, Interface development Advanced Usage Advanced 25 min Low-level API, custom configs, debugging"},{"location":"tutorials/#quick-reference","title":"Quick Reference","text":""},{"location":"tutorials/#common-workflow-patterns","title":"Common Workflow Patterns","text":""},{"location":"tutorials/#pattern-1-basic-optimization","title":"Pattern 1: Basic Optimization","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\n\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface, './results', llm_api)\n</code></pre>"},{"location":"tutorials/#pattern-2-algorithm-comparison","title":"Pattern 2: Algorithm Comparison","text":"<pre><code>algorithms = [\n    ('EoH', EoHPythonInterface(task)),\n    ('EvoEngineer', EvoEngineerPythonInterface(task)),\n    ('FunSearch', FunSearchPythonInterface(task))\n]\n\nfor name, interface in algorithms:\n    result = evotoolkit.solve(interface, f'./results/{name}', llm_api)\n</code></pre>"},{"location":"tutorials/#pattern-3-custom-configuration","title":"Pattern 3: Custom Configuration","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=20,\n    pop_size=10\n)\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n</code></pre>"},{"location":"tutorials/#downloadable-examples","title":"Downloadable Examples","text":"<p>All tutorial code is available as standalone Python scripts in the <code>examples/</code> directory:</p> <ul> <li><code>examples/scientific_regression/</code> - Scientific equation discovery</li> <li><code>examples/custom_task/my_custom_task.py</code> - Custom task implementation</li> <li><code>examples/cuda_task/kernel_optimization.py</code> - CUDA kernel optimization</li> <li><code>examples/advanced/low_level_api.py</code> - Low-level API usage</li> </ul> <p>Clone the repository to get started:</p> <pre><code>git clone https://github.com/pgg3/evotoolkitkit.git\ncd evotool/examples\n</code></pre>"},{"location":"tutorials/#need-help","title":"Need Help?","text":""},{"location":"tutorials/#documentation-resources","title":"Documentation &amp; Resources","text":"<ul> <li>API Reference - Detailed API documentation</li> <li>Development Guide - Contributing guidelines</li> <li>Advanced Examples - Complex use case references</li> </ul>"},{"location":"tutorials/#community-support","title":"Community Support","text":"<ul> <li>GitHub Discussions - Ask questions and share projects</li> <li>GitHub Issues - Report bugs and request features</li> <li>Example Gallery - Community-contributed examples</li> <li>Blog - Articles and case studies</li> </ul>"},{"location":"tutorials/#direct-contact","title":"Direct Contact","text":"<ul> <li>Email: pguo6680@gmail.com</li> </ul>"},{"location":"tutorials/#video-tutorials","title":"Video Tutorials","text":"<p>Coming soon! Subscribe to our YouTube channel for video tutorials.</p>"},{"location":"tutorials/advanced-overview/","title":"Advanced Usage","text":"<p>Master the low-level API for maximum control and customization.</p>"},{"location":"tutorials/advanced-overview/#overview","title":"Overview","text":"<p>These advanced tutorials cover:</p> <ul> <li>Low-Level API - Direct algorithm control and configuration</li> <li>Algorithm Configuration - Fine-tune evolution parameters</li> <li>Algorithm Internals - Access and analyze internal state</li> <li>Debugging &amp; Profiling - Troubleshoot and optimize performance</li> </ul>"},{"location":"tutorials/advanced-overview/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Scientific Regression tutorial</li> <li>Completed Custom Task tutorial</li> <li>Understanding of evolutionary algorithms</li> </ul>"},{"location":"tutorials/advanced-overview/#tutorials","title":"Tutorials","text":""},{"location":"tutorials/advanced-overview/#low-level-api","title":"Low-Level API","text":"<p>\u2192 Start Tutorial</p> <p>Learn the difference between high-level and low-level APIs, and when to use each.</p> <p>You'll Learn: - High-level vs low-level API comparison - Direct algorithm instantiation - Accessing internal state - Custom workflow control</p> <p>Time: 15 minutes</p>"},{"location":"tutorials/advanced-overview/#algorithm-configuration","title":"Algorithm Configuration","text":"<p>\u2192 Start Tutorial</p> <p>Master detailed configuration options for each evolutionary algorithm.</p> <p>You'll Learn: - EvoEngineer configuration parameters - FunSearch island model setup - EoH operator control - Parallel execution tuning</p> <p>Time: 20 minutes</p>"},{"location":"tutorials/advanced-overview/#algorithm-internals","title":"Algorithm Internals","text":"<p>\u2192 Start Tutorial</p> <p>Access and analyze the internal state of evolutionary algorithms.</p> <p>You'll Learn: - Inspect evolution history - Access solution populations - Plot evolution progress - Extract metrics and statistics</p> <p>Time: 15 minutes</p>"},{"location":"tutorials/advanced-overview/#debugging-profiling","title":"Debugging &amp; Profiling","text":"<p>\u2192 Start Tutorial</p> <p>Debug issues and optimize performance of your evolutionary workflows.</p> <p>You'll Learn: - Enable verbose logging - Save intermediate solutions - Inspect LLM prompts/responses - Time and memory profiling - Implement custom algorithms</p> <p>Time: 25 minutes</p>"},{"location":"tutorials/advanced-overview/#when-to-use-advanced-features","title":"When to Use Advanced Features","text":""},{"location":"tutorials/advanced-overview/#use-low-level-api-when","title":"Use Low-Level API When:","text":"<ul> <li>You need fine-grained control over the evolution process</li> <li>Default configurations don't meet your requirements</li> <li>You want to implement custom stopping criteria</li> <li>You need access to intermediate results</li> </ul>"},{"location":"tutorials/advanced-overview/#use-custom-configuration-when","title":"Use Custom Configuration When:","text":"<ul> <li>Default parameters don't work well for your task</li> <li>You want to optimize for speed or quality</li> <li>You need to tune parallel execution</li> <li>You're experimenting with algorithm variants</li> </ul>"},{"location":"tutorials/advanced-overview/#use-debugging-tools-when","title":"Use Debugging Tools When:","text":"<ul> <li>Evolution doesn't converge as expected</li> <li>You want to understand algorithm behavior</li> <li>You need to optimize resource usage</li> <li>You're developing custom algorithms</li> </ul>"},{"location":"tutorials/advanced-overview/#quick-reference","title":"Quick Reference","text":""},{"location":"tutorials/advanced-overview/#basic-low-level-pattern","title":"Basic Low-Level Pattern","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=8,\n    verbose=True\n)\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# Access results\nbest = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n</code></pre>"},{"location":"tutorials/advanced-overview/#next-steps","title":"Next Steps","text":"<p>After mastering advanced usage:</p> <ul> <li>Explore the API Reference for complete documentation</li> <li>Read Architecture Documentation to understand internals</li> <li>Contribute your improvements via the Contributing Guide</li> </ul>"},{"location":"tutorials/built-in-overview/","title":"Built-in Tasks","text":"<p>EvoToolkit provides several pre-built optimization tasks that demonstrate the power of LLM-driven evolution across different domains.</p>"},{"location":"tutorials/built-in-overview/#available-tasks","title":"Available Tasks","text":""},{"location":"tutorials/built-in-overview/#scientific-regression","title":"Scientific Regression","text":"<p>\u2192 Start Tutorial</p> <p>Learn how to discover mathematical equations from real scientific datasets.</p> <p>You'll Learn: - Loading and working with scientific datasets - Creating scientific regression tasks - Using the high-level <code>evotoolkit.solve()</code> API - Comparing different evolutionary algorithms (EoH, EvoEngineer, FunSearch) - Interpreting discovered equations</p> <p>Prerequisites: Basic Python and NumPy knowledge</p>"},{"location":"tutorials/built-in-overview/#prompt-engineering","title":"Prompt Engineering","text":"<p>\u2192 Start Tutorial</p> <p>Optimize LLM prompts to improve task performance.</p> <p>You'll Learn: - LLM prompt optimization basics - Using string optimization tasks - Evolving prompt templates - Evaluating and comparing different prompts</p> <p>Prerequisites: Scientific Regression tutorial</p>"},{"location":"tutorials/built-in-overview/#adversarial-attack","title":"Adversarial Attack","text":"<p>\u2192 Start Tutorial</p> <p>Learn how to evolve adversarial examples and attack algorithms.</p> <p>You'll Learn: - Creating adversarial attack tasks - Evolving attack strategies - Generating adversarial examples - Evaluating attack effectiveness</p> <p>Prerequisites: Scientific Regression tutorial, machine learning basics</p>"},{"location":"tutorials/built-in-overview/#cuda-tasks","title":"CUDA Tasks","text":"<p>\u2192 Start Tutorial</p> <p>Optimize GPU kernels using LLM-driven evolution.</p> <p>You'll Learn: - Creating CUDA optimization tasks - Benchmarking GPU performance - Evolving efficient CUDA kernels - Handling compilation and execution</p> <p>Prerequisites: CUDA programming basics, GPU hardware</p>"},{"location":"tutorials/built-in-overview/#task-comparison","title":"Task Comparison","text":"Task Domain Difficulty Best For Scientific Regression Data Science Beginner Learning the basics, equation discovery Prompt Engineering NLP/LLM Intermediate Optimizing LLM interactions Adversarial Attack Security/ML Intermediate Security research, robustness testing CUDA Tasks GPU Computing Advanced Performance optimization"},{"location":"tutorials/built-in-overview/#getting-started","title":"Getting Started","text":"<ol> <li>Start with Scientific Regression if you're new to EvoToolkit</li> <li>Try Prompt Engineering to see how evolution can optimize text</li> <li>Explore Adversarial Attack for security applications</li> <li>Master CUDA Tasks for GPU optimization</li> </ol> <p>Each tutorial includes complete, runnable code examples that you can adapt for your own problems.</p>"},{"location":"tutorials/customization-overview/","title":"Customization","text":"<p>Learn how to extend EvoToolkit to solve your specific optimization problems.</p>"},{"location":"tutorials/customization-overview/#customization-options","title":"Customization Options","text":""},{"location":"tutorials/customization-overview/#custom-tasks","title":"Custom Tasks","text":"<p>\u2192 Start Tutorial</p> <p>Create your own optimization tasks for domain-specific problems.</p> <p>You'll Learn: - Extending the <code>Task</code> base class - Implementing custom evaluation logic - Defining solution spaces - Integrating with evolutionary algorithms</p> <p>Prerequisites: Basic EvoToolkit knowledge (Scientific Regression tutorial)</p>"},{"location":"tutorials/customization-overview/#customizing-evolution-methods","title":"Customizing Evolution Methods","text":"<p>\u2192 Start Tutorial</p> <p>Learn how to customize evolutionary behavior by modifying prompts or developing new algorithms.</p> <p>You'll Learn: - Understanding the Interface architecture - Customizing LLM prompts to improve results - Designing task-specific prompts - Developing brand new evolution algorithms (advanced) - Implementing custom strategies like temperature annealing</p> <p>Prerequisites: Basic EvoToolkit knowledge (Scientific Regression tutorial)</p>"},{"location":"tutorials/customization-overview/#when-to-customize","title":"When to Customize","text":""},{"location":"tutorials/customization-overview/#create-a-custom-task-when","title":"Create a Custom Task When:","text":"<ul> <li>Your problem domain isn't covered by built-in tasks</li> <li>You need specific evaluation metrics</li> <li>You want to optimize domain-specific code or structures</li> <li>You need custom constraints or validation</li> </ul>"},{"location":"tutorials/customization-overview/#customize-evolution-methods-when","title":"Customize Evolution Methods When:","text":"<ul> <li>Default prompts don't work well for your task</li> <li>You want to incorporate domain knowledge into the evolution</li> <li>You need special mutation or crossover strategies</li> <li>You want to experiment with novel evolutionary approaches</li> </ul>"},{"location":"tutorials/customization-overview/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"tutorials/customization-overview/#custom-task-example","title":"Custom Task Example","text":"<pre><code>from evotoolkit.core import BaseTask, Solution\n\nclass MyCustomTask(BaseTask):\n    def evaluate(self, solution: Solution) -&gt; float:\n        # Your evaluation logic here\n        return fitness_score\n</code></pre>"},{"location":"tutorials/customization-overview/#custom-interface-example","title":"Custom Interface Example","text":"<pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\n\nclass MyCustomInterface(EvoEngineerPythonInterface):\n    def get_prompt_components(self):\n        # Customize prompts for your task\n        return custom_prompts\n</code></pre>"},{"location":"tutorials/customization-overview/#best-practices","title":"Best Practices","text":"<ol> <li>Start Simple: Begin with modifying existing tasks or prompts before creating entirely new ones</li> <li>Test Thoroughly: Validate your custom evaluation logic with known solutions</li> <li>Document Well: Clearly document your task requirements and constraints</li> <li>Share Your Work: Consider contributing your custom tasks back to the community</li> </ol>"},{"location":"tutorials/customization-overview/#next-steps","title":"Next Steps","text":"<p>After mastering customization: - Explore Advanced Usage for low-level API control - Check the API Reference for detailed documentation - Share your custom tasks in GitHub Discussions</p>"},{"location":"tutorials/advanced/configuration/","title":"Algorithm Configuration","text":"<p>Master detailed configuration options for each evolutionary algorithm.</p>"},{"location":"tutorials/advanced/configuration/#overview","title":"Overview","text":"<p>Each evolutionary algorithm in EvoToolkit has its own configuration class with specific parameters. This tutorial covers all configuration options and how to tune them for your use case.</p>"},{"location":"tutorials/advanced/configuration/#evoengineer-configuration","title":"EvoEngineer Configuration","text":"<p>EvoEngineer is the primary LLM-driven evolutionary algorithm.</p> <pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n\n    # Evolution parameters\n    max_generations=20,      # Maximum number of generations\n    pop_size=10,             # Population size\n    max_sample_nums=15,      # Maximum samples per generation\n\n    # Parallel control\n    num_samplers=4,          # Number of parallel samplers\n    num_evaluators=4,        # Number of parallel evaluators\n\n    # Logging\n    verbose=True             # Show verbose logging\n)\n</code></pre>"},{"location":"tutorials/advanced/configuration/#key-parameters","title":"Key Parameters","text":"<p>Evolution Parameters: - <code>max_generations</code> - Number of evolutionary generations to run - <code>pop_size</code> - Number of solutions to maintain in population - <code>max_sample_nums</code> - Maximum new solutions to sample per generation</p> <p>Parallel Execution: - <code>num_samplers</code> - Parallel LLM sampling workers - <code>num_evaluators</code> - Parallel evaluation workers</p> <p>Logging: - <code>verbose</code> - Enable detailed progress logging</p>"},{"location":"tutorials/advanced/configuration/#important-note","title":"Important Note","text":"<p>LLM temperature and other sampling parameters are set when creating <code>HttpsApi</code>, NOT in algorithm configuration.</p> <pre><code>from evotoolkit.tools.llm import HttpsApi\n\n# LLM configuration happens here\nllm_api = HttpsApi(\n    api_key=\"your-key\",\n    model=\"claude-3-5-sonnet-20241022\",\n    temperature=0.7,  # LLM temperature\n    max_tokens=4096\n)\n\n# Algorithm config does NOT include temperature\nconfig = EvoEngineerConfig(\n    running_llm=llm_api,  # Pass configured LLM\n    # ... other params\n)\n</code></pre>"},{"location":"tutorials/advanced/configuration/#funsearch-configuration","title":"FunSearch Configuration","text":"<p>FunSearch uses an island model for continuous evolution.</p> <pre><code>from evotoolkit.evo_method.funsearch import FunSearchConfig\n\nconfig = FunSearchConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n\n    # Sampling parameters\n    max_sample_nums=30,           # Maximum number of samples\n    programs_per_prompt=2,        # Programs generated per prompt\n\n    # Island model\n    num_islands=4,                # Number of parallel evolution islands\n    max_population_size=1000,     # Maximum population size per island\n\n    # Parallel control\n    num_samplers=5,               # Number of parallel samplers\n    num_evaluators=5,             # Number of parallel evaluators\n\n    # Logging\n    verbose=True\n)\n</code></pre>"},{"location":"tutorials/advanced/configuration/#key-parameters_1","title":"Key Parameters","text":"<p>Sampling: - <code>max_sample_nums</code> - Total samples to generate - <code>programs_per_prompt</code> - Solutions per LLM call</p> <p>Island Model: - <code>num_islands</code> - Independent evolution islands (increases diversity) - <code>max_population_size</code> - Maximum solutions per island</p> <p>Note: FunSearch does NOT use <code>max_generations</code>. It evolves continuously based on the island model until <code>max_sample_nums</code> is reached.</p>"},{"location":"tutorials/advanced/configuration/#when-to-use-funsearch","title":"When to Use FunSearch","text":"<ul> <li>When you want continuous evolution without fixed generations</li> <li>For exploring diverse solution spaces</li> <li>When you have computational resources for large populations</li> </ul>"},{"location":"tutorials/advanced/configuration/#eoh-configuration","title":"EoH Configuration","text":"<p>EoH (Evolution of Heuristics) provides explicit control over genetic operators.</p> <pre><code>from evotoolkit.evo_method.eoh import EoHConfig\n\nconfig = EoHConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n\n    # Evolution parameters\n    max_generations=10,       # Maximum number of generations\n    pop_size=5,               # Population size\n    max_sample_nums=20,       # Maximum samples per generation\n    selection_num=2,          # Number of parents for crossover\n\n    # Operator control\n    use_e2_operator=True,     # Use E2 operator (crossover)\n    use_m1_operator=True,     # Use M1 operator (mutation)\n    use_m2_operator=True,     # Use M2 operator (second mutation)\n\n    # Parallel control\n    num_samplers=5,           # Number of parallel samplers\n    num_evaluators=5,         # Number of parallel evaluators\n\n    # Logging\n    verbose=True\n)\n</code></pre>"},{"location":"tutorials/advanced/configuration/#key-parameters_2","title":"Key Parameters","text":"<p>Evolution: - <code>max_generations</code> - Number of generations - <code>pop_size</code> - Population size (typically smaller than EvoEngineer) - <code>max_sample_nums</code> - Samples per generation - <code>selection_num</code> - Parents selected for crossover</p> <p>Genetic Operators: - <code>use_e2_operator</code> - Enable/disable crossover operator - <code>use_m1_operator</code> - Enable/disable first mutation operator - <code>use_m2_operator</code> - Enable/disable second mutation operator</p>"},{"location":"tutorials/advanced/configuration/#when-to-use-eoh","title":"When to Use EoH","text":"<ul> <li>When you want explicit control over genetic operators</li> <li>For research comparing different operator combinations</li> <li>When traditional EA concepts are important</li> </ul>"},{"location":"tutorials/advanced/configuration/#tuning-guidelines","title":"Tuning Guidelines","text":""},{"location":"tutorials/advanced/configuration/#population-size","title":"Population Size","text":"<p>Small (5-10): - Pros: Faster generations, lower cost - Cons: Less diversity, may converge too quickly - Best for: Simple problems, limited resources</p> <p>Medium (10-20): - Pros: Good balance of speed and diversity - Cons: None major - Best for: Most problems (recommended default)</p> <p>Large (20+): - Pros: Maximum diversity, thorough exploration - Cons: Slower, higher cost - Best for: Complex problems, research</p>"},{"location":"tutorials/advanced/configuration/#parallel-execution","title":"Parallel Execution","text":"<pre><code>config = EvoEngineerConfig(\n    # ... other params\n    num_samplers=4,      # Parallel LLM calls\n    num_evaluators=4,    # Parallel evaluations\n)\n</code></pre> <p>Guidelines: - <code>num_samplers</code>: Set based on LLM API rate limits - <code>num_evaluators</code>: Set based on CPU/GPU availability - Start conservatively (2-4) and increase if resources allow</p> <p>Example Configurations:</p> <pre><code># Conservative (low resources)\nnum_samplers=2\nnum_evaluators=2\n\n# Balanced (moderate resources)\nnum_samplers=4\nnum_evaluators=4\n\n# Aggressive (high resources)\nnum_samplers=8\nnum_evaluators=8\n</code></pre>"},{"location":"tutorials/advanced/configuration/#generation-count","title":"Generation Count","text":"<p>Few Generations (5-10): - Quick experiments - Simple problems - Rapid prototyping</p> <p>Medium Generations (10-20): - Most problems - Balanced exploration - Recommended default</p> <p>Many Generations (20+): - Complex problems - Research studies - Final optimization runs</p>"},{"location":"tutorials/advanced/configuration/#configuration-presets","title":"Configuration Presets","text":""},{"location":"tutorials/advanced/configuration/#quick-experimentation","title":"Quick Experimentation","text":"<pre><code>config = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    pop_size=5,\n    max_sample_nums=10,\n    num_samplers=2,\n    num_evaluators=2,\n    verbose=True\n)\n</code></pre> <p>Use for: Testing, debugging, rapid iteration</p>"},{"location":"tutorials/advanced/configuration/#balanced-performance","title":"Balanced Performance","text":"<pre><code>config = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=15,\n    pop_size=10,\n    max_sample_nums=20,\n    num_samplers=4,\n    num_evaluators=4,\n    verbose=True\n)\n</code></pre> <p>Use for: Most production use cases</p>"},{"location":"tutorials/advanced/configuration/#thorough-search","title":"Thorough Search","text":"<pre><code>config = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=30,\n    pop_size=15,\n    max_sample_nums=30,\n    num_samplers=6,\n    num_evaluators=6,\n    verbose=True\n)\n</code></pre> <p>Use for: Research, benchmarking, final runs</p>"},{"location":"tutorials/advanced/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Algorithm Internals to analyze evolution behavior</li> <li>Check Debugging &amp; Profiling for performance optimization</li> <li>Review the API Reference for complete parameter details</li> </ul>"},{"location":"tutorials/advanced/configuration/#resources","title":"Resources","text":"<ul> <li>EvoEngineer Paper - Algorithm details</li> <li>FunSearch Paper - Island model theory</li> <li>EoH Paper - Heuristic evolution</li> </ul>"},{"location":"tutorials/advanced/debugging/","title":"Debugging &amp; Profiling","text":"<p>Debug issues and optimize performance of your evolutionary workflows.</p>"},{"location":"tutorials/advanced/debugging/#enabling-verbose-logging","title":"Enabling Verbose Logging","text":""},{"location":"tutorials/advanced/debugging/#basic-verbose-mode","title":"Basic Verbose Mode","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    verbose=True  # Enable verbose logging\n)\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n</code></pre> <p>Output Example: <pre><code>Generation 1/10:\n  - Generated 12 solutions\n  - Valid solutions: 8\n  - Best score: 0.245\n  - Average score: 0.512\n  - Elites preserved: 2\n\nGeneration 2/10:\n  - Generated 12 solutions\n  - Valid solutions: 10\n  - Best score: 0.189\n  - Average score: 0.431\n  - Elites preserved: 2\n...\n</code></pre></p>"},{"location":"tutorials/advanced/debugging/#saving-intermediate-solutions","title":"Saving Intermediate Solutions","text":""},{"location":"tutorials/advanced/debugging/#save-all-generations","title":"Save All Generations","text":"<pre><code>config = EvoEngineerConfig(\n    # ... other params\n    save_all_generations=True  # Save solutions from each generation\n)\n</code></pre> <p>Directory Structure: <pre><code>results/\n\u251c\u2500\u2500 generation_1/\n\u2502   \u251c\u2500\u2500 solution_1.py\n\u2502   \u251c\u2500\u2500 solution_2.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 generation_2/\n\u2502   \u251c\u2500\u2500 solution_1.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 ...\n\u2514\u2500\u2500 best_solution.py\n</code></pre></p> <p>This allows you to: - Inspect failed solutions - Debug evaluation errors - Analyze solution evolution - Recover from crashes</p>"},{"location":"tutorials/advanced/debugging/#inspecting-llm-interactions","title":"Inspecting LLM Interactions","text":""},{"location":"tutorials/advanced/debugging/#enable-llm-logging","title":"Enable LLM Logging","text":"<pre><code>import logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('./results/llm_debug.log'),\n        logging.StreamHandler()\n    ]\n)\n\n# Enable LLM logger\nlogger = logging.getLogger('evotoolkit.llm')\nlogger.setLevel(logging.DEBUG)\n\n# Now run algorithm - all LLM interactions will be logged\nalgorithm.run()\n</code></pre> <p>Log Output Example: <pre><code>2024-01-15 10:23:45 - evotoolkit.llm - DEBUG - Sending prompt to LLM:\n  --- PROMPT START ---\n  You are an expert Python programmer...\n  --- PROMPT END ---\n\n2024-01-15 10:23:52 - evotoolkit.llm - DEBUG - Received LLM response:\n  --- RESPONSE START ---\n  def target_function(x):\n      return x ** 2 + 2 * x + 1\n  --- RESPONSE END ---\n\n2024-01-15 10:23:52 - evotoolkit.llm - DEBUG - Token usage: 245 input, 67 output\n</code></pre></p>"},{"location":"tutorials/advanced/debugging/#save-prompts-and-responses","title":"Save Prompts and Responses","text":"<pre><code>class DebugInterface(EvoEngineerPythonInterface):\n    def __init__(self, task):\n        super().__init__(task)\n        self.prompt_history = []\n\n    def query_llm(self, prompt):\n        response = super().query_llm(prompt)\n\n        # Save for debugging\n        self.prompt_history.append({\n            'prompt': prompt,\n            'response': response,\n            'timestamp': time.time()\n        })\n\n        # Save to file\n        with open('./results/llm_history.json', 'w') as f:\n            json.dump(self.prompt_history, f, indent=2)\n\n        return response\n</code></pre>"},{"location":"tutorials/advanced/debugging/#performance-profiling","title":"Performance Profiling","text":""},{"location":"tutorials/advanced/debugging/#time-profiling","title":"Time Profiling","text":"<pre><code>import time\n\nstart_time = time.time()\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\nelapsed = time.time() - start_time\nprint(f\"\\nTotal optimization time: {elapsed:.2f} seconds\")\nprint(f\"Time per generation: {elapsed / config.max_generations:.2f} seconds\")\n\n# Detailed timing (if available)\nif hasattr(algorithm.run_state_dict, 'metadata'):\n    gen_times = algorithm.run_state_dict.metadata.get('generation_times', [])\n    for i, t in enumerate(gen_times):\n        print(f\"Generation {i+1}: {t:.2f}s\")\n</code></pre>"},{"location":"tutorials/advanced/debugging/#detailed-profiling-with-cprofile","title":"Detailed Profiling with cProfile","text":"<pre><code>import cProfile\nimport pstats\nfrom pstats import SortKey\n\n# Profile the run\nprofiler = cProfile.Profile()\nprofiler.enable()\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\nprofiler.disable()\n\n# Save and analyze results\nstats = pstats.Stats(profiler)\nstats.sort_stats(SortKey.CUMULATIVE)\n\n# Print top 20 time consumers\nprint(\"\\nTop 20 time-consuming functions:\")\nstats.print_stats(20)\n\n# Save to file\nwith open('./results/profile_stats.txt', 'w') as f:\n    stats = pstats.Stats(profiler, stream=f)\n    stats.sort_stats(SortKey.CUMULATIVE)\n    stats.print_stats()\n</code></pre>"},{"location":"tutorials/advanced/debugging/#memory-profiling","title":"Memory Profiling","text":"<pre><code>import tracemalloc\n\n# Start memory tracking\ntracemalloc.start()\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# Get memory usage\ncurrent, peak = tracemalloc.get_traced_memory()\nprint(f\"\\nCurrent memory usage: {current / 1024 / 1024:.2f} MB\")\nprint(f\"Peak memory usage: {peak / 1024 / 1024:.2f} MB\")\n\n# Get top memory allocations\nsnapshot = tracemalloc.take_snapshot()\ntop_stats = snapshot.statistics('lineno')\n\nprint(\"\\nTop 10 memory allocations:\")\nfor stat in top_stats[:10]:\n    print(stat)\n\ntracemalloc.stop()\n</code></pre>"},{"location":"tutorials/advanced/debugging/#common-debugging-scenarios","title":"Common Debugging Scenarios","text":""},{"location":"tutorials/advanced/debugging/#issue-solutions-not-improving","title":"Issue: Solutions Not Improving","text":"<p>Diagnosis: <pre><code># Check score progression\nscores = [s.evaluation_res.score for s in all_solutions if s.evaluation_res.valid]\nprint(f\"First 5 scores: {scores[:5]}\")\nprint(f\"Last 5 scores: {scores[-5:]}\")\n\n# Check if stuck in local optimum\nif len(set(scores[-10:])) == 1:\n    print(\"Warning: Scores not changing - may be stuck!\")\n</code></pre></p> <p>Solutions: - Increase population diversity (larger <code>pop_size</code>) - Increase sampling (larger <code>max_sample_nums</code>) - Adjust LLM temperature (higher for more exploration) - Check if task evaluation is working correctly</p>"},{"location":"tutorials/advanced/debugging/#issue-many-invalid-solutions","title":"Issue: Many Invalid Solutions","text":"<p>Diagnosis: <pre><code>valid_count = sum(1 for s in all_solutions if s.evaluation_res.valid)\ntotal_count = len(all_solutions)\nsuccess_rate = valid_count / total_count * 100\n\nprint(f\"Success rate: {success_rate:.1f}%\")\n\n# Check error messages\nerrors = [s.evaluation_res.error_message for s in all_solutions if not s.evaluation_res.valid]\nfrom collections import Counter\nprint(\"\\nMost common errors:\")\nfor error, count in Counter(errors).most_common(5):\n    print(f\"  {count}x: {error[:100]}...\")\n</code></pre></p> <p>Solutions: - Improve prompt clarity - Add more examples to prompts - Relax task constraints - Check task evaluation logic</p>"},{"location":"tutorials/advanced/debugging/#issue-slow-performance","title":"Issue: Slow Performance","text":"<p>Diagnosis: <pre><code>import time\n\n# Time each component\nstart = time.time()\nalgorithm = EvoEngineer(config)\ninit_time = time.time() - start\n\nstart = time.time()\nalgorithm.run()\nrun_time = time.time() - start\n\nprint(f\"Initialization: {init_time:.2f}s\")\nprint(f\"Execution: {run_time:.2f}s\")\nprint(f\"Per generation: {run_time / config.max_generations:.2f}s\")\n</code></pre></p> <p>Solutions: - Increase parallelism (<code>num_samplers</code>, <code>num_evaluators</code>) - Reduce <code>max_sample_nums</code> - Use faster LLM model - Optimize task evaluation code</p>"},{"location":"tutorials/advanced/debugging/#custom-algorithm-implementation","title":"Custom Algorithm Implementation","text":"<p>For advanced users who want to implement their own evolutionary algorithms:</p> <pre><code>from evotoolkit.core import BaseMethod, BaseConfig, Solution\n\nclass MyCustomAlgorithm(BaseMethod):\n    \"\"\"Custom evolutionary algorithm implementation\"\"\"\n\n    def __init__(self, config: BaseConfig):\n        super().__init__(config)\n        self.population = []\n\n    def run(self):\n        \"\"\"Main evolution loop\"\"\"\n        # Initialize population\n        self.population = self.initialize_population()\n\n        for generation in range(self.config.max_generations):\n            print(f\"\\nGeneration {generation + 1}/{self.config.max_generations}\")\n\n            # Generate new solutions using LLM\n            new_solutions = self.generate_solutions()\n\n            # Evaluate solutions\n            for solution in new_solutions:\n                eval_res = self.config.interface.task.evaluate_code(solution.sol_string)\n                solution.evaluation_res = eval_res\n\n            # Update population\n            self.population = self.select(self.population + new_solutions)\n\n            # Log progress\n            valid_pop = [s for s in self.population if s.evaluation_res.valid]\n            if valid_pop:\n                best = max(valid_pop, key=lambda s: s.evaluation_res.score)\n                print(f\"  Best score: {best.evaluation_res.score:.4f}\")\n\n        # Save results\n        self.save_results()\n\n    def initialize_population(self):\n        \"\"\"Generate initial population\"\"\"\n        initial_solutions = []\n\n        # Use LLM to generate initial solutions\n        for i in range(self.config.pop_size):\n            prompt = self.config.interface.get_init_prompt()\n            response = self.config.running_llm.query(prompt)\n\n            solution = Solution(sol_string=response)\n            eval_res = self.config.interface.task.evaluate_code(response)\n            solution.evaluation_res = eval_res\n\n            initial_solutions.append(solution)\n\n        return initial_solutions\n\n    def generate_solutions(self):\n        \"\"\"Generate new solutions for current generation\"\"\"\n        new_solutions = []\n\n        # Example: mutation\n        for parent in self.population[:3]:  # Take top 3\n            prompt = self.config.interface.get_mutation_prompt(parent)\n            response = self.config.running_llm.query(prompt)\n\n            solution = Solution(sol_string=response)\n            new_solutions.append(solution)\n\n        return new_solutions\n\n    def select(self, solutions):\n        \"\"\"Select best solutions for next generation\"\"\"\n        # Filter valid solutions\n        valid = [s for s in solutions if s.evaluation_res.valid]\n\n        # Sort by score (higher is better)\n        valid.sort(key=lambda s: s.evaluation_res.score, reverse=True)\n\n        # Keep top pop_size solutions\n        return valid[:self.config.pop_size]\n\n    def save_results(self):\n        \"\"\"Save final results\"\"\"\n        best = max(self.population, key=lambda s: s.evaluation_res.score)\n\n        with open(f'{self.config.output_path}/best_solution.py', 'w') as f:\n            f.write(best.sol_string)\n\n        print(f\"\\nOptimization complete!\")\n        print(f\"Best score: {best.evaluation_res.score:.4f}\")\n</code></pre> <p>Usage: <pre><code>algorithm = MyCustomAlgorithm(config)\nalgorithm.run()\n</code></pre></p>"},{"location":"tutorials/advanced/debugging/#debugging-checklist","title":"Debugging Checklist","text":"<p>When things go wrong, check:</p> <ul> <li> Task evaluation function works correctly</li> <li> LLM API is responding (check logs)</li> <li> Prompts are clear and contain examples</li> <li> Solutions are being generated (check <code>sol_history</code>)</li> <li> Scores are being computed correctly</li> <li> Configuration parameters are reasonable</li> <li> Sufficient resources (API rate limits, memory)</li> <li> Output directory is writable</li> </ul>"},{"location":"tutorials/advanced/debugging/#next-steps","title":"Next Steps","text":"<ul> <li>Review Algorithm Internals for analysis techniques</li> <li>Check Configuration for parameter tuning</li> <li>Explore Low-Level API for more control</li> </ul>"},{"location":"tutorials/advanced/debugging/#resources","title":"Resources","text":"<ul> <li>Python Logging Documentation</li> <li>cProfile Documentation</li> <li>tracemalloc Documentation</li> <li>Performance Profiling Guide</li> </ul>"},{"location":"tutorials/advanced/internals/","title":"Algorithm Internals","text":"<p>Access and analyze the internal state of evolutionary algorithms.</p>"},{"location":"tutorials/advanced/internals/#overview","title":"Overview","text":"<p>EvoToolkit's low-level API provides full access to algorithm internals, allowing you to: - Inspect evolution history - Access solution populations - Extract metrics and statistics - Plot evolution progress</p>"},{"location":"tutorials/advanced/internals/#accessing-run-state","title":"Accessing Run State","text":"<p>All algorithms store their internal state in <code>run_state_dict</code>:</p> <pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# Access run state\nrun_state = algorithm.run_state_dict\n\n# Get all solutions history\nall_solutions = run_state.sol_history\n\n# Get current population\ncurrent_population = run_state.population\n</code></pre>"},{"location":"tutorials/advanced/internals/#inspecting-evolution-history","title":"Inspecting Evolution History","text":""},{"location":"tutorials/advanced/internals/#get-all-solutions","title":"Get All Solutions","text":"<pre><code># All solutions ever generated (including invalid ones)\nall_solutions = algorithm.run_state_dict.sol_history\n\nprint(f\"Total solutions generated: {len(all_solutions)}\")\n</code></pre>"},{"location":"tutorials/advanced/internals/#filter-valid-solutions","title":"Filter Valid Solutions","text":"<pre><code># Only valid solutions\nvalid_solutions = [\n    sol for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nprint(f\"Valid solutions: {len(valid_solutions)}\")\nprint(f\"Success rate: {len(valid_solutions) / len(all_solutions) * 100:.1f}%\")\n</code></pre>"},{"location":"tutorials/advanced/internals/#get-score-history","title":"Get Score History","text":"<pre><code># Extract scores (higher is better)\nscore_history = [\n    sol.evaluation_res.score\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nprint(f\"Best score: {max(score_history)}\")\nprint(f\"Average score: {sum(score_history) / len(score_history):.4f}\")\nprint(f\"Score improvement: {max(score_history) - score_history[0]:.4f}\")\n</code></pre>"},{"location":"tutorials/advanced/internals/#get-best-solution","title":"Get Best Solution","text":"<pre><code># Method 1: Using built-in helper\nbest_solution = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n\n# Method 2: Manual search\nbest_solution = max(\n    all_solutions,\n    key=lambda s: s.evaluation_res.score if s.evaluation_res.valid else float('-inf')\n)\n\nprint(f\"Best score: {best_solution.evaluation_res.score}\")\nprint(f\"Best code:\\n{best_solution.sol_string}\")\n</code></pre>"},{"location":"tutorials/advanced/internals/#solution-object-structure","title":"Solution Object Structure","text":"<p>Each solution contains detailed information:</p> <pre><code>solution = all_solutions[0]\n\n# Core attributes\nsolution.sol_string          # The actual code/solution string\nsolution.evaluation_res      # Evaluation result object\nsolution.other_info         # Additional metadata dictionary\n\n# Evaluation result\neval_res = solution.evaluation_res\neval_res.valid              # Boolean: is solution valid?\neval_res.score              # Float: fitness score (higher = better)\neval_res.error_message      # String: error if invalid\neval_res.metadata           # Dict: additional evaluation info\n\n# Example: print solution details\nfor i, sol in enumerate(all_solutions[:5]):\n    print(f\"\\nSolution {i+1}:\")\n    print(f\"  Valid: {sol.evaluation_res.valid}\")\n    print(f\"  Score: {sol.evaluation_res.score:.4f}\")\n    if not sol.evaluation_res.valid:\n        print(f\"  Error: {sol.evaluation_res.error_message}\")\n</code></pre>"},{"location":"tutorials/advanced/internals/#plotting-evolution-progress","title":"Plotting Evolution Progress","text":""},{"location":"tutorials/advanced/internals/#score-over-time","title":"Score Over Time","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Get valid scores in order\nscores = [\n    sol.evaluation_res.score\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nplt.figure(figsize=(10, 6))\nplt.plot(scores, marker='o', alpha=0.6, linewidth=1, markersize=4)\nplt.xlabel('Solution Index', fontsize=12)\nplt.ylabel('Score (Higher = Better)', fontsize=12)\nplt.title('Evolution Progress', fontsize=14)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('./results/evolution_progress.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"tutorials/advanced/internals/#best-score-by-generation","title":"Best Score by Generation","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Group solutions by generation\ngenerations = {}\nfor sol in all_solutions:\n    if sol.evaluation_res.valid:\n        gen = sol.other_info.get('generation', 0)\n        if gen not in generations:\n            generations[gen] = []\n        generations[gen].append(sol.evaluation_res.score)\n\n# Get best score per generation\ngen_numbers = sorted(generations.keys())\nbest_scores = [max(generations[gen]) for gen in gen_numbers]\navg_scores = [np.mean(generations[gen]) for gen in gen_numbers]\n\nplt.figure(figsize=(10, 6))\nplt.plot(gen_numbers, best_scores, 'g-o', label='Best Score', linewidth=2)\nplt.plot(gen_numbers, avg_scores, 'b--s', label='Average Score', linewidth=2)\nplt.xlabel('Generation', fontsize=12)\nplt.ylabel('Score', fontsize=12)\nplt.title('Score by Generation', fontsize=14)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('./results/score_by_generation.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"tutorials/advanced/internals/#success-rate-analysis","title":"Success Rate Analysis","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Calculate success rate by generation\nsuccess_rates = []\nfor gen in gen_numbers:\n    total = len([s for s in all_solutions if s.other_info.get('generation') == gen])\n    valid = len(generations.get(gen, []))\n    success_rates.append(valid / total * 100 if total &gt; 0 else 0)\n\nplt.figure(figsize=(10, 6))\nplt.bar(gen_numbers, success_rates, alpha=0.7, color='steelblue')\nplt.xlabel('Generation', fontsize=12)\nplt.ylabel('Success Rate (%)', fontsize=12)\nplt.title('Solution Validity by Generation', fontsize=14)\nplt.ylim(0, 100)\nplt.grid(True, alpha=0.3, axis='y')\nplt.tight_layout()\nplt.savefig('./results/success_rate.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"tutorials/advanced/internals/#analyzing-solution-diversity","title":"Analyzing Solution Diversity","text":""},{"location":"tutorials/advanced/internals/#code-length-distribution","title":"Code Length Distribution","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Get code lengths\ncode_lengths = [\n    len(sol.sol_string)\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nplt.figure(figsize=(10, 6))\nplt.hist(code_lengths, bins=20, alpha=0.7, color='coral', edgecolor='black')\nplt.xlabel('Code Length (characters)', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\nplt.title('Solution Code Length Distribution', fontsize=14)\nplt.grid(True, alpha=0.3, axis='y')\nplt.tight_layout()\nplt.savefig('./results/code_length_dist.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"tutorials/advanced/internals/#score-distribution","title":"Score Distribution","text":"<pre><code>import matplotlib.pyplot as plt\n\nscores = [\n    sol.evaluation_res.score\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nplt.figure(figsize=(10, 6))\nplt.hist(scores, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.xlabel('Score', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\nplt.title('Score Distribution', fontsize=14)\nplt.axvline(max(scores), color='r', linestyle='--', linewidth=2, label=f'Best: {max(scores):.4f}')\nplt.axvline(np.mean(scores), color='b', linestyle='--', linewidth=2, label=f'Mean: {np.mean(scores):.4f}')\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3, axis='y')\nplt.tight_layout()\nplt.savefig('./results/score_distribution.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"tutorials/advanced/internals/#extracting-metrics","title":"Extracting Metrics","text":""},{"location":"tutorials/advanced/internals/#comprehensive-statistics","title":"Comprehensive Statistics","text":"<pre><code>import numpy as np\n\ndef compute_statistics(all_solutions):\n    \"\"\"Compute comprehensive evolution statistics\"\"\"\n\n    valid_solutions = [s for s in all_solutions if s.evaluation_res.valid]\n    scores = [s.evaluation_res.score for s in valid_solutions]\n\n    stats = {\n        'total_solutions': len(all_solutions),\n        'valid_solutions': len(valid_solutions),\n        'success_rate': len(valid_solutions) / len(all_solutions) * 100,\n        'best_score': max(scores) if scores else None,\n        'worst_score': min(scores) if scores else None,\n        'mean_score': np.mean(scores) if scores else None,\n        'median_score': np.median(scores) if scores else None,\n        'std_score': np.std(scores) if scores else None,\n        'score_range': max(scores) - min(scores) if scores else None,\n    }\n\n    return stats\n\nstats = compute_statistics(all_solutions)\n\nprint(\"Evolution Statistics:\")\nprint(f\"  Total solutions: {stats['total_solutions']}\")\nprint(f\"  Valid solutions: {stats['valid_solutions']}\")\nprint(f\"  Success rate: {stats['success_rate']:.1f}%\")\nprint(f\"\\nScore Statistics:\")\nprint(f\"  Best: {stats['best_score']:.4f}\")\nprint(f\"  Worst: {stats['worst_score']:.4f}\")\nprint(f\"  Mean: {stats['mean_score']:.4f}\")\nprint(f\"  Median: {stats['median_score']:.4f}\")\nprint(f\"  Std Dev: {stats['std_score']:.4f}\")\nprint(f\"  Range: {stats['score_range']:.4f}\")\n</code></pre>"},{"location":"tutorials/advanced/internals/#export-to-dataframe","title":"Export to DataFrame","text":"<pre><code>import pandas as pd\n\n# Convert solutions to DataFrame for analysis\ndata = []\nfor i, sol in enumerate(all_solutions):\n    data.append({\n        'index': i,\n        'valid': sol.evaluation_res.valid,\n        'score': sol.evaluation_res.score if sol.evaluation_res.valid else None,\n        'generation': sol.other_info.get('generation', -1),\n        'code_length': len(sol.sol_string),\n        'error': sol.evaluation_res.error_message if not sol.evaluation_res.valid else None\n    })\n\ndf = pd.DataFrame(data)\n\n# Save to CSV\ndf.to_csv('./results/evolution_data.csv', index=False)\n\n# Quick analysis\nprint(df.describe())\nprint(\"\\nScore by generation:\")\nprint(df.groupby('generation')['score'].agg(['mean', 'max', 'count']))\n</code></pre>"},{"location":"tutorials/advanced/internals/#next-steps","title":"Next Steps","text":"<ul> <li>Learn Debugging &amp; Profiling to troubleshoot issues</li> <li>Review Low-Level API for more control options</li> <li>Check Configuration for parameter tuning</li> </ul>"},{"location":"tutorials/advanced/internals/#resources","title":"Resources","text":"<ul> <li>Matplotlib Documentation - Plotting library</li> <li>Pandas Documentation - Data analysis</li> <li>NumPy Documentation - Numerical computing</li> </ul>"},{"location":"tutorials/advanced/low-level-api/","title":"Low-Level API","text":"<p>Learn when and how to use the low-level API for maximum control over evolutionary optimization.</p>"},{"location":"tutorials/advanced/low-level-api/#high-level-vs-low-level-api","title":"High-Level vs Low-Level API","text":""},{"location":"tutorials/advanced/low-level-api/#high-level-api-recommended-for-most-users","title":"High-Level API (Recommended for Most Users)","text":"<pre><code>import evotoolkit\n\n# Simple and concise\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre> <p>Pros: - Simple and concise - Automatic configuration - Best practices built-in - Less code to maintain</p> <p>Cons: - Less control over internals - Limited customization - Fixed workflow structure</p> <p>Best For: - Most optimization tasks - Rapid prototyping - Standard workflows - Getting started quickly</p>"},{"location":"tutorials/advanced/low-level-api/#low-level-api-advanced-users","title":"Low-Level API (Advanced Users)","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\n# Full control over configuration\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=8,\n    max_sample_nums=12,\n    num_samplers=4,  # Number of parallel samplers\n    num_evaluators=4,  # Number of parallel evaluators\n    verbose=True\n)\n\n# Create and run algorithm\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# Access internal state\nbest_solution = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\nall_solutions = algorithm.run_state_dict.sol_history\n</code></pre> <p>Pros: - Full control over parameters - Access to internal state - Custom workflow integration - Advanced debugging capabilities</p> <p>Cons: - More complex code - Requires algorithm knowledge - More maintenance burden - Easy to misconfigure</p> <p>Best For: - Research and experimentation - Custom workflow integration - Performance optimization - Algorithm development</p>"},{"location":"tutorials/advanced/low-level-api/#using-different-algorithms","title":"Using Different Algorithms","text":""},{"location":"tutorials/advanced/low-level-api/#evoengineer","title":"EvoEngineer","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=8,\n    max_sample_nums=12,\n    num_samplers=4,\n    num_evaluators=4,\n    verbose=True\n)\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n</code></pre>"},{"location":"tutorials/advanced/low-level-api/#funsearch","title":"FunSearch","text":"<pre><code>from evotoolkit.evo_method.funsearch import FunSearch, FunSearchConfig\n\nconfig = FunSearchConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_sample_nums=30,\n    programs_per_prompt=2,\n    num_islands=4,\n    max_population_size=1000,\n    num_samplers=5,\n    num_evaluators=5,\n    verbose=True\n)\n\nalgorithm = FunSearch(config)\nalgorithm.run()\n</code></pre> <p>Note: FunSearch does not use <code>max_generations</code>. It evolves continuously based on the island model.</p>"},{"location":"tutorials/advanced/low-level-api/#eoh-evolution-of-heuristics","title":"EoH (Evolution of Heuristics)","text":"<pre><code>from evotoolkit.evo_method.eoh import EoH, EoHConfig\n\nconfig = EoHConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20,\n    selection_num=2,\n    use_e2_operator=True,  # Crossover\n    use_m1_operator=True,  # Mutation 1\n    use_m2_operator=True,  # Mutation 2\n    num_samplers=5,\n    num_evaluators=5,\n    verbose=True\n)\n\nalgorithm = EoH(config)\nalgorithm.run()\n</code></pre>"},{"location":"tutorials/advanced/low-level-api/#accessing-results","title":"Accessing Results","text":""},{"location":"tutorials/advanced/low-level-api/#get-best-solution","title":"Get Best Solution","text":"<pre><code>algorithm.run()\n\n# Method 1: Using built-in helper\nbest_solution = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n\n# Method 2: Manual search\nall_solutions = algorithm.run_state_dict.sol_history\nvalid_solutions = [s for s in all_solutions if s.evaluation_res.valid]\nbest_solution = max(valid_solutions, key=lambda s: s.evaluation_res.score)\n\nprint(f\"Best score: {best_solution.evaluation_res.score}\")\nprint(f\"Best code:\\n{best_solution.sol_string}\")\n</code></pre>"},{"location":"tutorials/advanced/low-level-api/#access-evolution-history","title":"Access Evolution History","text":"<pre><code># Get run state\nrun_state = algorithm.run_state_dict\n\n# All solutions ever generated\nall_solutions = run_state.sol_history\n\n# Current population\ncurrent_population = run_state.population\n\n# Score progression\nscores = [\n    sol.evaluation_res.score\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nprint(f\"Total solutions: {len(all_solutions)}\")\nprint(f\"Valid solutions: {len(scores)}\")\nprint(f\"Best score: {max(scores)}\")\nprint(f\"Average score: {sum(scores) / len(scores)}\")\n</code></pre>"},{"location":"tutorials/advanced/low-level-api/#custom-workflow-integration","title":"Custom Workflow Integration","text":""},{"location":"tutorials/advanced/low-level-api/#checkpoint-and-resume","title":"Checkpoint and Resume","text":"<pre><code>import pickle\n\n# Run for a few generations\nalgorithm = EvoEngineer(config)\nfor gen in range(5):\n    algorithm.run_one_generation()\n\n    # Save checkpoint\n    with open(f'checkpoint_gen{gen}.pkl', 'wb') as f:\n        pickle.dump(algorithm.run_state_dict, f)\n\n# Later: resume from checkpoint\nwith open('checkpoint_gen4.pkl', 'rb') as f:\n    saved_state = pickle.load(f)\n\nalgorithm.run_state_dict = saved_state\nalgorithm.run()  # Continue from where we left off\n</code></pre>"},{"location":"tutorials/advanced/low-level-api/#custom-stopping-criteria","title":"Custom Stopping Criteria","text":"<pre><code>class CustomEvoEngineer(EvoEngineer):\n    def should_stop(self):\n        # Stop if we found a solution with score &gt; 0.95\n        best = self._get_best_sol(self.run_state_dict.sol_history)\n        if best and best.evaluation_res.score &gt; 0.95:\n            print(\"Found excellent solution! Stopping early.\")\n            return True\n\n        # Otherwise use default stopping criteria\n        return super().should_stop()\n\nalgorithm = CustomEvoEngineer(config)\nalgorithm.run()\n</code></pre>"},{"location":"tutorials/advanced/low-level-api/#hybrid-algorithms","title":"Hybrid Algorithms","text":"<pre><code># Start with EvoEngineer for exploration\nconfig1 = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results/phase1',\n    running_llm=llm_api,\n    max_generations=5,\n    pop_size=10\n)\n\nalgo1 = EvoEngineer(config1)\nalgo1.run()\n\n# Get best solutions from phase 1\nbest_from_phase1 = sorted(\n    algo1.run_state_dict.sol_history,\n    key=lambda s: s.evaluation_res.score if s.evaluation_res.valid else float('-inf'),\n    reverse=True\n)[:3]\n\n# Refine with FunSearch\nconfig2 = FunSearchConfig(\n    interface=interface,\n    output_path='./results/phase2',\n    running_llm=llm_api,\n    max_sample_nums=50\n)\n\nalgo2 = FunSearch(config2)\n# Initialize with solutions from phase 1\nalgo2.run_state_dict.population = best_from_phase1\nalgo2.run()\n</code></pre>"},{"location":"tutorials/advanced/low-level-api/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Algorithm Configuration for detailed parameter tuning</li> <li>Explore Algorithm Internals to analyze evolution behavior</li> <li>Check Debugging &amp; Profiling for troubleshooting tips</li> </ul>"},{"location":"tutorials/advanced/low-level-api/#resources","title":"Resources","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Architecture Guide - Understanding internals</li> </ul>"},{"location":"tutorials/built-in/adversarial-attack/","title":"Adversarial Attack Tutorial","text":"<p>Learn how to use LLM-driven evolution to discover effective adversarial attack algorithms.</p> <p>Academic Citation</p> <p>The adversarial attack task is based on L-AutoDA research. If you use this feature in academic work, please cite:</p> <pre><code>@inproceedings{10.1145/3638530.3664121,\n    author = {Guo, Ping and Liu, Fei and Lin, Xi and Zhao, Qingchuan and Zhang, Qingfu},\n    title = {L-AutoDA: Large Language Models for Automatically Evolving Decision-based Adversarial Attacks},\n    year = {2024},\n    isbn = {9798400704956},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3638530.3664121},\n    doi = {10.1145/3638530.3664121},\n    pages = {1846\u20131854},\n    numpages = {9},\n    keywords = {large language models, adversarial attacks, automated algorithm design, evolutionary algorithms},\n    location = {Melbourne, VIC, Australia},\n    series = {GECCO '24 Companion}\n}\n</code></pre> <p>Complete Example Code</p> <p>This tutorial provides complete, runnable examples (click to view/download):</p> <ul> <li> basic_example.py - Basic usage example</li> <li> README.md - Examples documentation and usage guide</li> </ul> <p>Run locally: <pre><code>cd examples/adversarial_attack\npython basic_example.py\n</code></pre></p>"},{"location":"tutorials/built-in/adversarial-attack/#overview","title":"Overview","text":"<p>This tutorial demonstrates:</p> <ul> <li>Creating adversarial attack tasks</li> <li>Using LLM-driven evolution to discover attack algorithms</li> <li>Understanding the <code>draw_proposals</code> function</li> <li>Evaluating attacks on neural networks</li> <li>Evolving effective black-box attacks automatically</li> </ul>"},{"location":"tutorials/built-in/adversarial-attack/#installation","title":"Installation","text":"<p>GPU Recommended</p> <p>For best performance, install PyTorch with CUDA support before EvoToolkit. We recommend CUDA 12.9 (latest stable).</p>"},{"location":"tutorials/built-in/adversarial-attack/#step-1-install-pytorch-with-gpu-support","title":"Step 1: Install PyTorch with GPU Support","text":"<pre><code># CUDA 12.9 (recommended)\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n\n# For other versions, visit: https://pytorch.org/get-started/locally/\n# CUDA 12.1\n# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n\n# CPU only (not recommended, slower performance)\n# pip install torch torchvision\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#step-2-install-evotoolkit","title":"Step 2: Install EvoToolkit","text":"<pre><code>pip install evotoolkit[adversarial_attack]\n</code></pre> <p>This installs:</p> <ul> <li><code>timm</code> - PyTorch Image Models (provides CIFAR-10 pretrained models from Hugging Face)</li> <li><code>foolbox</code> - Adversarial attacks library</li> </ul> <p>Prerequisites:</p> <ul> <li>Python &gt;= 3.11</li> <li>PyTorch &gt;= 2.0 (with CUDA support recommended)</li> <li>LLM API access (OpenAI, Claude, or other compatible providers)</li> <li>Basic understanding of adversarial machine learning</li> </ul>"},{"location":"tutorials/built-in/adversarial-attack/#understanding-adversarial-attack-tasks","title":"Understanding Adversarial Attack Tasks","text":""},{"location":"tutorials/built-in/adversarial-attack/#what-is-an-adversarial-attack-task","title":"What is an Adversarial Attack Task?","text":"<p>An adversarial attack task evolves proposal generation algorithms to create adversarial examples that fool neural networks with minimal distortion.</p> Aspect Scientific Regression Adversarial Attack Solution type Mathematical equation Proposal algorithm Function name <code>equation</code> <code>draw_proposals</code> Inputs Data + params Images + noise + hyperparams Evaluation MSE on predictions L2 distance of adversarials Goal Minimize prediction error Minimize distortion"},{"location":"tutorials/built-in/adversarial-attack/#task-components","title":"Task Components","text":"<p>An adversarial attack task requires:</p> <ul> <li>Target model: Neural network to attack</li> <li>Test data: Images to generate adversarial examples for</li> <li>Attack budget: Number of iterations/queries</li> <li>Evaluation metric: L2 distance between original and adversarial images</li> </ul>"},{"location":"tutorials/built-in/adversarial-attack/#creating-your-first-adversarial-attack-task","title":"Creating Your First Adversarial Attack Task","text":""},{"location":"tutorials/built-in/adversarial-attack/#step-1-load-target-model-and-data","title":"Step 1: Load Target Model and Data","text":"<pre><code>import torch\nimport torch.nn as nn\nimport timm\nfrom torchvision import datasets, transforms\n\n# Load CIFAR-10 pretrained ResNet18 model (from Hugging Face Hub)\n# This model achieves 94.98% accuracy on CIFAR-10\n# CIFAR-10 ResNet18 uses modified architecture (3x3 conv1, removed maxpool)\nbase_model = timm.create_model(\"resnet18\", num_classes=10, pretrained=False)\nbase_model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nbase_model.maxpool = nn.Identity()\n\n# Load pretrained weights\nbase_model.load_state_dict(\n    torch.hub.load_state_dict_from_url(\n        \"https://huggingface.co/edadaltocg/resnet18_cifar10/resolve/main/pytorch_model.bin\",\n        map_location=\"cpu\",\n        file_name=\"resnet18_cifar10.pth\"\n    )\n)\nbase_model.eval()\n\n# Create model wrapper with normalization\n# Important: Foolbox expects inputs in [0, 1], so normalization must be inside the model\nclass NormalizedModel(nn.Module):\n    def __init__(self, model, mean, std):\n        super().__init__()\n        self.model = model\n        self.register_buffer('mean', torch.tensor(mean).view(1, 3, 1, 1))\n        self.register_buffer('std', torch.tensor(std).view(1, 3, 1, 1))\n\n    def forward(self, x):\n        # x is in [0, 1], normalize it\n        x_normalized = (x - self.mean) / self.std\n        return self.model(x_normalized)\n\nmodel = NormalizedModel(base_model,\n                        mean=[0.4914, 0.4822, 0.4465],\n                        std=[0.2471, 0.2435, 0.2616])\nmodel.eval()\n\nif torch.cuda.is_available():\n    model.cuda()\n\n# Load CIFAR-10 test set (only ToTensor, no Normalize in transform)\ntransform = transforms.Compose([\n    transforms.ToTensor(),  # Converts to [0, 1] range\n])\ntest_set = datasets.CIFAR10(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transform\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_set,\n    batch_size=32,\n    shuffle=False\n)\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#step-2-create-task-and-test-initial-solution","title":"Step 2: Create Task and Test Initial Solution","text":"<pre><code>from evotoolkit.task.python_task import AdversarialAttackTask\n\n# Create task\ntask = AdversarialAttackTask(\n    model=model,\n    test_loader=test_loader,\n    attack_steps=1000,\n    n_test_samples=10,\n    use_mock=False\n)\n\n# Get initial solution\ninit_sol = task.make_init_sol_wo_other_info()\n\nprint(f\"Initial algorithm:\")\nprint(init_sol.sol_string)\nprint(f\"\\nScore: {init_sol.evaluation_res.score:.2f}\")\nprint(f\"Avg L2 distance: {init_sol.evaluation_res.additional_info['avg_distance']:.2f}\")\n</code></pre> <p>Output: <pre><code>Initial algorithm:\nimport numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    \"\"\"Baseline proposal generation...\"\"\"\n    ...\n\nScore: -2.34\nAvg L2 distance: 2.34\n</code></pre></p>"},{"location":"tutorials/built-in/adversarial-attack/#step-3-test-custom-algorithm","title":"Step 3: Test Custom Algorithm","text":"<pre><code>custom_code = '''import numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    \"\"\"Simple algorithm: move toward original with noise.\"\"\"\n    org = org_img.flatten()\n    best = best_adv_img.flatten()\n    noise = std_normal_noise.flatten()\n\n    # Move toward original with random perturbation\n    direction = org - best\n    step = hyperparams[0] * 0.1\n    candidate = best + step * direction + step * noise * 0.5\n\n    return candidate.reshape(org_img.shape)\n'''\n\nresult = task.evaluate_code(custom_code)\nprint(f\"Score: {result.score:.2f}\")\nprint(f\"Avg L2 distance: {result.additional_info['avg_distance']:.2f}\")\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#understanding-the-draw_proposals-function","title":"Understanding the draw_proposals Function","text":""},{"location":"tutorials/built-in/adversarial-attack/#function-signature","title":"Function Signature","text":"<p>The evolved function must have this exact signature:</p> <pre><code>def draw_proposals(\n    org_img: np.ndarray,         # Original clean image\n    best_adv_img: np.ndarray,    # Current best adversarial\n    std_normal_noise: np.ndarray,# Random noise for exploration\n    hyperparams: np.ndarray      # Adaptive step size\n) -&gt; np.ndarray:                 # New candidate adversarial\n    \"\"\"Generate new candidate adversarial example.\"\"\"\n    ...\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#input-details","title":"Input Details","text":"<p>org_img (Original Image): - Shape: <code>(3, H, W)</code> for RGB images (e.g., <code>(3, 32, 32)</code> for CIFAR-10) - Values: <code>[0, 1]</code> normalized pixel values - Purpose: The clean image we're attacking</p> <p>best_adv_img (Best Adversarial): - Shape: <code>(3, H, W)</code> - same as org_img - Values: <code>[0, 1]</code> - Purpose: Current best adversarial example (fools the model, closest to original)</p> <p>std_normal_noise (Random Noise): - Shape: <code>(3, H, W)</code> - same as org_img - Values: Sampled from standard normal distribution N(0, 1) - Purpose: Provides randomness for exploration</p> <p>hyperparams (Adaptive Parameters): - Shape: <code>(1,)</code> - single scalar value - Values: Typically in range <code>[0.5, 1.5]</code> - Purpose: Adaptive step size that increases when finding adversarials</p>"},{"location":"tutorials/built-in/adversarial-attack/#return-value","title":"Return Value","text":"<p>Must return a numpy array with: - Shape: <code>(3, H, W)</code> - same as org_img - Values: Any (will be clipped to <code>[0, 1]</code> automatically) - Purpose: New candidate adversarial example</p>"},{"location":"tutorials/built-in/adversarial-attack/#algorithm-design-principles","title":"Algorithm Design Principles","text":"<p>1. Exploitation (Refinement)</p> <p>Move along the direction from org_img toward decision boundary:</p> <pre><code>direction = org_img - best_adv_img\ncandidate = best_adv_img + step_size * direction\n</code></pre> <p>2. Exploration (Discovery)</p> <p>Add random noise to discover new regions:</p> <pre><code>candidate = best_adv_img + noise_component\n</code></pre> <p>3. Adaptive Step Size</p> <p>Use hyperparams to balance exploration/exploitation:</p> <pre><code># hyperparams increases when finding adversarials\nstep = hyperparams[0] * base_step_size\n</code></pre> <p>4. Complete Example</p> <pre><code>import numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    \"\"\"Combine parallel and perpendicular components.\"\"\"\n    # Flatten to vectors\n    org = org_img.flatten()\n    best = best_adv_img.flatten()\n    noise = std_normal_noise.flatten()\n\n    # Compute direction\n    direction = org - best\n    direction_norm = np.linalg.norm(direction)\n\n    # Parallel component (toward original)\n    noise_norm = np.linalg.norm(noise)\n    step_size = (noise_norm * hyperparams[0]) ** 2\n    d_parallel = step_size * direction\n\n    # Perpendicular component (exploration)\n    if direction_norm &gt; 1e-8:\n        dot_product = np.dot(direction, noise)\n        projection = (dot_product / direction_norm) * direction\n        d_perpendicular = (projection / direction_norm - direction_norm * noise) * hyperparams[0]\n    else:\n        d_perpendicular = noise * hyperparams[0]\n\n    # Combine\n    candidate = best + d_parallel + d_perpendicular\n\n    return candidate.reshape(org_img.shape)\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#running-evolution-to-discover-attacks","title":"Running Evolution to Discover Attacks","text":""},{"location":"tutorials/built-in/adversarial-attack/#step-1-create-interface","title":"Step 1: Create Interface","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools.llm import HttpsApi\n\n# Create interface\ninterface = EvoEngineerPythonInterface(task)\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#step-2-configure-llm","title":"Step 2: Configure LLM","text":"<pre><code>llm_api = HttpsApi(\n    api_url=\"api.openai.com\",  # Your API URL\n    key=\"your-api-key-here\",   # Your API key\n    model=\"gpt-4o\"\n)\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#step-3-run-evolution","title":"Step 3: Run Evolution","text":"<pre><code>result = evotoolkit.solve(\n    interface=interface,\n    output_path='./attack_results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20\n)\n\nprint(f\"Best algorithm found:\")\nprint(result.sol_string)\nprint(f\"\\nAvg L2 distance: {-result.evaluation_res.score:.2f}\")\n</code></pre> <p>Try Different Algorithms</p> <p>EvoToolkit supports multiple evolutionary algorithms for adversarial attacks:</p> <pre><code># Using EoH\nfrom evotoolkit.task.python_task import EoHPythonInterface\ninterface = EoHPythonInterface(task)\n\n# Using FunSearch\nfrom evotoolkit.task.python_task import FunSearchPythonInterface\ninterface = FunSearchPythonInterface(task)\n\n# Using EvoEngineer (default)\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\ninterface = EvoEngineerPythonInterface(task)\n</code></pre> <p>Then use the same <code>evotoolkit.solve()</code> call to run evolution. Different interfaces may discover different attack strategies.</p>"},{"location":"tutorials/built-in/adversarial-attack/#attack-evolution-example","title":"Attack Evolution Example","text":"<p>During evolution, the LLM discovers increasingly effective algorithms:</p> <p>Generation 1: Simple baseline <pre><code>def draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    return best_adv_img + 0.01 * std_normal_noise\n# Avg L2: 3.5\n</code></pre></p> <p>Generation 3: Direction-based <pre><code>def draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    direction = org_img - best_adv_img\n    return best_adv_img + hyperparams[0] * 0.1 * direction\n# Avg L2: 2.1\n</code></pre></p> <p>Generation 7: Sophisticated combination <pre><code>def draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    # Complex algorithm combining multiple components\n    ...\n# Avg L2: 0.8\n</code></pre></p>"},{"location":"tutorials/built-in/adversarial-attack/#customizing-evolution-behavior","title":"Customizing Evolution Behavior","text":"<p>The quality of evolved attacks is controlled by the evolution method and its internal prompt design. To improve results:</p> <ul> <li>Adjust prompts: Inherit existing Interface classes and customize LLM prompts</li> <li>Develop new algorithms: Create entirely new evolutionary strategies</li> </ul> <p>Learn More</p> <p>These are general techniques applicable to all tasks. For detailed tutorials, see:</p> <ul> <li>Customizing Evolution Methods - How to modify prompts and develop new algorithms</li> <li>Advanced Usage - More advanced configuration options</li> </ul> <p>Quick Example - Custom Prompts for Adversarial Attacks:</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\n\nclass EvoEngineerCustomAttackInterface(EvoEngineerPythonInterface):\n    \"\"\"Interface optimized for adversarial attack evolution.\"\"\"\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        \"\"\"Customize mutation prompt to emphasize attack effectiveness.\"\"\"\n\n        if operator_name == \"mutation\":\n            task_description = self.task.get_base_task_description()\n            individual = selected_individuals[0]\n\n            prompt = f\"\"\"# Adversarial Attack Algorithm Evolution\n\n{task_description}\n\n## Current Best Algorithm\n**Avg L2 Distance:** {-current_best_sol.evaluation_res.score:.2f}\n**Algorithm:** {current_best_sol.sol_string}\n\n## Algorithm to Mutate\n**Avg L2 Distance:** {-individual.evaluation_res.score:.2f}\n**Algorithm:** {individual.sol_string}\n\n## Optimization Guidelines\nFocus on improving the algorithm by:\n- Better balancing exploitation (refinement) and exploration (discovery)\n- More effective use of the adaptive hyperparams\n- Clever combination of direction vectors and noise\n- Numerical stability and efficiency\n\nGenerate an improved draw_proposals function that achieves lower L2 distances.\n\n## Response Format:\nname: [descriptive_name]\ncode:\n[Your improved draw_proposals function]\nthought: [reasoning for changes]\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # Use default for other operators\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# Use custom interface\ninterface = EvoEngineerCustomAttackInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./custom_results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#understanding-evaluation","title":"Understanding Evaluation","text":""},{"location":"tutorials/built-in/adversarial-attack/#scoring-mechanism","title":"Scoring Mechanism","text":"<ol> <li>Attack Execution: Run evolved algorithm on test samples</li> <li>Adversarial Generation: Create adversarial examples using draw_proposals</li> <li>Distance Measurement: Compute L2 distance from original images</li> <li>Fitness Calculation: Score = -(average L2 distance)</li> </ol> <p>Lower L2 distance = better attack = higher score (less negative)</p>"},{"location":"tutorials/built-in/adversarial-attack/#evaluation-output","title":"Evaluation Output","text":"<pre><code>result = task.evaluate_code(algorithm_code)\n\nif result.valid:\n    print(f\"Score: {result.score:.2f}\")  # Negative L2 distance\n    print(f\"Avg L2: {result.additional_info['avg_distance']:.2f}\")\n    print(f\"Attack steps: {result.additional_info['attack_steps']}\")\nelse:\n    print(f\"Error: {result.additional_info['error']}\")\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#use-cases-and-applications","title":"Use Cases and Applications","text":""},{"location":"tutorials/built-in/adversarial-attack/#1-black-box-attack-discovery","title":"1. Black-Box Attack Discovery","text":"<p>Evolve algorithms for black-box scenarios where gradients are unavailable:</p> <pre><code>task = AdversarialAttackTask(\n    model=black_box_model,\n    test_loader=test_loader,\n    attack_steps=5000,  # More iterations for black-box\n    n_test_samples=50\n)\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#2-robustness-evaluation","title":"2. Robustness Evaluation","text":"<p>Test model defenses by evolving strong attacks:</p> <pre><code># Load more robust model (e.g., adversarially trained)\n# Note: You need to train or obtain robust models yourself\nfrom torchvision import models\nmodel = models.resnet50(pretrained=True)  # Or your robust model\nmodel.eval()\n\ntask = AdversarialAttackTask(\n    model=model,\n    test_loader=test_loader,\n    attack_steps=10000,  # Thorough evaluation\n    n_test_samples=100\n)\n</code></pre> <p>About Robust Models</p> <p>EvoToolkit no longer depends on robustbench library. If you need to test robust models:</p> <ul> <li>Use your own adversarially trained models</li> <li>Load pretrained robust models from other sources</li> <li>Or use standard models for basic testing</li> </ul>"},{"location":"tutorials/built-in/adversarial-attack/#3-transfer-attack-development","title":"3. Transfer Attack Development","text":"<p>Evolve attacks that transfer across models:</p> <pre><code># Train on surrogate model\nfrom torchvision import models\nsurrogate_model = models.resnet18(pretrained=True)\nsurrogate_model.eval()\n\ntask = AdversarialAttackTask(\n    model=surrogate_model,\n    test_loader=test_loader,\n    attack_steps=5000,\n    n_test_samples=50\n)\n\n# Evolve attack\nresult = evotoolkit.solve(interface, ...)\n\n# Test on target model\ntarget_model = models.resnet50(pretrained=True)  # Different architecture\ntarget_model.eval()\n# Evaluate evolved algorithm on target_model\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#4-query-efficient-attacks","title":"4. Query-Efficient Attacks","text":"<p>Optimize for minimal queries to the target model:</p> <pre><code>task = AdversarialAttackTask(\n    model=model,\n    test_loader=test_loader,\n    attack_steps=100,  # Limited queries\n    n_test_samples=20\n)\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#complete-example","title":"Complete Example","text":"<p>Here's a full working example:</p> <pre><code>import torch\nimport torch.nn as nn\nimport timm\nimport evotoolkit\nfrom torchvision import datasets, transforms\nfrom evotoolkit.task.python_task import (\n    AdversarialAttackTask,\n    EvoEngineerPythonInterface\n)\nfrom evotoolkit.tools.llm import HttpsApi\n\n# 1. Load CIFAR-10 pretrained ResNet18 model\nmodel = timm.create_model(\"resnet18\", num_classes=10, pretrained=False)\nmodel.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nmodel.maxpool = nn.Identity()\n\n# Load pretrained weights\nmodel.load_state_dict(\n    torch.hub.load_state_dict_from_url(\n        \"https://huggingface.co/edadaltocg/resnet18_cifar10/resolve/main/pytorch_model.bin\",\n        map_location=\"cpu\",\n        file_name=\"resnet18_cifar10.pth\"\n    )\n)\nmodel.eval()\n\nif torch.cuda.is_available():\n    model.cuda()\n\n# 2. Prepare test data\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n                        std=[0.2471, 0.2435, 0.2616])\n])\ntest_set = datasets.CIFAR10(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transform\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_set, batch_size=32, shuffle=False\n)\n\n# 3. Create task\ntask = AdversarialAttackTask(\n    model=model,\n    test_loader=test_loader,\n    attack_steps=1000,\n    n_test_samples=10,\n    use_mock=False\n)\n\n# 4. Create LLM API\nllm_api = HttpsApi(\n    api_url=\"api.openai.com\",  # Your API URL\n    key=\"your-api-key-here\",   # Your API key\n    model=\"gpt-4o\"\n)\n\n# 5. Create interface\ninterface = EvoEngineerPythonInterface(task)\n\n# 6. Run evolution\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./attack_results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20\n)\n\n# 7. Show results\nprint(f\"Best attack algorithm found:\")\nprint(result.sol_string)\nprint(f\"\\nAvg L2 distance: {-result.evaluation_res.score:.2f}\")\nprint(f\"Attack steps: {result.evaluation_res.additional_info['attack_steps']}\")\n</code></pre>"},{"location":"tutorials/built-in/adversarial-attack/#next-steps","title":"Next Steps","text":""},{"location":"tutorials/built-in/adversarial-attack/#explore-different-attack-scenarios","title":"Explore Different Attack Scenarios","text":"<ul> <li>Try different target models (standard vs robust)</li> <li>Experiment with different datasets (CIFAR-10, ImageNet)</li> <li>Compare different evolutionary algorithms</li> <li>Test evolved attacks on multiple models</li> </ul>"},{"location":"tutorials/built-in/adversarial-attack/#customize-and-improve-evolution","title":"Customize and Improve Evolution","text":"<ul> <li>Examine prompt designs in existing Interface classes</li> <li>Inherit and override Interfaces to customize prompts</li> <li>Design specialized prompts for different attack types</li> <li>Develop new evolutionary algorithms if needed</li> </ul>"},{"location":"tutorials/built-in/adversarial-attack/#learn-more","title":"Learn More","text":"<ul> <li>Customizing Evolution Methods - Deep dive into prompt customization</li> <li>Advanced Usage - Advanced configuration and techniques</li> <li>API Reference - Complete API documentation</li> <li>L-AutoDA Paper - GECCO 2024</li> </ul>"},{"location":"tutorials/built-in/adversarial-attack/#references","title":"References","text":"<ul> <li>L-AutoDA: Large Language Models for Automatically Evolving Decision-based Adversarial Attacks (GECCO 2024)</li> <li>Foolbox: A Python toolbox to create adversarial examples</li> <li>PyTorch Models: Pretrained computer vision models (https://pytorch.org/vision/stable/models.html)</li> </ul>"},{"location":"tutorials/built-in/cuda-task/","title":"CUDA Kernel Optimization Tutorial","text":"<p>Learn how to optimize CUDA kernels using LLM-driven evolution to reduce runtime while maintaining correctness.</p> <p>Academic Citation</p> <p>The CUDA kernel optimization task is based on EvoEngineer research. If you use this feature in academic work, please cite:</p> <pre><code>@misc{guo2025evoengineermasteringautomatedcuda,\n    title={EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models},\n    author={Ping Guo and Chenyu Zhu and Siyuan Chen and Fei Liu and Xi Lin and Zhichao Lu and Qingfu Zhang},\n    year={2025},\n    eprint={2510.03760},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG},\n    url={https://arxiv.org/abs/2510.03760}\n}\n</code></pre> <p>Complete Example Code</p> <p>This tutorial provides complete, runnable examples (click to view/download):</p> <ul> <li> basic_example.py - Basic usage</li> <li> dataset_example.py - Using predefined dataset</li> <li> custom_prompt.py - Custom prompt example</li> <li> compare_algorithms.py - Algorithm comparison</li> <li> README.md - Examples documentation and usage guide</li> </ul> <p>Run locally: <pre><code>cd examples/cuda_task\npython basic_example.py\n# or use predefined dataset\npython dataset_example.py\n</code></pre></p>"},{"location":"tutorials/built-in/cuda-task/#overview","title":"Overview","text":"<p>This tutorial demonstrates:</p> <ul> <li>Creating CUDA kernel optimization tasks</li> <li>Optimizing kernel runtime using LLM-driven evolution</li> <li>Automatically verifying kernel correctness</li> <li>Evolving high-performance GPU code</li> </ul>"},{"location":"tutorials/built-in/cuda-task/#installation","title":"Installation","text":"<p>GPU Recommended</p> <p>CUDA kernel optimization requires a GPU and PyTorch. Install PyTorch with CUDA support before EvoToolkit. We recommend CUDA 12.9 (latest stable).</p>"},{"location":"tutorials/built-in/cuda-task/#step-1-install-pytorch-with-gpu-support","title":"Step 1: Install PyTorch with GPU Support","text":"<pre><code># CUDA 12.9 (recommended - for custom tasks)\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n\n# For other versions, visit: https://pytorch.org/get-started/locally/\n# CUDA 12.1\n# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n\n# CPU only (not recommended for CUDA tasks)\n# pip install torch torchvision\n</code></pre> <p>About PyTorch Versions</p> <p>We recommend installing the latest CUDA 12.9 version for custom task development. However, please note:</p> <ul> <li>Predefined datasets: Our example datasets are built on CUDA 12.4 + PyTorch 2.4.0</li> <li>Version compatibility: Different PyTorch versions may generate different CUDA code. When using predefined datasets, consider installing matching PyTorch versions</li> <li>Custom tasks: If you're creating your own tasks, you can use any PyTorch version</li> </ul>"},{"location":"tutorials/built-in/cuda-task/#step-2-install-evotoolkit","title":"Step 2: Install EvoToolkit","text":"<pre><code>pip install evotoolkit[cuda_engineering]\n</code></pre> <p>This installs:</p> <ul> <li>Ninja (high-performance build system)</li> <li>Portalocker (cross-process file locking)</li> <li>Psutil (system and process utilities)</li> </ul>"},{"location":"tutorials/built-in/cuda-task/#step-3-install-c-compiler-required","title":"Step 3: Install C++ Compiler (Required)","text":"<p>Critical Prerequisite: C++ Compiler</p> <p>CUDA kernel compilation requires a C++ compiler! Without it, you'll encounter errors like: <pre><code>Error checking compiler version for cl: [WinError 2] The system cannot find the file specified.\n</code></pre></p>"},{"location":"tutorials/built-in/cuda-task/#windows-users","title":"Windows Users","text":"<p>You must install Visual Studio with MSVC compiler:</p> <ol> <li>Download Visual Studio</li> <li>Visit: https://visualstudio.microsoft.com/downloads/</li> <li> <p>Recommended: Visual Studio 2022 Community (free)</p> </li> <li> <p>Select Workload During Installation</p> </li> <li>Check \"Desktop development with C++\"</li> <li> <p>This installs MSVC compiler and necessary build tools</p> </li> <li> <p>CUDA Version &amp; MSVC Compatibility</p> </li> </ol> CUDA Version Supported Visual Studio Supported MSVC 12.9 VS 2022 (17.x)VS 2019 (16.x) MSVC 193xMSVC 192x 12.4 VS 2022 (17.x)VS 2019 (16.x) MSVC 193xMSVC 192x 12.1 VS 2022 (17.x)VS 2019 (16.x)VS 2017 (15.x) MSVC 193xMSVC 192xMSVC 191x <p>Important Notes</p> <ul> <li>Visual Studio 2017 deprecated in CUDA 12.5, completely removed in 12.9</li> <li>Only 64-bit compilation supported from CUDA 12.0 onwards (no 32-bit)</li> <li>Supports C++14 (default), C++17, and C++20</li> </ul> <ol> <li>Verify Compiler Installation <pre><code># Open \"x64 Native Tools Command Prompt for VS 2022\" (find it in Start menu)\ncl\n\n# Should see output like:\n# Microsoft (R) C/C++ Optimizing Compiler Version 19.39.xxxxx for x64\n</code></pre></li> </ol> <p>If <code>cl</code> command is not available in regular Command Prompt, use one of these solutions:</p> <p>Solution A: Use VS Developer Command Prompt (Recommended)    - Search for \"x64 Native Tools Command Prompt for VS 2022\" in Start menu    - Run your Python scripts in this prompt</p> <p>Solution B: Add to System PATH (Permanent) <pre><code># Add MSVC to system PATH environment variable (example path, adjust to your installation)\n# C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.39.xxxxx\\bin\\Hostx64\\x64\n</code></pre></p>"},{"location":"tutorials/built-in/cuda-task/#linuxubuntu-users","title":"Linux/Ubuntu Users","text":"<p>Install GCC/G++ compiler:</p> <pre><code># Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install build-essential\n\n# Verify installation\ngcc --version\ng++ --version\n\n# Recommended: GCC 9.x or higher\n</code></pre> <p>CUDA Version &amp; GCC Compatibility:</p> CUDA Version Supported GCC Versions 12.9 GCC 9.x - 13.x 12.4 GCC 9.x - 13.x 12.1 GCC 9.x - 12.x <p>Check CUDA &amp; Compiler Compatibility</p> <p>If you encounter compilation errors:</p> <ol> <li>Check CUDA version: <code>nvcc --version</code></li> <li>Check compiler version: <code>cl</code> on Windows, <code>gcc --version</code> on Linux</li> <li>Verify versions are within compatibility ranges above</li> </ol> <p>Prerequisites Summary:</p> <ul> <li>\u2705 NVIDIA GPU with CUDA support</li> <li>\u2705 CUDA toolkit installed (12.1+ recommended)</li> <li>\u2705 Compatible C++ compiler (Windows: MSVC, Linux: GCC)</li> <li>\u2705 PyTorch &gt;= 2.0 (with CUDA support)</li> <li>\u2705 Basic understanding of CUDA programming</li> <li>\u2705 Familiarity with kernel optimization concepts</li> </ul>"},{"location":"tutorials/built-in/cuda-task/#understanding-cuda-tasks","title":"Understanding CUDA Tasks","text":""},{"location":"tutorials/built-in/cuda-task/#what-is-a-cuda-task","title":"What is a CUDA Task?","text":"<p>A CUDA task optimizes GPU kernel code to minimize runtime while ensuring correctness. The framework:</p> <ol> <li>Takes your Python function implementation</li> <li>Converts it to functional Python code (if needed)</li> <li>Translates to initial CUDA kernel</li> <li>Evolves the kernel to improve performance</li> <li>Validates correctness against the Python reference</li> </ol>"},{"location":"tutorials/built-in/cuda-task/#task-components","title":"Task Components","text":"<p>A CUDA task requires:</p> <ul> <li>Original Python Code (<code>org_py_code</code>): Original PyTorch model code (optional, can be empty)</li> <li>Functional Python Code (<code>func_py_code</code>): Extracted functional implementation for correctness comparison and performance benchmarking</li> <li>CUDA Code (<code>cuda_code</code>): Initial CUDA kernel implementation</li> <li>GPU Info: GPU type and CUDA version</li> </ul> <p>About org_py_code and func_py_code</p> <ul> <li><code>func_py_code</code> must be provided - it's the actual Python reference used for CUDA correctness validation and performance comparison</li> <li>If you only have <code>org_py_code</code>, you can use the AI-CUDA-Engineer workflow (Stage 0) to convert it to <code>func_py_code</code> using LLM</li> <li><code>org_py_code</code> can be empty if you provide <code>func_py_code</code> directly (recommended for evolution optimization)</li> </ul> <p>Windows Users: Multiprocessing Protection Required</p> <p>CUDA task evaluator uses the multiprocessing module for timeout control. On Windows, you MUST protect all main code with <code>if __name__ == '__main__':</code> or it will cause infinite process recursion!</p> <p>Wrong example (causes RuntimeError): <pre><code># \u274c Wrong - no protection\nimport os\nfrom evotoolkit.task.cuda_engineering import CudaTask\n\nevaluator = Evaluator(temp_path)  # Will crash on Windows!\ntask_info = CudaTaskInfoMaker.make_task_info(...)\n</code></pre></p> <p>Correct example: <pre><code># \u2705 Correct - use if __name__ == '__main__': protection\nimport os\nfrom evotoolkit.task.cuda_engineering import CudaTask\n\ndef main():\n    evaluator = Evaluator(temp_path)\n    task_info = CudaTaskInfoMaker.make_task_info(...)\n    # ... other code\n\nif __name__ == '__main__':\n    main()\n</code></pre></p> <p>Why is this protection needed?</p> <ul> <li>Windows doesn't support <code>fork</code>, only <code>spawn</code> for starting subprocesses</li> <li><code>spawn</code> re-imports the main module to create subprocesses</li> <li>Without protection, every import re-executes main code, causing infinite recursion</li> </ul> <p>Rule: Any code that calls CUDA task evaluation MUST be inside <code>if __name__ == '__main__':</code> protection!</p>"},{"location":"tutorials/built-in/cuda-task/#using-predefined-datasets","title":"Using Predefined Datasets","text":"<p>EvoToolkit provides predefined CUDA optimization datasets containing various common deep learning operations.</p>"},{"location":"tutorials/built-in/cuda-task/#downloading-the-dataset","title":"Downloading the Dataset","text":"<p>The dataset is not included in the main repository and needs to be downloaded separately:</p> <p>Download methods:</p> <pre><code># Method 1: Using wget\ncd /path/to/evotool/project/root\nwget https://github.com/pgg3/evotoolkit/releases/download/data-v1.0.0/rtx4090_cu12_4_py311_torch_2_4_0.json\n\n# Method 2: Using curl\ncurl -L -O https://github.com/pgg3/evotoolkit/releases/download/data-v1.0.0/rtx4090_cu12_4_py311_torch_2_4_0.json\n</code></pre> <p>Dataset information:</p> <ul> <li>Filename: <code>rtx4090_cu12_4_py311_torch_2_4_0.json</code></li> <li>Size: ~580 KB</li> <li>Format: JSON</li> <li>Optimized for: RTX 4090 GPU + CUDA 12.4.1 + PyTorch 2.4.0</li> </ul> <p>Dataset Note</p> <p>This is a sample dataset for specific hardware/software configuration. Unlike scientific_regression tasks, it does not support automatic download. You can create similar datasets for your own hardware environment.</p>"},{"location":"tutorials/built-in/cuda-task/#loading-a-dataset","title":"Loading a Dataset","text":"<pre><code>import json\n\n# Load dataset for RTX 4090 + CUDA 12.4.1 + PyTorch 2.4.0\nwith open('rtx4090_cu12_4_py311_torch_2_4_0.json', 'r') as f:\n    dataset = json.load(f)\n\n# View available tasks\nprint(f\"Available tasks: {len(dataset)}\")\nprint(f\"Task list: {list(dataset.keys())[:5]}...\")  # Show first 5\n\n# Select a task\ntask_name = \"10_3D_tensor_matrix_multiplication\"\ntask_data = dataset[task_name]\n\nprint(f\"\\nTask: {task_name}\")\nprint(f\"- org_py_code: {'Provided' if task_data['org_py_code'] else 'Empty'}\")\nprint(f\"- func_py_code: {'Provided' if task_data['func_py_code'] else 'Empty'}\")\nprint(f\"- cuda_code: {'Provided' if task_data['cuda_code'] else 'Empty'}\")\n</code></pre> <p>Dataset includes task types:</p> <ul> <li>Matrix multiplication variants (3D, 4D tensors, diagonal, symmetric matrices, etc.)</li> <li>Activation functions (ReLU, Sigmoid, Tanh, GELU, etc.)</li> <li>Loss functions (CrossEntropy, HingeLoss, etc.)</li> <li>Normalization layers (LayerNorm, BatchNorm, etc.)</li> <li>Attention mechanisms and Transformer components</li> </ul>"},{"location":"tutorials/built-in/cuda-task/#creating-a-task-from-dataset","title":"Creating a Task from Dataset","text":"<pre><code>from evotoolkit.task.cuda_engineering import CudaTask, CudaTaskInfoMaker\nfrom evotoolkit.task.cuda_engineering.evaluator import Evaluator\nimport tempfile\nimport os\n\n\ndef main():\n    # Configure CUDA environment variables (must be set before running)\n    # Windows: Set to your CUDA installation path\n    os.environ[\"CUDA_HOME\"] = \"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.4\"\n    # Linux/Ubuntu: Usually the default path\n    # os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n\n    # Specify GPU architecture to save compilation time\n    # RTX 4090: 8.9, RTX 3090: 8.6, V100: 7.0\n    os.environ['TORCH_CUDA_ARCH_LIST'] = \"8.9\"\n\n    # Use task data from dataset\n    task_data = dataset[\"10_3D_tensor_matrix_multiplication\"]\n\n    # Create evaluator and task\n    temp_path = tempfile.mkdtemp()\n    evaluator = Evaluator(temp_path)\n\n    task_info = CudaTaskInfoMaker.make_task_info(\n        evaluator=evaluator,\n        gpu_type=\"RTX 4090\",\n        cuda_version=\"12.4.1\",\n        org_py_code=task_data[\"org_py_code\"],      # Can be empty\n        func_py_code=task_data[\"func_py_code\"],    # Functional implementation\n        cuda_code=task_data[\"cuda_code\"],          # Initial CUDA kernel\n        fake_mode=False\n    )\n\n    task = CudaTask(data=task_info, temp_path=temp_path, fake_mode=False)\n    print(f\"Task created, initial runtime: {task.task_info['cuda_info']['runtime']:.4f} ms\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"tutorials/built-in/cuda-task/#example-creating-matrix-multiplication-from-scratch","title":"Example: Creating Matrix Multiplication from Scratch","text":"<p>If you want to create your own CUDA optimization task from scratch:</p>"},{"location":"tutorials/built-in/cuda-task/#step-1-prepare-your-python-function","title":"Step 1: Prepare Your Python Function","text":"<p>func_py_code Format Requirements</p> <p><code>func_py_code</code> must contain the following components:</p> <ol> <li><code>module_fn</code> function: Core functionality implementation</li> <li><code>Model</code> class: Inherits from <code>nn.Module</code>, with <code>forward</code> method accepting <code>fn=module_fn</code> parameter</li> <li><code>get_inputs()</code> function: Generates test input data</li> <li><code>get_init_inputs()</code> function: Generates initialization inputs (usually empty list)</li> </ol> <p>This design allows CUDA kernels to replace <code>module_fn</code> by passing different <code>fn</code>, enabling correctness validation.</p> <pre><code># Original function to optimize (optional)\norg_py_code = '''\nimport torch\n\ndef matmul(A, B):\n    \"\"\"Matrix multiplication using PyTorch.\"\"\"\n    return torch.matmul(A, B)\n'''\n\n# Functional implementation (for correctness comparison and benchmarking)\nfunc_py_code = '''\nimport torch\nimport torch.nn as nn\n\ndef module_fn(A: torch.Tensor, B: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Functional matrix multiplication implementation.\"\"\"\n    return torch.matmul(A, B)\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, A, B, fn=module_fn):\n        return fn(A, B)\n\nM = 1024\nK = 2048\nN = 1024\n\ndef get_inputs():\n    A = torch.randn(M, K)\n    B = torch.randn(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []\n'''\n</code></pre>"},{"location":"tutorials/built-in/cuda-task/#step-2-create-initial-cuda-kernel","title":"Step 2: Create Initial CUDA Kernel","text":"<pre><code># Initial CUDA implementation (naive version)\ncuda_code = '''\n#include &lt;torch/extension.h&gt;\n#include &lt;cuda_runtime.h&gt;\n\n__global__ void matmul_kernel(float* A, float* B, float* C,\n                               int M, int N, int K) {\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (row &lt; M &amp;&amp; col &lt; N) {\n        float sum = 0.0f;\n        for (int k = 0; k &lt; K; k++) {\n            sum += A[row * K + k] * B[k * N + col];\n        }\n        C[row * N + col] = sum;\n    }\n}\n\ntorch::Tensor matmul_cuda(torch::Tensor A, torch::Tensor B) {\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n\n    auto C = torch::zeros({M, N}, A.options());\n\n    dim3 threads(16, 16);\n    dim3 blocks((N + 15) / 16, (M + 15) / 16);\n\n    matmul_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(\n        A.data_ptr&lt;float&gt;(),\n        B.data_ptr&lt;float&gt;(),\n        C.data_ptr&lt;float&gt;(),\n        M, N, K\n    );\n\n    return C;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &amp;matmul_cuda, \"Matrix multiplication (CUDA)\");\n}\n'''\n</code></pre>"},{"location":"tutorials/built-in/cuda-task/#step-3-create-cuda-task","title":"Step 3: Create CUDA Task","text":"<pre><code>from evotoolkit.task.cuda_engineering import CudaTask, CudaTaskInfoMaker\nfrom evotoolkit.task.cuda_engineering.evaluator import Evaluator\nimport tempfile\nimport os\n\n\ndef main():\n    # Configure CUDA environment variables (must be set before running)\n    # Windows: Set to your CUDA installation path\n    os.environ[\"CUDA_HOME\"] = \"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.4\"\n    # Linux/Ubuntu: Usually the default path\n    # os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n\n    # Specify GPU architecture to save compilation time\n    # RTX 4090: 8.9, RTX 3090: 8.6, V100: 7.0\n    os.environ['TORCH_CUDA_ARCH_LIST'] = \"8.9\"\n\n    # Create evaluator\n    temp_path = tempfile.mkdtemp()\n    evaluator = Evaluator(temp_path)\n\n    # Create task info\n    task_info = CudaTaskInfoMaker.make_task_info(\n        evaluator=evaluator,\n        gpu_type=\"RTX 4090\",\n        cuda_version=\"12.4.1\",\n        org_py_code=org_py_code,\n        func_py_code=func_py_code,\n        cuda_code=cuda_code,\n        fake_mode=False  # Set True for testing without GPU\n    )\n\n    # Create task\n    task = CudaTask(\n        data=task_info,\n        temp_path=temp_path,\n        fake_mode=False\n    )\n\n    print(f\"GPU Type: {task.task_info['gpu_type']}\")\n    print(f\"CUDA Version: {task.task_info['cuda_version']}\")\n    print(f\"Initial runtime: {task.task_info['cuda_info']['runtime']:.4f} ms\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>Output: <pre><code>GPU Type: RTX 4090\nCUDA Version: 12.4.1\nInitial runtime: 2.3456 ms\n</code></pre></p>"},{"location":"tutorials/built-in/cuda-task/#step-4-test-with-initial-solution","title":"Step 4: Test with Initial Solution","text":"<pre><code>def main():\n    # ... (previous Step 3 code)\n\n    # Get initial solution\n    init_sol = task.make_init_sol_wo_other_info()\n\n    print(\"Initial kernel info:\")\n    print(f\"Runtime: {-init_sol.evaluation_res.score:.4f} ms\")\n    print(f\"Score: {init_sol.evaluation_res.score:.6f}\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>Understanding Evaluation:</p> <ul> <li>Score: Negative runtime (higher is better, so faster kernels have higher scores)</li> <li>Runtime: Kernel execution time in milliseconds</li> <li>Correctness: Automatically verified against Python reference</li> <li>Profile String: CUDA profiler output showing bottlenecks</li> </ul>"},{"location":"tutorials/built-in/cuda-task/#step-5-run-evolution-with-evoengineer","title":"Step 5: Run Evolution with EvoEngineer","text":"<p>Complete Code Example</p> <p>The following code assumes you have completed the previous steps (Steps 1-4) and the <code>task</code> object has been created. For a complete runnable code example, please refer to basic_example.py.</p> <pre><code>import os\nimport evotoolkit\nfrom evotoolkit.task.cuda_engineering import EvoEngineerFullCudaInterface\nfrom evotoolkit.tools.llm import HttpsApi\n\n\ndef main():\n    # === Previous Steps (Steps 1-4) ===\n    # This should include code from previous steps:\n    # - Define org_py_code, func_py_code, cuda_code\n    # - Create evaluator and task_info\n    # - Create task object\n    # See basic_example.py for complete code\n\n    # Set CUDA environment variables (required for CUDA kernel compilation)\n    # CUDA_HOME: Path to CUDA installation directory\n    os.environ.setdefault(\"CUDA_HOME\", \"/usr/local/cuda\")\n    # TORCH_CUDA_ARCH_LIST: GPU compute capability (e.g., \"8.9\" for RTX 4090)\n    os.environ.setdefault(\"TORCH_CUDA_ARCH_LIST\", \"8.9\")\n\n    # Create interface (using the task object from previous steps)\n    interface = EvoEngineerFullCudaInterface(task)\n\n    # Configure LLM API\n    # Set LLM_API_URL and LLM_API_KEY environment variables\n    llm_api = HttpsApi(\n        api_url=os.environ.get(\"LLM_API_URL\", \"https://api.openai.com/v1/chat/completions\"),\n        key=os.environ.get(\"LLM_API_KEY\", \"your-api-key-here\"),\n        model=\"gpt-4o\"\n    )\n\n    # Run evolution\n    result = evotoolkit.solve(\n        interface=interface,\n        output_path='./cuda_optimization_results',\n        running_llm=llm_api,\n        max_generations=10,\n        pop_size=5,\n        max_sample_nums=20\n    )\n\n    print(f\"Best kernel found!\")\n    print(f\"Runtime: {-result.evaluation_res.score:.4f} ms\")\n    print(f\"Speedup: {task.task_info['cuda_info']['runtime'] / (-result.evaluation_res.score):.2f}x\")\n    print(f\"\\nOptimized kernel:\\n{result.sol_string}\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>Try Other Algorithms</p> <p>EvoToolkit supports multiple evolution algorithms for CUDA optimization:</p> <pre><code># Use EoH\nfrom evotoolkit.task.cuda_engineering import EoHCudaInterface\ninterface = EoHCudaInterface(task)\n\n# Use FunSearch\nfrom evotoolkit.task.cuda_engineering import FunSearchCudaInterface\ninterface = FunSearchCudaInterface(task)\n\n# Use EvoEngineer with Insights\nfrom evotoolkit.task.cuda_engineering import EvoEngineerInsightCudaInterface\ninterface = EvoEngineerInsightCudaInterface(task)\n\n# Use EvoEngineer Free-form\nfrom evotoolkit.task.cuda_engineering import EvoEngineerFreeCudaInterface\ninterface = EvoEngineerFreeCudaInterface(task)\n</code></pre> <p>Then use the same <code>evotoolkit.solve()</code> call to run evolution. Different interfaces may perform better for different kernels.</p>"},{"location":"tutorials/built-in/cuda-task/#customizing-evolution-behavior","title":"Customizing Evolution Behavior","text":"<p>The quality of the evolutionary process is primarily controlled by the evolution method and its internal prompt design. If you want to improve results:</p> <ul> <li>Adjust prompts: Inherit existing Interface classes and customize LLM prompts</li> <li>Develop new algorithms: Create brand new evolutionary strategies and operators</li> </ul> <p>Learn More</p> <p>These are universal techniques applicable to all tasks. For detailed tutorials, see:</p> <ul> <li>Customizing Evolution Methods - How to modify prompts and develop new algorithms</li> <li>Advanced Usage - More advanced configuration options</li> </ul> <p>Quick Example - Customize prompt for CUDA optimization:</p> <pre><code>from evotoolkit.task.cuda_engineering import EvoEngineerFullCudaInterface\n\nclass OptimizedCudaInterface(EvoEngineerFullCudaInterface):\n    \"\"\"Interface optimized for memory-bound kernels.\"\"\"\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        \"\"\"Customize mutation prompt to emphasize memory access patterns.\"\"\"\n\n        if operator_name == \"mutation\":\n            task_description = self.task.get_base_task_description()\n            individual = selected_individuals[0]\n\n            prompt = f\"\"\"# CUDA KERNEL OPTIMIZATION - MEMORY FOCUS\n{task_description}\n\n## CURRENT BEST\n**Name:** {current_best_sol.other_info['name']}\n**Runtime:** {-current_best_sol.evaluation_res.score:.5f} milliseconds\n\n## KERNEL TO MUTATE\n**Name:** {individual.other_info['name']}\n**Runtime:** {-individual.evaluation_res.score:.5f} milliseconds\n\n## OPTIMIZATION FOCUS\nFocus on optimizing memory access patterns:\n- Use shared memory to reduce global memory accesses\n- Implement memory coalescing for better bandwidth\n- Consider memory bank conflicts\n- Use appropriate memory access patterns (texture, constant memory)\n\nGenerate an improved kernel that reduces memory bottlenecks.\n\n## RESPONSE FORMAT:\nname: [descriptive_name]\ncode:\n```cpp\n[Your CUDA kernel implementation]\n```\nthought: [Memory optimization rationale]\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # Use default prompts for other operators\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# Use custom interface\ninterface = OptimizedCudaInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre> <p>About EvoEngineer Operators</p> <p>EvoEngineer uses three operators: init (initialization), mutation (mutation), crossover (crossover). The parent class <code>EvoEngineerFullCudaInterface</code> already defines these operators and default prompts. You only need to override <code>get_operator_prompt()</code> to customize specific operator prompts - others will automatically use the default implementation.</p> <p>For complete customization tutorials and more examples, see Customizing Evolution Methods.</p>"},{"location":"tutorials/built-in/cuda-task/#understanding-evaluation","title":"Understanding Evaluation","text":""},{"location":"tutorials/built-in/cuda-task/#how-scoring-works","title":"How Scoring Works","text":"<ol> <li>Correctness Validation: CUDA kernel output is compared against Python reference implementation</li> <li>Runtime Measurement: Kernel execution time is measured using CUDA events and profiling</li> <li>Fitness: Negative runtime (higher is better, so lower runtime = higher fitness)</li> </ol>"},{"location":"tutorials/built-in/cuda-task/#evaluation-output","title":"Evaluation Output","text":"<pre><code>result = task.evaluate_code(candidate_cuda_code)\n\nif result.valid:\n    print(f\"Score: {result.score}\")                                    # Higher is better\n    print(f\"Runtime: {-result.score:.4f} ms\")                          # Actual runtime\n    print(f\"Profile: {result.additional_info['prof_string']}\")         # CUDA profiler output\nelse:\n    if result.additional_info['compilation_error']:\n        print(f\"Compilation error: {result.additional_info['error_msg']}\")\n    elif result.additional_info['comparison_error']:\n        print(f\"Correctness error: {result.additional_info['error_msg']}\")\n</code></pre>"},{"location":"tutorials/built-in/cuda-task/#fake-mode-for-testing","title":"Fake Mode for Testing","text":"<p>You can test without GPU using fake mode:</p> <pre><code>def main():\n    task_info = CudaTaskInfoMaker.make_task_info(\n        evaluator=evaluator,\n        gpu_type=\"RTX 4090\",\n        cuda_version=\"12.4.1\",\n        org_py_code=org_py_code,\n        func_py_code=func_py_code,\n        cuda_code=cuda_code,\n        fake_mode=True  # Skip actual CUDA evaluation\n    )\n\n    task = CudaTask(data=task_info, fake_mode=True)\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"tutorials/built-in/cuda-task/#faq","title":"FAQ","text":""},{"location":"tutorials/built-in/cuda-task/#q-how-to-handle-the-_get_vc_env-is-private-warning","title":"Q: How to handle the <code>_get_vc_env is private</code> warning?","text":"<p>Problem Description:</p> <p>When compiling CUDA extensions on Windows, you may see the following warning:</p> <pre><code>UserWarning: _get_vc_env is private; find an alternative (pypa/distutils#340)\n</code></pre> <p>Root Cause:</p> <p>This is a compatibility warning from setuptools/distutils when detecting the MSVC compiler on Windows:</p> <ul> <li>CUDA extension compilation requires Visual Studio C++ compiler (MSVC)</li> <li>setuptools calls the internal function <code>_get_vc_env()</code> to get compiler environment</li> <li>Python is migrating distutils from stdlib to setuptools, and some internal APIs are marked as private during this transition</li> </ul> <p>Impact:</p> <ul> <li>\u26a0\ufe0f This is just a UserWarning, it does not affect program execution</li> <li>\u2705 Does not affect CUDA kernel compilation</li> <li>\u2705 Does not affect optimization results</li> </ul> <p>Solutions:</p> <p>Solution 1: Filter the warning (Recommended)</p> <p>Add warning filter at the beginning of your script:</p> <pre><code>import warnings\nwarnings.filterwarnings('ignore', category=UserWarning, module='setuptools')\n\n# Or more precisely\nwarnings.filterwarnings('ignore', message='.*_get_vc_env is private.*')\n\n# Then import other modules\nfrom evotoolkit.task.cuda_engineering import CudaTask\n# ...\n</code></pre> <p>Solution 2: Upgrade setuptools</p> <p>Try upgrading to the latest version (may have fixed the issue):</p> <pre><code>pip install --upgrade setuptools\n</code></pre> <p>Solution 3: Ignore it</p> <p>If you don't mind seeing the warning, you can simply ignore it. This warning doesn't affect functionality, it just reminds developers that the internal API may change in future versions.</p>"},{"location":"tutorials/built-in/cuda-task/#q-why-is-if-__name__-__main__-protection-required-on-windows","title":"Q: Why is <code>if __name__ == '__main__':</code> protection required on Windows?","text":"<p>Reason:</p> <ul> <li>Windows does not support <code>fork</code> process creation, only <code>spawn</code></li> <li><code>spawn</code> re-imports the main module to create subprocesses</li> <li>CUDA task evaluator uses <code>multiprocessing</code> module for timeout control</li> <li>Without protection, every import will execute the main code, causing infinite recursive process creation</li> </ul> <p>Correct Example:</p> <pre><code>from evotoolkit.task.cuda_engineering import CudaTask\n\ndef main():\n    evaluator = Evaluator(temp_path)\n    task = CudaTask(...)\n    # All task code\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>Incorrect Example (will crash):</p> <pre><code>from evotoolkit.task.cuda_engineering import CudaTask\n\n# \u274c Executing directly at module level\nevaluator = Evaluator(temp_path)  # Will cause RuntimeError\n</code></pre>"},{"location":"tutorials/built-in/cuda-task/#next-steps","title":"Next Steps","text":""},{"location":"tutorials/built-in/cuda-task/#explore-different-optimization-strategies","title":"Explore different optimization strategies","text":"<ul> <li>Try different evolution algorithms (EvoEngineer variants, EoH, FunSearch)</li> <li>Compare results across different interfaces</li> <li>Analyze performance profiles to identify bottlenecks</li> <li>Experiment with different kernel patterns (tiled, shared memory, etc.)</li> </ul>"},{"location":"tutorials/built-in/cuda-task/#customize-and-improve-the-evolution-process","title":"Customize and improve the evolution process","text":"<ul> <li>Inspect prompt designs in existing Interface classes</li> <li>Inherit and override Interface to customize prompts</li> <li>Design specialized prompts for different optimization goals (memory-bound, compute-bound, etc.)</li> <li>If needed, develop brand new evolution algorithms</li> </ul>"},{"location":"tutorials/built-in/cuda-task/#learn-more","title":"Learn more","text":"<ul> <li>Customizing Evolution Methods - Deep dive into prompt customization and algorithm development</li> <li>Advanced Usage - Advanced configurations and techniques</li> <li>API Reference - Complete API documentation</li> <li>Development Docs - Contributing new methods and features</li> </ul>"},{"location":"tutorials/built-in/prompt-engineering/","title":"Prompt Engineering Tutorial","text":"<p>Learn how to use LLM-driven evolution to optimize prompt templates for better downstream task performance.</p> <p>Academic Citation</p> <p>If you use EvoToolkit in your research, please cite:</p> <pre><code>@article{guo2025evotoolkit,\ntitle={evotoolkit: A Unified LLM-Driven Evolutionary Framework for Generalized Solution Search},\nauthor={Guo, Ping and Zhang, Qingfu},\njournal={arXiv preprint arXiv:XXXX.XXXXX},\nyear={2025},\nnote={Submitted to arXiv}\n}\n</code></pre> <p>Complete Example Code</p> <p>This tutorial provides complete, runnable examples (click to view/download):</p> <ul> <li> basic_example.py - Basic usage with mock LLM</li> <li> README.md - Examples documentation and usage guide</li> </ul> <p>Run locally: <pre><code>cd examples/prompt_optimization\npython basic_example.py\n</code></pre></p>"},{"location":"tutorials/built-in/prompt-engineering/#overview","title":"Overview","text":"<p>This tutorial demonstrates:</p> <ul> <li>Creating prompt optimization tasks</li> <li>Using LLM-driven evolution to improve prompt templates</li> <li>Testing prompts on specific downstream tasks</li> <li>Evolving high-quality prompts automatically</li> </ul>"},{"location":"tutorials/built-in/prompt-engineering/#installation","title":"Installation","text":"<p>Install EvoToolkit:</p> <pre><code>pip install evotoolkit\n</code></pre> <p>Prerequisites:</p> <ul> <li>Python &gt;= 3.11</li> <li>LLM API access (OpenAI, Claude, or other compatible providers)</li> <li>Basic understanding of prompt engineering</li> </ul>"},{"location":"tutorials/built-in/prompt-engineering/#understanding-prompt-optimization-tasks","title":"Understanding Prompt Optimization Tasks","text":""},{"location":"tutorials/built-in/prompt-engineering/#what-is-a-prompt-optimization-task","title":"What is a Prompt Optimization Task?","text":"<p>A prompt optimization task evolves string templates to maximize performance on downstream tasks. Unlike Python tasks that evolve code, prompt tasks evolve prompt text directly.</p> Aspect Python Task Prompt Task Solution type Python code String template Evolution target Function/algorithm Prompt text Evaluation Execute code Test template with LLM Example <code>def func(x): return x**2</code> <code>\"Solve: {question}\\nAnswer:\"</code>"},{"location":"tutorials/built-in/prompt-engineering/#task-components","title":"Task Components","text":"<p>A prompt optimization task requires:</p> <ul> <li>Test cases: Question-answer pairs for evaluation</li> <li>Template syntax: String with <code>{question}</code> placeholder</li> <li>LLM API: For testing prompt templates (or use mock mode)</li> <li>Evaluation metric: Accuracy on test cases</li> </ul>"},{"location":"tutorials/built-in/prompt-engineering/#creating-your-first-prompt-task","title":"Creating Your First Prompt Task","text":""},{"location":"tutorials/built-in/prompt-engineering/#step-1-define-test-cases","title":"Step 1: Define Test Cases","text":"<p>Create test cases with questions and expected answers:</p> <pre><code>test_cases = [\n    {\"question\": \"What is 2+2?\", \"expected\": \"4\"},\n    {\"question\": \"What is 5*3?\", \"expected\": \"15\"},\n    {\"question\": \"What is 10-7?\", \"expected\": \"3\"},\n    {\"question\": \"What is 12/4?\", \"expected\": \"3\"},\n    {\"question\": \"What is 7+8?\", \"expected\": \"15\"},\n]\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#step-2-create-the-task","title":"Step 2: Create the Task","text":"<pre><code>from evotoolkit.task import PromptOptimizationTask\nfrom evotoolkit.tools.llm import HttpsApi\n\n# Configure LLM API\nllm_api = HttpsApi(\n    api_url=\"your_api_url\",  # e.g., \"ai.api.example.com\"\n    key=\"your_api_key\",       # Your API key\n    model=\"gpt-4o\"\n)\n\ntask = PromptOptimizationTask(\n    test_cases=test_cases,\n    llm_api=llm_api,\n    use_mock=False\n)\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#step-3-test-initial-template","title":"Step 3: Test Initial Template","text":"<pre><code># Get initial solution\ninit_sol = task.make_init_sol_wo_other_info()\n\nprint(f\"Initial template: {init_sol.sol_string}\")\nprint(f\"Accuracy: {init_sol.evaluation_res.score:.2%}\")\nprint(f\"Correct: {init_sol.evaluation_res.additional_info['correct']}/{init_sol.evaluation_res.additional_info['total']}\")\n</code></pre> <p>Output: <pre><code>Initial template: \"Answer this question: {question}\"\nAccuracy: 100.00%\nCorrect: 5/5\n</code></pre></p>"},{"location":"tutorials/built-in/prompt-engineering/#step-4-test-custom-templates","title":"Step 4: Test Custom Templates","text":"<pre><code># Test your own template\ncustom_template = \"Solve this math problem and give only the number: {question}\"\nresult = task.evaluate_code(custom_template)\n\nprint(f\"Custom template: {custom_template}\")\nprint(f\"Accuracy: {result.score:.2%}\")\nprint(f\"Correct: {result.additional_info['correct']}/{result.additional_info['total']}\")\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#running-evolution-to-optimize-prompts","title":"Running Evolution to Optimize Prompts","text":""},{"location":"tutorials/built-in/prompt-engineering/#step-1-create-interface","title":"Step 1: Create Interface","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task import EvoEngineerStringInterface\n\n# Create interface\ninterface = EvoEngineerStringInterface(task)\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#step-2-run-evolution","title":"Step 2: Run Evolution","text":"<pre><code># Run evolution with LLM\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./prompt_results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20\n)\n\nprint(f\"Best template found: {result.sol_string}\")\nprint(f\"Accuracy: {result.evaluation_res.score:.2%}\")\n</code></pre> <p>Try Different Algorithms</p> <p>EvoToolkit supports multiple evolutionary algorithms for prompt optimization:</p> <pre><code># Using EoH\nfrom evotoolkit.task import EoHStringInterface\ninterface = EoHStringInterface(task)\n\n# Using FunSearch\nfrom evotoolkit.task import FunSearchStringInterface\ninterface = FunSearchStringInterface(task)\n\n# Using EvoEngineer (default)\nfrom evotoolkit.task import EvoEngineerStringInterface\ninterface = EvoEngineerStringInterface(task)\n</code></pre> <p>Then use the same <code>evotoolkit.solve()</code> call to run evolution. Different interfaces may perform better on different tasks.</p>"},{"location":"tutorials/built-in/prompt-engineering/#understanding-template-format","title":"Understanding Template Format","text":""},{"location":"tutorials/built-in/prompt-engineering/#valid-templates","title":"Valid Templates","text":"<p>Prompt templates must include the <code>{question}</code> placeholder:</p> <pre><code># \u2705 Good templates\n\"Answer this question: {question}\"\n\"Solve this math problem: {question}\\nGive only the number.\"\n\"Question: {question}\\nThink step by step and provide only the final answer.\"\n\"Let's solve: {question}\\nFirst, analyze the problem...\"\n\n# \u274c Bad templates (missing placeholder)\n\"Solve this problem\"     # No {question} placeholder\n\"Answer: 42\"            # No {question} placeholder\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#template-evolution-example","title":"Template Evolution Example","text":"<p>During evolution, the LLM generates improved templates:</p> <pre><code># Generation 1\n\"Answer: {question}\"\n# Accuracy: 60%\n\n# Generation 3\n\"Solve this math problem: {question}\\nProvide only the numerical answer.\"\n# Accuracy: 85%\n\n# Generation 7\n\"Calculate: {question}\\nShow only the final number, no explanation.\"\n# Accuracy: 100%\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#use-cases-and-applications","title":"Use Cases and Applications","text":""},{"location":"tutorials/built-in/prompt-engineering/#1-math-problem-solving","title":"1. Math Problem Solving","text":"<pre><code>test_cases = [\n    {\"question\": \"What is 15 * 7?\", \"expected\": \"105\"},\n    {\"question\": \"What is 144 / 12?\", \"expected\": \"12\"},\n    # ...\n]\n\ntask = PromptOptimizationTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#2-text-classification","title":"2. Text Classification","text":"<pre><code>test_cases = [\n    {\"question\": \"This movie is amazing!\", \"expected\": \"positive\"},\n    {\"question\": \"This movie is terrible!\", \"expected\": \"negative\"},\n    {\"question\": \"I loved this film!\", \"expected\": \"positive\"},\n    # ...\n]\n\ntask = PromptOptimizationTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#3-information-extraction","title":"3. Information Extraction","text":"<pre><code>test_cases = [\n    {\"question\": \"Extract the date: The meeting is on 2024-03-15\", \"expected\": \"2024-03-15\"},\n    {\"question\": \"Extract the date: We'll meet on March 20th, 2024\", \"expected\": \"2024-03-20\"},\n    # ...\n]\n\ntask = PromptOptimizationTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#4-translation-tasks","title":"4. Translation Tasks","text":"<pre><code>test_cases = [\n    {\"question\": \"Translate to French: Hello\", \"expected\": \"Bonjour\"},\n    {\"question\": \"Translate to French: Thank you\", \"expected\": \"Merci\"},\n    # ...\n]\n\ntask = PromptOptimizationTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#customizing-evolution-behavior","title":"Customizing Evolution Behavior","text":"<p>The quality of evolved prompts is controlled by the evolution method and its internal prompt design. To improve results:</p> <ul> <li>Adjust prompts: Inherit existing Interface classes and customize LLM prompts</li> <li>Develop new algorithms: Create entirely new evolutionary strategies</li> </ul> <p>Learn More</p> <p>These are general techniques applicable to all tasks. For detailed tutorials, see:</p> <ul> <li>Customizing Evolution Methods - How to modify prompts and develop new algorithms</li> <li>Advanced Usage - More advanced configuration options</li> </ul> <p>Quick Example - Custom Prompts for Prompt Optimization:</p> <pre><code>from evotoolkit.task import EvoEngineerStringInterface\n\nclass CustomPromptInterface(EvoEngineerStringInterface):\n    \"\"\"Interface optimized for prompt template evolution.\"\"\"\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        \"\"\"Customize mutation prompt to emphasize clarity and structure.\"\"\"\n\n        if operator_name == \"mutation\":\n            task_description = self.task.get_base_task_description()\n            individual = selected_individuals[0]\n\n            prompt = f\"\"\"# Prompt Template Optimization\n\n{task_description}\n\n## Current Best Template\n**Accuracy:** {current_best_sol.evaluation_res.score:.2%}\n**Template:** {current_best_sol.sol_string}\n\n## Template to Mutate\n**Accuracy:** {individual.evaluation_res.score:.2%}\n**Template:** {individual.sol_string}\n\n## Optimization Guidelines\nFocus on improving the template by:\n- Adding clear instructions\n- Specifying output format explicitly\n- Including relevant context or examples\n- Using appropriate tone and style\n- Ensuring the {{question}} placeholder is preserved\n\nGenerate an improved template that increases accuracy.\n\n## Response Format:\nname: [descriptive_name]\ncode:\n[Your improved template with {{question}} placeholder]\nthought: [reasoning for changes]\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # Use default for other operators\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# Use custom interface\ninterface = CustomPromptInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./custom_results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#understanding-evaluation","title":"Understanding Evaluation","text":""},{"location":"tutorials/built-in/prompt-engineering/#scoring-mechanism","title":"Scoring Mechanism","text":"<ol> <li>Template Testing: Each template is tested on all test cases</li> <li>LLM Response: The LLM generates answers using the template</li> <li>Answer Checking: Responses are compared to expected answers</li> <li>Accuracy Calculation: Score = (correct answers) / (total test cases)</li> </ol>"},{"location":"tutorials/built-in/prompt-engineering/#evaluation-output","title":"Evaluation Output","text":"<pre><code>result = task.evaluate_code(template)\n\nif result.valid:\n    print(f\"Accuracy: {result.score:.2%}\")\n    print(f\"Correct: {result.additional_info['correct']}/{result.additional_info['total']}\")\n    print(f\"Details: {result.additional_info['details']}\")\nelse:\n    print(f\"Error: {result.additional_info['error_msg']}\")\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#mock-mode-for-testing","title":"Mock Mode for Testing","text":"<p>Use mock mode to test without LLM API costs:</p> <pre><code># Mock mode always returns correct answers for testing\ntask = PromptOptimizationTask(\n    test_cases=test_cases,\n    use_mock=True  # No actual LLM calls\n)\n\n# Good for:\n# - Testing task setup\n# - Debugging template format\n# - Understanding the workflow\n# - Developing custom interfaces\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#custom-evaluation-logic","title":"Custom Evaluation Logic","text":"<p>For specialized tasks, you can customize answer checking:</p> <pre><code>from evotoolkit.task import PromptOptimizationTask\n\nclass CustomPromptTask(PromptOptimizationTask):\n    \"\"\"Custom task with specialized answer checking.\"\"\"\n\n    def _check_answer(self, response: str, expected: str) -&gt; bool:\n        \"\"\"Custom evaluation logic.\"\"\"\n        # Example: Case-insensitive comparison\n        return response.strip().lower() == expected.strip().lower()\n\n        # Example: Fuzzy matching\n        # from difflib import SequenceMatcher\n        # similarity = SequenceMatcher(None, response, expected).ratio()\n        # return similarity &gt; 0.8\n\n        # Example: Regex matching\n        # import re\n        # return bool(re.search(expected, response))\n\n# Use custom task\ntest_cases = [\n    {\"question\": \"Capital of France?\", \"expected\": \"paris\"},\n    # \"Paris\", \"PARIS\", \"paris\" all accepted\n]\n\ntask = CustomPromptTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#complete-example","title":"Complete Example","text":"<p>Here's a full working example:</p> <pre><code>import evotoolkit\nfrom evotoolkit.task import PromptOptimizationTask, EvoEngineerStringInterface\nfrom evotoolkit.tools.llm import HttpsApi\n\n# 1. Define test cases\ntest_cases = [\n    {\"question\": \"What is 2+2?\", \"expected\": \"4\"},\n    {\"question\": \"What is 5*3?\", \"expected\": \"15\"},\n    {\"question\": \"What is 10-7?\", \"expected\": \"3\"},\n    {\"question\": \"What is 12/4?\", \"expected\": \"3\"},\n    {\"question\": \"What is 7+8?\", \"expected\": \"15\"},\n]\n\n# 2. Configure LLM API\nllm_api = HttpsApi(\n    api_url=\"your_api_url\",  # e.g., \"ai.api.example.com\"\n    key=\"your_api_key\",       # Your API key\n    model=\"gpt-4o\"\n)\n\n# 3. Create task\ntask = PromptOptimizationTask(\n    test_cases=test_cases,\n    llm_api=llm_api,\n    use_mock=False\n)\n\n# 4. Create interface\ninterface = EvoEngineerStringInterface(task)\n\n# 5. Run evolution\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./prompt_optimization_results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20\n)\n\n# 6. Show results\nprint(f\"Best template found:\")\nprint(f\"  {result.sol_string}\")\nprint(f\"Accuracy: {result.evaluation_res.score:.2%}\")\nprint(f\"Correct: {result.evaluation_res.additional_info['correct']}/{result.evaluation_res.additional_info['total']}\")\n</code></pre>"},{"location":"tutorials/built-in/prompt-engineering/#next-steps","title":"Next Steps","text":""},{"location":"tutorials/built-in/prompt-engineering/#explore-different-optimization-strategies","title":"Explore Different Optimization Strategies","text":"<ul> <li>Try different evolutionary algorithms (EvoEngineer variants, EoH, FunSearch)</li> <li>Compare results across different interfaces</li> <li>Experiment with different test case sets</li> <li>Test on various downstream tasks</li> </ul>"},{"location":"tutorials/built-in/prompt-engineering/#customize-and-improve-evolution","title":"Customize and Improve Evolution","text":"<ul> <li>Examine prompt designs in existing Interface classes</li> <li>Inherit and override Interfaces to customize prompts</li> <li>Design specialized prompts for different task types</li> <li>Develop new evolutionary algorithms if needed</li> </ul>"},{"location":"tutorials/built-in/prompt-engineering/#learn-more","title":"Learn More","text":"<ul> <li>Customizing Evolution Methods - Deep dive into prompt customization and algorithm development</li> <li>Advanced Usage - Advanced configuration and techniques</li> <li>API Reference - Complete API documentation</li> <li>Development Docs - Contribute new methods and features</li> </ul>"},{"location":"tutorials/built-in/scientific-regression/","title":"Scientific Symbolic Regression Tutorial","text":"<p>Learn how to discover mathematical equations from real scientific datasets using LLM-driven evolution.</p> <p>Academic Citation</p> <p>The scientific regression task and datasets are based on research from CoEvo. If you use this feature in academic work, please cite:</p> <pre><code>@misc{guo2024coevocontinualevolutionsymbolic,\n    title={CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models},\n    author={Ping Guo and Qingfu Zhang and Xi Lin},\n    year={2024},\n    eprint={2412.18890},\n    archivePrefix={arXiv},\n    primaryClass={cs.AI},\n    url={https://arxiv.org/abs/2412.18890}\n}\n</code></pre> <p>Complete Example Code</p> <p>This tutorial provides complete, runnable examples (click to view/download):</p> <ul> <li> basic_example.py - Basic usage</li> <li> custom_prompt.py - Custom prompt example</li> <li> compare_algorithms.py - Algorithm comparison</li> <li> README.md - Examples documentation and usage guide</li> </ul> <p>Run locally: <pre><code>cd examples/scientific_regression\npython basic_example.py\n</code></pre></p>"},{"location":"tutorials/built-in/scientific-regression/#overview","title":"Overview","text":"<p>This tutorial demonstrates:</p> <ul> <li>Loading scientific datasets for symbolic regression</li> <li>Discovering mathematical equations from data</li> <li>Optimizing equation parameters automatically</li> <li>Evolving complex scientific models</li> </ul>"},{"location":"tutorials/built-in/scientific-regression/#installation","title":"Installation","text":"<p>Install scientific regression dependencies:</p> <pre><code>pip install evotoolkit[scientific_regression]\n</code></pre> <p>This installs:</p> <ul> <li>SciPy (for parameter optimization)</li> <li>Pandas (for data loading)</li> </ul> <p>Prerequisites:</p> <ul> <li>Basic understanding of symbolic regression concepts</li> <li>Familiarity with NumPy and SciPy usage</li> </ul>"},{"location":"tutorials/built-in/scientific-regression/#prepare-datasets","title":"Prepare Datasets","text":"<p>EvoToolkit supports lazy downloading - datasets are automatically downloaded on first use to a default location.</p> <p>Available datasets:</p> <ul> <li>bactgrow: E. Coli bacterial growth rate prediction (4 inputs: population, substrate, temp, pH)</li> <li>oscillator1: Damped nonlinear oscillator acceleration (2 inputs: position, velocity)</li> <li>oscillator2: Damped nonlinear oscillator variant 2 (2 inputs: position, velocity)</li> <li>stressstrain: Aluminium stress prediction (2 inputs: strain, temperature)</li> </ul> <p>Custom data directory:</p> <pre><code># Specify data directory in task (auto-downloads on first run)\ntask = ScientificRegressionTask(\n    dataset_name=\"bactgrow\",\n    data_dir='./my_data'\n)\n</code></pre>"},{"location":"tutorials/built-in/scientific-regression/#example-bacterial-growth-modeling","title":"Example: Bacterial Growth Modeling","text":""},{"location":"tutorials/built-in/scientific-regression/#step-1-create-the-task","title":"Step 1: Create the Task","text":"<pre><code>from evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\n\n# Create task for bacterial growth dataset\ntask = ScientificRegressionTask(\n    dataset_name=\"bactgrow\",\n    max_params=10,          # Number of optimizable parameters\n    timeout_seconds=60.0    # Timeout per evaluation\n)\n\nprint(f\"Dataset: {task.dataset_name}\")\nprint(f\"Train size: {task.task_info['train_size']}\")\nprint(f\"Test size: {task.task_info['test_size']}\")\n</code></pre> <p>Output: <pre><code>Dataset: bactgrow\nTrain size: 7500\nTest size: 2500\nNumber of inputs: 4\n</code></pre></p>"},{"location":"tutorials/built-in/scientific-regression/#step-2-understand-the-task","title":"Step 2: Understand the Task","text":"<p>The goal of scientific symbolic regression is to discover mathematical equations from data . For the bacterial growth dataset, we need to find a function that predicts growth rate.</p> <p>Function signature: <code>equation(b, s, temp, pH, params) -&gt; growth_rate</code></p> <p>Input variables:</p> <ul> <li><code>b</code>: Population density</li> <li><code>s</code>: Substrate concentration</li> <li><code>temp</code>: Temperature</li> <li><code>pH</code>: pH level</li> <li><code>params</code>: Array of optimizable constants (params[0] to params[9])</li> </ul> <p>Evaluation process:</p> <ol> <li>You provide the equation structure (e.g., <code>params[0] * s / (params[1] + s)</code>)</li> <li>The framework automatically optimizes parameter values using <code>scipy.optimize.minimize</code></li> <li>MSE (Mean Squared Error) on the test set is calculated as fitness (lower is better)</li> </ol>"},{"location":"tutorials/built-in/scientific-regression/#step-3-test-with-initial-solution","title":"Step 3: Test with Initial Solution","text":"<pre><code># Get initial solution (simple linear model)\ninit_sol = task.make_init_sol_wo_other_info()\n\nprint(\"Initial solution code:\")\nprint(init_sol.sol_string)\n\n# Evaluate it\nresult = task.evaluate_code(init_sol.sol_string)\nprint(f\"Score: {result.score:.6f}\")\nprint(f\"Test MSE: {result.additional_info['test_mse']:.6f}\")\n</code></pre> <p>Output: <pre><code>Initial solution code:\nimport numpy as np\n\ndef equation(b, s, temp, pH, params):\n    \"\"\"Linear baseline model.\"\"\"\n    return params[0] * b + params[1] * s + params[2] * temp + params[3] * pH + params[4]\n\nScore: 0.017200\nTest MSE: 0.017200\n</code></pre></p>"},{"location":"tutorials/built-in/scientific-regression/#step-4-try-a-custom-initial-solution","title":"Step 4: Try a Custom Initial Solution","text":"<p>You can provide a custom initial equation as the starting point for evolution. For example, here's a more complex model based on biological mechanisms:</p> <pre><code>custom_code = '''import numpy as np\n\ndef equation(b, s, temp, pH, params):\n    \"\"\"Nonlinear bacterial growth model with biological mechanisms.\"\"\"\n\n    # Monod equation for substrate limitation\n    growth_rate = params[0] * s / (params[1] + s)\n\n    # Gaussian temperature effect\n    optimal_temp = params[4]\n    temp_effect = params[2] * np.exp(-params[3] * (temp - optimal_temp)**2)\n\n    # Gaussian pH effect\n    optimal_pH = params[7]\n    pH_effect = params[5] * np.exp(-params[6] * (pH - optimal_pH)**2)\n\n    # Logistic growth with carrying capacity\n    carrying_capacity = params[9]\n    density_limit = params[8] * (1 - b / carrying_capacity)\n\n    return growth_rate * temp_effect * pH_effect * density_limit\n'''\n\nresult = task.evaluate_code(custom_code)\nprint(f\"Custom model score: {result.score:.6f}\")\nprint(f\"Test MSE: {result.additional_info['test_mse']:.6f}\")\n</code></pre> <p>Output: <pre><code>Custom model score: 0.021515\nTest MSE: 0.021515\n</code></pre></p> <p>About Initial Solutions</p> <p>Note: Any custom equation you write here serves only as an initialization solution. The evolutionary algorithm will use the LLM to generate and improve equations starting from this point. The final evolutionary results depend on the chosen evolution method and its internal prompt design.</p>"},{"location":"tutorials/built-in/scientific-regression/#step-5-run-evolution-with-evoengineer","title":"Step 5: Run Evolution with EvoEngineer","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools.llm import HttpsApi\nimport os\n\n# Create interface for EvoEngineer\ninterface = EvoEngineerPythonInterface(task)\n\n# Configure LLM API\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"your-api-key-here\",\n    model=\"gpt-4o\"\n)\n\n# Run evolution\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./scientific_regression_results',\n    running_llm=llm_api,\n    max_generations=5,\n    pop_size=10\n)\n\nprint(f\"Best solution found!\")\nprint(f\"Score: {result['best_solution'].evaluation_res.score:.6f}\")\nprint(f\"Code:\\n{result['best_solution'].sol_string}\")\n</code></pre> <p>Try Other Algorithms</p> <p>EvoToolkit supports multiple evolution algorithms. Simply swap the Interface:</p> <pre><code># Use EoH\nfrom evotoolkit.task.python_task import EoHPythonInterface\ninterface = EoHPythonInterface(task)\n\n# Use FunSearch\nfrom evotoolkit.task.python_task import FunSearchPythonInterface\ninterface = FunSearchPythonInterface(task)\n</code></pre> <p>Then use the same <code>evotoolkit.solve()</code> call to run evolution. Different algorithms may perform better on different tasks - try multiple and compare.</p>"},{"location":"tutorials/built-in/scientific-regression/#customizing-evolution-behavior","title":"Customizing Evolution Behavior","text":"<p>The quality of the evolutionary process is primarily controlled by the evolution method and its internal prompt design. If you want to improve results:</p> <ul> <li>Adjust prompts: Inherit existing Interface classes and customize LLM prompts</li> <li>Develop new algorithms: Create brand new evolutionary strategies and operators</li> </ul> <p>Learn More</p> <p>These are universal techniques applicable to all tasks. For detailed tutorials, see:</p> <ul> <li>Customizing Evolution Methods - How to modify prompts and develop new algorithms</li> <li>Advanced Usage - More advanced configuration options</li> </ul> <p>Quick Example - Customize prompt for scientific regression:</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\n\nclass ScientificRegressionInterface(EvoEngineerPythonInterface):\n    \"\"\"Interface optimized for scientific equation discovery, with custom mutation prompt\"\"\"\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        \"\"\"Customize the mutation operator prompt to emphasize physical/biological principles\"\"\"\n\n        if operator_name == \"mutation\":\n            task_description = self.task.get_base_task_description()\n            prompt = f\"\"\"You are an expert in scientific equation discovery.\n\nTask: {task_description}\n\nCurrent best equation (score: {current_best_sol.evaluation_res.score:.5f}):\n{current_best_sol.sol_string}\n\nRequirements: Generate an improved equation based on known physical/biological principles\n(e.g., Monod equation, Arrhenius equation). Ensure numerical stability and model parsimony.\n\nOutput format:\n- name: equation name\n- code: Python code\n- thought: improvement rationale\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # init and crossover operators use parent class default prompts\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# Use custom Interface\ninterface = ScientificRegressionInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre> <p>About EvoEngineer Operators</p> <p>EvoEngineer uses three operators: init (initialization), mutation (mutation), crossover (crossover). The parent class <code>EvoEngineerPythonInterface</code> already defines these operators and default prompts. You only need to override <code>get_operator_prompt()</code> to customize specific operator prompts - others will automatically use the default implementation.</p> <p>For complete customization tutorials and more examples, see Customizing Evolution Methods.</p>"},{"location":"tutorials/built-in/scientific-regression/#understanding-evaluation","title":"Understanding Evaluation","text":""},{"location":"tutorials/built-in/scientific-regression/#how-scoring-works","title":"How Scoring Works","text":"<ol> <li>Parameter Optimization: Your equation structure is evaluated by optimizing parameters using <code>scipy.optimize.minimize</code> with BFGS method</li> <li>MSE Calculation: Mean Squared Error between predictions and ground truth</li> <li>Fitness: Negative MSE (higher is better, so lower MSE = higher fitness)</li> </ol>"},{"location":"tutorials/built-in/scientific-regression/#evaluation-output","title":"Evaluation Output","text":"<pre><code>result = task.evaluate_code(code)\n\nif result.valid:\n    print(f\"Score: {result.score}\")                           # Higher is better\n    print(f\"Train MSE: {result.additional_info['train_mse']}\")  # On training data\n    print(f\"Test MSE: {result.additional_info['test_mse']}\")    # On test data (used for fitness)\nelse:\n    print(f\"Error: {result.additional_info['error']}\")\n</code></pre>"},{"location":"tutorials/built-in/scientific-regression/#next-steps","title":"Next Steps","text":""},{"location":"tutorials/built-in/scientific-regression/#explore-different-tasks-and-methods","title":"Explore different tasks and methods","text":"<ul> <li>Try different datasets (oscillator1, oscillator2, stressstrain)</li> <li>Compare results across evolution methods (EvoEngineer, EoH, FunSearch)</li> <li>Visualize predictions vs ground truth</li> </ul>"},{"location":"tutorials/built-in/scientific-regression/#customize-and-improve-the-evolution-process","title":"Customize and improve the evolution process","text":"<ul> <li>Inspect prompt designs in existing Interface classes</li> <li>Inherit and override Interface to customize prompts</li> <li>Design specialized prompts for different operators (init/mutation/crossover)</li> <li>If needed, develop brand new evolution algorithms</li> </ul>"},{"location":"tutorials/built-in/scientific-regression/#learn-more","title":"Learn more","text":"<ul> <li>Customizing Evolution Methods - Deep dive into prompt customization and algorithm development</li> <li>Advanced Usage - Advanced configurations and techniques</li> <li>API Reference - Complete API documentation</li> <li>Development Docs - Contributing new methods and features</li> </ul>"},{"location":"tutorials/customization/custom-task/","title":"Custom Task Tutorial","text":"<p>Learn how to create your own optimization tasks in EvoToolkit.</p>"},{"location":"tutorials/customization/custom-task/#overview","title":"Overview","text":"<p>This tutorial shows you how to:</p> <ul> <li>Extend the <code>PythonTask</code> base class</li> <li>Implement custom evaluation logic</li> <li>Use your custom task with evolutionary algorithms</li> </ul> <p>Complete Example Code</p> <p>This tutorial provides a complete runnable example (click to view/download):</p> <ul> <li> my_custom_task.py - Complete custom task example</li> </ul> <p>Run locally: <pre><code>cd examples/custom_task\npython my_custom_task.py\n</code></pre></p>"},{"location":"tutorials/customization/custom-task/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed the Scientific Regression Tutorial</li> <li>Understanding of Python classes and inheritance</li> </ul>"},{"location":"tutorials/customization/custom-task/#creating-a-custom-task","title":"Creating a Custom Task","text":""},{"location":"tutorials/customization/custom-task/#step-1-define-the-task-class","title":"Step 1: Define the Task Class","text":"<pre><code>from evotoolkit.task.python_task import PythonTask\nfrom evotoolkit.core import Solution, EvaluationResult\nimport numpy as np\n\nclass MyOptimizationTask(PythonTask):\n    \"\"\"Custom task for optimizing a specific problem\"\"\"\n\n    def __init__(self, data, target, timeout_seconds=30.0):\n        \"\"\"\n        Initialize task with problem-specific data\n\n        Args:\n            data: Input data (NumPy array)\n            target: Target output values (NumPy array)\n            timeout_seconds: Code execution timeout (seconds)\n        \"\"\"\n        self.target = target\n        super().__init__(data, timeout_seconds)\n\n    def _process_data(self, data):\n        \"\"\"Process input data and create task_info\"\"\"\n        self.data = data\n        self.task_info = {\n            'data_size': len(data),\n            'description': 'Function approximation task'\n        }\n\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"Evaluate candidate code and return evaluation result\"\"\"\n        # 1. Execute code\n        namespace = {'np': np}\n        exec(candidate_code, namespace)\n\n        # 2. Check if function exists\n        if 'my_function' not in namespace:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': 'Function \"my_function\" not found'}\n            )\n\n        evolved_func = namespace['my_function']\n\n        # 3. Compute fitness (higher score is better)\n        predictions = np.array([evolved_func(x) for x in self.data])\n        mse = np.mean((predictions - self.target) ** 2)\n        score = -mse  # Negative MSE, higher is better\n\n        return EvaluationResult(\n            valid=True,\n            score=score,\n            additional_info={'mse': mse}\n        )\n\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"Get task description for prompt generation\"\"\"\n        return \"\"\"You are a function approximation expert.\n\nTask: Create a function my_function(x) that produces outputs as close as possible to target values.\n\nRequirements:\n- Define function my_function(x: float) -&gt; float\n- Use mathematical operations: +, -, *, /, **, np.exp, np.log, np.sin, np.cos, etc.\n- Ensure numerical stability\n\nExample code:\n    import numpy as np\n\n    def my_function(x):\n        return np.sin(x)\n\"\"\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"Create initial solution\"\"\"\n        initial_code = '''import numpy as np\n\ndef my_function(x):\n    \"\"\"Simple linear function as baseline\"\"\"\n    return x\n'''\n        eval_res = self.evaluate_code(initial_code)\n        return Solution(\n            sol_string=initial_code,\n            evaluation_res=eval_res\n        )\n</code></pre> <p>Key Points:</p> <ul> <li>Inherit from <code>PythonTask</code> instead of directly from <code>BaseTask</code></li> <li>Implement <code>_evaluate_code_impl()</code> returning <code>EvaluationResult</code> object</li> <li>Implement <code>get_base_task_description()</code> to provide task description</li> <li>Implement <code>make_init_sol_wo_other_info()</code> to create initial solution</li> <li>Use <code>_process_data()</code> to set up <code>task_info</code></li> <li><code>score</code> should be higher for better solutions (use negative MSE)</li> </ul>"},{"location":"tutorials/customization/custom-task/#step-2-use-your-custom-task","title":"Step 2: Use Your Custom Task","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools.llm import HttpsApi\nimport numpy as np\nimport os\n\n# Create task instance\ndata = np.linspace(0, 10, 50)\ntarget = np.sin(data)  # Target: approximate sine function\n\ntask = MyOptimizationTask(data, target)\n\n# Create interface\ninterface = EvoEngineerPythonInterface(task)\n\n# Setup LLM\nllm_api = HttpsApi(\n    api_url=os.environ.get(\"LLM_API_URL\", \"https://api.openai.com/v1/chat/completions\"),\n    key=os.environ.get(\"LLM_API_KEY\", \"your-api-key-here\"),\n    model=\"gpt-4o\"\n)\n\n# Solve\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results/custom_task',\n    running_llm=llm_api,\n    max_generations=10\n)\n\nprint(f\"Best score: {result.evaluation_res.score:.4f}\")\nprint(f\"Best MSE: {result.evaluation_res.additional_info['mse']:.4f}\")\n</code></pre>"},{"location":"tutorials/customization/custom-task/#example-string-matching-task","title":"Example: String Matching Task","text":"<pre><code>from evotoolkit.task.python_task import PythonTask\nfrom evotoolkit.core import Solution, EvaluationResult\n\nclass StringMatchTask(PythonTask):\n    \"\"\"Task to evolve a function that generates a target string\"\"\"\n\n    def __init__(self, target_string, timeout_seconds=30.0):\n        self.target = target_string\n        super().__init__(data={'target': target_string}, timeout_seconds=timeout_seconds)\n\n    def _process_data(self, data):\n        \"\"\"Process input data\"\"\"\n        self.data = data\n        self.task_info = {\n            'target': self.target,\n            'target_length': len(self.target)\n        }\n\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"Evaluate code\"\"\"\n        namespace = {}\n        exec(candidate_code, namespace)\n\n        if 'generate_string' not in namespace:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': 'Function \"generate_string\" not found'}\n            )\n\n        try:\n            generated = namespace['generate_string']()\n            # Edit distance lower is better, so use negative value as score\n            distance = self.levenshtein_distance(generated, self.target)\n            score = -distance  # Higher is better\n\n            return EvaluationResult(\n                valid=True,\n                score=score,\n                additional_info={'distance': distance, 'generated': generated}\n            )\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': str(e)}\n            )\n\n    def levenshtein_distance(self, s1, s2):\n        \"\"\"Compute Levenshtein edit distance\"\"\"\n        if len(s1) &lt; len(s2):\n            return self.levenshtein_distance(s2, s1)\n        if len(s2) == 0:\n            return len(s1)\n\n        previous_row = range(len(s2) + 1)\n        for i, c1 in enumerate(s1):\n            current_row = [i + 1]\n            for j, c2 in enumerate(s2):\n                insertions = previous_row[j + 1] + 1\n                deletions = current_row[j] + 1\n                substitutions = previous_row[j] + (c1 != c2)\n                current_row.append(min(insertions, deletions, substitutions))\n            previous_row = current_row\n\n        return previous_row[-1]\n\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"Task description\"\"\"\n        return f\"\"\"You are a string generation expert.\n\nTask: Create a function generate_string() that generates the target string \"{self.target}\".\n\nRequirements:\n- Define function generate_string() -&gt; str\n- Function should return a string as close as possible to the target string\n\nExample code:\n    def generate_string():\n        return \"Hello, World!\"\n\"\"\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"Create initial solution\"\"\"\n        initial_code = f'''def generate_string():\n    \"\"\"Initial simple implementation\"\"\"\n    return \"\"\n'''\n        eval_res = self.evaluate_code(initial_code)\n        return Solution(\n            sol_string=initial_code,\n            evaluation_res=eval_res\n        )\n</code></pre> <p>Usage:</p> <pre><code>task = StringMatchTask(\"Hello, EvoToolkit!\")\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface, './results', llm_api)\nprint(f\"Generated string: {result.evaluation_res.additional_info['generated']}\")\n</code></pre>"},{"location":"tutorials/customization/custom-task/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/customization/custom-task/#1-robust-error-handling","title":"1. Robust Error Handling","text":"<pre><code>def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n    \"\"\"Implement robust error handling in _evaluate_code_impl\"\"\"\n    try:\n        # Execution and evaluation logic\n        namespace = {}\n        exec(candidate_code, namespace)\n        # ... evaluation logic ...\n\n        return EvaluationResult(\n            valid=True,\n            score=score,\n            additional_info={}\n        )\n    except SyntaxError as e:\n        return EvaluationResult(\n            valid=False,\n            score=float('-inf'),\n            additional_info={'error': f'Syntax error: {str(e)}'}\n        )\n    except Exception as e:\n        return EvaluationResult(\n            valid=False,\n            score=float('-inf'),\n            additional_info={'error': f'Evaluation error: {str(e)}'}\n        )\n</code></pre> <p>Note: PythonTask's parent method <code>evaluate_code()</code> already provides timeout control. Set the <code>timeout_seconds</code> parameter in the constructor.</p>"},{"location":"tutorials/customization/custom-task/#2-validate-solution-output","title":"2. Validate Solution Output","text":"<pre><code>def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n    \"\"\"Validate function output type and range\"\"\"\n    namespace = {}\n    exec(candidate_code, namespace)\n\n    evolved_func = namespace['my_function']\n    result = evolved_func(test_input)\n\n    # Validate type\n    if not isinstance(result, (int, float, np.ndarray)):\n        return EvaluationResult(\n            valid=False,\n            score=float('-inf'),\n            additional_info={'error': 'Invalid output type'}\n        )\n\n    # Validate range\n    if isinstance(result, np.ndarray):\n        if np.any(np.isnan(result)) or np.any(np.isinf(result)):\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': 'Output contains NaN or Inf'}\n            )\n\n    # Compute fitness\n    score = -abs(result - expected)  # Negative error, higher is better\n    return EvaluationResult(valid=True, score=score, additional_info={})\n</code></pre>"},{"location":"tutorials/customization/custom-task/#3-store-task-metadata-in-task_info","title":"3. Store Task Metadata in task_info","text":"<pre><code>def _process_data(self, data):\n    \"\"\"Store important task metadata in task_info\"\"\"\n    self.data = data\n    self.task_info = {\n        'data_size': len(data),\n        'input_dim': data.shape[1] if len(data.shape) &gt; 1 else 1,\n        'description': 'Custom optimization task',\n        'metric': 'MSE',\n        # Other useful metadata...\n    }\n</code></pre>"},{"location":"tutorials/customization/custom-task/#advanced-custom-interface","title":"Advanced: Custom Interface","text":"<p>If you need more fine-grained control, you can customize interfaces for different evolutionary methods. Different methods (such as EvoEngineer, FunSearch, EoH) have their own interface implementations, which control prompt generation, LLM response parsing, and other behaviors.</p> <p>For details on how to customize evolutionary methods and interfaces, please refer to the Customizing Evolution Methods Tutorial.</p>"},{"location":"tutorials/customization/custom-task/#complete-example","title":"Complete Example","text":"<p>See <code>examples/custom_task/my_custom_task.py</code> for a complete runnable example.</p>"},{"location":"tutorials/customization/custom-task/#next-steps","title":"Next Steps","text":"<ul> <li>Try the CUDA Task Tutorial for GPU optimization</li> <li>Explore Advanced Usage for low-level API</li> <li>Check the API Reference for Task class details</li> </ul>"},{"location":"tutorials/customization/customizing-evolution/","title":"Customizing Evolution Methods","text":"<p>Learn how to customize evolutionary behavior in EvoToolkit by modifying prompts or developing entirely new algorithms.</p>"},{"location":"tutorials/customization/customizing-evolution/#overview","title":"Overview","text":"<p>The quality of evolutionary optimization in EvoToolkit is controlled by:</p> <ol> <li>Evolution Method: The algorithm framework (EvoEngineer, EoH, FunSearch)</li> <li>Interface: The bridge between tasks and methods, containing prompt logic</li> <li>Prompts: Instructions sent to the LLM to guide solution generation</li> </ol> <p>This tutorial covers two levels of customization:</p> <ul> <li>Level 1: Customize prompts - Inherit existing Interfaces and modify prompts (recommended)</li> <li>Level 2: Develop new algorithms - Create entirely new evolutionary strategies (advanced)</li> </ul>"},{"location":"tutorials/customization/customizing-evolution/#level-1-customizing-prompts","title":"Level 1: Customizing Prompts","text":""},{"location":"tutorials/customization/customizing-evolution/#11-understanding-interfaces","title":"1.1 Understanding Interfaces","text":"<p>Each evolution method uses an Interface class that:</p> <ul> <li>Defines operators (init, mutation, crossover, etc.)</li> <li>Generates LLM prompts for each operator via <code>get_operator_prompt()</code></li> <li>Parses LLM responses into solutions</li> </ul> <p>Available Interfaces:</p> Interface Method Description <code>EvoEngineerPythonInterface</code> EvoEngineer Main LLM-driven algorithm for Python tasks <code>EoHPythonInterface</code> EoH Evolution of Heuristics for Python tasks <code>FunSearchPythonInterface</code> FunSearch Function search for Python tasks <code>EvoEngineerCUDAInterface</code> EvoEngineer For CUDA code evolution"},{"location":"tutorials/customization/customizing-evolution/#12-inspecting-existing-prompts","title":"1.2 Inspecting Existing Prompts","text":"<p>Before customizing, examine how existing Interfaces generate prompts:</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\nimport inspect\n\n# Create an interface\ninterface = EvoEngineerPythonInterface(task)\n\n# View the source code of the prompt generation method\nprint(inspect.getsource(interface.get_operator_prompt))\n</code></pre> <p>This shows you:</p> <ul> <li>What information is included in prompts</li> <li>How prompts are structured</li> <li>What format LLMs are expected to follow</li> </ul>"},{"location":"tutorials/customization/customizing-evolution/#13-creating-custom-interfaces","title":"1.3 Creating Custom Interfaces","text":"<p>To customize prompts, inherit from an existing Interface and override <code>get_operator_prompt()</code>:</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.core import Solution\nfrom typing import List\n\nclass CustomInterface(EvoEngineerPythonInterface):\n    \"\"\"Custom Interface with modified prompts\"\"\"\n\n    def get_operator_prompt(self, operator_name: str,\n                           selected_individuals: List[Solution],\n                           current_best_sol: Solution,\n                           random_thoughts: List[str],\n                           **kwargs) -&gt; List[dict]:\n        \"\"\"Override this method to customize prompts for any operator\"\"\"\n\n        # Get base task description\n        task_description = self.task.get_base_task_description()\n\n        if operator_name == \"mutation\":\n            # Custom mutation prompt\n            prompt = f\"\"\"You are an expert optimizer.\nCurrent best solution score: {current_best_sol.evaluation_res.score:.5f}\n\nYour task: {task_description}\n\nCurrent code:\n{current_best_sol.sol_string}\n\nGenerate an improved solution by applying a mutation.\nFocus on: [YOUR CUSTOM REQUIREMENTS HERE]\n\nFormat:\n- name: descriptive_name\n- code: [complete code]\n- thought: [reasoning]\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"crossover\":\n            # Custom crossover prompt\n            parent1, parent2 = selected_individuals[0], selected_individuals[1]\n            prompt = f\"\"\"Combine these two solutions...\nParent 1 (score {parent1.evaluation_res.score:.5f}):\n{parent1.sol_string}\n\nParent 2 (score {parent2.evaluation_res.score:.5f}):\n{parent2.sol_string}\n\nCreate an offspring combining their strengths...\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # Use default implementation for other operators\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# Use your custom Interface\ncustom_interface = CustomInterface(task)\nresult = evotoolkit.solve(\n    interface=custom_interface,\n    output_path='./custom_results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#14-prompt-engineering-best-practices","title":"1.4 Prompt Engineering Best Practices","text":"<p>When customizing prompts:</p>"},{"location":"tutorials/customization/customizing-evolution/#141-be-specific-about-requirements","title":"1.4.1 Be Specific About Requirements","text":"<pre><code># Vague\nprompt = \"Improve this code\"\n\n# Specific\nprompt = \"\"\"Improve this code by:\n1. Reducing computational complexity\n2. Maintaining numerical stability\n3. Ensuring correctness on edge cases\"\"\"\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#142-provide-context-and-examples","title":"1.4.2 Provide Context and Examples","text":"<pre><code>prompt = f\"\"\"Task: {task_description}\n\nGood practices:\n- Use vectorized NumPy operations\n- Avoid loops when possible\n- Handle edge cases (empty arrays, zero values)\n\nBad practices:\n- Explicit Python loops over large arrays\n- Division without checking for zeros\n\nCurrent code:\n{current_best_sol.sol_string}\n\nGenerate an improved version...\"\"\"\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#143-include-domain-knowledge","title":"1.4.3 Include Domain Knowledge","text":"<pre><code># For scientific regression\nprompt = \"\"\"Base equations on known physical/biological principles:\n- Monod equation for substrate limitation: \u03bc = \u03bcmax * S / (Ks + S)\n- Arrhenius equation for temperature: k = A * exp(-Ea / RT)\n- Logistic growth for population dynamics\n...\"\"\"\n\n# For CUDA optimization\nprompt = \"\"\"Apply GPU optimization techniques:\n- Coalesced memory access\n- Shared memory for frequently accessed data\n- Minimize divergent branches\n...\"\"\"\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#144-customize-by-operator-type","title":"1.4.4 Customize by Operator Type","text":"<p>Different operators benefit from different prompts:</p> <pre><code>def get_operator_prompt(self, operator_name, ...):\n    if operator_name == \"init\":\n        # Initial exploration - encourage diversity\n        prompt = \"Explore diverse solution approaches...\"\n\n    elif operator_name == \"mutation\":\n        # Local search - small improvements\n        prompt = \"Make incremental improvements to current solution...\"\n\n    elif operator_name == \"crossover\":\n        # Combine features - recombination\n        prompt = \"Combine strengths from both parent solutions...\"\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#level-2-developing-new-algorithms","title":"Level 2: Developing New Algorithms","text":"<p>Advanced Topic</p> <p>This section is for users who want to implement entirely new evolutionary strategies. Most users should start with Level 1 (customizing prompts) which is often sufficient.</p>"},{"location":"tutorials/customization/customizing-evolution/#21-when-to-develop-new-algorithms","title":"2.1 When to Develop New Algorithms","text":"<p>Consider developing a new algorithm when:</p> <ul> <li>Existing algorithms (EvoEngineer, EoH, FunSearch) don't fit your problem structure</li> <li>You have domain-specific evolutionary strategies</li> <li>You want to research novel LLM-driven optimization approaches</li> <li>You need completely different evolutionary workflows or selection mechanisms</li> </ul>"},{"location":"tutorials/customization/customizing-evolution/#22-algorithm-architecture","title":"2.2 Algorithm Architecture","text":"<p>EvoToolkit uses a three-layer architecture to implement new algorithms:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Layer 1: Algorithm Class               \u2502\n\u2502  - Inherits from Method base class      \u2502\n\u2502  - Implements run() method (main loop)  \u2502\n\u2502  - Defines Config class (parameters)    \u2502\n\u2502  Location: evo_method/your_algorithm/   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Layer 2: Generic Interface Base Class  \u2502\n\u2502  - Only requires: make_init_sol()       \u2502\n\u2502  -               parse_response()       \u2502\n\u2502  - Other methods: algorithm-specific    \u2502\n\u2502  Location: core/method_interface/       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Layer 3: Task-Specific Interface       \u2502\n\u2502  - Inherits from generic Interface      \u2502\n\u2502  - Implements task-specific logic       \u2502\n\u2502  Location: task/*/method_interface/     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Interface Design Flexibility</p> <p>Core Requirements: <code>BaseMethodInterface</code> only mandates two methods:</p> <ul> <li><code>make_init_sol()</code> - Create initial solution</li> <li><code>parse_response(response_str)</code> - Parse LLM response</li> </ul> <p>Algorithm-Specific Methods: All other methods are defined by your algorithm's needs:</p> <ul> <li>Operator-based (like EvoEngineer): <code>get_init_operators()</code>, <code>get_offspring_operators()</code>, <code>get_operator_prompt()</code></li> <li>Iterative (like FunSearch): <code>generate_evolution_prompt()</code></li> <li>Your design: Define any methods your algorithm requires</li> </ul> <p>Existing Algorithm Examples:</p> <ul> <li>EvoEngineer: <code>evo_method/evoengineer/evoengineer.py</code> (Layer 1) \u2192 <code>core/method_interface/evoengineer_interface.py</code> (Layer 2) \u2192 <code>task/python_task/method_interface/evoengineer_interface.py</code> (Layer 3)</li> <li>EoH: <code>evo_method/eoh/</code> \u2192 <code>core/method_interface/eoh_interface.py</code> \u2192 <code>task/python_task/method_interface/eoh_interface.py</code></li> <li>FunSearch: <code>evo_method/funsearch/</code> \u2192 <code>core/method_interface/funsearch_interface.py</code> \u2192 <code>task/python_task/method_interface/funsearch_interface.py</code></li> </ul>"},{"location":"tutorials/customization/customizing-evolution/#23-creating-a-new-algorithm","title":"2.3 Creating a New Algorithm","text":"<p>Complete Implementation Required</p> <p>Creating a new algorithm requires implementing all three layers. For most customization needs, Level 1 (custom prompts) is sufficient.</p> <p>Due to the complexity of implementing a full three-layer architecture, we recommend:</p> <ol> <li>Study existing implementations - See section 2.4 below</li> <li>Start with prompt customization (Level 1) - Much easier and often sufficient</li> <li>Extend existing algorithms - Inherit from EvoEngineerInterface rather than creating from scratch</li> </ol> <p>For a complete implementation guide, refer to the existing algorithm implementations in the source code</p>"},{"location":"tutorials/customization/customizing-evolution/#24-example-temperature-based-mutation-algorithm","title":"2.4 Example: Temperature-based Mutation Algorithm","text":"<p>Here's a complete example of a custom algorithm with temperature-controlled mutation:</p> <pre><code>from evotoolkit.core import EvoEngineerInterface, Operator, Solution\nfrom evotoolkit.task.python_task import PythonTask\nfrom typing import List\nimport math\n\nclass TemperatureBasedEvolution(EvoEngineerInterface):\n    \"\"\"Custom algorithm with simulated annealing-style temperature\"\"\"\n\n    def __init__(self, task: PythonTask, initial_temp=10.0, cooling_rate=0.9):\n        super().__init__(task)\n        self.temperature = initial_temp\n        self.cooling_rate = cooling_rate\n        self.generation = 0\n\n    def get_init_operators(self):\n        return [Operator(\"init\", 0)]\n\n    def get_offspring_operators(self):\n        return [\n            Operator(\"hot_mutation\", 1),   # Large changes\n            Operator(\"cool_mutation\", 1),  # Small changes\n            Operator(\"crossover\", 2),\n        ]\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n\n        task_description = self.task.get_base_task_description()\n\n        # Cool down temperature each generation\n        self.temperature *= self.cooling_rate\n        self.generation += 1\n\n        if operator_name == \"init\":\n            prompt = f\"\"\"Initialize solution for: {task_description}\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"hot_mutation\":\n            # High temperature = large changes\n            if self.temperature &gt; 5.0:\n                prompt = f\"\"\"Make a BOLD, exploratory change to:\n{selected_individuals[0].sol_string}\n\nTry a completely different approach or algorithm.\n\"\"\"\n            else:\n                # Fallback to regular mutation at low temp\n                prompt = f\"\"\"Make a moderate change to:\n{selected_individuals[0].sol_string}\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"cool_mutation\":\n            # Low temperature = small refinements\n            prompt = f\"\"\"Make a SMALL, refinement change to:\n{selected_individuals[0].sol_string}\n\nFocus on minor improvements: better constants, edge cases, small optimizations.\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"crossover\":\n            parent1, parent2 = selected_individuals[0], selected_individuals[1]\n            prompt = f\"\"\"Combine these solutions:\nParent 1 (score {parent1.evaluation_res.score}):\n{parent1.sol_string}\n\nParent 2 (score {parent2.evaluation_res.score}):\n{parent2.sol_string}\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n# Use the custom algorithm\ntask = MyTask(...)\nalgo = TemperatureBasedEvolution(task, initial_temp=10.0, cooling_rate=0.9)\nresult = evotoolkit.solve(interface=algo, running_llm=llm_api, max_generations=20)\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#task-specific-customization-examples","title":"Task-Specific Customization Examples","text":""},{"location":"tutorials/customization/customizing-evolution/#31-for-scientific-regression","title":"3.1 For Scientific Regression","text":"<pre><code>class ScientificInterface(EvoEngineerPythonInterface):\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        if operator_name == \"mutation\":\n            prompt = f\"\"\"You are a physicist/biologist discovering equations.\n\nCurrent equation (MSE: {current_best_sol.evaluation_res.score:.6f}):\n{current_best_sol.sol_string}\n\nUse established principles:\n- Monod: \u03bc = \u03bcmax * S / (Ks + S)\n- Arrhenius: k = A * exp(-Ea / RT)\n- Michaelis-Menten kinetics\n- Logistic growth\n\nConstraints:\n- Ensure dimensional consistency\n- Avoid numerical instabilities\n- Keep model parsimonious\n\nGenerate improved equation...\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#32-for-cuda-optimization","title":"3.2 For CUDA Optimization","text":"<pre><code>class CUDAInterface(EvoEngineerCUDAInterface):\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        if operator_name == \"mutation\":\n            prompt = f\"\"\"You are a GPU optimization expert.\n\nCurrent CUDA kernel (time: {current_best_sol.evaluation_res.score:.3f}ms):\n{current_best_sol.sol_string}\n\nApply optimizations:\n- Coalesced memory access patterns\n- Shared memory for temporary data\n- Reduce bank conflicts\n- Minimize thread divergence\n- Optimize block/grid dimensions\n\nGenerate optimized kernel...\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#33-for-prompt-engineering","title":"3.3 For Prompt Engineering","text":"<pre><code>class PromptOptimizationInterface(EvoEngineerPythonInterface):\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        if operator_name == \"mutation\":\n            prompt = f\"\"\"You are an expert in LLM prompt engineering.\n\nCurrent prompt (score: {current_best_sol.evaluation_res.score:.3f}):\n{current_best_sol.sol_string}\n\nImprovement strategies:\n- Add clear instructions and structure\n- Provide relevant examples\n- Specify output format\n- Include constraints and guidelines\n- Use appropriate tone and style\n\nGenerate improved prompt...\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#testing-and-debugging","title":"Testing and Debugging","text":""},{"location":"tutorials/customization/customizing-evolution/#41-logging-prompts","title":"4.1 Logging Prompts","text":"<p>To see what prompts are sent to the LLM:</p> <pre><code>class DebugInterface(EvoEngineerPythonInterface):\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n\n        prompts = super().get_operator_prompt(operator_name, selected_individuals,\n                                             current_best_sol, random_thoughts, **kwargs)\n\n        # Log prompts for debugging\n        print(f\"\\n{'='*60}\")\n        print(f\"OPERATOR: {operator_name}\")\n        print(f\"PROMPT:\\n{prompts[0]['content']}\")\n        print(f\"{'='*60}\\n\")\n\n        return prompts\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#42-validating-custom-interfaces","title":"4.2 Validating Custom Interfaces","text":"<p>Before running full evolution, test your Interface:</p> <pre><code># Create interface\ninterface = CustomInterface(task)\n\n# Get initial solution\ninit_sol = task.make_init_sol_wo_other_info()\n\n# Test prompt generation for each operator\nfor op in interface.get_offspring_operators():\n    prompts = interface.get_operator_prompt(\n        operator_name=op.name,\n        selected_individuals=[init_sol],\n        current_best_sol=init_sol,\n        random_thoughts=[]\n    )\n    print(f\"Operator {op.name}:\")\n    print(prompts[0]['content'][:200] + \"...\")\n    print()\n</code></pre>"},{"location":"tutorials/customization/customizing-evolution/#next-steps","title":"Next Steps","text":"<ul> <li>Experiment: Try different prompt styles and see what works best</li> <li>Analyze: Compare results across different customizations</li> <li>Share: Consider contributing successful customizations to the project</li> </ul> <p>Related Documentation:</p> <ul> <li>Scientific Regression Tutorial - Example application</li> <li>CUDA Task Tutorial - GPU code optimization</li> <li>Advanced Usage - More configuration options</li> <li>API Reference - Complete Interface API docs</li> <li>Contributing - Share your custom methods</li> </ul>"},{"location":"zh/","title":"EvoToolkit","text":"<p>LLM\u9a71\u52a8\u7684\u89e3\u8fdb\u5316\u4f18\u5316\u5de5\u5177\u5305</p> <p>EvoToolkit \u662f\u4e00\u4e2a Python \u5e93\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u8fdb\u5316\u4f18\u5316\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b83\u7ed3\u5408\u4e86\u8fdb\u5316\u7b97\u6cd5\u7684\u5f3a\u5927\u80fd\u529b\u4e0e\u57fa\u4e8e LLM \u7684\u89e3\u751f\u6210\u548c\u6539\u8fdb\uff0c\u652f\u6301\u4ee3\u7801\u3001\u6587\u672c\u53ca\u5176\u4ed6\u53ef\u8bc4\u4f30\u7684\u8868\u793a\u5f62\u5f0f\u3002</p>"},{"location":"zh/#_1","title":"\u2728 \u4e3b\u8981\u7279\u6027","text":"<ul> <li>\ud83e\udd16 LLM \u9a71\u52a8\u8fdb\u5316: \u4f7f\u7528\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u751f\u6210\u548c\u8fdb\u5316\u89e3\u51b3\u65b9\u6848</li> <li>\ud83d\udd2c \u591a\u79cd\u7b97\u6cd5: \u652f\u6301 EoH\u3001EvoEngineer \u548c FunSearch \u8fdb\u5316\u65b9\u6cd5</li> <li>\ud83c\udf0d \u4efb\u52a1\u65e0\u5173: \u652f\u6301\u4efb\u4f55\u53ef\u8bc4\u4f30\u7684\u4f18\u5316\u4efb\u52a1\uff08\u4ee3\u7801\u3001\u6587\u672c\u3001\u6570\u5b66\u8868\u8fbe\u5f0f\u7b49\uff09</li> <li>\ud83c\udfaf \u53ef\u6269\u5c55\u6846\u67b6: \u6613\u4e8e\u6269\u5c55\u7684\u4efb\u52a1\u7cfb\u7edf\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u4f18\u5316\u95ee\u9898</li> <li>\ud83d\udd0c \u7b80\u5355 API: \u9ad8\u7ea7 <code>evotoolkit.solve()</code> \u51fd\u6570\uff0c\u5feb\u901f\u539f\u578b\u5f00\u53d1</li> <li>\ud83d\udee0\ufe0f \u9ad8\u7ea7\u5b9a\u5236: \u4f4e\u7ea7 API\uff0c\u63d0\u4f9b\u7cbe\u7ec6\u5316\u63a7\u5236</li> </ul>"},{"location":"zh/#_2","title":"\u5185\u7f6e\u4efb\u52a1\u7c7b\u578b","text":"\u4efb\u52a1\u7c7b\u578b \u63cf\u8ff0 \u8be6\u60c5 \ud83d\udd2c \u79d1\u5b66\u7b26\u53f7\u56de\u5f52 \u5728\u771f\u5b9e\u79d1\u5b66\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7b26\u53f7\u56de\u5f52 \u79d1\u5b66\u56de\u5f52\u6559\u7a0b \ud83d\udcac \u63d0\u793a\u8bcd\u5de5\u7a0b \u4f18\u5316 LLM prompts \u4ee5\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd \u63d0\u793a\u8bcd\u5de5\u7a0b\u6559\u7a0b \ud83d\udee1\ufe0f \u5bf9\u6297\u653b\u51fb \u8fdb\u5316\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5 \u5bf9\u6297\u653b\u51fb\u6559\u7a0b \u26a1 CUDA \u4ee3\u7801\u8fdb\u5316 \u8fdb\u5316\u548c\u4f18\u5316 CUDA kernels CUDA \u4efb\u52a1\u6559\u7a0b"},{"location":"zh/#_3","title":"\ud83d\ude80 \u5feb\u901f\u5f00\u59cb","text":""},{"location":"zh/#_4","title":"\u5b89\u88c5","text":"<pre><code>pip install evotoolkit\n\n# \u6216\u5b89\u88c5\u5168\u90e8\u4f9d\u8d56\npip install evotoolkit[all]\n</code></pre> <p>\u8be6\u7ec6\u5b89\u88c5\u8bf4\u660e\u8bf7\u53c2\u9605\u5b89\u88c5\u6307\u5357\u3002</p>"},{"location":"zh/#_5","title":"\u7b2c\u4e00\u4e2a\u4f18\u5316\u4efb\u52a1","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools import HttpsApi\n\n# 1. \u521b\u5efa\u4efb\u52a1\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\n\n# 2. \u521b\u5efa\u63a5\u53e3\ninterface = EvoEngineerPythonInterface(task)\n\n# 3. \u4f7f\u7528 LLM \u6c42\u89e3\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"your-api-key-here\",\n    model=\"gpt-4o\"\n)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre> <p>\u5c31\u662f\u8fd9\u4e48\u7b80\u5355\uff01EvoToolkit \u5c06\u4f7f\u7528 LLM \u8fdb\u5316\u6570\u5b66\u65b9\u7a0b\u6765\u62df\u5408\u60a8\u7684\u79d1\u5b66\u6570\u636e\u3002</p> <p>\u5b8c\u6574\u7684\u6f14\u793a\u8bf7\u67e5\u770b\u5feb\u901f\u5f00\u59cb\u6307\u5357\u3002</p>"},{"location":"zh/#_6","title":"\ud83d\udcda \u53ef\u7528\u7b97\u6cd5","text":"\u7b97\u6cd5 \u63cf\u8ff0 EvoEngineer \u4e3b\u8981\u7684 LLM \u9a71\u52a8\u8fdb\u5316\u7b97\u6cd5 FunSearch \u51fd\u6570\u641c\u7d22\u4f18\u5316\u65b9\u6cd5 EoH \u542f\u53d1\u5f0f\u8fdb\u5316 <p>\u67e5\u770b\u6559\u7a0b\u4e86\u89e3\u66f4\u591a\u4f7f\u7528\u793a\u4f8b\u3002</p>"},{"location":"zh/#_7","title":"\ud83d\udcd6 \u6587\u6863","text":"<ul> <li>\u5b89\u88c5: \u5b89\u88c5\u8bf4\u660e\u548c\u8bbe\u7f6e</li> <li>\u5feb\u901f\u5f00\u59cb: \u5feb\u901f\u5165\u95e8\u6307\u5357\u548c\u57fa\u672c\u7528\u6cd5</li> <li>\u6559\u7a0b: \u5e38\u89c1\u4efb\u52a1\u7684\u5206\u6b65\u6559\u7a0b</li> <li>API \u53c2\u8003: \u8be6\u7ec6\u7684 API \u6587\u6863</li> <li>\u5f00\u53d1: \u8d21\u732e\u6307\u5357\u548c\u67b6\u6784</li> </ul>"},{"location":"zh/#_8","title":"\ud83d\udd17 \u94fe\u63a5","text":"<ul> <li>GitHub: https://github.com/pgg3/evotoolkit</li> <li>PyPI: https://pypi.org/project/evotoolkit/</li> <li>\u8bba\u6587: arXiv\uff08\u5df2\u63d0\u4ea4\uff09</li> </ul>"},{"location":"zh/#_9","title":"\ud83d\udcc4 \u8bb8\u53ef\u8bc1","text":"<p>EvoToolkit \u91c7\u7528\u53cc\u91cd\u8bb8\u53ef\uff1a</p> <ul> <li>\u5b66\u672f\u4e0e\u5f00\u6e90\u4f7f\u7528: \u514d\u8d39\u7528\u4e8e\u5b66\u672f\u7814\u7a76\u3001\u6559\u80b2\u548c\u5f00\u6e90\u9879\u76ee\u3002\u5b66\u672f\u51fa\u7248\u7269\u4e2d \u9700\u8981\u5f15\u7528\u3002</li> <li>\u5546\u4e1a\u4f7f\u7528: \u9700\u8981\u5355\u72ec\u7684\u5546\u4e1a\u8bb8\u53ef\u8bc1\u3002\u8bf7\u8054\u7cfb pguo6680@gmail.com \u83b7\u53d6\u8bb8\u53ef\u3002</li> </ul> <p>\u8be6\u7ec6\u6761\u6b3e\u8bf7\u53c2\u9605 LICENSE\u3002</p>"},{"location":"zh/#_10","title":"\ud83d\ude4f \u5f15\u7528","text":"<p>\u5982\u679c\u60a8\u5728\u7814\u7a76\u4e2d\u4f7f\u7528 EvoToolkit\uff0c\u8bf7\u5f15\u7528\uff1a</p> <pre><code>@article{guo2025evotoolkit,\n  title={evotoolkit: A Unified LLM-Driven Evolutionary Framework for Generalized Solution Search},\n  author={Guo, Ping and Zhang, Qingfu},\n  journal={arXiv preprint arXiv:XXXX.XXXXX},\n  year={2025},\n  note={Submitted to arXiv}\n}\n</code></pre>"},{"location":"zh/#_11","title":"\ud83d\udcac \u83b7\u53d6\u5e2e\u52a9","text":"<ul> <li>\u95ee\u9898: GitHub Issues</li> <li>\u8ba8\u8bba: GitHub Discussions</li> <li>\u90ae\u7bb1: pguo6680@gmail.com</li> </ul>"},{"location":"zh/getting-started/","title":"\u5feb\u901f\u5f00\u59cb","text":"<p>\u672c\u6307\u5357\u5c06\u5f15\u5bfc\u60a8\u5b8c\u6210\u4f7f\u7528 EvoToolkit \u7684\u7b2c\u4e00\u4e2a\u4f18\u5316\u4efb\u52a1\u3002</p>"},{"location":"zh/getting-started/#_2","title":"\u5feb\u901f\u5f00\u59cb","text":"<p>\u51e0\u5206\u949f\u5185\u521b\u5efa\u65b0\u9879\u76ee\u5e76\u8fd0\u884c\u60a8\u7684\u7b2c\u4e00\u4e2a\u4f18\u5316\uff1a</p> <pre><code>mkdir my-evotool-project\ncd my-evotool-project\n</code></pre> <p>\u7136\u540e\u6309\u7167\u4e0b\u9762\u7684\u6307\u5357\u521b\u5efa\u60a8\u7684\u7b2c\u4e00\u4e2a\u4f18\u5316\u811a\u672c\u3002</p>"},{"location":"zh/getting-started/#_3","title":"\u4e3b\u9898","text":"<ul> <li>\u7b2c\u4e00\u4e2a\u4f18\u5316\u4efb\u52a1: \u7b2c\u4e00\u4e2a\u4f18\u5316\u4efb\u52a1\uff1a\u79d1\u5b66\u7b26\u53f7\u56de\u5f52</li> <li>\u7406\u89e3\u4ee3\u7801: \u7406\u89e3\u4ee3\u7801</li> <li>\u63a2\u7d22\u7ed3\u679c: \u63a2\u7d22\u7ed3\u679c</li> <li>\u5c1d\u8bd5\u4e0d\u540c\u7684\u7b97\u6cd5: \u5c1d\u8bd5\u4e0d\u540c\u7684\u7b97\u6cd5</li> <li>\u4e0b\u4e00\u6b65: \u4e0b\u4e00\u6b65</li> </ul> <p>\u63a5\u4e0b\u6765\uff0c\u67e5\u770b\u6559\u7a0b\uff1a \u6559\u7a0b</p>"},{"location":"zh/installation/","title":"\u5b89\u88c5","text":"<p>\u672c\u8282\u5e2e\u52a9\u60a8\u5b8c\u6210 EvoToolkit \u7684\u5b89\u88c5\u4e0e\u73af\u5883\u8bbe\u7f6e\u3002</p>"},{"location":"zh/installation/#_2","title":"\u5feb\u901f\u5b89\u88c5","text":"<pre><code>pip install evotoolkit\n</code></pre>"},{"location":"zh/installation/#_3","title":"\u5185\u5bb9\u5bfc\u822a","text":"<ul> <li>\u7cfb\u7edf\u8981\u6c42\uff1a \u7cfb\u7edf\u8981\u6c42</li> <li>\u4ece PyPI \u5b89\u88c5\uff1a \u4ece PyPI \u5b89\u88c5</li> <li>\u4ece\u6e90\u7801\u5b89\u88c5\uff1a \u4ece\u6e90\u7801\u5b89\u88c5</li> <li>\u73af\u5883\u4e0e\u5305\u7ba1\u7406\u5668\uff1a \u73af\u5883\u4e0e\u5305\u7ba1\u7406\u5668</li> <li>LLM \u8bbe\u7f6e\u4e0e\u9a8c\u8bc1\uff1a LLM \u8bbe\u7f6e\u4e0e\u9a8c\u8bc1</li> <li>\u5e38\u89c1\u95ee\u9898\uff1a \u5e38\u89c1\u95ee\u9898</li> </ul> <p>\u63a5\u4e0b\u6765\u53ef\u67e5\u770b\uff1a\u5feb\u901f\u5f00\u59cb</p>"},{"location":"zh/api/","title":"API \u53c2\u8003","text":"<p>\u6b22\u8fce\u6765\u5230 EvoToolkit API \u53c2\u8003\u6587\u6863\u3002\u672c\u8282\u63d0\u4f9b\u6240\u6709\u516c\u5171 API\u3001\u7c7b\u548c\u51fd\u6570\u7684\u8be6\u7ec6\u4fe1\u606f\u3002</p>"},{"location":"zh/api/#_1","title":"\u6982\u8ff0","text":"<p>EvoToolkit \u7ec4\u7ec7\u4e3a\u51e0\u4e2a\u4e3b\u8981\u6a21\u5757\uff1a</p> <ul> <li>\u6838\u5fc3 API: \u6838\u5fc3\u529f\u80fd\uff0c\u5305\u62ec <code>evotoolkit.solve()</code>\u3001<code>Solution</code>\u3001<code>Task</code> \u548c\u57fa\u7c7b</li> <li>\u4efb\u52a1: \u5185\u7f6e\u4f18\u5316\u4efb\u52a1\uff08Python \u548c CUDA\uff09</li> <li>\u65b9\u6cd5: \u8fdb\u5316\u7b97\u6cd5\uff08EoH\u3001EvoEngineer\u3001FunSearch\uff09</li> <li>\u63a5\u53e3: \u8fde\u63a5\u4efb\u52a1\u548c\u7b97\u6cd5\u7684\u65b9\u6cd5\u63a5\u53e3</li> <li>\u5de5\u5177: \u5b9e\u7528\u5de5\u5177\u548c LLM API \u5ba2\u6237\u7aef</li> </ul>"},{"location":"zh/api/#api_1","title":"\u5feb\u901f API \u53c2\u8003","text":""},{"location":"zh/api/#api_2","title":"\u9ad8\u7ea7 API","text":"<p>\u4f7f\u7528 EvoToolkit \u7684\u6700\u7b80\u5355\u65b9\u5f0f\uff1a</p> <pre><code>import evotoolkit\n\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre> <p>\u8be6\u89c1 \u6838\u5fc3 API: evotoolkit.solve()\u3002</p>"},{"location":"zh/api/#_2","title":"\u6838\u5fc3\u7c7b","text":"\u7c7b \u63cf\u8ff0 \u6587\u6863 <code>Solution</code> \u8868\u793a\u5019\u9009\u89e3 \u6838\u5fc3 API <code>Task</code> \u4f18\u5316\u4efb\u52a1\u57fa\u7c7b \u6838\u5fc3 API <code>MethodInterface</code> \u7b97\u6cd5\u63a5\u53e3\u57fa\u7c7b \u63a5\u53e3"},{"location":"zh/api/#_3","title":"\u5185\u7f6e\u4efb\u52a1","text":"\u4efb\u52a1 \u63cf\u8ff0 \u6587\u6863 <code>ScientificRegressionTask</code> \u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4efb\u52a1 \u4efb\u52a1 <code>PythonTask</code> \u901a\u7528 Python \u4efb\u52a1 \u4efb\u52a1 <code>CudaTask</code> GPU \u5185\u6838\u4f18\u5316\u4efb\u52a1 \u4efb\u52a1"},{"location":"zh/api/#_4","title":"\u8fdb\u5316\u7b97\u6cd5","text":"\u7b97\u6cd5 \u63cf\u8ff0 \u6587\u6863 <code>EvoEngineer</code> \u4e3b\u8981\u7684 LLM \u9a71\u52a8\u8fdb\u5316\u7b97\u6cd5 \u65b9\u6cd5 <code>FunSearch</code> \u51fd\u6570\u641c\u7d22\u4f18\u5316 \u65b9\u6cd5 <code>EoH</code> \u542f\u53d1\u5f0f\u8fdb\u5316 \u65b9\u6cd5"},{"location":"zh/api/#api_3","title":"API \u8bbe\u8ba1\u7406\u5ff5","text":"<p>EvoToolkit \u63d0\u4f9b\u4e24\u4e2a\u7ea7\u522b\u7684 API\uff1a</p>"},{"location":"zh/api/#1-api","title":"1. \u9ad8\u7ea7 API\uff08\u63a8\u8350\uff09","text":"<p>\u901a\u8fc7 <code>evotoolkit.solve()</code> \u7684\u9ad8\u7ea7 API \u81ea\u52a8\u5904\u7406\u5927\u90e8\u5206\u590d\u6742\u6027\uff1a</p> <pre><code># \u521b\u5efa\u4efb\u52a1\u548c\u63a5\u53e3\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = EvoEngineerPythonInterface(task)\n\n# \u6c42\u89e3\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre> <p>\u4f18\u70b9: - \u7b80\u5355\u660e\u4e86 - \u81ea\u52a8\u914d\u7f6e - \u9002\u5408\u5927\u591a\u6570\u7528\u4f8b</p>"},{"location":"zh/api/#2-api","title":"2. \u4f4e\u7ea7 API\uff08\u9ad8\u7ea7\uff09","text":"<p>\u4f4e\u7ea7 API \u63d0\u4f9b\u7ec6\u7c92\u5ea6\u63a7\u5236\uff1a</p> <pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\n# \u521b\u5efa\u81ea\u5b9a\u4e49\u914d\u7f6e\nconfig = EvoEngineerConfig(\n    task=task,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    pop_size=10,\n    # ... \u66f4\u591a\u81ea\u5b9a\u4e49\u8bbe\u7f6e\n)\n\n# \u521b\u5efa\u5e76\u8fd0\u884c\u7b97\u6cd5\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# \u83b7\u53d6\u6700\u4f73\u89e3\nbest_solution = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n</code></pre> <p>\u4f18\u70b9: - \u5b8c\u5168\u81ea\u5b9a\u4e49 - \u8bbf\u95ee\u5185\u90e8\u72b6\u6001 - \u9ad8\u7ea7\u8c03\u8bd5</p> <p>\u8be6\u89c1 \u9ad8\u7ea7\u7528\u6cd5\u6559\u7a0b\u3002</p>"},{"location":"zh/api/#_5","title":"\u6a21\u5757\u7ec4\u7ec7","text":"<pre><code>evotool/\n\u251c\u2500\u2500 __init__.py              # \u9ad8\u7ea7 API (solve \u51fd\u6570)\n\u251c\u2500\u2500 core/                    # \u6838\u5fc3\u62bd\u8c61\n\u2502   \u251c\u2500\u2500 base_task.py        # Task \u57fa\u7c7b\n\u2502   \u251c\u2500\u2500 solution.py         # Solution \u7c7b\n\u2502   \u251c\u2500\u2500 base_method.py      # \u7b97\u6cd5\u57fa\u7c7b\n\u2502   \u251c\u2500\u2500 base_config.py      # \u914d\u7f6e\u57fa\u7c7b\n\u2502   \u2514\u2500\u2500 method_interface/   # \u7b97\u6cd5\u63a5\u53e3\n\u251c\u2500\u2500 evo_method/             # \u8fdb\u5316\u7b97\u6cd5\n\u2502   \u251c\u2500\u2500 eoh/               # EoH \u5b9e\u73b0\n\u2502   \u251c\u2500\u2500 evoengineer/       # EvoEngineer \u5b9e\u73b0\n\u2502   \u2514\u2500\u2500 funsearch/         # FunSearch \u5b9e\u73b0\n\u251c\u2500\u2500 task/                   # \u4efb\u52a1\u5b9e\u73b0\n\u2502   \u251c\u2500\u2500 python_task/       # Python \u4efb\u52a1\u6846\u67b6\n\u2502   \u251c\u2500\u2500 cuda_engineering/  # CUDA \u4efb\u52a1\u6846\u67b6\n\u2502   \u2514\u2500\u2500 string_optimization/ # \u5b57\u7b26\u4e32\u4f18\u5316\u4efb\u52a1\n\u251c\u2500\u2500 tools/                  # \u5de5\u5177\n\u2502   \u2514\u2500\u2500 llm.py             # LLM API \u5ba2\u6237\u7aef (HttpsApi)\n\u2514\u2500\u2500 data/                   # \u6570\u636e\u7ba1\u7406\u5de5\u5177\n</code></pre>"},{"location":"zh/api/#_6","title":"\u5e38\u89c1\u6a21\u5f0f","text":""},{"location":"zh/api/#1","title":"\u6a21\u5f0f 1: \u57fa\u672c\u4f18\u5316","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\n\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface, './results', llm_api, max_generations=5)\n</code></pre>"},{"location":"zh/api/#2","title":"\u6a21\u5f0f 2: \u81ea\u5b9a\u4e49\u4efb\u52a1","text":"<pre><code>from evotoolkit.core import BaseTask, Solution\n\nclass MyTask(BaseTask):\n    def evaluate(self, solution: Solution) -&gt; float:\n        # \u60a8\u7684\u8bc4\u4f30\u903b\u8f91\n        return fitness_value\n\ntask = MyTask()\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface, './results', llm_api)\n</code></pre>"},{"location":"zh/api/#3","title":"\u6a21\u5f0f 3: \u7b97\u6cd5\u6bd4\u8f83","text":"<pre><code>algorithms = [\n    ('EoH', EoHPythonInterface(task)),\n    ('EvoEngineer', EvoEngineerPythonInterface(task)),\n    ('FunSearch', FunSearchPythonInterface(task))\n]\n\nfor name, interface in algorithms:\n    result = evotoolkit.solve(interface, f'./results/{name}', llm_api)\n    print(f\"{name}: {result.fitness}\")\n</code></pre>"},{"location":"zh/api/#api_4","title":"API \u7248\u672c\u63a7\u5236","text":"<p>EvoToolkit \u9075\u5faa\u8bed\u4e49\u5316\u7248\u672c\uff1a</p> <ul> <li>\u4e3b\u7248\u672c (1.x.x): \u7834\u574f\u6027 API \u66f4\u6539</li> <li>\u6b21\u7248\u672c (x.1.x): \u65b0\u529f\u80fd\uff0c\u5411\u540e\u517c\u5bb9</li> <li>\u4fee\u8ba2\u7248\u672c (x.x.1): Bug \u4fee\u590d\uff0c\u5411\u540e\u517c\u5bb9</li> </ul> <p>\u68c0\u67e5\u5f53\u524d\u7248\u672c\uff1a</p> <pre><code>import evotoolkit\nprint(evotoolkit.__version__)  # \u4f8b\u5982 \"1.0.0\"\n</code></pre>"},{"location":"zh/api/#_7","title":"\u7c7b\u578b\u63d0\u793a","text":"<p>EvoToolkit \u5728\u6574\u4e2a\u4ee3\u7801\u5e93\u4e2d\u4f7f\u7528\u7c7b\u578b\u63d0\u793a\u3002\u4f7f\u7528 <code>mypy</code> \u7b49\u7c7b\u578b\u68c0\u67e5\u5668\u8fdb\u884c\u9759\u6001\u5206\u6790\uff1a</p> <pre><code>pip install mypy\nmypy your_script.py\n</code></pre>"},{"location":"zh/api/#_8","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u6d4f\u89c8 \u6838\u5fc3 API \u6587\u6863</li> <li>\u63a2\u7d22 \u4efb\u52a1 API \u4e86\u89e3\u5185\u7f6e\u4efb\u52a1</li> <li>\u67e5\u770b \u65b9\u6cd5 API \u4e86\u89e3\u8fdb\u5316\u7b97\u6cd5</li> <li>\u4e86\u89e3 \u63a5\u53e3 API \u7684\u7b97\u6cd5\u96c6\u6210</li> </ul>"},{"location":"zh/api/core/","title":"\u6838\u5fc3 API \u6982\u89c8","text":"<p>\u672c\u8282\u6587\u6863\u5316 EvoToolkit \u7684\u6838\u5fc3\u6784\u5efa\u5757\u3002\u4e3a\u4fdd\u6301\u9875\u9762\u7b80\u6d01\uff0c\u6bcf\u4e2a\u4e3b\u9898\u63d0\u4f9b\u5355\u72ec\u9875\u9762\u3002</p>"},{"location":"zh/api/core/#_1","title":"\u51fd\u6570","text":"<ul> <li>evotoolkit.solve()</li> <li>evotoolkit.list_algorithms()</li> <li>evotoolkit.list_tasks()</li> </ul>"},{"location":"zh/api/core/#_2","title":"\u7c7b","text":"<ul> <li>Solution</li> <li>BaseTask</li> <li>Method</li> <li>BaseConfig</li> <li>HistoryManager</li> <li>Operator</li> <li>BaseRunStateDict</li> </ul>"},{"location":"zh/api/core/#_3","title":"\u76f8\u5173","text":"<ul> <li>\u53c2\u89c1\u63a5\u53e3\u4e86\u89e3\u4efb\u52a1\u4e0e\u7b97\u6cd5\u7684\u8fde\u63a5\u9002\u914d\u5668\u3002</li> </ul>"},{"location":"zh/api/interfaces/","title":"\u63a5\u53e3 API","text":"<p>\u63a5\u53e3\u5c06\u4f18\u5316\u4efb\u52a1\u8fde\u63a5\u5230\u8fdb\u5316\u7b97\u6cd5\uff0c\u5904\u7406\u7279\u5b9a\u4e8e\u7b97\u6cd5\u7684\u9002\u914d\u3002</p>"},{"location":"zh/api/interfaces/#_1","title":"\u4ec0\u4e48\u662f\u63a5\u53e3\uff1f","text":"<p>\u63a5\u53e3**\u662f**\u4efb\u52a1\uff08\u60a8\u60f3\u8981\u4f18\u5316\u4ec0\u4e48\uff09\u548c**\u65b9\u6cd5**\uff08\u5982\u4f55\u4f18\u5316\uff09\u4e4b\u95f4\u7684\u6865\u6881\u3002</p> <pre><code>\u4efb\u52a1\uff08\u95ee\u9898\uff09 \u2192 \u63a5\u53e3\uff08\u9002\u914d\u5668\uff09 \u2192 \u65b9\u6cd5\uff08\u7b97\u6cd5\uff09\n</code></pre> <p>\u63a5\u53e3\u5904\u7406\uff1a - \u4e3a LLM \u751f\u6210\u7279\u5b9a\u4e8e\u7b97\u6cd5\u7684\u63d0\u793a - \u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u7b97\u5b50\uff08\u53d8\u5f02\u3001\u4ea4\u53c9\u7b49\uff09 - \u89e3\u683c\u5f0f\u8f6c\u6362 - \u8bc4\u4f30\u7f16\u6392</p>"},{"location":"zh/api/interfaces/#python","title":"Python \u4efb\u52a1\u63a5\u53e3","text":""},{"location":"zh/api/interfaces/#evoengineerpythoninterface","title":"EvoEngineerPythonInterface","text":"<pre><code>class EvoEngineerPythonInterface(BaseMethodInterface):\n    def __init__(self, task: PythonTask)\n</code></pre> <p>\u5c06 Python \u4efb\u52a1\u8fde\u63a5\u5230 EvoEngineer \u7b97\u6cd5\u3002</p> <p>\u7528\u6cd5:</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nimport evotoolkit\n\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre>"},{"location":"zh/api/interfaces/#funsearchpythoninterface","title":"FunSearchPythonInterface","text":"<pre><code>class FunSearchPythonInterface(BaseMethodInterface):\n    def __init__(self, task: PythonTask)\n</code></pre> <p>\u5c06 Python \u4efb\u52a1\u8fde\u63a5\u5230 FunSearch \u7b97\u6cd5\u3002</p> <p>\u7528\u6cd5:</p> <pre><code>from evotoolkit.task.python_task import FunSearchPythonInterface\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nimport evotoolkit\n\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = FunSearchPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre>"},{"location":"zh/api/interfaces/#eohpythoninterface","title":"EoHPythonInterface","text":"<pre><code>class EoHPythonInterface(BaseMethodInterface):\n    def __init__(self, task: PythonTask)\n</code></pre> <p>\u5c06 Python \u4efb\u52a1\u8fde\u63a5\u5230 EoH \u7b97\u6cd5\u3002</p> <p>\u7528\u6cd5:</p> <pre><code>from evotoolkit.task.python_task import EoHPythonInterface\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nimport evotoolkit\n\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = EoHPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre>"},{"location":"zh/api/interfaces/#cuda","title":"CUDA \u4efb\u52a1\u63a5\u53e3","text":"<p>CUDA \u4efb\u52a1\u63a5\u53e3\u53ef\u7528\u4e8e GPU \u5185\u6838\u4f18\u5316\u4efb\u52a1\u3002</p> <p>\u53ef\u7528\u63a5\u53e3:</p> <ul> <li><code>EvoEngineerFullInterface</code> - \u5b8c\u6574\u7684 CUDA \u5de5\u7a0b\u5de5\u4f5c\u6d41</li> <li><code>EvoEngineerFreeInterface</code> - \u81ea\u7531\u5f62\u5f0f\u7684 CUDA \u4f18\u5316</li> <li><code>EvoEngineerInsightInterface</code> - \u6d1e\u5bdf\u5f15\u5bfc\u7684 CUDA \u4f18\u5316</li> <li><code>FunSearchInterface</code> - \u7528\u4e8e CUDA \u7684\u51fd\u6570\u641c\u7d22</li> <li><code>EoHInterface</code> - \u7528\u4e8e CUDA \u7684\u542f\u53d1\u5f0f\u8fdb\u5316</li> </ul> <p>\u7528\u6cd5\u793a\u4f8b:</p> <pre><code>from evotoolkit.task.cuda_engineering.method_interface import EvoEngineerFullInterface\nimport evotoolkit\n\ntask = MyCudaTask()\ninterface = EvoEngineerFullInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre> <p>\u8be6\u89c1 CUDA \u4efb\u52a1\u6559\u7a0b\u3002</p>"},{"location":"zh/api/interfaces/#_2","title":"\u57fa\u7840\u63a5\u53e3\u7c7b","text":""},{"location":"zh/api/interfaces/#basemethodinterface","title":"BaseMethodInterface","text":"<p>\u6240\u6709\u65b9\u6cd5\u63a5\u53e3\u7684\u57fa\u7c7b\u3002\u8be6\u89c1\u53c2\u8003\u9875\uff1a BaseMethodInterface\u3002</p>"},{"location":"zh/api/interfaces/#_3","title":"\u63a5\u53e3\u9009\u62e9\u6307\u5357","text":""},{"location":"zh/api/interfaces/#python_1","title":"\u5bf9\u4e8e Python \u4efb\u52a1","text":"\u4efb\u52a1\u7c7b\u578b \u63a8\u8350\u63a5\u53e3 \u66ff\u4ee3\u9009\u62e9 \u79d1\u5b66\u7b26\u53f7\u56de\u5f52 <code>EvoEngineerPythonInterface</code> <code>FunSearchPythonInterface</code> \u901a\u7528\u4f18\u5316 <code>EvoEngineerPythonInterface</code> <code>EoHPythonInterface</code> \u5feb\u901f\u539f\u578b <code>EoHPythonInterface</code> <code>EvoEngineerPythonInterface</code>"},{"location":"zh/api/interfaces/#cuda_1","title":"\u5bf9\u4e8e CUDA \u4efb\u52a1","text":"\u4efb\u52a1\u7c7b\u578b \u63a8\u8350\u63a5\u53e3 \u5185\u6838\u4f18\u5316 <code>EvoEngineerCudaInterface</code> GPU \u7b97\u6cd5\u53d1\u73b0 <code>FunSearchCudaInterface</code>"},{"location":"zh/api/interfaces/#_4","title":"\u63a5\u53e3\u5de5\u4f5c\u539f\u7406","text":""},{"location":"zh/api/interfaces/#1","title":"1. \u63d0\u793a\u751f\u6210","text":"<p>\u63a5\u53e3\u4e3a LLM \u521b\u5efa\u7279\u5b9a\u4e8e\u7b97\u6cd5\u7684\u63d0\u793a\uff1a</p> <pre><code># EvoEngineer \u63d0\u793a\u793a\u4f8b\nprompt = \"\"\"\n\u60a8\u6b63\u5728\u8fdb\u5316\u4e00\u4e2a Python \u51fd\u6570\u6765\u8fd1\u4f3c\u6570\u636e\u3002\n\n\u4e0a\u4e00\u4ee3\u6700\u4f73\u89e3:\n{previous_best_code}\n\n\u5f53\u524d\u9002\u5e94\u5ea6: {fitness}\n\n\u8bf7\u6539\u8fdb\u6b64\u89e3\u6216\u521b\u5efa\u65b0\u89e3\u3002\n\"\"\"\n</code></pre>"},{"location":"zh/api/interfaces/#2","title":"2. \u54cd\u5e94\u89e3\u6790","text":"<p>\u63a5\u53e3\u4ece LLM \u54cd\u5e94\u4e2d\u63d0\u53d6\u4ee3\u7801\uff1a</p> <pre><code>response = llm_api.call(prompt)\nsolution = interface.parse_llm_response(response)\n# solution.sol_string \u73b0\u5728\u5305\u542b\u63d0\u53d6\u7684 Python/CUDA \u4ee3\u7801\n</code></pre>"},{"location":"zh/api/interfaces/#3","title":"3. \u7b97\u5b50\u5e94\u7528","text":"<p>\u63a5\u53e3\u5e94\u7528\u8fdb\u5316\u7b97\u5b50\uff1a</p> <pre><code># \u53d8\u5f02\nmutated = interface.mutate(solution)\n\n# \u4ea4\u53c9\noffspring = interface.crossover(parent1, parent2)\n</code></pre>"},{"location":"zh/api/interfaces/#_5","title":"\u9ad8\u7ea7\uff1a\u81ea\u5b9a\u4e49\u63a5\u53e3","text":"<p>\u4e3a\u4e13\u95e8\u7684\u7b97\u6cd5\u6216\u4efb\u52a1\u521b\u5efa\u81ea\u5b9a\u4e49\u63a5\u53e3\uff1a</p> <pre><code>from evotoolkit.core.method_interface import BaseMethodInterface\nfrom evotoolkit.core import Solution\n\nclass MySpecializedInterface(BaseMethodInterface):\n    def __init__(self, task):\n        super().__init__(task)\n        self.custom_config = self.load_custom_config()\n\n    def generate_prompt(self, generation, population):\n        # \u5177\u6709\u9886\u57df\u7279\u5b9a\u6307\u4ee4\u7684\u81ea\u5b9a\u4e49\u63d0\u793a\n        best_sol = max(population, key=lambda s: s.evaluation_res.score if s.evaluation_res.valid else float('-inf'))\n\n        prompt = f\"\"\"\n        \u9886\u57df\u7279\u5b9a\u4e0a\u4e0b\u6587: {self.custom_config['context']}\n\n        \u8fdb\u5316\u4e00\u4e2a\u6539\u8fdb\u4ee5\u4e0b\u5185\u5bb9\u7684\u89e3:\n        {best_sol.sol_string}\n\n        \u5f53\u524d\u6700\u4f73\u5f97\u5206: {best_sol.evaluation_res.score}\n        \u4ee3\u6570: {generation}\n        \"\"\"\n        return prompt\n\n    def parse_llm_response(self, response):\n        # \u81ea\u5b9a\u4e49\u89e3\u6790\u903b\u8f91\n        code = self.extract_code_with_custom_markers(response)\n        return Solution(code=code)\n\n    def load_custom_config(self):\n        # \u52a0\u8f7d\u9886\u57df\u7279\u5b9a\u914d\u7f6e\n        return {\"context\": \"\u81ea\u5b9a\u4e49\u9886\u57df\u77e5\u8bc6\"}\n</code></pre> <p>\u7528\u6cd5:</p> <pre><code>task = MyCustomTask()\ninterface = MySpecializedInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre>"},{"location":"zh/api/interfaces/#vs","title":"\u6bd4\u8f83\uff1a\u63a5\u53e3 vs \u76f4\u63a5\u65b9\u6cd5\u8c03\u7528","text":""},{"location":"zh/api/interfaces/#api_1","title":"\u4f7f\u7528\u63a5\u53e3\uff08\u9ad8\u7ea7 API\uff09\u2705 \u63a8\u8350","text":"<pre><code>interface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre> <p>\u4f18\u70b9: - \u7b80\u5355\u660e\u4e86 - \u81ea\u52a8\u914d\u7f6e - \u4ece\u63a5\u53e3\u63a8\u65ad\u7b97\u6cd5</p>"},{"location":"zh/api/interfaces/#api_2","title":"\u76f4\u63a5\u65b9\u6cd5\u8c03\u7528\uff08\u4f4e\u7ea7 API\uff09\u2699\ufe0f \u9ad8\u7ea7","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nconfig = EvoEngineerConfig(interface=interface, ...)\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n</code></pre> <p>\u4f18\u70b9: - \u5b8c\u5168\u63a7\u5236\u914d\u7f6e - \u8bbf\u95ee\u5185\u90e8\u72b6\u6001 - \u81ea\u5b9a\u4e49\u540e\u5904\u7406</p>"},{"location":"zh/api/interfaces/#_6","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u53c2\u89c1 \u4efb\u52a1 API \u4e86\u89e3\u53ef\u7528\u7684\u4f18\u5316\u4efb\u52a1</li> <li>\u67e5\u770b \u65b9\u6cd5 API \u4e86\u89e3\u8fdb\u5316\u7b97\u6cd5</li> <li>\u5c1d\u8bd5 \u9ad8\u7ea7\u7528\u6cd5\u6559\u7a0b \u4e86\u89e3\u4f4e\u7ea7 API</li> </ul>"},{"location":"zh/api/methods/","title":"\u65b9\u6cd5 API","text":"<p>\u8fdb\u5316\u65b9\u6cd5\u662f\u9a71\u52a8\u4f18\u5316\u8fc7\u7a0b\u7684\u6838\u5fc3\u7b97\u6cd5\u3002</p>"},{"location":"zh/api/methods/#_1","title":"\u53ef\u7528\u7b97\u6cd5","text":"<p>EvoToolkit \u63d0\u4f9b\u4e09\u79cd\u4e3b\u8981\u7684\u8fdb\u5316\u7b97\u6cd5\uff1a</p> \u7b97\u6cd5 \u6700\u9002\u5408 \u7279\u5f81 EvoEngineer \u901a\u7528\u4f18\u5316 \u591a\u529f\u80fd\u3001\u7a33\u5065\u3001\u826f\u597d\u7684\u9ed8\u8ba4\u9009\u62e9 FunSearch \u51fd\u6570\u53d1\u73b0 \u4e13\u95e8\u7528\u4e8e\u51fd\u6570\u8fd1\u4f3c EoH \u542f\u53d1\u5f0f\u4f18\u5316 \u5feb\u901f\u3001\u9ad8\u6548\uff0c\u9002\u5408\u7b80\u5355\u95ee\u9898"},{"location":"zh/api/methods/#evoengineer","title":"EvoEngineer","text":"<pre><code>class EvoEngineer(Method):\n    def __init__(self, config: EvoEngineerConfig)\n    def run(self)\n</code></pre> <p>EvoEngineer \u662f EvoToolkit \u4e2d\u4e3b\u8981\u7684 LLM \u9a71\u52a8\u8fdb\u5316\u7b97\u6cd5\u3002</p>"},{"location":"zh/api/methods/#api_1","title":"\u9ad8\u7ea7 API \u7528\u6cd5","text":"<pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\nimport evotoolkit\n\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=8\n)\n</code></pre>"},{"location":"zh/api/methods/#api_2","title":"\u4f4e\u7ea7 API \u7528\u6cd5","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=8,\n    elite_ratio=0.2,\n    mutation_rate=0.3,\n    crossover_rate=0.7\n)\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\nbest = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n</code></pre>"},{"location":"zh/api/methods/#_2","title":"\u914d\u7f6e\u53c2\u6570","text":"<p>\u8fdb\u5316\u53c2\u6570: - <code>max_generations</code> (<code>int</code>): \u6700\u5927\u8fdb\u5316\u4ee3\u6570 - <code>pop_size</code> (<code>int</code>): \u79cd\u7fa4\u5927\u5c0f - <code>max_sample_nums</code> (<code>int</code>): \u6bcf\u4ee3\u6700\u5927 LLM \u91c7\u6837\u6570</p> <p>\u9009\u62e9\u53c2\u6570: - <code>elite_ratio</code> (<code>float</code>): \u4fdd\u7559\u4e3a\u7cbe\u82f1\u7684\u6bd4\u4f8b\uff08\u9ed8\u8ba4: 0.2\uff09 - <code>tournament_size</code> (<code>int</code>): \u9526\u6807\u8d5b\u9009\u62e9\u5927\u5c0f\uff08\u9ed8\u8ba4: 3\uff09</p> <p>\u53d8\u5f02\u53c2\u6570: - <code>mutation_rate</code> (<code>float</code>): \u53d8\u5f02\u6982\u7387\uff08\u9ed8\u8ba4: 0.3\uff09 - <code>crossover_rate</code> (<code>float</code>): \u4ea4\u53c9\u6982\u7387\uff08\u9ed8\u8ba4: 0.7\uff09</p>"},{"location":"zh/api/methods/#funsearch","title":"FunSearch","text":"<pre><code>class FunSearch(Method):\n    def __init__(self, config: FunSearchConfig)\n    def run(self)\n</code></pre> <p>FunSearch \u662f\u4e00\u79cd\u4e13\u95e8\u7528\u4e8e\u51fd\u6570\u53d1\u73b0\u7684\u4f18\u5316\u65b9\u6cd5\u3002</p>"},{"location":"zh/api/methods/#_3","title":"\u7528\u6cd5","text":"<pre><code>from evotoolkit.task.python_task import FunSearchPythonInterface\nimport evotoolkit\n\ninterface = FunSearchPythonInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=20,\n    num_islands=4\n)\n</code></pre>"},{"location":"zh/api/methods/#api_3","title":"\u4f4e\u7ea7 API","text":"<pre><code>from evotoolkit.evo_method.funsearch import FunSearch, FunSearchConfig\n\nconfig = FunSearchConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=20,\n    num_islands=4,\n    island_size=8,\n    migration_rate=0.1,\n    migration_interval=5\n)\n\nalgorithm = FunSearch(config)\nalgorithm.run()\n</code></pre>"},{"location":"zh/api/methods/#_4","title":"\u914d\u7f6e\u53c2\u6570","text":"<p>\u5c9b\u6a21\u578b\u53c2\u6570: - <code>num_islands</code> (<code>int</code>): \u5e76\u884c\u8fdb\u5316\u5c9b\u6570\u91cf\uff08\u9ed8\u8ba4: 4\uff09 - <code>island_size</code> (<code>int</code>): \u6bcf\u4e2a\u5c9b\u7684\u79cd\u7fa4\u5927\u5c0f\uff08\u9ed8\u8ba4: 8\uff09 - <code>migration_rate</code> (<code>float</code>): \u5c9b\u95f4\u8fc1\u79fb\u7387\uff08\u9ed8\u8ba4: 0.1\uff09 - <code>migration_interval</code> (<code>int</code>): \u8fc1\u79fb\u95f4\u9694\u4ee3\u6570\uff08\u9ed8\u8ba4: 5\uff09</p>"},{"location":"zh/api/methods/#eoh","title":"EoH","text":"<pre><code>class EoH(Method):\n    def __init__(self, config: EoHConfig)\n    def run(self)\n</code></pre> <p>EoH\uff08\u542f\u53d1\u5f0f\u8fdb\u5316\uff09\u662f\u4e00\u79cd\u5feb\u901f\u9ad8\u6548\u7684\u8fdb\u5316\u65b9\u6cd5\u3002</p>"},{"location":"zh/api/methods/#_5","title":"\u7528\u6cd5","text":"<pre><code>from evotoolkit.task.python_task import EoHPythonInterface\nimport evotoolkit\n\ninterface = EoHPythonInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre>"},{"location":"zh/api/methods/#api_4","title":"\u4f4e\u7ea7 API","text":"<pre><code>from evotoolkit.evo_method.eoh import EoH, EoHConfig\n\nconfig = EoHConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    max_sample_nums=20,\n    elite_ratio=0.3,\n    heuristic_pool_size=50\n)\n\nalgorithm = EoH(config)\nalgorithm.run()\n</code></pre>"},{"location":"zh/api/methods/#_6","title":"\u914d\u7f6e\u53c2\u6570","text":"<p>\u542f\u53d1\u5f0f\u53c2\u6570: - <code>heuristic_pool_size</code> (<code>int</code>): \u542f\u53d1\u5f0f\u6c60\u5927\u5c0f\uff08\u9ed8\u8ba4: 50\uff09 - <code>elite_ratio</code> (<code>float</code>): \u7cbe\u82f1\u6bd4\u4f8b\uff08\u9ed8\u8ba4: 0.3\uff09</p>"},{"location":"zh/api/methods/#_7","title":"\u7b97\u6cd5\u6bd4\u8f83","text":""},{"location":"zh/api/methods/#_8","title":"\u6027\u80fd\u7279\u5f81","text":"\u7279\u5f81 EvoEngineer FunSearch EoH \u6536\u655b\u901f\u5ea6 \u4e2d\u7b49 \u6162 \u5feb \u89e3\u8d28\u91cf \u9ad8 \u5f88\u9ad8 \u4e2d\u7b49 \u8ba1\u7b97\u6210\u672c \u4e2d\u7b49 \u9ad8 \u4f4e \u9002\u7528\u8303\u56f4 \u5e7f\u6cdb \u51fd\u6570\u53d1\u73b0 \u542f\u53d1\u5f0f\u4f18\u5316"},{"location":"zh/api/methods/#_9","title":"\u4f55\u65f6\u4f7f\u7528","text":"<p>EvoEngineer: - \u901a\u7528\u4f18\u5316\u95ee\u9898 - \u5e73\u8861\u6027\u80fd\u548c\u8d28\u91cf - \u4e0d\u786e\u5b9a\u4f7f\u7528\u54ea\u4e2a\u65f6\u7684\u9ed8\u8ba4\u9009\u62e9</p> <p>FunSearch: - \u9700\u8981\u9ad8\u8d28\u91cf\u89e3 - \u6709\u8db3\u591f\u8ba1\u7b97\u9884\u7b97 - \u51fd\u6570\u8fd1\u4f3c\u548c\u53d1\u73b0\u4efb\u52a1</p> <p>EoH: - \u5feb\u901f\u539f\u578b\u8bbe\u8ba1 - \u7b80\u5355\u4f18\u5316\u95ee\u9898 - \u6709\u9650\u7684\u8ba1\u7b97\u8d44\u6e90</p>"},{"location":"zh/api/methods/#_10","title":"\u81ea\u5b9a\u4e49\u7b97\u6cd5","text":"<p>\u5b9e\u73b0\u60a8\u81ea\u5df1\u7684\u8fdb\u5316\u7b97\u6cd5\uff1a</p> <pre><code>from evotoolkit.core import BaseMethod, BaseConfig\n\nclass MyAlgorithm(BaseMethod):\n    def __init__(self, config: BaseConfig):\n        super().__init__(config)\n\n    def run(self):\n        # \u521d\u59cb\u5316\n        population = self.initialize_population()\n\n        for gen in range(self.config.max_generations):\n            # \u751f\u6210\u65b0\u89e3\n            new_solutions = self.generate_with_llm()\n\n            # \u8bc4\u4f30\n            for sol in new_solutions:\n                eval_res = self.config.interface.task.evaluate_code(sol.sol_string)\n                sol.evaluation_res = eval_res\n\n            # \u9009\u62e9\n            population = self.select(population + new_solutions)\n\n            # \u8bb0\u5f55\n            best = max(population, key=lambda s: s.evaluation_res.score if s.evaluation_res.valid else float('-inf'))\n            print(f\"\u7b2c {gen} \u4ee3: {best.evaluation_res.score}\")\n</code></pre>"},{"location":"zh/api/methods/#_11","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u63a2\u7d22 \u63a5\u53e3 API \u4e86\u89e3\u7b97\u6cd5-\u4efb\u52a1\u96c6\u6210</li> <li>\u67e5\u770b \u6838\u5fc3 API \u4e86\u89e3\u57fa\u7c7b</li> <li>\u5c1d\u8bd5 \u9ad8\u7ea7\u7528\u6cd5\u6559\u7a0b</li> <li>\u5b66\u4e60 \u81ea\u5b9a\u4e49\u4efb\u52a1 \u521b\u5efa</li> </ul>"},{"location":"zh/api/tasks/","title":"\u4efb\u52a1 API","text":"<p>\u4efb\u52a1\u5b9a\u4e49\u4f18\u5316\u95ee\u9898\u4ee5\u53ca\u5982\u4f55\u8bc4\u4f30\u5019\u9009\u89e3\u3002</p>"},{"location":"zh/api/tasks/#_1","title":"\u6982\u89c8","text":"<p>EvoToolkit \u63d0\u4f9b\u4e09\u7c7b\u4efb\u52a1\uff1a</p> <ul> <li>Python \u4efb\u52a1 - \u4f18\u5316 Python \u4ee3\u7801\u51fd\u6570</li> <li>String \u4efb\u52a1 - \u4f18\u5316\u6587\u672c/\u5b57\u7b26\u4e32\u89e3\uff08\u5982\u63d0\u793a\u8bcd\uff09</li> <li>CUDA \u4efb\u52a1 - \u4f18\u5316 GPU \u5185\u6838\u4ee3\u7801</li> </ul>"},{"location":"zh/api/tasks/#python","title":"Python \u4efb\u52a1","text":""},{"location":"zh/api/tasks/#pythontask","title":"PythonTask","text":"<p>Python \u4ee3\u7801\u4f18\u5316\u4efb\u52a1\u7684\u57fa\u7c7b\u3002</p> <p>\u53c2\u89c1\u4e13\u95e8\u9875\u9762\uff1aPythonTask\u3002</p>"},{"location":"zh/api/tasks/#scientificregressiontask","title":"ScientificRegressionTask","text":"<p>\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u6570\u5b66\u65b9\u7a0b\u7684\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u3002</p> <p>\u53c2\u89c1\u4e13\u95e8\u9875\u9762\uff1aScientificRegressionTask\u3002</p>"},{"location":"zh/api/tasks/#adversarialattacktask","title":"AdversarialAttackTask","text":"<p>\u4e3a\u9ed1\u76d2\u6a21\u578b\u8fdb\u5316\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\u3002</p> <p>\u7528\u6cd5\uff1a</p> <pre><code>from evotoolkit.task.python_task.adversarial_attack import AdversarialAttackTask\n\n# \u4f7f\u7528 mock \u8bc4\u4f30\u521b\u5efa\u4efb\u52a1\ntask = AdversarialAttackTask(\n    model=None,  # \u53ef\u9009\uff1aPyTorch \u6a21\u578b\n    test_loader=None,  # \u53ef\u9009\uff1a\u6d4b\u8bd5\u6570\u636e\u52a0\u8f7d\u5668\n    attack_steps=1000,\n    n_test_samples=10,\n    timeout_seconds=300.0,\n    use_mock=True  # \u4f7f\u7528 mock \u8bc4\u4f30\u8fdb\u884c\u6d4b\u8bd5\n)\n\n# \u8bc4\u4f30\u653b\u51fb\u4ee3\u7801\ncode = '''\ndef draw_proposals(x, num_proposals, step_size):\n    # \u751f\u6210\u5bf9\u6297\u6027\u63d0\u6848\u6837\u672c\n    proposals = ...\n    return proposals\n'''\n\nresult = task.evaluate_code(code)\nprint(f\"\u5f97\u5206: {result.score}\")  # \u8d1f\u7684 L2 \u8ddd\u79bb\uff08\u8d8a\u9ad8\u8d8a\u597d\uff09\n</code></pre> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>model</code> (<code>any</code>\uff0c\u53ef\u9009)\uff1a\u8981\u653b\u51fb\u7684\u76ee\u6807\u6a21\u578b\u3002\u5982\u679c\u4e3a None\uff0c\u5219\u4f7f\u7528 mock \u8bc4\u4f30\u3002</li> <li><code>test_loader</code> (<code>any</code>\uff0c\u53ef\u9009)\uff1a\u5305\u542b\u6d4b\u8bd5\u6837\u672c\u7684 DataLoader\u3002\u5982\u679c\u4e3a None\uff0c\u5219\u4f7f\u7528 mock \u8bc4\u4f30\u3002</li> <li><code>attack_steps</code> (<code>int</code>)\uff1a\u6bcf\u4e2a\u6837\u672c\u7684\u653b\u51fb\u8fed\u4ee3\u6b21\u6570\uff08\u9ed8\u8ba4\uff1a1000\uff09</li> <li><code>n_test_samples</code> (<code>int</code>)\uff1a\u8981\u8bc4\u4f30\u7684\u6d4b\u8bd5\u6837\u672c\u6570\u91cf\uff08\u9ed8\u8ba4\uff1a10\uff09</li> <li><code>timeout_seconds</code> (<code>float</code>)\uff1a\u6267\u884c\u8d85\u65f6\uff08\u9ed8\u8ba4\uff1a300.0\uff09</li> <li><code>use_mock</code> (<code>bool</code>)\uff1a\u4f7f\u7528 mock \u8bc4\u4f30\u800c\u4e0d\u662f\u771f\u5b9e\u653b\u51fb\uff08\u9ed8\u8ba4\uff1aFalse\uff09</li> </ul> <p>\u65b9\u6cd5\uff1a</p> <ul> <li><code>evaluate_code(code: str) -&gt; EvaluationResult</code>\uff1a\u8bc4\u4f30\u653b\u51fb\u7b97\u6cd5\u4ee3\u7801</li> </ul> <p>\u8be6\u89c1 \u5bf9\u6297\u653b\u51fb\u6559\u7a0b\u3002</p>"},{"location":"zh/api/tasks/#string","title":"String \u4efb\u52a1","text":""},{"location":"zh/api/tasks/#stringtask","title":"StringTask","text":"<p>\u57fa\u4e8e\u5b57\u7b26\u4e32\u7684\u4f18\u5316\u4efb\u52a1\u7684\u57fa\u7c7b\uff08\u5982\u63d0\u793a\u8bcd\u4f18\u5316\uff09\u3002</p> <p>\u7528\u6cd5\uff1a</p> <pre><code>from evotoolkit.task.string_optimization.string_task import StringTask\nfrom evotoolkit.core import EvaluationResult, Solution\n\nclass MyStringTask(StringTask):\n    def _evaluate_string_impl(self, candidate_string: str) -&gt; EvaluationResult:\n        # \u8bc4\u4f30\u5b57\u7b26\u4e32\u89e3\n        score = self.compute_score(candidate_string)\n        return EvaluationResult(\n            valid=True,\n            score=score,\n            additional_info={}\n        )\n\n    def get_base_task_description(self) -&gt; str:\n        return \"\u4f18\u5316\u4e00\u4e2a\u5b57\u7b26\u4e32\u89e3...\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        return Solution(\"\u521d\u59cb\u5b57\u7b26\u4e32\")\n</code></pre> <p>\u6784\u9020\u51fd\u6570\uff1a</p> <pre><code>def __init__(self, data, timeout_seconds: float = 30.0)\n</code></pre> <p>\u62bd\u8c61\u65b9\u6cd5\uff1a</p> <ul> <li><code>_evaluate_string_impl(candidate_string: str) -&gt; EvaluationResult</code></li> <li><code>get_base_task_description() -&gt; str</code></li> <li><code>make_init_sol_wo_other_info() -&gt; Solution</code></li> </ul>"},{"location":"zh/api/tasks/#promptoptimizationtask","title":"PromptOptimizationTask","text":"<p>\u4f18\u5316 LLM \u63d0\u793a\u8bcd\u6a21\u677f\u4ee5\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\u3002</p> <p>\u7528\u6cd5\uff1a</p> <pre><code>from evotoolkit.task.string_optimization.prompt_optimization import PromptOptimizationTask\n\n# \u5b9a\u4e49\u6d4b\u8bd5\u7528\u4f8b\ntest_cases = [\n    {\"question\": \"2+2\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"4\"},\n    {\"question\": \"5*3\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"15\"}\n]\n\n# \u521b\u5efa\u4efb\u52a1\ntask = PromptOptimizationTask(\n    test_cases=test_cases,\n    llm_api=my_llm_api,  # \u5982\u679c use_mock=True \u5219\u53ef\u9009\n    timeout_seconds=30.0,\n    use_mock=True  # \u4f7f\u7528 mock LLM \u8fdb\u884c\u6d4b\u8bd5\n)\n\n# \u8bc4\u4f30\u63d0\u793a\u8bcd\u6a21\u677f\nprompt_template = \"\u89e3\u7b54\u8fd9\u9053\u6570\u5b66\u9898\uff1a{question}\\n\u53ea\u7ed9\u51fa\u6570\u5b57\u3002\"\nresult = task.evaluate_code(prompt_template)\nprint(f\"\u51c6\u786e\u7387: {result.score}\")  # \u6b63\u786e\u7387\uff080.0 \u5230 1.0\uff09\n</code></pre> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>test_cases</code> (<code>List[Dict[str, str]]</code>)\uff1a\u5305\u542b 'question' \u548c 'expected' \u952e\u7684\u6d4b\u8bd5\u7528\u4f8b</li> <li><code>llm_api</code> (\u53ef\u9009)\uff1a\u7528\u4e8e\u6d4b\u8bd5\u63d0\u793a\u8bcd\u7684 LLM API \u5b9e\u4f8b\uff08\u5982\u679c <code>use_mock=False</code> \u5219\u5fc5\u9700\uff09</li> <li><code>timeout_seconds</code> (<code>float</code>)\uff1a\u8bc4\u4f30\u8d85\u65f6\uff08\u9ed8\u8ba4\uff1a30.0\uff09</li> <li><code>use_mock</code> (<code>bool</code>)\uff1a\u4f7f\u7528 mock LLM \u54cd\u5e94\u8fdb\u884c\u6d4b\u8bd5\uff08\u9ed8\u8ba4\uff1aFalse\uff09</li> </ul> <p>\u6a21\u677f\u683c\u5f0f\uff1a</p> <p>\u63d0\u793a\u8bcd\u6a21\u677f\u5fc5\u987b\u5305\u542b <code>{question}</code> \u5360\u4f4d\u7b26\uff1a</p> <pre><code># \u6709\u6548\u6a21\u677f\n\"\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff1a{question}\"\n\"\u95ee\uff1a{question}\\n\u7b54\uff1a\"\n\n# \u65e0\u6548 - \u7f3a\u5c11\u5360\u4f4d\u7b26\n\"\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\"  # \u9519\u8bef\uff01\n</code></pre> <p>\u65b9\u6cd5\uff1a</p> <ul> <li><code>evaluate_code(prompt_template: str) -&gt; EvaluationResult</code>\uff1a\u8bc4\u4f30\u63d0\u793a\u8bcd\u6a21\u677f</li> </ul> <p>\u8be6\u89c1 \u63d0\u793a\u8bcd\u5de5\u7a0b\u6559\u7a0b\u3002</p>"},{"location":"zh/api/tasks/#cuda","title":"CUDA \u4efb\u52a1","text":""},{"location":"zh/api/tasks/#cudatask","title":"CudaTask","text":"<p>CUDA \u5185\u6838\u4f18\u5316\u4efb\u52a1\u7684\u57fa\u7c7b\u3002</p> <p>\u7528\u6cd5\uff1a</p> <pre><code>from evotoolkit.task.cuda_engineering import CudaTask, CudaTaskInfoMaker, Evaluator\n\n# \u521b\u5efa\u8bc4\u4f30\u5668\nevaluator = Evaluator(temp_path='./temp')\n\n# \u521b\u5efa\u4efb\u52a1\u4fe1\u606f\ntask_info = CudaTaskInfoMaker.make_task_info(\n    evaluator=evaluator,\n    gpu_type=\"RTX 4090\",\n    cuda_version=\"12.4\",\n    org_py_code=original_python_code,\n    func_py_code=function_python_code,\n    cuda_code=baseline_cuda_code\n)\n\n# \u521b\u5efa\u4efb\u52a1\ntask = CudaTask(data=task_info, temp_path='./temp')\n\n# \u8bc4\u4f30 CUDA \u4ee3\u7801\neval_res = task.evaluate_code(candidate_cuda_code)\nprint(f\"\u8fd0\u884c\u65f6\u95f4: {-eval_res.score:.4f}s\")  # \u5f97\u5206\u4e3a\u8d1f\u8fd0\u884c\u65f6\u95f4\n</code></pre> <p>\u6784\u9020\u51fd\u6570\uff1a</p> <pre><code>def __init__(self, data, temp_path=None, fake_mode: bool = False)\n</code></pre> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>data</code> (<code>dict</code>)\uff1a\u6765\u81ea <code>CudaTaskInfoMaker.make_task_info()</code> \u7684\u4efb\u52a1\u4fe1\u606f</li> <li><code>temp_path</code> (<code>str</code>\uff0c\u53ef\u9009)\uff1aCUDA \u7f16\u8bd1\u7684\u4e34\u65f6\u8def\u5f84</li> <li><code>fake_mode</code> (<code>bool</code>)\uff1a\u8df3\u8fc7\u5b9e\u9645\u7684 CUDA \u8bc4\u4f30\uff08\u9ed8\u8ba4\uff1aFalse\uff09</li> </ul> <p>\u65b9\u6cd5\uff1a</p> <ul> <li><code>evaluate_code(code: str) -&gt; EvaluationResult</code>\uff1a\u8bc4\u4f30 CUDA \u5185\u6838\u4ee3\u7801\u5e76\u8fd4\u56de\u7ed3\u679c\uff0c\u5f97\u5206\u4e3a\u8d1f\u8fd0\u884c\u65f6\u95f4\uff08\u5f97\u5206\u8d8a\u9ad8 = \u5185\u6838\u8d8a\u5feb\uff09</li> </ul> <p>\u6ce8\u610f\uff1a CUDA \u4efb\u52a1\u9700\u8981 <code>cuda_engineering</code> \u989d\u5916\u4f9d\u8d56\uff1a</p> <pre><code>pip install evotoolkit[cuda_engineering]\n</code></pre> <p>\u8be6\u89c1 CUDA \u4efb\u52a1\u6559\u7a0b\u3002</p>"},{"location":"zh/api/tasks/#_2","title":"\u6570\u636e\u7ba1\u7406","text":"<p>\u9996\u6b21\u8bbf\u95ee\u65f6\uff0c\u6570\u636e\u96c6\u4f1a\u81ea\u52a8\u4ece GitHub releases \u4e0b\u8f7d\u3002</p>"},{"location":"zh/api/tasks/#python-api","title":"Python API","text":"<pre><code>from evotoolkit.data import get_dataset_path, list_available_datasets\n\n# \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84\uff08\u5982\u679c\u4e0d\u5b58\u5728\u5219\u81ea\u52a8\u4e0b\u8f7d\uff09\nbase_dir = get_dataset_path('scientific_regression')\n\n# \u8bbf\u95ee\u7279\u5b9a\u6570\u636e\u96c6\nbactgrow_path = base_dir / 'bactgrow'\ntrain_csv = bactgrow_path / 'train.csv'\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u76ee\u5f55\nbase_dir = get_dataset_path('scientific_regression', data_dir='./my_data')\n\n# \u5217\u51fa\u7c7b\u522b\u4e2d\u7684\u6240\u6709\u6570\u636e\u96c6\ndatasets = list_available_datasets('scientific_regression')\nprint(datasets.keys())  # dict_keys(['bactgrow', 'oscillator1', 'oscillator2', 'stressstrain'])\n</code></pre> <p>\u53ef\u7528\u51fd\u6570\uff1a</p> <ul> <li><code>get_dataset_path(category, data_dir=None)</code> - \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84\uff0c\u5982\u9700\u8981\u5219\u81ea\u52a8\u4e0b\u8f7d</li> <li><code>list_available_datasets(category)</code> - \u5217\u51fa\u7c7b\u522b\u4e2d\u7684\u6240\u6709\u6570\u636e\u96c6</li> </ul> <p>\u9ed8\u8ba4\u4f4d\u7f6e\uff1a <code>~/.evotool/data/</code></p>"},{"location":"zh/api/tasks/#_3","title":"\u521b\u5efa\u81ea\u5b9a\u4e49\u4efb\u52a1","text":""},{"location":"zh/api/tasks/#python_1","title":"Python \u4efb\u52a1\u793a\u4f8b","text":"<pre><code>from evotoolkit.task.python_task import PythonTask\nfrom evotoolkit.core import EvaluationResult, Solution\n\nclass MyOptimizationTask(PythonTask):\n    \"\"\"\u81ea\u5b9a\u4e49\u4f18\u5316\u4efb\u52a1\"\"\"\n\n    def __init__(self, data, target):\n        self.data = data\n        self.target = target\n        super().__init__(data={'data': data, 'target': target}, timeout_seconds=30.0)\n\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"\u8bc4\u4f30\u89e3\u5e76\u8fd4\u56de\u7ed3\u679c\uff08\u5f97\u5206\u8d8a\u9ad8\u8d8a\u597d\uff09\"\"\"\n        # 1. \u6267\u884c\u89e3\u4ee3\u7801\n        namespace = {}\n        try:\n            exec(candidate_code, namespace)\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': str(e)}\n            )\n\n        # 2. \u63d0\u53d6\u51fd\u6570\n        if 'my_function' not in namespace:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': '\u672a\u627e\u5230\u51fd\u6570 \"my_function\"'}\n            )\n\n        func = namespace['my_function']\n\n        # 3. \u8ba1\u7b97\u9002\u5e94\u5ea6\uff08\u8d1f MSE\uff0c\u4f7f\u5f97\u8d8a\u9ad8\u8d8a\u597d\uff09\n        try:\n            predictions = [func(x) for x in self.data]\n            mse = sum((p - t)**2 for p, t in zip(predictions, self.target)) / len(self.data)\n            score = -mse\n            return EvaluationResult(\n                valid=True,\n                score=score,\n                additional_info={'mse': mse}\n            )\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': str(e)}\n            )\n\n    def get_base_task_description(self) -&gt; str:\n        return \"\u4f18\u5316\u4e00\u4e2a\u51fd\u6570\u4ee5\u62df\u5408\u6570\u636e...\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        return Solution(\"def my_function(x): return x\")\n</code></pre> <p>\u8be6\u89c1 \u81ea\u5b9a\u4e49\u4efb\u52a1\u6559\u7a0b\u3002</p>"},{"location":"zh/api/tasks/#_4","title":"\u4efb\u52a1\u9009\u62e9\u6307\u5357","text":"\u4efb\u52a1\u7c7b\u578b \u63a8\u8350\u7c7b \u7528\u4f8b \u79d1\u5b66\u65b9\u7a0b\u53d1\u73b0 <code>ScientificRegressionTask</code> \u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u6570\u5b66\u6a21\u578b \u5bf9\u6297\u653b\u51fb <code>AdversarialAttackTask</code> \u8fdb\u5316\u653b\u51fb\u7b97\u6cd5 \u63d0\u793a\u8bcd\u4f18\u5316 <code>PromptOptimizationTask</code> \u4f18\u5316 LLM \u63d0\u793a\u8bcd Python \u4ee3\u7801 <code>PythonTask</code> \u901a\u7528 Python \u4f18\u5316 \u5b57\u7b26\u4e32\u4f18\u5316 <code>StringTask</code> \u6587\u672c/\u914d\u7f6e\u4f18\u5316 GPU \u5185\u6838 <code>CudaTask</code> CUDA \u6027\u80fd\u4f18\u5316 \u81ea\u5b9a\u4e49\u95ee\u9898 <code>BaseTask</code> \u4efb\u4f55\u5176\u4ed6\u4f18\u5316\u95ee\u9898"},{"location":"zh/api/tasks/#_5","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u63a2\u7d22 \u65b9\u6cd5 API \u4e86\u89e3\u8fdb\u5316\u7b97\u6cd5</li> <li>\u67e5\u770b \u63a5\u53e3 API \u4e86\u89e3\u4efb\u52a1-\u7b97\u6cd5\u8fde\u63a5</li> <li>\u5c1d\u8bd5 \u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b</li> <li>\u5b66\u4e60\u521b\u5efa \u81ea\u5b9a\u4e49\u4efb\u52a1</li> </ul>"},{"location":"zh/api/tools/","title":"\u5de5\u5177 API","text":"<p>EvoToolkit \u7684\u5b9e\u7528\u5de5\u5177\u548c\u8f85\u52a9\u529f\u80fd\uff0c\u5305\u62ec LLM API \u5ba2\u6237\u7aef\u3002</p>"},{"location":"zh/api/tools/#httpsapi","title":"HttpsApi","text":"<pre><code>class HttpsApi:\n    def __init__(\n        self,\n        api_url: str,\n        key: str,\n        model: str,\n        timeout: int = 300,\n        temperature: float = 1.0\n    )\n\n    def get_response(self, messages: list) -&gt; tuple[str, dict]\n</code></pre> <p><code>HttpsApi</code> \u7c7b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u7684 HTTP(S) \u5ba2\u6237\u7aef\uff0c\u7528\u4e8e\u4e0e LLM API\uff08OpenAI\u3001Claude \u6216\u517c\u5bb9\u670d\u52a1\uff09\u4ea4\u4e92\u3002</p> <p>\u7528\u9014\uff1a</p> <ul> <li>\u8fde\u63a5\u5230 LLM \u804a\u5929 API</li> <li>\u53d1\u9001\u63d0\u793a\u5e76\u63a5\u6536\u54cd\u5e94</li> <li>\u81ea\u52a8\u5904\u7406\u8eab\u4efd\u9a8c\u8bc1\u548c\u91cd\u8bd5</li> </ul> <p>\u4f7f\u7528\u793a\u4f8b\uff1a</p> <pre><code>from evotoolkit.tools import HttpsApi\nimport os\n\n# \u521b\u5efa LLM API \u5ba2\u6237\u7aef\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=os.environ[\"OPENAI_API_KEY\"],\n    model=\"gpt-4o\",\n    temperature=1.0\n)\n\n# \u53d1\u9001\u63d0\u793a\nmessages = [{\"role\": \"user\", \"content\": \"\u5199\u4e00\u4e2a\u8ba1\u7b97\u6590\u6ce2\u90a3\u5951\u6570\u5217\u7684 Python \u51fd\u6570\"}]\nresponse, usage = llm_api.get_response(messages)\n\nprint(response)\nprint(f\"\u4f7f\u7528\u7684 token \u6570: {usage['total_tokens']}\")\n</code></pre> <p>\u4e0e evotoolkit.solve() \u4e00\u8d77\u4f7f\u7528\uff1a</p> <pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import ScientificRegressionTask, EvoEngineerPythonInterface\nfrom evotoolkit.tools import HttpsApi\n\n# \u914d\u7f6e LLM\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=os.environ[\"OPENAI_API_KEY\"],\n    model=\"gpt-4o\"\n)\n\n# \u521b\u5efa\u4efb\u52a1\u548c\u63a5\u53e3\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\ninterface = EvoEngineerPythonInterface(task)\n\n# \u4f7f\u7528 LLM \u6c42\u89e3\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre>"},{"location":"zh/api/tools/#_1","title":"\u6784\u9020\u51fd\u6570","text":"<pre><code>HttpsApi(api_url, key, model, embed_url=None, timeout=60, **kwargs)\n</code></pre> <p>\u53c2\u6570\uff1a</p> <ul> <li>api_url (<code>str</code>): API \u7aef\u70b9 URL\uff0c\u652f\u6301\u591a\u79cd\u683c\u5f0f\uff1a</li> <li>\u5b8c\u6574 URL: <code>\"https://api.openai.com/v1/chat/completions\"</code></li> <li> <p>\u4ec5\u4e3b\u673a\u540d: <code>\"api.openai.com\"</code> (\u9ed8\u8ba4\u4e3a <code>/v1/chat/completions</code>)</p> </li> <li> <p>key (<code>str</code>): \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684 API \u5bc6\u94a5</p> </li> <li>OpenAI: <code>\"sk-...\"</code></li> <li>Anthropic Claude: \u60a8\u7684 API \u5bc6\u94a5</li> <li> <p>\u81ea\u5b9a\u4e49\u63d0\u4f9b\u5546: \u67e5\u770b\u63d0\u4f9b\u5546\u6587\u6863</p> </li> <li> <p>model (<code>str</code>): \u8981\u4f7f\u7528\u7684\u6a21\u578b\u540d\u79f0</p> </li> <li>OpenAI: <code>\"gpt-4o\"</code>, <code>\"gpt-4o-mini\"</code>, <code>\"gpt-3.5-turbo\"</code></li> <li>Anthropic: <code>\"claude-3-5-sonnet-20241022\"</code>, <code>\"claude-3-opus-20240229\"</code></li> <li>Deepseek: <code>\"deepseek-chat\"</code></li> <li> <p>\u6216\u4efb\u4f55\u517c\u5bb9\u6a21\u578b</p> </li> <li> <p>embed_url (<code>str</code>, \u53ef\u9009): \u5d4c\u5165 API URL</p> </li> <li>\u5b8c\u6574 URL: <code>\"https://api.openai.com/v1/embeddings\"</code></li> <li>\u4ec5\u8def\u5f84: <code>\"/v1/embeddings\"</code></li> <li> <p>\u5982\u679c\u672a\u63d0\u4f9b\u5219\u81ea\u52a8\u63a8\u65ad</p> </li> <li> <p>timeout (<code>int</code>, \u9ed8\u8ba4=60): \u8bf7\u6c42\u8d85\u65f6\u65f6\u95f4\uff08\u79d2\uff09</p> </li> <li> <p>****kwargs**: \u9644\u52a0\u53c2\u6570</p> </li> <li><code>temperature</code> (<code>float</code>, \u9ed8\u8ba4=1.0): \u91c7\u6837\u6e29\u5ea6 (0.0 \u5230 2.0)</li> <li>\u5176\u4ed6\u63d0\u4f9b\u5546\u7279\u5b9a\u53c2\u6570</li> </ul> <p>\u793a\u4f8b\uff1a</p> <pre><code># OpenAI\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"sk-...\",\n    model=\"gpt-4o\"\n)\n\n# Anthropic Claude (\u901a\u8fc7\u4ee3\u7406)\nllm_api = HttpsApi(\n    api_url=\"https://your-proxy.com/v1/chat/completions\",\n    key=\"sk-ant-...\",\n    model=\"claude-3-5-sonnet-20241022\"\n)\n\n# \u81ea\u5b9a\u4e49\u63d0\u4f9b\u5546 (\u4ec5\u4e3b\u673a\u540d)\nllm_api = HttpsApi(\n    api_url=\"api.custom-provider.com\",\n    key=\"your-key\",\n    model=\"custom-model\"\n)\n\n# \u81ea\u5b9a\u4e49\u6e29\u5ea6\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"sk-...\",\n    model=\"gpt-4o\",\n    temperature=0.7\n)\n</code></pre>"},{"location":"zh/api/tools/#_2","title":"\u65b9\u6cd5","text":""},{"location":"zh/api/tools/#get_response","title":"get_response()","text":"<pre><code>get_response(prompt: str | list[dict], *args, **kwargs) -&gt; Tuple[str, dict]\n</code></pre> <p>\u5411 LLM \u53d1\u9001\u63d0\u793a\u5e76\u83b7\u53d6\u54cd\u5e94\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li>prompt (<code>str</code> \u6216 <code>list[dict]</code>): \u8981\u53d1\u9001\u7684\u63d0\u793a</li> <li>\u5b57\u7b26\u4e32: \u7b80\u5355\u6587\u672c\u63d0\u793a</li> <li>\u5b57\u5178\u5217\u8868: OpenAI \u683c\u5f0f\u7684\u804a\u5929\u6d88\u606f</li> </ul> <p>\u8fd4\u56de\uff1a</p> <ul> <li><code>tuple[str, dict]</code>: \u4e00\u4e2a\u5143\u7ec4 <code>(response_text, usage_info)</code></li> <li><code>response_text</code> (<code>str</code>): \u6a21\u578b\u7684\u54cd\u5e94</li> <li><code>usage_info</code> (<code>dict</code>): token \u4f7f\u7528\u7edf\u8ba1</li> </ul> <p>\u7528\u6cd5\uff1a</p> <pre><code># \u7b80\u5355\u5b57\u7b26\u4e32\u63d0\u793a\nresponse, usage = llm_api.get_response(\"\u5199\u4e00\u4e2a hello world \u51fd\u6570\")\n\n# \u804a\u5929\u6d88\u606f\nmessages = [\n    {\"role\": \"system\", \"content\": \"\u4f60\u662f\u4e00\u4e2a\u6709\u5e2e\u52a9\u7684\u52a9\u624b\"},\n    {\"role\": \"user\", \"content\": \"\u89e3\u91ca Python \u88c5\u9970\u5668\"}\n]\nresponse, usage = llm_api.get_response(messages)\n\nprint(response)\nprint(f\"Tokens: {usage['total_tokens']}\")\n</code></pre> <p>\u9519\u8bef\u5904\u7406\uff1a</p> <ul> <li>\u5931\u8d25\u65f6\u81ea\u52a8\u91cd\u8bd5\uff08\u6700\u591a 10 \u6b21\uff09</li> <li>\u8d85\u8fc7\u6700\u5927\u91cd\u8bd5\u6b21\u6570\u540e\u629b\u51fa <code>RuntimeError</code></li> </ul>"},{"location":"zh/api/tools/#get_embedding","title":"get_embedding()","text":"<pre><code>get_embedding(text: str, *args, **kwargs) -&gt; list[float]\n</code></pre> <p>\u83b7\u53d6\u6587\u672c\u5b57\u7b26\u4e32\u7684\u5d4c\u5165\u5411\u91cf\u3002</p> <p>\u53c2\u6570\uff1a</p> <ul> <li>text (<code>str</code>): \u8981\u5d4c\u5165\u7684\u8f93\u5165\u6587\u672c</li> </ul> <p>\u8fd4\u56de\uff1a</p> <ul> <li><code>list[float]</code>: \u5d4c\u5165\u5411\u91cf</li> </ul> <p>\u7528\u6cd5\uff1a</p> <pre><code>embedding = llm_api.get_embedding(\"Hello world\")\nprint(f\"\u5d4c\u5165\u7ef4\u5ea6: {len(embedding)}\")\n</code></pre> <p>\u6ce8\u610f\uff1a \u9700\u8981\u914d\u7f6e <code>embed_url</code>\uff08\u5bf9\u4e8e\u5e38\u89c1\u63d0\u4f9b\u5546\u4f1a\u81ea\u52a8\u63a8\u65ad\uff09\u3002</p>"},{"location":"zh/api/tools/#_3","title":"\u73af\u5883\u53d8\u91cf","text":""},{"location":"zh/api/tools/#openai_api_key","title":"OPENAI_API_KEY","text":"<p>\u5b58\u50a8\u60a8\u7684 OpenAI API \u5bc6\u94a5\uff1a</p> <pre><code>export OPENAI_API_KEY=\"sk-...\"\n</code></pre> <p>\u7136\u540e\u5728 Python \u4e2d\u4f7f\u7528\uff1a</p> <pre><code>import os\nfrom evotoolkit.tools import HttpsApi\n\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=os.environ[\"OPENAI_API_KEY\"],\n    model=\"gpt-4o\"\n)\n</code></pre>"},{"location":"zh/api/tools/#llm_api_url-llm_api_key","title":"LLM_API_URL / LLM_API_KEY","text":"<p>\u5bf9\u4e8e\u81ea\u5b9a\u4e49\u914d\u7f6e\uff1a</p> <pre><code>export LLM_API_URL=\"https://your-api.com/v1/chat/completions\"\nexport LLM_API_KEY=\"your-key\"\nexport LLM_MODEL=\"gpt-4o\"\n</code></pre>"},{"location":"zh/api/tools/#_4","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"zh/api/tools/#_5","title":"\u5e94\u8be5\u505a\u7684 \u2705","text":"<ul> <li>\u5c06 API \u5bc6\u94a5\u5b58\u50a8\u5728\u73af\u5883\u53d8\u91cf\u4e2d\uff08\u6c38\u8fdc\u4e0d\u8981\u786c\u7f16\u7801\uff09</li> <li>\u4e3a\u60a8\u7684\u7528\u4f8b\u4f7f\u7528\u9002\u5f53\u7684\u8d85\u65f6\u503c</li> <li>\u4f18\u96c5\u5730\u5904\u7406\u901f\u7387\u9650\u5236</li> <li>\u76d1\u63a7 token \u4f7f\u7528\u4ee5\u63a7\u5236\u6210\u672c</li> <li>\u4f7f\u7528\u8f83\u4f4e\u6e29\u5ea6 (0.0-0.5) \u83b7\u5f97\u786e\u5b9a\u6027\u8f93\u51fa</li> <li>\u4f7f\u7528\u8f83\u9ad8\u6e29\u5ea6 (0.7-1.5) \u83b7\u5f97\u521b\u9020\u6027\u8f93\u51fa</li> </ul>"},{"location":"zh/api/tools/#_6","title":"\u4e0d\u5e94\u8be5\u505a\u7684 \u274c","text":"<ul> <li>\u4e0d\u8981\u5c06 API \u5bc6\u94a5\u63d0\u4ea4\u5230 git</li> <li>\u4e0d\u8981\u4f7f\u7528\u8fc7\u4f4e\u7684\u8d85\u65f6\uff08&lt; 30\u79d2\uff09</li> <li>\u4e0d\u8981\u5ffd\u7565 token \u4f7f\u7528\u6307\u6807</li> <li>\u4e0d\u8981\u5728\u751f\u4ea7\u4ee3\u7801\u4e2d\u7981\u7528\u91cd\u8bd5</li> </ul>"},{"location":"zh/api/tools/#_7","title":"\u63d0\u4f9b\u5546\u7279\u5b9a\u8bf4\u660e","text":""},{"location":"zh/api/tools/#openai","title":"OpenAI","text":"<pre><code>llm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=os.environ[\"OPENAI_API_KEY\"],\n    model=\"gpt-4o\"\n)\n</code></pre> <ul> <li>\u6a21\u578b: <code>gpt-4o</code>, <code>gpt-4o-mini</code>, <code>gpt-3.5-turbo</code></li> <li>\u901f\u7387\u9650\u5236: \u67e5\u770b\u60a8\u7684\u8d26\u6237\u7b49\u7ea7</li> <li>\u6587\u6863: https://platform.openai.com/docs/api-reference</li> </ul>"},{"location":"zh/api/tools/#anthropic-claude","title":"Anthropic Claude","text":"<p>\u9700\u8981\u517c\u5bb9\u7684\u4ee3\u7406\u6216 API \u7f51\u5173\uff1a</p> <pre><code>llm_api = HttpsApi(\n    api_url=\"https://your-gateway.com/v1/chat/completions\",\n    key=os.environ[\"ANTHROPIC_API_KEY\"],\n    model=\"claude-3-5-sonnet-20241022\"\n)\n</code></pre> <ul> <li>\u6a21\u578b: <code>claude-3-5-sonnet-20241022</code>, <code>claude-3-opus-20240229</code></li> <li>\u6ce8\u610f: \u9700\u8981 OpenAI \u517c\u5bb9\u7684 API \u683c\u5f0f</li> <li>\u6587\u6863: https://docs.anthropic.com/</li> </ul>"},{"location":"zh/api/tools/#_8","title":"\u81ea\u5b9a\u4e49\u63d0\u4f9b\u5546","text":"<p>\u8bb8\u591a LLM \u63d0\u4f9b\u5546\u63d0\u4f9b OpenAI \u517c\u5bb9\u7684 API\uff1a</p> <pre><code>llm_api = HttpsApi(\n    api_url=\"api.custom-provider.com\",  # \u4ec5\u4e3b\u673a\u540d\n    key=\"your-key\",\n    model=\"provider-model-name\"\n)\n</code></pre> <p>\u67e5\u770b\u63d0\u4f9b\u5546\u6587\u6863\u4e86\u89e3\uff1a - API \u7aef\u70b9 URL - \u8eab\u4efd\u9a8c\u8bc1\u65b9\u6cd5 - \u652f\u6301\u7684\u6a21\u578b - \u8bf7\u6c42/\u54cd\u5e94\u683c\u5f0f</p>"},{"location":"zh/api/tools/#_9","title":"\u6545\u969c\u6392\u9664","text":""},{"location":"zh/api/tools/#_10","title":"\u8fde\u63a5\u9519\u8bef","text":"<p>\u95ee\u9898: <code>RuntimeError: Model Response Error!</code></p> <p>\u89e3\u51b3\u65b9\u6848: - \u68c0\u67e5 API URL \u662f\u5426\u6b63\u786e - \u9a8c\u8bc1 API \u5bc6\u94a5\u662f\u5426\u6709\u6548 - \u786e\u4fdd\u7f51\u7edc\u8fde\u63a5 - \u68c0\u67e5\u63d0\u4f9b\u5546\u72b6\u6001\u9875\u9762</p>"},{"location":"zh/api/tools/#_11","title":"\u8d85\u65f6\u9519\u8bef","text":"<p>\u95ee\u9898: \u8bf7\u6c42\u8d85\u65f6</p> <p>\u89e3\u51b3\u65b9\u6848: - \u589e\u52a0 <code>timeout</code> \u53c2\u6570 - \u68c0\u67e5\u7f51\u7edc\u5ef6\u8fdf - \u5c1d\u8bd5\u8f83\u5c0f\u7684\u6a21\u578b - \u964d\u4f4e\u63d0\u793a\u590d\u6742\u5ea6</p>"},{"location":"zh/api/tools/#_12","title":"\u901f\u7387\u9650\u5236","text":"<p>\u95ee\u9898: \u8bf7\u6c42\u8fc7\u591a</p> <p>\u89e3\u51b3\u65b9\u6848: - \u5728\u8bf7\u6c42\u4e4b\u95f4\u6dfb\u52a0\u5ef6\u8fdf - \u51cf\u5c11\u5e76\u884c\u5ea6 - \u5347\u7ea7 API \u7b49\u7ea7 - \u5b9e\u73b0\u6307\u6570\u9000\u907f</p>"},{"location":"zh/api/tools/#_13","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u67e5\u770b \u6838\u5fc3 API \u4e86\u89e3\u5982\u4f55\u5728 <code>evotoolkit.solve()</code> \u4e2d\u4f7f\u7528 LLM</li> <li>\u67e5\u770b \u65b9\u6cd5 API \u4e86\u89e3\u8fdb\u5316\u7b97\u6cd5</li> <li>\u5c1d\u8bd5 \u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b</li> </ul>"},{"location":"zh/api/core/base-config/","title":"BaseConfig\uff08\u914d\u7f6e\u57fa\u7c7b\uff09","text":"<p>\u5e38\u89c1\u53c2\u6570\uff1a</p> <ul> <li><code>interface</code>\uff08<code>BaseMethodInterface</code>\uff09\uff1a\u4efb\u52a1\u63a5\u53e3</li> <li><code>output_path</code>\uff08<code>str</code>\uff09\uff1a\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84</li> <li><code>running_llm</code>\uff08<code>HttpsApi</code>\uff09\uff1aLLM \u5ba2\u6237\u7aef</li> <li><code>max_generations</code>\uff08<code>int</code>\uff09\uff1a\u6700\u5927\u4ee3\u6570</li> <li><code>pop_size</code>\uff08<code>int</code>\uff09\uff1a\u79cd\u7fa4\u5927\u5c0f</li> </ul>"},{"location":"zh/api/core/base-run-state-dict/","title":"BaseRunStateDict\uff08\u8fd0\u884c\u72b6\u6001\u5b57\u5178\uff09","text":""},{"location":"zh/api/core/base-task/","title":"BaseTask\uff08\u4efb\u52a1\u57fa\u7c7b\uff09","text":"<p>\u8be6\u89c1\u6559\u7a0b\uff1a\u81ea\u5b9a\u4e49\u4efb\u52a1\u3002</p>"},{"location":"zh/api/core/history-manager/","title":"HistoryManager\uff08\u5386\u53f2\u8bb0\u5f55\u7ba1\u7406\uff09","text":""},{"location":"zh/api/core/list-algorithms/#_1","title":"\u793a\u4f8b","text":"<pre><code>import evotoolkit\n\nalgorithms = evotoolkit.list_algorithms()\nfor algo in algorithms:\n    print(f\"- {algo}\")\n</code></pre>"},{"location":"zh/api/core/list-tasks/#_1","title":"\u793a\u4f8b","text":"<pre><code>import evotoolkit\n\ntasks = evotoolkit.list_tasks()\nfor task in tasks:\n    print(f\"- {task}\")\n</code></pre>"},{"location":"zh/api/core/method/","title":"Method\uff08\u7b97\u6cd5\u57fa\u7c7b\uff09","text":"<p>\u5982\u679c\u4f60\u8981\u5b9e\u73b0\u81ea\u5b9a\u4e49\u8fdb\u5316\u7b97\u6cd5\uff0c\u53ef\u7ee7\u627f <code>Method</code>\uff1a</p> <pre><code>from evotoolkit.core import Method, BaseConfig\n\nclass MyCustomAlgorithm(Method):\n    def run(self):\n        for generation in range(self.config.max_generations):\n            # \u751f\u6210\u3001\u8bc4\u4f30\u3001\u9009\u62e9\n            pass\n</code></pre>"},{"location":"zh/api/core/operators/","title":"Operator\uff08\u7b97\u5b50\uff09","text":""},{"location":"zh/api/core/solution/","title":"Solution\uff08\u89e3\uff09","text":""},{"location":"zh/api/core/solution/#_1","title":"\u793a\u4f8b","text":"<pre><code>from evotoolkit.core import Solution, EvaluationResult\n\neval_res = EvaluationResult(valid=True, score=0.95, additional_info={\"generation\": 3})\nsolution = Solution(\n    sol_string=\"def f(x): return x**2\",\n    evaluation_res=eval_res,\n    other_info={\"method\": \"mutation\"}\n)\n\nprint(solution.sol_string)\nprint(f\"\u5f97\u5206: {solution.evaluation_res.score}\")\n</code></pre>"},{"location":"zh/api/core/solve/#_1","title":"\u793a\u4f8b","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools import HttpsApi\n\n# \u521b\u5efa\u4efb\u52a1\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\n\n# \u521b\u5efa\u63a5\u53e3\ninterface = EvoEngineerPythonInterface(task)\n\n# \u914d\u7f6e LLM\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"your-api-key\",\n    model=\"gpt-4o\"\n)\n\n# \u6c42\u89e3\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    max_sample_nums=10,\n    pop_size=5\n)\n\nprint(f\"\u6700\u4f73\u5f97\u5206: {result.evaluation_res.score}\")\n</code></pre>"},{"location":"zh/api/interfaces/base-method-interface/","title":"BaseMethodInterface\uff08\u57fa\u7840\u63a5\u53e3\u7c7b\uff09","text":"<p>\u6240\u6709\u65b9\u6cd5\u63a5\u53e3\u7684\u57fa\u7c7b\u3002\u53c2\u89c1\uff1a</p> <ul> <li>Python \u63a5\u53e3</li> <li>CUDA \u63a5\u53e3</li> </ul>"},{"location":"zh/api/interfaces/cuda/","title":"CUDA \u63a5\u53e3","text":"<p>\u7528\u4e8e CUDA \u5185\u6838\u4f18\u5316\u4efb\u52a1\u7684\u63a5\u53e3\u3002</p> <ul> <li>EvoEngineerFullCudaInterface</li> <li>EvoEngineerFreeCudaInterface</li> <li>EvoEngineerInsightCudaInterface</li> <li>FunSearchCudaInterface</li> <li>EoHCudaInterface</li> </ul>"},{"location":"zh/api/interfaces/python/","title":"Python \u63a5\u53e3","text":"<p>\u8fde\u63a5 Python \u4efb\u52a1\u4e0e\u8fdb\u5316\u7b97\u6cd5\u7684\u63a5\u53e3\u3002</p> <ul> <li>EvoEngineerPythonInterface</li> <li>FunSearchPythonInterface</li> <li>EoHPythonInterface</li> </ul>"},{"location":"zh/api/methods/eoh/","title":"EoH\uff08Evolution of Heuristics\uff09","text":""},{"location":"zh/api/methods/eoh/#_1","title":"\u914d\u7f6e","text":""},{"location":"zh/api/methods/evoengineer/","title":"EvoEngineer\uff08\u8fdb\u5316\u5de5\u7a0b\u5e08\uff09","text":""},{"location":"zh/api/methods/evoengineer/#_1","title":"\u914d\u7f6e","text":""},{"location":"zh/api/methods/funsearch/","title":"FunSearch\uff08\u51fd\u6570\u641c\u7d22\uff09","text":""},{"location":"zh/api/methods/funsearch/#_1","title":"\u914d\u7f6e","text":""},{"location":"zh/api/tasks/cuda/cuda-task/","title":"CudaTask\uff08CUDA \u4efb\u52a1\u57fa\u7c7b\uff09","text":""},{"location":"zh/api/tasks/python/python-task/","title":"PythonTask\uff08Python \u4efb\u52a1\u57fa\u7c7b\uff09","text":""},{"location":"zh/api/tasks/python/scientific-regression/","title":"ScientificRegressionTask\uff08\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\uff09","text":""},{"location":"zh/api/tools/https-api/","title":"HttpsApi\uff08LLM \u5ba2\u6237\u7aef\uff09","text":""},{"location":"zh/development/architecture/","title":"\u67b6\u6784\u8bbe\u8ba1","text":"<p>EvoToolkit \u8bbe\u8ba1\u6ce8\u91cd\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002</p>"},{"location":"zh/development/architecture/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"zh/development/architecture/#1-evotoolkittask","title":"1. \u4efb\u52a1 (<code>evotoolkit.task</code>)","text":"<p>\u5b9a\u4e49\u4f18\u5316\u95ee\u9898\u548c\u8bc4\u4f30\u903b\u8f91\u3002</p> <p>\u5173\u952e\u7c7b: - <code>BaseTask</code>: \u6240\u6709\u4efb\u52a1\u7684\u57fa\u7c7b - <code>PythonTask</code>: Python \u4ee3\u7801\u4f18\u5316\u4efb\u52a1 - <code>CudaTask</code>: CUDA \u5185\u6838\u4f18\u5316\u4efb\u52a1 - <code>ScientificRegressionTask</code>: \u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4efb\u52a1</p> <p>\u804c\u8d23: - \u5b9a\u4e49\u95ee\u9898\u7a7a\u95f4 - \u5b9e\u73b0\u89e3\u8bc4\u4f30\u903b\u8f91 - \u63d0\u4f9b\u521d\u59cb\u89e3</p>"},{"location":"zh/development/architecture/#2-evotoolkitevo_method","title":"2. \u65b9\u6cd5 (<code>evotoolkit.evo_method</code>)","text":"<p>\u5b9e\u73b0\u8fdb\u5316\u7b97\u6cd5\uff08EoH\u3001EvoEngineer\u3001FunSearch\uff09\u3002</p> <p>\u5173\u952e\u7c7b: - <code>BaseMethod</code>: \u6240\u6709\u7b97\u6cd5\u7684\u57fa\u7c7b - <code>EvoEngineer</code>: \u4e3b\u8981 LLM \u9a71\u52a8\u8fdb\u5316\u7b97\u6cd5 - <code>FunSearch</code>: \u51fd\u6570\u641c\u7d22\u65b9\u6cd5 - <code>EoH</code>: \u542f\u53d1\u5f0f\u8fdb\u5316\u65b9\u6cd5</p> <p>\u804c\u8d23: - \u7ba1\u7406\u8fdb\u5316\u8fc7\u7a0b - \u7ef4\u62a4\u79cd\u7fa4 - \u9009\u62e9\u548c\u53d8\u5f02\u64cd\u4f5c - \u4e0e LLM \u4ea4\u4e92</p>"},{"location":"zh/development/architecture/#3-evotoolkitcoremethod_interface","title":"3. \u63a5\u53e3 (<code>evotoolkit.core.method_interface</code>)","text":"<p>\u4efb\u52a1\u548c\u65b9\u6cd5\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u5904\u7406\u7279\u5b9a\u4e8e\u7b97\u6cd5\u7684\u9002\u914d\u3002</p> <p>\u5173\u952e\u7c7b: - <code>BaseMethodInterface</code>: \u6240\u6709\u63a5\u53e3\u7684\u57fa\u7c7b - <code>EvoEngineerPythonInterface</code>: EvoEngineer \u7684 Python \u4efb\u52a1\u63a5\u53e3 - <code>FunSearchPythonInterface</code>: FunSearch \u7684 Python \u4efb\u52a1\u63a5\u53e3 - <code>EoHPythonInterface</code>: EoH \u7684 Python \u4efb\u52a1\u63a5\u53e3</p> <p>\u804c\u8d23: - \u751f\u6210\u7279\u5b9a\u4e8e\u7b97\u6cd5\u7684 LLM \u63d0\u793a - \u89e3\u6790 LLM \u54cd\u5e94 - \u5b9e\u73b0\u4efb\u52a1\u7279\u5b9a\u7684\u7b97\u5b50 - \u534f\u8c03\u8bc4\u4f30</p>"},{"location":"zh/development/architecture/#4-evotoolkitregistry","title":"4. \u6ce8\u518c\u8868 (<code>evotoolkit.registry</code>)","text":"<p>\u4efb\u52a1\u548c\u7b97\u6cd5\u7684\u81ea\u52a8\u53d1\u73b0\u548c\u6ce8\u518c\u3002</p> <p>\u529f\u80fd: - \u81ea\u52a8\u6ce8\u518c\u4efb\u52a1\u548c\u65b9\u6cd5 - \u63d0\u4f9b\u67e5\u627e\u548c\u679a\u4e3e - \u652f\u6301\u63d2\u4ef6\u6269\u5c55</p>"},{"location":"zh/development/architecture/#_3","title":"\u8bbe\u8ba1\u6a21\u5f0f","text":""},{"location":"zh/development/architecture/#_4","title":"\u5de5\u5382\u6a21\u5f0f","text":"<p><code>evotoolkit.solve()</code> \u521b\u5efa\u7b97\u6cd5\u5b9e\u4f8b\uff1a</p> <pre><code>def solve(interface, **kwargs):\n    # \u6839\u636e\u63a5\u53e3\u7c7b\u578b\u81ea\u52a8\u9009\u62e9\u7b97\u6cd5\n    method_class = registry.get_method_for_interface(interface)\n    config = create_config(interface, **kwargs)\n    algorithm = method_class(config)\n    return algorithm.run()\n</code></pre>"},{"location":"zh/development/architecture/#_5","title":"\u7b56\u7565\u6a21\u5f0f","text":"<p>\u63a5\u53e3\u63d0\u4f9b\u7279\u5b9a\u4e8e\u7b97\u6cd5\u7684\u7b56\u7565\uff1a</p> <pre><code>class BaseMethodInterface:\n    def generate_prompt(self, generation, population):\n        # \u6bcf\u4e2a\u63a5\u53e3\u5b9e\u73b0\u81ea\u5df1\u7684\u63d0\u793a\u7b56\u7565\n        pass\n\n    def mutate(self, solution):\n        # \u6bcf\u4e2a\u63a5\u53e3\u5b9e\u73b0\u81ea\u5df1\u7684\u53d8\u5f02\u7b56\u7565\n        pass\n</code></pre>"},{"location":"zh/development/architecture/#_6","title":"\u6a21\u677f\u65b9\u6cd5\u6a21\u5f0f","text":"<p>\u57fa\u7c7b\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u5b50\u7c7b\u81ea\u5b9a\u4e49\uff1a</p> <pre><code>class BaseMethod:\n    def run(self):\n        # \u6a21\u677f\u65b9\u6cd5\u5b9a\u4e49\u7b97\u6cd5\u9aa8\u67b6\n        self.initialize()\n        for gen in range(self.max_generations):\n            self.evolve_generation()\n        return self.get_best_solution()\n\n    def evolve_generation(self):\n        # \u7531\u5b50\u7c7b\u5b9e\u73b0\n        raise NotImplementedError\n</code></pre>"},{"location":"zh/development/architecture/#_7","title":"\u6a21\u5757\u7ec4\u7ec7","text":"<pre><code>evotool/\n\u251c\u2500\u2500 __init__.py              # \u9ad8\u7ea7 API\n\u251c\u2500\u2500 core/                    # \u57fa\u7c7b\u548c\u62bd\u8c61\n\u2502   \u251c\u2500\u2500 base_task.py        # Task \u57fa\u7c7b\n\u2502   \u251c\u2500\u2500 solution.py         # Solution \u7c7b\n\u2502   \u251c\u2500\u2500 base_method.py      # Method \u57fa\u7c7b\n\u2502   \u251c\u2500\u2500 base_config.py      # Config \u57fa\u7c7b\n\u2502   \u2514\u2500\u2500 method_interface/   # Interface \u57fa\u7c7b\n\u251c\u2500\u2500 evo_method/             # \u7b97\u6cd5\u5b9e\u73b0\n\u2502   \u251c\u2500\u2500 eoh/               # EoH \u5b9e\u73b0\n\u2502   \u251c\u2500\u2500 evoengineer/       # EvoEngineer \u5b9e\u73b0\n\u2502   \u2514\u2500\u2500 funsearch/         # FunSearch \u5b9e\u73b0\n\u251c\u2500\u2500 task/                   # \u4efb\u52a1\u5b9e\u73b0\n\u2502   \u251c\u2500\u2500 python_task/       # Python \u4efb\u52a1\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 scientific_regression/\n\u2502   \u2502   \u2514\u2500\u2500 method_interface/\n\u2502   \u2514\u2500\u2500 cuda_engineering/  # CUDA \u4efb\u52a1\n\u251c\u2500\u2500 tools/                  # \u5de5\u5177\n\u2502   \u251c\u2500\u2500 llm/               # LLM API \u5ba2\u6237\u7aef\n\u2502   \u2514\u2500\u2500 data/              # \u6570\u636e\u96c6\u7ba1\u7406\n\u2514\u2500\u2500 registry.py            # \u7ec4\u4ef6\u6ce8\u518c\n</code></pre>"},{"location":"zh/development/architecture/#_8","title":"\u6570\u636e\u6d41","text":""},{"location":"zh/development/architecture/#1","title":"1. \u521d\u59cb\u5316\u6d41\u7a0b","text":"<pre><code>\u7528\u6237 \u2192 evotoolkit.solve()\n    \u2193\n\u521b\u5efa Config (interface, llm_api, params)\n    \u2193\n\u521b\u5efa Method \u5b9e\u4f8b (EvoEngineer/FunSearch/EoH)\n    \u2193\n\u521d\u59cb\u5316\u79cd\u7fa4\n</code></pre>"},{"location":"zh/development/architecture/#2","title":"2. \u8fdb\u5316\u5faa\u73af","text":"<pre><code>\u5bf9\u4e8e\u6bcf\u4e00\u4ee3:\n    \u2193\nInterface.generate_prompt() \u2192 \u521b\u5efa LLM \u63d0\u793a\n    \u2193\nLLM API \u2192 \u751f\u6210\u65b0\u4ee3\u7801\n    \u2193\nInterface.parse_llm_response() \u2192 \u63d0\u53d6\u89e3\n    \u2193\nTask.evaluate() \u2192 \u8bc4\u4f30\u9002\u5e94\u5ea6\n    \u2193\nMethod.select() \u2192 \u9009\u62e9\u4e0b\u4e00\u4ee3\n</code></pre>"},{"location":"zh/development/architecture/#3","title":"3. \u7ed3\u679c\u8fd4\u56de","text":"<pre><code>Method.get_best_solution()\n    \u2193\n\u4fdd\u5b58\u7ed3\u679c\u5230 output_path\n    \u2193\n\u8fd4\u56de\u6700\u4f73\u89e3\u7ed9\u7528\u6237\n</code></pre>"},{"location":"zh/development/architecture/#_9","title":"\u6269\u5c55\u70b9","text":""},{"location":"zh/development/architecture/#_10","title":"\u6dfb\u52a0\u65b0\u4efb\u52a1","text":"<ol> <li>\u7ee7\u627f <code>BaseTask</code> \u6216 <code>PythonTask</code>/<code>CudaTask</code></li> <li>\u5b9e\u73b0 <code>evaluate()</code> \u65b9\u6cd5</li> <li>\uff08\u53ef\u9009\uff09\u5728\u6ce8\u518c\u8868\u4e2d\u6ce8\u518c</li> </ol> <pre><code>from evotoolkit.core import BaseTask\n\nclass MyNewTask(BaseTask):\n    def evaluate(self, solution):\n        # \u60a8\u7684\u8bc4\u4f30\u903b\u8f91\n        return fitness\n</code></pre>"},{"location":"zh/development/architecture/#_11","title":"\u6dfb\u52a0\u65b0\u7b97\u6cd5","text":"<ol> <li>\u7ee7\u627f <code>BaseMethod</code></li> <li>\u5b9e\u73b0 <code>run()</code> \u548c\u76f8\u5173\u65b9\u6cd5</li> <li>\u521b\u5efa\u5bf9\u5e94\u7684 <code>Config</code> \u7c7b</li> <li>\u5728\u6ce8\u518c\u8868\u4e2d\u6ce8\u518c</li> </ol> <pre><code>from evotoolkit.core import BaseMethod\n\nclass MyNewAlgorithm(BaseMethod):\n    def run(self):\n        # \u60a8\u7684\u7b97\u6cd5\u903b\u8f91\n        pass\n</code></pre>"},{"location":"zh/development/architecture/#_12","title":"\u6dfb\u52a0\u65b0\u63a5\u53e3","text":"<ol> <li>\u7ee7\u627f <code>BaseMethodInterface</code></li> <li>\u5b9e\u73b0\u63d0\u793a\u751f\u6210\u548c\u54cd\u5e94\u89e3\u6790</li> <li>\uff08\u53ef\u9009\uff09\u5b9e\u73b0\u81ea\u5b9a\u4e49\u7b97\u5b50</li> </ol> <pre><code>from evotoolkit.core.method_interface import BaseMethodInterface\n\nclass MyNewInterface(BaseMethodInterface):\n    def generate_prompt(self, generation, population):\n        # \u63d0\u793a\u751f\u6210\n        pass\n\n    def parse_llm_response(self, response):\n        # \u54cd\u5e94\u89e3\u6790\n        pass\n</code></pre>"},{"location":"zh/development/architecture/#_13","title":"\u6027\u80fd\u8003\u8651","text":""},{"location":"zh/development/architecture/#llm","title":"LLM \u8c03\u7528\u4f18\u5316","text":"<ul> <li>\u6279\u5904\u7406\u8bf7\u6c42</li> <li>\u7f13\u5b58\u5e38\u89c1\u54cd\u5e94</li> <li>\u5e76\u884c\u8bc4\u4f30</li> </ul>"},{"location":"zh/development/architecture/#_14","title":"\u5185\u5b58\u7ba1\u7406","text":"<ul> <li>\u6d41\u5f0f\u5904\u7406\u5927\u578b\u79cd\u7fa4</li> <li>\u53ca\u65f6\u6e05\u7406\u4e34\u65f6\u7ed3\u679c</li> <li>\u4f7f\u7528\u751f\u6210\u5668\u800c\u975e\u5217\u8868</li> </ul>"},{"location":"zh/development/architecture/#_15","title":"\u5e76\u884c\u5316","text":"<ul> <li>\u652f\u6301\u591a\u8fdb\u7a0b\u8bc4\u4f30</li> <li>GPU \u52a0\u901f\uff08CUDA \u4efb\u52a1\uff09</li> <li>\u5206\u5e03\u5f0f\u8fdb\u5316\uff08\u672a\u6765\uff09</li> </ul>"},{"location":"zh/development/architecture/#_16","title":"\u5b89\u5168\u6027","text":""},{"location":"zh/development/architecture/#_17","title":"\u4ee3\u7801\u6267\u884c","text":"<ul> <li>\u6c99\u76d2\u73af\u5883\uff08\u8ba1\u5212\u4e2d\uff09</li> <li>\u6267\u884c\u8d85\u65f6</li> <li>\u8d44\u6e90\u9650\u5236</li> </ul>"},{"location":"zh/development/architecture/#api","title":"API \u5bc6\u94a5","text":"<ul> <li>\u73af\u5883\u53d8\u91cf\u5b58\u50a8</li> <li>\u4e0d\u5728\u65e5\u5fd7\u4e2d\u8bb0\u5f55</li> <li>\u5b89\u5168\u4f20\u8f93</li> </ul>"},{"location":"zh/development/architecture/#_18","title":"\u6d4b\u8bd5\u67b6\u6784","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/              # \u5355\u5143\u6d4b\u8bd5\n\u2502   \u251c\u2500\u2500 test_tasks.py\n\u2502   \u251c\u2500\u2500 test_methods.py\n\u2502   \u2514\u2500\u2500 test_interfaces.py\n\u251c\u2500\u2500 integration/       # \u96c6\u6210\u6d4b\u8bd5\n\u2502   \u2514\u2500\u2500 test_workflows.py\n\u2514\u2500\u2500 fixtures/          # \u6d4b\u8bd5\u6570\u636e\n    \u2514\u2500\u2500 test_data/\n</code></pre>"},{"location":"zh/development/architecture/#_19","title":"\u672a\u6765\u6269\u5c55","text":""},{"location":"zh/development/architecture/#_20","title":"\u8ba1\u5212\u529f\u80fd","text":"<ul> <li>\u5206\u5e03\u5f0f\u8fdb\u5316</li> <li>\u66f4\u591a\u5185\u7f6e\u4efb\u52a1</li> <li>Web UI</li> <li>\u5b9e\u65f6\u76d1\u63a7</li> </ul>"},{"location":"zh/development/architecture/#api_1","title":"API \u7a33\u5b9a\u6027","text":"<ul> <li>\u6838\u5fc3 API \u4fdd\u6301\u5411\u540e\u517c\u5bb9</li> <li>\u5b9e\u9a8c\u6027\u529f\u80fd\u6807\u8bb0\u4e3a <code>@experimental</code></li> <li>\u5f03\u7528\u7b56\u7565\uff1a\u81f3\u5c11\u4fdd\u7559\u4e24\u4e2a\u4e3b\u8981\u7248\u672c</li> </ul> <p>\u8be6\u7ec6\u7684\u5b9e\u73b0\u6307\u5357\uff0c\u8bf7\u53c2\u9605\u6e90\u4ee3\u7801\u6587\u6863\u3002</p>"},{"location":"zh/development/contributing/","title":"\u8d21\u732e\u6307\u5357","text":"<p>\u611f\u8c22\u60a8\u5bf9 EvoToolkit \u7684\u8d21\u732e\u5174\u8da3\uff01\u672c\u6307\u5357\u5c06\u5e2e\u52a9\u60a8\u5f00\u59cb\u3002</p>"},{"location":"zh/development/contributing/#_2","title":"\u5f00\u53d1\u8bbe\u7f6e","text":""},{"location":"zh/development/contributing/#1-fork","title":"1. Fork \u548c\u514b\u9686\u4ed3\u5e93","text":"<pre><code># Fork \u4ed3\u5e93\u5230\u60a8\u7684 GitHub \u8d26\u6237\n# \u7136\u540e\u514b\u9686\u60a8\u7684 fork\ngit clone https://github.com/YOUR_USERNAME/evotoolkit.git\ncd evotool\n</code></pre>"},{"location":"zh/development/contributing/#2","title":"2. \u5b89\u88c5\u5f00\u53d1\u4f9d\u8d56","text":"<pre><code># \u5b89\u88c5\u5f00\u53d1\u4f9d\u8d56\nuv sync --group dev\n\n# \u8fd9\u4f1a\u5b89\u88c5:\n# - black (\u4ee3\u7801\u683c\u5f0f\u5316)\n# - isort (\u5bfc\u5165\u6392\u5e8f)\n# - mypy (\u7c7b\u578b\u68c0\u67e5)\n# - mkdocs (\u6587\u6863)\n\n# \u5982\u679c\u9700\u8981\u5f00\u53d1\u7279\u5b9a\u4efb\u52a1\uff0c\u53ef\u4ee5\u5b89\u88c5\u53ef\u9009\u4f9d\u8d56:\nuv sync --extra cuda_engineering       # CUDA \u4efb\u52a1\nuv sync --extra scientific_regression  # \u79d1\u5b66\u7b26\u53f7\u56de\u5f52\nuv sync --extra adversarial_attack     # \u5bf9\u6297\u653b\u51fb\nuv sync --extra all_tasks              # \u6240\u6709\u4efb\u52a1\u4f9d\u8d56\n</code></pre>"},{"location":"zh/development/contributing/#3","title":"3. \u521b\u5efa\u5206\u652f","text":"<pre><code>git checkout -b feature/your-feature-name\n# \u6216\ngit checkout -b fix/your-bug-fix\n</code></pre>"},{"location":"zh/development/contributing/#_3","title":"\u5f00\u53d1\u5de5\u4f5c\u6d41","text":""},{"location":"zh/development/contributing/#_4","title":"\u4ee3\u7801\u683c\u5f0f\u5316","text":"<pre><code># \u683c\u5f0f\u5316\u4ee3\u7801\nuv run black .\n\n# \u6392\u5e8f\u5bfc\u5165\nuv run isort .\n\n# \u7c7b\u578b\u68c0\u67e5\nuv run mypy src/evotool\n</code></pre>"},{"location":"zh/development/contributing/#_5","title":"\u6784\u5efa\u6587\u6863","text":"<pre><code># \u5728\u672c\u5730\u670d\u52a1\u6587\u6863\nuv run mkdocs serve\n\n# \u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00 http://127.0.0.1:8000\n</code></pre>"},{"location":"zh/development/contributing/#_6","title":"\u8d21\u732e\u7c7b\u578b","text":""},{"location":"zh/development/contributing/#bug","title":"Bug \u4fee\u590d","text":"<ol> <li>\u5728 GitHub Issues \u4e2d\u521b\u5efa issue</li> <li>\u63cf\u8ff0 bug \u548c\u91cd\u73b0\u6b65\u9aa4</li> <li>\u63d0\u4ea4\u4fee\u590d\u7684 pull request</li> </ol>"},{"location":"zh/development/contributing/#_7","title":"\u65b0\u529f\u80fd","text":"<ol> <li>\u9996\u5148\u5728 GitHub Discussions \u4e2d\u8ba8\u8bba</li> <li>\u83b7\u5f97\u7ef4\u62a4\u8005\u6279\u51c6\u540e\u521b\u5efa issue</li> <li>\u5b9e\u73b0\u529f\u80fd\u5e76\u6dfb\u52a0\u6d4b\u8bd5</li> <li>\u66f4\u65b0\u6587\u6863</li> <li>\u63d0\u4ea4 pull request</li> </ol>"},{"location":"zh/development/contributing/#_8","title":"\u6587\u6863\u6539\u8fdb","text":"<ol> <li>\u8bc6\u522b\u9700\u8981\u6539\u8fdb\u7684\u6587\u6863</li> <li>\u5728 <code>docs/</code> \u4e2d\u8fdb\u884c\u66f4\u6539</li> <li>\u672c\u5730\u6d4b\u8bd5\uff08<code>mkdocs serve</code>\uff09</li> <li>\u63d0\u4ea4 pull request</li> </ol>"},{"location":"zh/development/contributing/#pull-request","title":"Pull Request \u6d41\u7a0b","text":""},{"location":"zh/development/contributing/#1","title":"1. \u51c6\u5907\u60a8\u7684\u66f4\u6539","text":"<pre><code># \u786e\u4fdd\u6d4b\u8bd5\u901a\u8fc7\nuv run pytest\n\n# \u683c\u5f0f\u5316\u4ee3\u7801\nuv run black .\nuv run isort .\n\n# \u68c0\u67e5\u7c7b\u578b\nuv run mypy src/evotool\n</code></pre>"},{"location":"zh/development/contributing/#2_1","title":"2. \u63d0\u4ea4\u66f4\u6539","text":"<pre><code>git add .\ngit commit -m \"\u7b80\u77ed\u63cf\u8ff0\u6027\u7684\u63d0\u4ea4\u4fe1\u606f\"\n\n# \u63d0\u4ea4\u4fe1\u606f\u683c\u5f0f:\n# feat: \u6dfb\u52a0\u65b0\u529f\u80fd\n# fix: \u4fee\u590d bug\n# docs: \u6587\u6863\u66f4\u6539\n# test: \u6d4b\u8bd5\u66f4\u6539\n# refactor: \u4ee3\u7801\u91cd\u6784\n</code></pre>"},{"location":"zh/development/contributing/#3-pr","title":"3. \u63a8\u9001\u5e76\u521b\u5efa PR","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>\u7136\u540e\u5728 GitHub \u4e0a\u521b\u5efa pull request\u3002</p>"},{"location":"zh/development/contributing/#4-pr","title":"4. PR \u68c0\u67e5\u6e05\u5355","text":"<ul> <li> \u6240\u6709\u6d4b\u8bd5\u901a\u8fc7</li> <li> \u4ee3\u7801\u5df2\u683c\u5f0f\u5316\uff08black\u3001isort\uff09</li> <li> \u7c7b\u578b\u68c0\u67e5\u901a\u8fc7\uff08mypy\uff09</li> <li> \u6dfb\u52a0\u4e86\u65b0\u529f\u80fd\u7684\u6587\u6863</li> <li> \u6dfb\u52a0\u4e86\u65b0\u4ee3\u7801\u7684\u6d4b\u8bd5</li> <li> PR \u63cf\u8ff0\u6e05\u6670\u8bf4\u660e\u66f4\u6539</li> </ul>"},{"location":"zh/development/contributing/#_9","title":"\u4ee3\u7801\u98ce\u683c","text":""},{"location":"zh/development/contributing/#python","title":"Python \u4ee3\u7801","text":"<ul> <li>\u9075\u5faa PEP 8</li> <li>\u4f7f\u7528 Black \u8fdb\u884c\u683c\u5f0f\u5316\uff08\u884c\u957f\u5ea6\uff1a88\uff09</li> <li>\u4e3a\u6240\u6709\u516c\u5171 API \u6dfb\u52a0\u7c7b\u578b\u63d0\u793a</li> <li>\u4e3a\u51fd\u6570\u548c\u7c7b\u7f16\u5199\u6587\u6863\u5b57\u7b26\u4e32</li> </ul> <p>\u793a\u4f8b\uff1a</p> <pre><code>def evaluate_solution(solution: Solution, task: BaseTask) -&gt; float:\n    \"\"\"\u8bc4\u4f30\u7ed9\u5b9a\u4efb\u52a1\u7684\u89e3\u3002\n\n    Args:\n        solution: \u8981\u8bc4\u4f30\u7684\u5019\u9009\u89e3\n        task: \u5b9a\u4e49\u8bc4\u4f30\u6807\u51c6\u7684\u4efb\u52a1\n\n    Returns:\n        \u9002\u5e94\u5ea6\u503c\uff08\u8d8a\u4f4e\u8d8a\u597d\uff09\n\n    Raises:\n        ValueError: \u5982\u679c\u89e3\u65e0\u6548\n    \"\"\"\n    # \u5b9e\u73b0\n    pass\n</code></pre>"},{"location":"zh/development/contributing/#_10","title":"\u6d4b\u8bd5","text":"<ul> <li>\u4e3a\u6240\u6709\u65b0\u529f\u80fd\u7f16\u5199\u6d4b\u8bd5</li> <li>\u4f7f\u7528\u63cf\u8ff0\u6027\u6d4b\u8bd5\u540d\u79f0</li> <li>\u9075\u5faa Arrange-Act-Assert \u6a21\u5f0f</li> </ul> <p>\u793a\u4f8b\uff1a</p> <pre><code>def test_scientific_regression_task_evaluation():\n    \"\"\"\u6d4b\u8bd5 ScientificRegressionTask \u662f\u5426\u6b63\u786e\u8bc4\u4f30\u6709\u6548\u65b9\u7a0b\u3002\"\"\"\n    # Arrange\n    task = ScientificRegressionTask(dataset_name=\"bactgrow\")\n    code = '''import numpy as np\n    def equation(b, s, temp, pH, params):\n        return params[0] * b + params[1]\n    '''\n\n    # Act\n    result = task.evaluate_code(code)\n\n    # Assert\n    assert result.valid\n    assert result.score &gt; 0\n</code></pre>"},{"location":"zh/development/contributing/#_11","title":"\u6587\u6863","text":""},{"location":"zh/development/contributing/#_12","title":"\u6587\u6863\u5b57\u7b26\u4e32","text":"<p>\u4f7f\u7528 Google \u98ce\u683c\u7684\u6587\u6863\u5b57\u7b26\u4e32\uff1a</p> <pre><code>def my_function(param1: str, param2: int) -&gt; bool:\n    \"\"\"\u5355\u884c\u6458\u8981\u3002\n\n    \u66f4\u8be6\u7ec6\u7684\u63cf\u8ff0\uff08\u53ef\u9009\uff09\u3002\n\n    Args:\n        param1: \u7b2c\u4e00\u4e2a\u53c2\u6570\u7684\u63cf\u8ff0\n        param2: \u7b2c\u4e8c\u4e2a\u53c2\u6570\u7684\u63cf\u8ff0\n\n    Returns:\n        \u8fd4\u56de\u503c\u7684\u63cf\u8ff0\n\n    Raises:\n        ValueError: \u4f55\u65f6\u5f15\u53d1\u6b64\u5f02\u5e38\n    \"\"\"\n    pass\n</code></pre>"},{"location":"zh/development/contributing/#markdown","title":"Markdown \u6587\u6863","text":"<ul> <li>\u4f7f\u7528\u6e05\u6670\u7684\u6807\u9898\u5c42\u6b21\u7ed3\u6784</li> <li>\u5305\u542b\u4ee3\u7801\u793a\u4f8b</li> <li>\u6dfb\u52a0\u5230 <code>mkdocs.yml</code> \u5bfc\u822a</li> </ul>"},{"location":"zh/development/contributing/#_13","title":"\u53d1\u5e03\u6d41\u7a0b","text":"<p>\uff08\u4ec5\u7ef4\u62a4\u8005\uff09</p> <ol> <li>\u66f4\u65b0 <code>pyproject.toml</code> \u4e2d\u7684\u7248\u672c</li> <li>\u66f4\u65b0 <code>CHANGELOG.md</code></li> <li>\u521b\u5efa git \u6807\u7b7e</li> <li>\u63a8\u9001\u5230 PyPI</li> </ol>"},{"location":"zh/development/contributing/#_14","title":"\u83b7\u53d6\u5e2e\u52a9","text":"<ul> <li>\u95ee\u9898: GitHub Issues</li> <li>\u8ba8\u8bba: GitHub Discussions</li> <li>\u7535\u5b50\u90ae\u4ef6: pguo6680@gmail.com</li> </ul>"},{"location":"zh/development/contributing/#_15","title":"\u884c\u4e3a\u51c6\u5219","text":"<p>\u8bf7\u53cb\u5584\u548c\u5c0a\u91cd\u3002\u6211\u4eec\u5e0c\u671b\u4e3a\u6bcf\u4e2a\u4eba\u8425\u9020\u4e00\u4e2a\u6b22\u8fce\u7684\u73af\u5883\u3002</p>"},{"location":"zh/development/contributing/#_16","title":"\u8bb8\u53ef\u8bc1","text":"<p>\u901a\u8fc7\u8d21\u732e\uff0c\u60a8\u540c\u610f\u60a8\u7684\u8d21\u732e\u5c06\u6839\u636e\u4e0e\u9879\u76ee\u76f8\u540c\u7684\u8bb8\u53ef\u8bc1\u8fdb\u884c\u8bb8\u53ef\uff08\u53c2\u89c1 LICENSE\uff09\u3002</p>"},{"location":"zh/getting-started/exploring-results/","title":"\u63a2\u7d22\u7ed3\u679c","text":"<p>\u8fd0\u884c\u540e\uff0c\u68c0\u67e5 <code>./results/</code> \u76ee\u5f55\uff1a</p>"},{"location":"zh/getting-started/exploring-results/#_2","title":"\u7ed3\u679c\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>results/\n\u251c\u2500\u2500 run_state.json              # \u8fd0\u884c\u72b6\u6001\u548c\u7edf\u8ba1\u4fe1\u606f\n\u251c\u2500\u2500 history/                    # \u5386\u53f2\u8bb0\u5f55\n\u2502   \u251c\u2500\u2500 gen_-1.json            # \u521d\u59cb\u79cd\u7fa4\n\u2502   \u251c\u2500\u2500 gen_1.json             # \u7b2c 1 \u4ee3\u7684\u6240\u6709\u89e3\n\u2502   \u251c\u2500\u2500 gen_2.json             # \u7b2c 2 \u4ee3\u7684\u6240\u6709\u89e3\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 summary/                    # \u6458\u8981\u4fe1\u606f\n    \u251c\u2500\u2500 usage_history.json     # LLM \u4f7f\u7528\u7edf\u8ba1\n    \u2514\u2500\u2500 best_per_generation.json  # \u6bcf\u4ee3\u6700\u4f18\u89e3\uff08\u5982\u6709\uff09\n</code></pre>"},{"location":"zh/getting-started/exploring-results/#_3","title":"\u4ee5\u7f16\u7a0b\u65b9\u5f0f\u5206\u6790\u7ed3\u679c","text":"<p>\u6bcf\u4e2a <code>gen_N.json</code> \u6587\u4ef6\u5305\u542b\u8be5\u4ee3\u7684\u6240\u6709\u89e3\u51b3\u65b9\u6848\u3001\u8bc4\u4f30\u7ed3\u679c\u548c\u7edf\u8ba1\u4fe1\u606f\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7\u7f16\u7a0b\u65b9\u5f0f\u52a0\u8f7d\u548c\u5206\u6790\u8fd9\u4e9b\u7ed3\u679c\uff1a</p> <pre><code>import json\n\n# \u52a0\u8f7d\u67d0\u4e00\u4ee3\u7684\u5386\u53f2\nwith open('./results/history/gen_1.json', 'r') as f:\n    gen_1 = json.load(f)\n\n# \u67e5\u770b\u8be5\u4ee3\u7684\u6240\u6709\u89e3\u51b3\u65b9\u6848\nfor sol in gen_1['solutions']:\n    print(f\"Score: {sol['evaluation_res']['score']}\")\n    print(f\"Solution:\\n{sol['sol_string']}\\n\")\n</code></pre> <p>\u4e0b\u4e00\u6b65\uff1a \u5c1d\u8bd5\u4e0d\u540c\u7684\u7b97\u6cd5</p>"},{"location":"zh/getting-started/first-optimization/","title":"\u7b2c\u4e00\u4e2a\u4f18\u5316\u4efb\u52a1\uff1a\u79d1\u5b66\u7b26\u53f7\u56de\u5f52","text":"<p>\u8ba9\u6211\u4eec\u4f7f\u7528 EvoToolkit \u4ece\u771f\u5b9e\u79d1\u5b66\u6570\u636e\u4e2d\u53d1\u73b0\u6570\u5b66\u65b9\u7a0b\u3002</p> <p>\u5b66\u672f\u5f15\u7528</p> <p>\u672c\u6307\u5357\u4f7f\u7528\u7684\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4efb\u52a1\u548c\u6570\u636e\u96c6\u57fa\u4e8e CoEvo \u7684\u7814\u7a76\u3002\u5982\u679c\u60a8\u5728\u5b66\u672f\u5de5\u4f5c\u4e2d\u4f7f\u7528\u6b64\u529f\u80fd\uff0c\u8bf7\u5f15\u7528\uff1a</p> <pre><code>@misc{guo2024coevocontinualevolutionsymbolic,\n    title={CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models},\n    author={Ping Guo and Qingfu Zhang and Xi Lin},\n    year={2024},\n    eprint={2412.18890},\n    archivePrefix={arXiv},\n    primaryClass={cs.AI},\n    url={https://arxiv.org/abs/2412.18890}\n}\n</code></pre>"},{"location":"zh/getting-started/first-optimization/#1","title":"\u6b65\u9aa4 1: \u521b\u5efa\u65b0\u9879\u76ee","text":"<pre><code>mkdir my-evotool-project\ncd my-evotool-project\n</code></pre>"},{"location":"zh/getting-started/first-optimization/#2","title":"\u6b65\u9aa4 2: \u7f16\u5199\u7b2c\u4e00\u4e2a\u811a\u672c","text":"<p>\u521b\u5efa\u540d\u4e3a <code>first_optimization.py</code> \u7684\u6587\u4ef6\uff1a</p> <pre><code>import evotoolkit\nfrom evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools import HttpsApi\n\n# \u6b65\u9aa4 1: \u521b\u5efa\u4efb\u52a1\nprint(\"\u521b\u5efa\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4efb\u52a1...\")\ntask = ScientificRegressionTask(dataset_name=\"bactgrow\")\n\n# \u6b65\u9aa4 2: \u521b\u5efa\u63a5\u53e3\nprint(\"\u8bbe\u7f6e EvoEngineer \u63a5\u53e3...\")\ninterface = EvoEngineerPythonInterface(task)\n\n# \u6b65\u9aa4 3: \u914d\u7f6e LLM API\nprint(\"\u914d\u7f6e LLM API...\")\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",  # \u586b\u5199\u60a8\u7684 API \u5730\u5740\n    key=\"your-api-key-here\",  # \u586b\u5199\u60a8\u7684 API \u5bc6\u94a5\n    model=\"gpt-4o\"\n)\n\n# \u6b65\u9aa4 4: \u8fd0\u884c\u4f18\u5316\nprint(\"\\n\u4f7f\u7528 EvoEngineer \u5f00\u59cb\u4f18\u5316...\")\nprint(\"\u8fd9\u53ef\u80fd\u9700\u8981\u51e0\u5206\u949f...\\n\")\n\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    max_sample_nums=10,\n    pop_size=5\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"\u4f18\u5316\u5b8c\u6210\uff01\")\nprint(\"=\"*60)\nprint(f\"\\n\u6700\u4f73\u89e3\u9002\u5e94\u5ea6: {result.evaluation_res.score}\")\nprint(f\"\u7ed3\u679c\u5df2\u4fdd\u5b58\u5230: ./results/\")\n</code></pre>"},{"location":"zh/getting-started/first-optimization/#3","title":"\u6b65\u9aa4 3: \u8fd0\u884c\u811a\u672c","text":"<pre><code>python first_optimization.py\n</code></pre> <p>\u60a8\u5e94\u8be5\u770b\u5230\u7c7b\u4f3c\u4ee5\u4e0b\u7684\u8f93\u51fa\uff1a</p> <pre><code>\u521b\u5efa\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4efb\u52a1...\n\u8bbe\u7f6e EvoEngineer \u63a5\u53e3...\n\u914d\u7f6e LLM API...\n\n\u4f7f\u7528 EvoEngineer \u5f00\u59cb\u4f18\u5316...\n\u8fd9\u53ef\u80fd\u9700\u8981\u51e0\u5206\u949f...\n\n\u7b2c 1/5 \u4ee3: \u6700\u4f73\u9002\u5e94\u5ea6 = 0.245\n\u7b2c 2/5 \u4ee3: \u6700\u4f73\u9002\u5e94\u5ea6 = 0.189\n\u7b2c 3/5 \u4ee3: \u6700\u4f73\u9002\u5e94\u5ea6 = 0.134\n\u7b2c 4/5 \u4ee3: \u6700\u4f73\u9002\u5e94\u5ea6 = 0.098\n\u7b2c 5/5 \u4ee3: \u6700\u4f73\u9002\u5e94\u5ea6 = 0.067\n\n============================================================\n\u4f18\u5316\u5b8c\u6210\uff01\n============================================================\n\n\u6700\u4f73\u89e3\u9002\u5e94\u5ea6: 0.067\n\u7ed3\u679c\u5df2\u4fdd\u5b58\u5230: ./results/\n</code></pre> <p>\u4e0b\u4e00\u6b65\uff1a \u7406\u89e3\u4ee3\u7801</p>"},{"location":"zh/getting-started/next-steps/","title":"\u4e0b\u4e00\u6b65","text":"<p>\u606d\u559c\uff01\u60a8\u5df2\u7ecf\u5b8c\u6210\u4e86\u4f7f\u7528 EvoToolkit \u7684\u7b2c\u4e00\u4e2a\u4f18\u5316\u4efb\u52a1\u3002\u63a5\u4e0b\u6765\u53ef\u4ee5\u63a2\u7d22\uff1a</p>"},{"location":"zh/getting-started/next-steps/#_2","title":"\u6559\u7a0b","text":"<ul> <li>\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b: \u6df1\u5165\u4e86\u89e3\u79d1\u5b66\u7b26\u53f7\u56de\u5f52</li> <li>\u81ea\u5b9a\u4e49\u4efb\u52a1\u6559\u7a0b: \u521b\u5efa\u60a8\u81ea\u5df1\u7684\u4f18\u5316\u4efb\u52a1</li> <li>API \u53c2\u8003: \u8be6\u7ec6\u7684 API \u6587\u6863</li> <li>\u9ad8\u7ea7\u7528\u6cd5: \u4f4e\u7ea7 API \u548c\u81ea\u5b9a\u4e49</li> </ul>"},{"location":"zh/getting-started/next-steps/#_3","title":"\u83b7\u53d6\u5e2e\u52a9","text":"<p>\u5982\u679c\u9047\u5230\u95ee\u9898\uff1a</p> <ul> <li>\u67e5\u770b API \u53c2\u8003 \u83b7\u53d6\u8be6\u7ec6\u6587\u6863</li> <li>\u8bbf\u95ee GitHub Issues</li> <li>\u52a0\u5165 GitHub Discussions</li> </ul>"},{"location":"zh/getting-started/try-algorithms/","title":"\u5c1d\u8bd5\u4e0d\u540c\u7684\u7b97\u6cd5","text":"<p>EvoToolkit \u652f\u6301\u591a\u79cd\u8fdb\u5316\u7b97\u6cd5\u3002\u8bd5\u8bd5\u6240\u6709\u7b97\u6cd5\uff1a</p>"},{"location":"zh/getting-started/try-algorithms/#eoh","title":"EoH\uff08\u542f\u53d1\u5f0f\u8fdb\u5316\uff09","text":"<pre><code>from evotoolkit.task.python_task import EoHPythonInterface\n\ninterface = EoHPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre>"},{"location":"zh/getting-started/try-algorithms/#funsearch","title":"FunSearch","text":"<pre><code>from evotoolkit.task.python_task import FunSearchPythonInterface\n\ninterface = FunSearchPythonInterface(task)\nresult = evotoolkit.solve(interface=interface, ...)\n</code></pre> <p>\u4e0b\u4e00\u6b65\uff1a \u63a5\u4e0b\u6765\u505a\u4ec0\u4e48</p>"},{"location":"zh/getting-started/understanding-code/","title":"\u7406\u89e3\u4ee3\u7801","text":"<p>\u8ba9\u6211\u4eec\u5206\u89e3\u6bcf\u4e2a\u90e8\u5206\u7684\u4f5c\u7528\uff1a</p>"},{"location":"zh/getting-started/understanding-code/#1","title":"1. \u4efb\u52a1\u521b\u5efa","text":"<pre><code>task = ScientificRegressionTask(dataset_name=\"bactgrow\")\n</code></pre> <p><code>Task</code> \u5b9a\u4e49\u4e86\u60a8\u8981\u89e3\u51b3\u7684\u95ee\u9898\u4ee5\u53ca\u5982\u4f55\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002<code>ScientificRegressionTask</code> \u662f\u7528\u4e8e\u4ece\u771f\u5b9e\u79d1\u5b66\u6570\u636e\u4e2d\u53d1\u73b0\u6570\u5b66\u65b9\u7a0b\u7684\u5185\u7f6e\u4efb\u52a1\u3002\u6570\u636e\u96c6\u4f1a\u5728\u9996\u6b21\u8fd0\u884c\u65f6\u81ea\u52a8\u4e0b\u8f7d\uff08\u61d2\u52a0\u8f7d\uff09\u3002</p>"},{"location":"zh/getting-started/understanding-code/#2","title":"2. \u63a5\u53e3\u521b\u5efa","text":"<pre><code>interface = EvoEngineerPythonInterface(task)\n</code></pre> <p><code>Interface</code> \u5c06\u60a8\u7684\u4efb\u52a1\u8fde\u63a5\u5230\u7279\u5b9a\u7684\u8fdb\u5316\u7b97\u6cd5\u3002\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528 <code>EvoEngineerPythonInterface</code> \u6765\u4f7f\u7528 EvoEngineer \u7b97\u6cd5\u3002</p>"},{"location":"zh/getting-started/understanding-code/#3-llm","title":"3. LLM \u914d\u7f6e","text":"<pre><code>llm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"your-api-key-here\",\n    model=\"gpt-4o\"\n)\n</code></pre> <p>\u8fd9\u4f1a\u8bbe\u7f6e LLM API \u5ba2\u6237\u7aef\uff0c\u7528\u4e8e\u751f\u6210\u548c\u6539\u8fdb\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\u3002\u8bf7\u5c06 <code>your-api-key-here</code> \u66ff\u6362\u4e3a\u60a8\u7684\u5b9e\u9645 API \u5bc6\u94a5\u3002</p>"},{"location":"zh/getting-started/understanding-code/#4","title":"4. \u6c42\u89e3\u95ee\u9898","text":"<pre><code>result = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    max_sample_nums=10,\n    pop_size=5\n)\n</code></pre> <p><code>evotoolkit.solve()</code> \u51fd\u6570\uff1a</p> <ul> <li>\u8fd0\u884c\u8fdb\u5316\u7b97\u6cd5 5 \u4ee3</li> <li>\u4f7f\u7528\u79cd\u7fa4\u5927\u5c0f\u4e3a 5</li> <li>\u6bcf\u4ee3\u6700\u591a\u91c7\u6837 10 \u4e2a LLM \u54cd\u5e94</li> <li>\u5c06\u7ed3\u679c\u4fdd\u5b58\u5230 <code>./results/</code></li> </ul> <p>\u4e0b\u4e00\u6b65\uff1a \u63a2\u7d22\u7ed3\u679c</p>"},{"location":"zh/installation/env-managers/","title":"\u73af\u5883\u4e0e\u5305\u7ba1\u7406\u5668","text":"<p>\u4f7f\u7528\u60a8\u719f\u6089\u7684\u5de5\u5177\u7ba1\u7406 Python \u73af\u5883\u3002</p>"},{"location":"zh/installation/env-managers/#uv","title":"\u4f7f\u7528 uv\uff08\u63a8\u8350\uff09","text":"<pre><code># \u5b89\u88c5 uv\npip install uv\n\n# \u521b\u5efa\u65b0\u9879\u76ee\nuv init my-evotool-project\ncd my-evotool-project\n\n# \u6dfb\u52a0 evotoolkit\nuv add evotoolkit\n\n# \u8fd0\u884c\u811a\u672c\nuv run python main.py\n</code></pre>"},{"location":"zh/installation/env-managers/#pip","title":"\u4f7f\u7528 pip","text":"<pre><code># \u521b\u5efa\u865a\u62df\u73af\u5883\npython -m venv .venv\nsource .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n\n# \u5b89\u88c5 evotoolkit\npip install evotoolkit\n</code></pre>"},{"location":"zh/installation/env-managers/#conda","title":"\u4f7f\u7528 conda","text":"<pre><code># \u521b\u5efa conda \u73af\u5883\nconda create -n evotool python=3.11\nconda activate evotool\n\n# \u5b89\u88c5 evotoolkit\npip install evotoolkit\n</code></pre>"},{"location":"zh/installation/from-source/","title":"\u4ece\u6e90\u7801\u5b89\u88c5","text":"<p>\u7528\u4e8e\u5f00\u53d1\u6216\u83b7\u53d6\u4ed3\u5e93\u4e2d\u7684\u6700\u65b0\u529f\u80fd\u3002</p>"},{"location":"zh/installation/from-source/#_2","title":"\u514b\u9686\u4ed3\u5e93","text":"<pre><code>git clone https://github.com/pgg3/evotoolkitkit.git\ncd evotool\n</code></pre>"},{"location":"zh/installation/from-source/#uv","title":"\u4f7f\u7528 uv \u5b89\u88c5\uff08\u63a8\u8350\uff09","text":"<pre><code>pip install uv\nuv sync\n</code></pre>"},{"location":"zh/installation/from-source/#pip","title":"\u4f7f\u7528 pip \u5b89\u88c5\uff08\u53ef\u7f16\u8f91\u6a21\u5f0f\uff09","text":"<pre><code>pip install -e .\n</code></pre>"},{"location":"zh/installation/llm-and-verify/","title":"LLM \u8bbe\u7f6e\u4e0e\u9a8c\u8bc1","text":"<p>\u914d\u7f6e LLM API \u5e76\u9a8c\u8bc1\u5b89\u88c5\u662f\u5426\u6210\u529f\u3002</p>"},{"location":"zh/installation/llm-and-verify/#_1","title":"\u9a8c\u8bc1\u5b89\u88c5","text":"<pre><code>import evotoolkit\nfrom evotoolkit.core import Solution\n\nprint(f\"EvoToolkit \u7248\u672c: {evotoolkit.__version__}\")\nprint(\"\u2705 \u5b89\u88c5\u6210\u529f\uff01\")\n</code></pre>"},{"location":"zh/installation/llm-and-verify/#llm-api","title":"LLM API \u8bbe\u7f6e","text":"<p>EvoToolkit \u4f7f\u7528\u5916\u90e8 LLM API\uff08\u4f8b\u5982 OpenAI GPT-4\uff09\u3002\u5728\u4ee3\u7801\u4e2d\u914d\u7f6e\u51ed\u636e\uff1a</p> <pre><code>from evotoolkit.tools import HttpsApi\n\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",  # \u586b\u5199\u60a8\u7684 API \u5730\u5740\n    key=\"your-api-key-here\",  # \u586b\u5199\u60a8\u7684 API \u5bc6\u94a5\n    model=\"gpt-4o\"\n)\n</code></pre> <p>\u60a8\u53ef\u4ee5\u4ece OpenAI \u83b7\u53d6 API Key\uff0c\u6216\u4f7f\u7528\u5176\u4ed6\u517c\u5bb9 OpenAI \u534f\u8bae\u7684\u670d\u52a1\u3002</p>"},{"location":"zh/installation/pypi/","title":"\u4ece PyPI \u5b89\u88c5","text":"<p>\u901a\u8fc7 pip \u5b89\u88c5 EvoToolkit \u662f\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u3002</p>"},{"location":"zh/installation/pypi/#_1","title":"\u57fa\u672c\u5b89\u88c5","text":"<pre><code>pip install evotoolkit\n</code></pre>"},{"location":"zh/installation/pypi/#_2","title":"\u53ef\u9009\u4f9d\u8d56","text":"<p>EvoToolkit \u4e3a\u7279\u5b9a\u4efb\u52a1\u63d0\u4f9b\u53ef\u9009\u7684\u9644\u52a0\u4f9d\u8d56\u3002\u4f8b\u5982\uff0c\u8981\u542f\u7528 CUDA \u5185\u6838\u5de5\u7a0b\u7c7b\u4efb\u52a1\uff1a</p> <pre><code>pip install evotoolkit[cuda_engineering]\n</code></pre>"},{"location":"zh/installation/requirements/","title":"\u7cfb\u7edf\u8981\u6c42","text":"<p>EvoToolkit \u9002\u7528\u4e8e\u73b0\u4ee3 Python \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u73af\u5883\u3002</p>"},{"location":"zh/installation/requirements/#_2","title":"\u652f\u6301\u7248\u672c","text":"<ul> <li>Python\uff1a3.11 \u6216\u66f4\u9ad8\u7248\u672c</li> <li>\u64cd\u4f5c\u7cfb\u7edf\uff1aLinux\u3001macOS \u6216 Windows</li> <li>\u53ef\u9009\uff1a\u652f\u6301 CUDA \u7684 GPU\uff08\u7528\u4e8e CUDA \u5de5\u7a0b\u4efb\u52a1\uff09</li> </ul>"},{"location":"zh/installation/troubleshooting/","title":"\u5e38\u89c1\u95ee\u9898","text":"<p>\u5b89\u88c5\u4e0e\u914d\u7f6e\u8fc7\u7a0b\u4e2d\u5e38\u89c1\u95ee\u9898\u4e0e\u5feb\u901f\u89e3\u51b3\u65b9\u6cd5\u3002</p>"},{"location":"zh/installation/troubleshooting/#pip-evotoolkit","title":"pip \u627e\u4e0d\u5230 evotoolkit","text":"<ul> <li>\u786e\u4fdd\u7f51\u7edc\u53ef\u7528\u5e76\u5347\u7ea7 pip\uff1a<code>python -m pip install -U pip</code>\u3002</li> <li>\u786e\u8ba4\u5305\u540d\u6b63\u786e\uff1a<code>evotoolkit</code>\u3002</li> </ul>"},{"location":"zh/installation/troubleshooting/#importerror-cannot-import-name-solution","title":"ImportError: cannot import name 'Solution'","text":"<ul> <li>\u68c0\u67e5\u7248\u672c\uff1a<code>python -c \"import evotoolkit, sys; print(evotoolkit.__version__)\"</code>\u3002</li> <li>\u82e5\u5b58\u5728\u591a\u4e2a Python \u7248\u672c\uff0c\u8bf7\u4f7f\u7528\u4e0e\u5b89\u88c5\u73af\u5883\u4e00\u81f4\u7684\u89e3\u91ca\u5668\u8fd0\u884c\u4ee3\u7801\u3002</li> </ul>"},{"location":"zh/installation/troubleshooting/#cuda","title":"\u672a\u68c0\u6d4b\u5230 CUDA","text":"<ul> <li>\u5b89\u88c5\u4e0e\u7cfb\u7edf\u548c\u663e\u5361\u5339\u914d\u7684 CUDA \u5de5\u5177\u5305\u4e0e\u9a71\u52a8\u3002</li> <li>\u67d0\u4e9b\u4efb\u52a1\u9700\u8981 <code>cuda_engineering</code> \u9644\u52a0\u4f9d\u8d56\uff1a<code>pip install evotoolkit[cuda_engineering]</code>\u3002</li> </ul>"},{"location":"zh/installation/troubleshooting/#llm-api-401403sslerror","title":"LLM API \u62a5\u9519\uff08401/403/SSLError\uff09","text":"<ul> <li>\u68c0\u67e5\u5e76\u6b63\u786e\u914d\u7f6e API Key\u3002</li> <li>\u68c0\u67e5\u7cfb\u7edf\u65f6\u95f4\u548c\u8bc1\u4e66\u914d\u7f6e\u3002</li> <li>\u5982\u4f7f\u7528\u4ee3\u7406\uff0c\u8bf7\u786e\u4fdd\u5141\u8bb8\u8bbf\u95ee\u5bf9\u5e94 API \u7aef\u70b9\u7684 HTTPS \u6d41\u91cf\u3002</li> </ul>"},{"location":"zh/tutorials/","title":"\u6559\u7a0b","text":"<p>\u6b22\u8fce\u6765\u5230 EvoToolkit \u6559\u7a0b\uff01\u8fd9\u4e9b\u5206\u6b65\u6307\u5357\u5c06\u5e2e\u52a9\u60a8\u638c\u63e1\u4f7f\u7528 LLM \u8fdb\u884c\u8fdb\u5316\u4f18\u5316\u3002</p>"},{"location":"zh/tutorials/#_2","title":"\u5165\u95e8\u6307\u5357","text":"<p>\u521d\u6b21\u4f7f\u7528 EvoToolkit\uff1f\u4ece\u8fd9\u91cc\u5f00\u59cb\uff1a</p> <ol> <li>\u5b89\u88c5 - \u8bbe\u7f6e\u60a8\u7684\u73af\u5883</li> <li>\u5feb\u901f\u5f00\u59cb - 5 \u5206\u949f\u5185\u8fd0\u884c\u60a8\u7684\u7b2c\u4e00\u4e2a\u4f18\u5316\u4efb\u52a1</li> <li>\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b - \u6df1\u5165\u4e86\u89e3\u5b8c\u6574\u793a\u4f8b</li> </ol>"},{"location":"zh/tutorials/#_3","title":"\u6559\u7a0b\u5206\u7c7b","text":""},{"location":"zh/tutorials/#_4","title":"\u5185\u7f6e\u4efb\u52a1","text":"<p>\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 EvoToolkit \u7684\u9884\u6784\u5efa\u4f18\u5316\u4efb\u52a1\uff1a</p> <ul> <li>\u79d1\u5b66\u7b26\u53f7\u56de\u5f52 - \u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u6570\u5b66\u65b9\u7a0b</li> <li>\u63d0\u793a\u8bcd\u5de5\u7a0b - \u4f18\u5316 LLM \u63d0\u793a\u8bcd\u4ee5\u63d0\u5347\u6027\u80fd</li> <li>\u5bf9\u6297\u653b\u51fb - \u751f\u6210\u5bf9\u6297\u6837\u672c</li> <li>CUDA \u4efb\u52a1 - \u4f18\u5316 GPU \u5185\u6838\u6027\u80fd</li> </ul>"},{"location":"zh/tutorials/#_5","title":"\u81ea\u5b9a\u4e49","text":"<p>\u6269\u5c55 EvoToolkit \u4ee5\u6ee1\u8db3\u60a8\u7684\u7279\u5b9a\u9700\u6c42\uff1a</p> <ul> <li>\u81ea\u5b9a\u4e49\u4efb\u52a1 - \u521b\u5efa\u60a8\u81ea\u5df1\u7684\u4f18\u5316\u95ee\u9898</li> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u4fee\u6539 prompt \u548c\u7b97\u6cd5</li> </ul>"},{"location":"zh/tutorials/#_6","title":"\u9ad8\u7ea7","text":"<p>\u638c\u63e1\u4f4e\u7ea7 API\uff1a</p> <ul> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u7cbe\u7ec6\u63a7\u5236\u548c\u8c03\u8bd5</li> </ul>"},{"location":"zh/tutorials/#_7","title":"\u6559\u7a0b\u6982\u89c8","text":"\u6559\u7a0b \u96be\u5ea6 \u65f6\u95f4 \u6db5\u76d6\u4e3b\u9898 \u79d1\u5b66\u7b26\u53f7\u56de\u5f52 \u521d\u7ea7 20 \u5206\u949f \u9ad8\u7ea7 API\u3001\u771f\u5b9e\u6570\u636e\u96c6\u3001\u65b9\u7a0b\u8fdb\u5316 \u63d0\u793a\u8bcd\u5de5\u7a0b \u521d\u7ea7-\u4e2d\u7ea7 20 \u5206\u949f LLM prompt \u4f18\u5316\u3001\u4efb\u52a1\u6027\u80fd\u63d0\u5347 \u5bf9\u6297\u653b\u51fb \u4e2d\u7ea7 25 \u5206\u949f \u8fdb\u5316\u5bf9\u6297\u6837\u672c\u3001\u653b\u51fb\u7b97\u6cd5\u8bbe\u8ba1 CUDA \u4efb\u52a1 \u9ad8\u7ea7 30 \u5206\u949f GPU \u4f18\u5316\u3001CUDA \u5185\u6838\u3001\u6027\u80fd \u81ea\u5b9a\u4e49\u4efb\u52a1 \u4e2d\u7ea7 20 \u5206\u949f \u521b\u5efa\u4efb\u52a1\u3001\u8bc4\u4f30\u3001\u81ea\u5b9a\u4e49\u9002\u5e94\u5ea6 \u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 \u4e2d\u7ea7-\u9ad8\u7ea7 30 \u5206\u949f Prompt \u5de5\u7a0b\u3001\u81ea\u5b9a\u4e49\u7b97\u6cd5\u3001Interface \u5f00\u53d1 \u9ad8\u7ea7\u7528\u6cd5 \u9ad8\u7ea7 25 \u5206\u949f \u4f4e\u7ea7 API\u3001\u81ea\u5b9a\u4e49\u914d\u7f6e\u3001\u8c03\u8bd5"},{"location":"zh/tutorials/#_8","title":"\u5feb\u901f\u53c2\u8003","text":""},{"location":"zh/tutorials/#_9","title":"\u5e38\u89c1\u5de5\u4f5c\u6d41\u6a21\u5f0f","text":""},{"location":"zh/tutorials/#1","title":"\u6a21\u5f0f 1: \u57fa\u7840\u4f18\u5316","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\n\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface, './results', llm_api)\n</code></pre>"},{"location":"zh/tutorials/#2","title":"\u6a21\u5f0f 2: \u7b97\u6cd5\u6bd4\u8f83","text":"<pre><code>algorithms = [\n    ('EoH', EoHPythonInterface(task)),\n    ('EvoEngineer', EvoEngineerPythonInterface(task)),\n    ('FunSearch', FunSearchPythonInterface(task))\n]\n\nfor name, interface in algorithms:\n    result = evotoolkit.solve(interface, f'./results/{name}', llm_api)\n</code></pre>"},{"location":"zh/tutorials/#3","title":"\u6a21\u5f0f 3: \u81ea\u5b9a\u4e49\u914d\u7f6e","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=20,\n    pop_size=10\n)\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n</code></pre>"},{"location":"zh/tutorials/#_10","title":"\u53ef\u4e0b\u8f7d\u793a\u4f8b","text":"<p>\u6240\u6709\u6559\u7a0b\u4ee3\u7801\u90fd\u53ef\u4ee5\u4f5c\u4e3a <code>examples/</code> \u76ee\u5f55\u4e2d\u7684\u72ec\u7acb Python \u811a\u672c\u4f7f\u7528\uff1a</p> <ul> <li><code>examples/scientific_regression/</code> - \u79d1\u5b66\u65b9\u7a0b\u53d1\u73b0</li> <li><code>examples/custom_task/my_custom_task.py</code> - \u81ea\u5b9a\u4e49\u4efb\u52a1\u5b9e\u73b0</li> <li><code>examples/cuda_task/kernel_optimization.py</code> - CUDA \u5185\u6838\u4f18\u5316</li> <li><code>examples/advanced/low_level_api.py</code> - \u4f4e\u7ea7 API \u7528\u6cd5</li> </ul> <p>\u514b\u9686\u4ed3\u5e93\u5f00\u59cb\uff1a</p> <pre><code>git clone https://github.com/pgg3/evotoolkitkit.git\ncd evotool/examples\n</code></pre>"},{"location":"zh/tutorials/#_11","title":"\u9700\u8981\u5e2e\u52a9\uff1f","text":""},{"location":"zh/tutorials/#_12","title":"\u6587\u6863\u548c\u8d44\u6e90","text":"<ul> <li>API \u53c2\u8003 - \u8be6\u7ec6\u7684 API \u6587\u6863</li> <li>\u5f00\u53d1\u6307\u5357 - \u8d21\u732e\u4ee3\u7801\u6307\u5357</li> <li>\u9ad8\u7ea7\u793a\u4f8b - \u590d\u6742\u7528\u4f8b\u53c2\u8003</li> </ul>"},{"location":"zh/tutorials/#_13","title":"\u793e\u533a\u652f\u6301","text":"<ul> <li>GitHub \u8ba8\u8bba - \u63d0\u95ee\u548c\u5206\u4eab\u9879\u76ee</li> <li>GitHub Issues - \u62a5\u544a\u95ee\u9898\u548c\u5efa\u8bae\u529f\u80fd</li> <li>\u793a\u4f8b\u5e93 - \u793e\u533a\u8d21\u732e\u7684\u793a\u4f8b</li> <li>\u535a\u5ba2 - \u6587\u7ae0\u548c\u6848\u4f8b\u7814\u7a76</li> </ul>"},{"location":"zh/tutorials/#_14","title":"\u76f4\u63a5\u8054\u7cfb","text":"<ul> <li>\u90ae\u4ef6: pguo6680@gmail.com</li> </ul>"},{"location":"zh/tutorials/#_15","title":"\u89c6\u9891\u6559\u7a0b","text":"<p>\u5373\u5c06\u63a8\u51fa\uff01\u8ba2\u9605\u6211\u4eec\u7684 YouTube \u9891\u9053 \u83b7\u53d6\u89c6\u9891\u6559\u7a0b\u3002</p>"},{"location":"zh/tutorials/advanced-overview/","title":"\u9ad8\u7ea7\u7528\u6cd5","text":"<p>\u638c\u63e1\u4f4e\u7ea7 API \u4ee5\u5b9e\u73b0\u6700\u5927\u63a7\u5236\u548c\u81ea\u5b9a\u4e49\u3002</p>"},{"location":"zh/tutorials/advanced-overview/#_2","title":"\u6982\u8ff0","text":"<p>\u8fd9\u4e9b\u9ad8\u7ea7\u6559\u7a0b\u6db5\u76d6\uff1a</p> <ul> <li>\u4f4e\u7ea7 API - \u76f4\u63a5\u63a7\u5236\u7b97\u6cd5\u548c\u914d\u7f6e</li> <li>\u7b97\u6cd5\u914d\u7f6e - \u5fae\u8c03\u8fdb\u5316\u53c2\u6570</li> <li>\u7b97\u6cd5\u5185\u90e8 - \u8bbf\u95ee\u548c\u5206\u6790\u5185\u90e8\u72b6\u6001</li> <li>\u8c03\u8bd5\u548c\u6027\u80fd\u5206\u6790 - \u6545\u969c\u6392\u9664\u548c\u6027\u80fd\u4f18\u5316</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#_3","title":"\u524d\u7f6e\u6761\u4ef6","text":"<ul> <li>\u5b8c\u6210 \u79d1\u5b66\u7b26\u53f7\u56de\u5f52 \u6559\u7a0b</li> <li>\u5b8c\u6210 \u81ea\u5b9a\u4e49\u4efb\u52a1 \u6559\u7a0b</li> <li>\u7406\u89e3\u8fdb\u5316\u7b97\u6cd5</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#_4","title":"\u6559\u7a0b","text":"<p>\u76ee\u524d\uff0c\u6240\u6709\u9ad8\u7ea7\u6559\u7a0b\u5185\u5bb9\u90fd\u6574\u5408\u5728\u4e00\u4e2a\u5b8c\u6574\u7684\u6559\u7a0b\u6587\u6863\u4e2d\uff1a</p> <p>\u2192 \u67e5\u770b\u5b8c\u6574\u7684\u9ad8\u7ea7\u7528\u6cd5\u6559\u7a0b</p> <p>\u8be5\u6559\u7a0b\u6db5\u76d6\u4ee5\u4e0b\u4e3b\u9898\uff1a</p>"},{"location":"zh/tutorials/advanced-overview/#1-api","title":"1. \u4f4e\u7ea7 API","text":"<p>\u4e86\u89e3\u9ad8\u7ea7\u548c\u4f4e\u7ea7 API \u4e4b\u95f4\u7684\u533a\u522b\uff0c\u4ee5\u53ca\u4f55\u65f6\u4f7f\u7528\u5b83\u4eec\u3002</p> <ul> <li>\u9ad8\u7ea7 vs \u4f4e\u7ea7 API \u5bf9\u6bd4</li> <li>\u76f4\u63a5\u5b9e\u4f8b\u5316\u7b97\u6cd5</li> <li>\u8bbf\u95ee\u5185\u90e8\u72b6\u6001</li> <li>\u81ea\u5b9a\u4e49\u5de5\u4f5c\u6d41\u63a7\u5236</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#2","title":"2. \u7b97\u6cd5\u914d\u7f6e","text":"<p>\u638c\u63e1\u6bcf\u4e2a\u8fdb\u5316\u7b97\u6cd5\u7684\u8be6\u7ec6\u914d\u7f6e\u9009\u9879\u3002</p> <ul> <li>EvoEngineer \u914d\u7f6e\u53c2\u6570</li> <li>FunSearch \u5c9b\u5c7f\u6a21\u578b\u8bbe\u7f6e</li> <li>EoH \u7b97\u5b50\u63a7\u5236</li> <li>\u5e76\u884c\u6267\u884c\u8c03\u4f18</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#3","title":"3. \u7b97\u6cd5\u5185\u90e8","text":"<p>\u8bbf\u95ee\u548c\u5206\u6790\u8fdb\u5316\u7b97\u6cd5\u7684\u5185\u90e8\u72b6\u6001\u3002</p> <ul> <li>\u68c0\u67e5\u8fdb\u5316\u5386\u53f2</li> <li>\u8bbf\u95ee\u89e3\u79cd\u7fa4</li> <li>\u7ed8\u5236\u8fdb\u5316\u8fdb\u7a0b</li> <li>\u63d0\u53d6\u6307\u6807\u548c\u7edf\u8ba1\u6570\u636e</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#4","title":"4. \u8c03\u8bd5\u548c\u6027\u80fd\u5206\u6790","text":"<p>\u8c03\u8bd5\u95ee\u9898\u5e76\u4f18\u5316\u8fdb\u5316\u5de5\u4f5c\u6d41\u7684\u6027\u80fd\u3002</p> <ul> <li>\u542f\u7528\u8be6\u7ec6\u65e5\u5fd7</li> <li>\u4fdd\u5b58\u4e2d\u95f4\u89e3</li> <li>\u68c0\u67e5 LLM \u63d0\u793a/\u54cd\u5e94</li> <li>\u65f6\u95f4\u548c\u5185\u5b58\u5206\u6790</li> <li>\u5b9e\u73b0\u81ea\u5b9a\u4e49\u7b97\u6cd5</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#_5","title":"\u4f55\u65f6\u4f7f\u7528\u9ad8\u7ea7\u529f\u80fd","text":""},{"location":"zh/tutorials/advanced-overview/#api","title":"\u4f7f\u7528\u4f4e\u7ea7 API \u7684\u65f6\u673a\uff1a","text":"<ul> <li>\u9700\u8981\u5bf9\u8fdb\u5316\u8fc7\u7a0b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u63a7\u5236</li> <li>\u9ed8\u8ba4\u914d\u7f6e\u4e0d\u6ee1\u8db3\u9700\u6c42</li> <li>\u60f3\u8981\u5b9e\u73b0\u81ea\u5b9a\u4e49\u505c\u6b62\u51c6\u5219</li> <li>\u9700\u8981\u8bbf\u95ee\u4e2d\u95f4\u7ed3\u679c</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#_6","title":"\u4f7f\u7528\u81ea\u5b9a\u4e49\u914d\u7f6e\u7684\u65f6\u673a\uff1a","text":"<ul> <li>\u9ed8\u8ba4\u53c2\u6570\u5bf9\u60a8\u7684\u4efb\u52a1\u6548\u679c\u4e0d\u4f73</li> <li>\u60f3\u8981\u4f18\u5316\u901f\u5ea6\u6216\u8d28\u91cf</li> <li>\u9700\u8981\u8c03\u6574\u5e76\u884c\u6267\u884c</li> <li>\u6b63\u5728\u5c1d\u8bd5\u7b97\u6cd5\u53d8\u4f53</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#_7","title":"\u4f7f\u7528\u8c03\u8bd5\u5de5\u5177\u7684\u65f6\u673a\uff1a","text":"<ul> <li>\u8fdb\u5316\u6ca1\u6709\u6309\u9884\u671f\u6536\u655b</li> <li>\u60f3\u8981\u7406\u89e3\u7b97\u6cd5\u884c\u4e3a</li> <li>\u9700\u8981\u4f18\u5316\u8d44\u6e90\u4f7f\u7528</li> <li>\u6b63\u5728\u5f00\u53d1\u81ea\u5b9a\u4e49\u7b97\u6cd5</li> </ul>"},{"location":"zh/tutorials/advanced-overview/#_8","title":"\u5feb\u901f\u53c2\u8003","text":""},{"location":"zh/tutorials/advanced-overview/#_9","title":"\u57fa\u7840\u4f4e\u7ea7\u6a21\u5f0f","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=8,\n    verbose=True\n)\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# \u8bbf\u95ee\u7ed3\u679c\nbest = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n</code></pre>"},{"location":"zh/tutorials/advanced-overview/#_10","title":"\u4e0b\u4e00\u6b65","text":"<p>\u638c\u63e1\u9ad8\u7ea7\u7528\u6cd5\u540e\uff1a</p> <ul> <li>\u63a2\u7d22 API \u53c2\u8003 \u83b7\u53d6\u5b8c\u6574\u6587\u6863</li> <li>\u9605\u8bfb \u67b6\u6784\u6587\u6863 \u4e86\u89e3\u5185\u90e8\u539f\u7406</li> <li>\u901a\u8fc7 \u8d21\u732e\u6307\u5357 \u8d21\u732e\u60a8\u7684\u6539\u8fdb</li> </ul>"},{"location":"zh/tutorials/built-in-overview/","title":"\u5185\u7f6e\u4efb\u52a1","text":"<p>EvoToolkit \u63d0\u4f9b\u4e86\u591a\u4e2a\u9884\u6784\u5efa\u7684\u4f18\u5316\u4efb\u52a1\uff0c\u5c55\u793a\u4e86 LLM \u9a71\u52a8\u8fdb\u5316\u5728\u4e0d\u540c\u9886\u57df\u7684\u5f3a\u5927\u529f\u80fd\u3002</p>"},{"location":"zh/tutorials/built-in-overview/#_2","title":"\u53ef\u7528\u4efb\u52a1","text":""},{"location":"zh/tutorials/built-in-overview/#_3","title":"\u79d1\u5b66\u7b26\u53f7\u56de\u5f52","text":"<p>\u2192 \u5f00\u59cb\u6559\u7a0b</p> <p>\u5b66\u4e60\u5982\u4f55\u4ece\u771f\u5b9e\u79d1\u5b66\u6570\u636e\u96c6\u4e2d\u53d1\u73b0\u6570\u5b66\u65b9\u7a0b\u3002</p> <p>\u60a8\u5c06\u5b66\u5230: - \u52a0\u8f7d\u548c\u4f7f\u7528\u79d1\u5b66\u6570\u636e\u96c6 - \u521b\u5efa\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4efb\u52a1 - \u4f7f\u7528\u9ad8\u7ea7 <code>evotoolkit.solve()</code> API - \u6bd4\u8f83\u4e0d\u540c\u7684\u8fdb\u5316\u7b97\u6cd5\uff08EoH\u3001EvoEngineer\u3001FunSearch\uff09 - \u89e3\u91ca\u53d1\u73b0\u7684\u65b9\u7a0b</p> <p>\u524d\u7f6e\u6761\u4ef6: \u57fa\u7840 Python \u548c NumPy \u77e5\u8bc6</p>"},{"location":"zh/tutorials/built-in-overview/#_4","title":"\u63d0\u793a\u8bcd\u5de5\u7a0b","text":"<p>\u2192 \u5f00\u59cb\u6559\u7a0b</p> <p>\u4f18\u5316 LLM \u63d0\u793a\u8bcd\u4ee5\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u3002</p> <p>\u60a8\u5c06\u5b66\u5230: - LLM \u63d0\u793a\u8bcd\u4f18\u5316\u57fa\u7840 - \u4f7f\u7528\u5b57\u7b26\u4e32\u4f18\u5316\u4efb\u52a1 - \u8fdb\u5316\u63d0\u793a\u8bcd\u6a21\u677f - \u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u63d0\u793a\u8bcd</p> <p>\u524d\u7f6e\u6761\u4ef6: \u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b</p>"},{"location":"zh/tutorials/built-in-overview/#_5","title":"\u5bf9\u6297\u653b\u51fb","text":"<p>\u2192 \u5f00\u59cb\u6559\u7a0b</p> <p>\u5b66\u4e60\u5982\u4f55\u8fdb\u5316\u5bf9\u6297\u6837\u672c\u548c\u653b\u51fb\u7b97\u6cd5\u3002</p> <p>\u60a8\u5c06\u5b66\u5230: - \u521b\u5efa\u5bf9\u6297\u653b\u51fb\u4efb\u52a1 - \u8fdb\u5316\u653b\u51fb\u7b56\u7565 - \u751f\u6210\u5bf9\u6297\u6837\u672c - \u8bc4\u4f30\u653b\u51fb\u6548\u679c</p> <p>\u524d\u7f6e\u6761\u4ef6: \u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b\uff0c\u673a\u5668\u5b66\u4e60\u57fa\u7840</p>"},{"location":"zh/tutorials/built-in-overview/#cuda","title":"CUDA \u4efb\u52a1","text":"<p>\u2192 \u5f00\u59cb\u6559\u7a0b</p> <p>\u4f7f\u7528 LLM \u9a71\u52a8\u7684\u8fdb\u5316\u4f18\u5316 GPU \u5185\u6838\u3002</p> <p>\u60a8\u5c06\u5b66\u5230: - \u521b\u5efa CUDA \u4f18\u5316\u4efb\u52a1 - GPU \u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5 - \u8fdb\u5316\u9ad8\u6548\u7684 CUDA \u5185\u6838 - \u5904\u7406\u7f16\u8bd1\u548c\u6267\u884c</p> <p>\u524d\u7f6e\u6761\u4ef6: CUDA \u7f16\u7a0b\u57fa\u7840\u3001GPU \u786c\u4ef6</p>"},{"location":"zh/tutorials/built-in-overview/#_6","title":"\u4efb\u52a1\u5bf9\u6bd4","text":"\u4efb\u52a1 \u9886\u57df \u96be\u5ea6 \u6700\u9002\u5408 \u79d1\u5b66\u7b26\u53f7\u56de\u5f52 \u6570\u636e\u79d1\u5b66 \u521d\u7ea7 \u5b66\u4e60\u57fa\u7840\uff0c\u65b9\u7a0b\u53d1\u73b0 \u63d0\u793a\u8bcd\u5de5\u7a0b NLP/LLM \u4e2d\u7ea7 \u4f18\u5316 LLM \u4ea4\u4e92 \u5bf9\u6297\u653b\u51fb \u5b89\u5168/ML \u4e2d\u7ea7 \u5b89\u5168\u7814\u7a76\uff0c\u9c81\u68d2\u6027\u6d4b\u8bd5 CUDA \u4efb\u52a1 GPU \u8ba1\u7b97 \u9ad8\u7ea7 \u6027\u80fd\u4f18\u5316"},{"location":"zh/tutorials/built-in-overview/#_7","title":"\u5f00\u59cb\u4f7f\u7528","text":"<ol> <li>\u4ece\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u5f00\u59cb \u5982\u679c\u60a8\u662f EvoToolkit \u65b0\u624b</li> <li>\u5c1d\u8bd5\u63d0\u793a\u8bcd\u5de5\u7a0b \u4e86\u89e3\u8fdb\u5316\u5982\u4f55\u4f18\u5316\u6587\u672c</li> <li>\u63a2\u7d22\u5bf9\u6297\u653b\u51fb \u7528\u4e8e\u5b89\u5168\u5e94\u7528</li> <li>\u638c\u63e1 CUDA \u4efb\u52a1 \u8fdb\u884c GPU \u4f18\u5316</li> </ol> <p>\u6bcf\u4e2a\u6559\u7a0b\u90fd\u5305\u542b\u5b8c\u6574\u7684\u3001\u53ef\u8fd0\u884c\u7684\u4ee3\u7801\u793a\u4f8b\uff0c\u60a8\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u95ee\u9898\u8fdb\u884c\u8c03\u6574\u3002</p>"},{"location":"zh/tutorials/customization-overview/","title":"\u81ea\u5b9a\u4e49","text":"<p>\u5b66\u4e60\u5982\u4f55\u6269\u5c55 EvoToolkit \u4ee5\u89e3\u51b3\u60a8\u7684\u7279\u5b9a\u4f18\u5316\u95ee\u9898\u3002</p>"},{"location":"zh/tutorials/customization-overview/#_2","title":"\u81ea\u5b9a\u4e49\u9009\u9879","text":""},{"location":"zh/tutorials/customization-overview/#_3","title":"\u81ea\u5b9a\u4e49\u4efb\u52a1","text":"<p>\u2192 \u5f00\u59cb\u6559\u7a0b</p> <p>\u4e3a\u7279\u5b9a\u9886\u57df\u95ee\u9898\u521b\u5efa\u60a8\u81ea\u5df1\u7684\u4f18\u5316\u4efb\u52a1\u3002</p> <p>\u60a8\u5c06\u5b66\u5230: - \u6269\u5c55 <code>Task</code> \u57fa\u7c7b - \u5b9e\u73b0\u81ea\u5b9a\u4e49\u8bc4\u4f30\u903b\u8f91 - \u5b9a\u4e49\u89e3\u7a7a\u95f4 - \u4e0e\u8fdb\u5316\u7b97\u6cd5\u96c6\u6210</p> <p>\u524d\u7f6e\u6761\u4ef6: \u57fa\u7840 EvoToolkit \u77e5\u8bc6\uff08\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b\uff09</p>"},{"location":"zh/tutorials/customization-overview/#_4","title":"\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5","text":"<p>\u2192 \u5f00\u59cb\u6559\u7a0b</p> <p>\u5b66\u4e60\u5982\u4f55\u901a\u8fc7\u4fee\u6539 prompt \u6216\u5f00\u53d1\u65b0\u7b97\u6cd5\u6765\u81ea\u5b9a\u4e49\u8fdb\u5316\u884c\u4e3a\u3002</p> <p>\u60a8\u5c06\u5b66\u5230: - \u7406\u89e3 Interface \u67b6\u6784 - \u81ea\u5b9a\u4e49 LLM prompt \u4ee5\u6539\u8fdb\u7ed3\u679c - \u4e3a\u7279\u5b9a\u4efb\u52a1\u8bbe\u8ba1\u4e13\u95e8\u7684 prompt - \u5f00\u53d1\u5168\u65b0\u7684\u8fdb\u5316\u7b97\u6cd5\uff08\u9ad8\u7ea7\uff09 - \u5b9e\u73b0\u6e29\u5ea6\u9000\u706b\u7b49\u81ea\u5b9a\u4e49\u7b56\u7565</p> <p>\u524d\u7f6e\u6761\u4ef6: \u57fa\u7840 EvoToolkit \u77e5\u8bc6\uff08\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b\uff09</p>"},{"location":"zh/tutorials/customization-overview/#_5","title":"\u4f55\u65f6\u81ea\u5b9a\u4e49","text":""},{"location":"zh/tutorials/customization-overview/#_6","title":"\u521b\u5efa\u81ea\u5b9a\u4e49\u4efb\u52a1\u7684\u65f6\u673a\uff1a","text":"<ul> <li>\u60a8\u7684\u95ee\u9898\u9886\u57df\u672a\u88ab\u5185\u7f6e\u4efb\u52a1\u8986\u76d6</li> <li>\u60a8\u9700\u8981\u7279\u5b9a\u7684\u8bc4\u4f30\u6307\u6807</li> <li>\u60a8\u60f3\u4f18\u5316\u7279\u5b9a\u9886\u57df\u7684\u4ee3\u7801\u6216\u7ed3\u6784</li> <li>\u60a8\u9700\u8981\u81ea\u5b9a\u4e49\u7ea6\u675f\u6216\u9a8c\u8bc1</li> </ul>"},{"location":"zh/tutorials/customization-overview/#_7","title":"\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5\u7684\u65f6\u673a\uff1a","text":"<ul> <li>\u9ed8\u8ba4 prompt \u5bf9\u60a8\u7684\u4efb\u52a1\u6548\u679c\u4e0d\u4f73</li> <li>\u60a8\u60f3\u5c06\u9886\u57df\u77e5\u8bc6\u878d\u5165\u8fdb\u5316\u8fc7\u7a0b</li> <li>\u60a8\u9700\u8981\u7279\u6b8a\u7684\u53d8\u5f02\u6216\u4ea4\u53c9\u7b56\u7565</li> <li>\u60a8\u60f3\u5c1d\u8bd5\u65b0\u9896\u7684\u8fdb\u5316\u65b9\u6cd5</li> </ul>"},{"location":"zh/tutorials/customization-overview/#_8","title":"\u5feb\u901f\u5f00\u59cb\u793a\u4f8b","text":""},{"location":"zh/tutorials/customization-overview/#_9","title":"\u81ea\u5b9a\u4e49\u4efb\u52a1\u793a\u4f8b","text":"<pre><code>from evotoolkit.core import BaseTask, Solution\n\nclass MyCustomTask(BaseTask):\n    def evaluate(self, solution: Solution) -&gt; float:\n        # \u60a8\u7684\u8bc4\u4f30\u903b\u8f91\n        return fitness_score\n</code></pre>"},{"location":"zh/tutorials/customization-overview/#_10","title":"\u81ea\u5b9a\u4e49\u63a5\u53e3\u793a\u4f8b","text":"<pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\n\nclass MyCustomInterface(EvoEngineerPythonInterface):\n    def get_prompt_components(self):\n        # \u4e3a\u60a8\u7684\u4efb\u52a1\u81ea\u5b9a\u4e49 prompt\n        return custom_prompts\n</code></pre>"},{"location":"zh/tutorials/customization-overview/#_11","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u4ece\u7b80\u5355\u5f00\u59cb\uff1a \u5728\u521b\u5efa\u5168\u65b0\u4efb\u52a1\u4e4b\u524d\uff0c\u5148\u5c1d\u8bd5\u4fee\u6539\u73b0\u6709\u4efb\u52a1\u6216 prompt</li> <li>\u5145\u5206\u6d4b\u8bd5\uff1a \u4f7f\u7528\u5df2\u77e5\u89e3\u9a8c\u8bc1\u60a8\u7684\u81ea\u5b9a\u4e49\u8bc4\u4f30\u903b\u8f91</li> <li>\u826f\u597d\u6587\u6863\uff1a \u6e05\u695a\u5730\u8bb0\u5f55\u60a8\u7684\u4efb\u52a1\u9700\u6c42\u548c\u7ea6\u675f</li> <li>\u5206\u4eab\u6210\u679c\uff1a \u8003\u8651\u5c06\u60a8\u7684\u81ea\u5b9a\u4e49\u4efb\u52a1\u8d21\u732e\u7ed9\u793e\u533a</li> </ol>"},{"location":"zh/tutorials/customization-overview/#_12","title":"\u4e0b\u4e00\u6b65","text":"<p>\u638c\u63e1\u81ea\u5b9a\u4e49\u540e\uff1a - \u63a2\u7d22\u9ad8\u7ea7\u7528\u6cd5\u4e86\u89e3\u4f4e\u7ea7 API \u63a7\u5236 - \u67e5\u770b API \u53c2\u8003\u83b7\u53d6\u8be6\u7ec6\u6587\u6863 - \u5728 GitHub \u8ba8\u8bba\u4e2d\u5206\u4eab\u60a8\u7684\u81ea\u5b9a\u4e49\u4efb\u52a1</p>"},{"location":"zh/tutorials/advanced/configuration/","title":"\u7b97\u6cd5\u914d\u7f6e","text":"<p>\u638c\u63e1\u6bcf\u4e2a\u8fdb\u5316\u7b97\u6cd5\u7684\u8be6\u7ec6\u914d\u7f6e\u9009\u9879\u3002</p>"},{"location":"zh/tutorials/advanced/configuration/#_2","title":"\u6982\u8ff0","text":"<p>EvoToolkit \u4e2d\u7684\u6bcf\u4e2a\u8fdb\u5316\u7b97\u6cd5\u90fd\u6709\u81ea\u5df1\u7684\u914d\u7f6e\u7c7b\u548c\u7279\u5b9a\u53c2\u6570\u3002\u672c\u6559\u7a0b\u6db5\u76d6\u6240\u6709\u914d\u7f6e\u9009\u9879\u4ee5\u53ca\u5982\u4f55\u6839\u636e\u60a8\u7684\u7528\u4f8b\u8fdb\u884c\u8c03\u4f18\u3002</p>"},{"location":"zh/tutorials/advanced/configuration/#evoengineer","title":"EvoEngineer \u914d\u7f6e","text":"<p>EvoEngineer \u662f\u4e3b\u8981\u7684 LLM \u9a71\u52a8\u8fdb\u5316\u7b97\u6cd5\u3002</p> <pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n\n    # \u8fdb\u5316\u53c2\u6570\n    max_generations=20,      # \u6700\u5927\u4ee3\u6570\n    pop_size=10,             # \u79cd\u7fa4\u5927\u5c0f\n    max_sample_nums=15,      # \u6bcf\u4ee3\u6700\u5927\u91c7\u6837\u6570\n\n    # \u5e76\u884c\u63a7\u5236\n    num_samplers=4,          # \u5e76\u884c\u91c7\u6837\u5668\u6570\u91cf\n    num_evaluators=4,        # \u5e76\u884c\u8bc4\u4f30\u5668\u6570\u91cf\n\n    # \u65e5\u5fd7\n    verbose=True             # \u663e\u793a\u8be6\u7ec6\u65e5\u5fd7\n)\n</code></pre>"},{"location":"zh/tutorials/advanced/configuration/#_3","title":"\u5173\u952e\u53c2\u6570","text":"<p>\u8fdb\u5316\u53c2\u6570\uff1a - <code>max_generations</code> - \u8981\u8fd0\u884c\u7684\u8fdb\u5316\u4ee3\u6570 - <code>pop_size</code> - \u79cd\u7fa4\u4e2d\u7ef4\u62a4\u7684\u89e3\u6570\u91cf - <code>max_sample_nums</code> - \u6bcf\u4ee3\u91c7\u6837\u7684\u6700\u5927\u65b0\u89e3\u6570\u91cf</p> <p>\u5e76\u884c\u6267\u884c\uff1a - <code>num_samplers</code> - \u5e76\u884c LLM \u91c7\u6837\u5de5\u4f5c\u5668 - <code>num_evaluators</code> - \u5e76\u884c\u8bc4\u4f30\u5de5\u4f5c\u5668</p> <p>\u65e5\u5fd7\uff1a - <code>verbose</code> - \u542f\u7528\u8be6\u7ec6\u8fdb\u5ea6\u65e5\u5fd7</p>"},{"location":"zh/tutorials/advanced/configuration/#_4","title":"\u91cd\u8981\u8bf4\u660e","text":"<p>LLM \u6e29\u5ea6\u548c\u5176\u4ed6\u91c7\u6837\u53c2\u6570\u5728\u521b\u5efa <code>HttpsApi</code> \u65f6\u8bbe\u7f6e\uff0c\u800c\u4e0d\u662f\u5728\u7b97\u6cd5\u914d\u7f6e\u4e2d\u3002</p> <pre><code>from evotoolkit.tools.llm import HttpsApi\n\n# LLM \u914d\u7f6e\u5728\u8fd9\u91cc\nllm_api = HttpsApi(\n    api_key=\"your-key\",\n    model=\"claude-3-5-sonnet-20241022\",\n    temperature=0.7,  # LLM \u6e29\u5ea6\n    max_tokens=4096\n)\n\n# \u7b97\u6cd5\u914d\u7f6e\u4e0d\u5305\u542b\u6e29\u5ea6\nconfig = EvoEngineerConfig(\n    running_llm=llm_api,  # \u4f20\u9012\u914d\u7f6e\u597d\u7684 LLM\n    # ... \u5176\u4ed6\u53c2\u6570\n)\n</code></pre>"},{"location":"zh/tutorials/advanced/configuration/#funsearch","title":"FunSearch \u914d\u7f6e","text":"<p>FunSearch \u4f7f\u7528\u5c9b\u5c7f\u6a21\u578b\u8fdb\u884c\u6301\u7eed\u8fdb\u5316\u3002</p> <pre><code>from evotoolkit.evo_method.funsearch import FunSearchConfig\n\nconfig = FunSearchConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n\n    # \u91c7\u6837\u53c2\u6570\n    max_sample_nums=30,           # \u6700\u5927\u91c7\u6837\u6570\n    programs_per_prompt=2,        # \u6bcf\u4e2a\u63d0\u793a\u751f\u6210\u7684\u7a0b\u5e8f\u6570\n\n    # \u5c9b\u5c7f\u6a21\u578b\n    num_islands=4,                # \u5e76\u884c\u8fdb\u5316\u5c9b\u5c7f\u6570\u91cf\n    max_population_size=1000,     # \u6bcf\u4e2a\u5c9b\u5c7f\u7684\u6700\u5927\u79cd\u7fa4\u5927\u5c0f\n\n    # \u5e76\u884c\u63a7\u5236\n    num_samplers=5,               # \u5e76\u884c\u91c7\u6837\u5668\u6570\u91cf\n    num_evaluators=5,             # \u5e76\u884c\u8bc4\u4f30\u5668\u6570\u91cf\n\n    # \u65e5\u5fd7\n    verbose=True\n)\n</code></pre>"},{"location":"zh/tutorials/advanced/configuration/#_5","title":"\u5173\u952e\u53c2\u6570","text":"<p>\u91c7\u6837\uff1a - <code>max_sample_nums</code> - \u8981\u751f\u6210\u7684\u603b\u91c7\u6837\u6570 - <code>programs_per_prompt</code> - \u6bcf\u6b21 LLM \u8c03\u7528\u7684\u89e3\u6570\u91cf</p> <p>\u5c9b\u5c7f\u6a21\u578b\uff1a - <code>num_islands</code> - \u72ec\u7acb\u7684\u8fdb\u5316\u5c9b\u5c7f\uff08\u589e\u52a0\u591a\u6837\u6027\uff09 - <code>max_population_size</code> - \u6bcf\u4e2a\u5c9b\u5c7f\u7684\u6700\u5927\u89e3\u6570\u91cf</p> <p>\u6ce8\u610f\uff1a FunSearch **\u4e0d**\u4f7f\u7528 <code>max_generations</code>\u3002\u5b83\u57fa\u4e8e\u5c9b\u5c7f\u6a21\u578b\u6301\u7eed\u8fdb\u5316\uff0c\u76f4\u5230\u8fbe\u5230 <code>max_sample_nums</code>\u3002</p>"},{"location":"zh/tutorials/advanced/configuration/#funsearch_1","title":"\u4f55\u65f6\u4f7f\u7528 FunSearch","text":"<ul> <li>\u5f53\u60a8\u60f3\u8981\u6301\u7eed\u8fdb\u5316\u800c\u4e0d\u662f\u56fa\u5b9a\u4ee3\u6570\u65f6</li> <li>\u7528\u4e8e\u63a2\u7d22\u591a\u6837\u5316\u7684\u89e3\u7a7a\u95f4</li> <li>\u5f53\u60a8\u6709\u8ba1\u7b97\u8d44\u6e90\u652f\u6301\u5927\u89c4\u6a21\u79cd\u7fa4\u65f6</li> </ul>"},{"location":"zh/tutorials/advanced/configuration/#eoh","title":"EoH \u914d\u7f6e","text":"<p>EoH\uff08\u542f\u53d1\u5f0f\u8fdb\u5316\uff09\u63d0\u4f9b\u5bf9\u9057\u4f20\u7b97\u5b50\u7684\u663e\u5f0f\u63a7\u5236\u3002</p> <pre><code>from evotoolkit.evo_method.eoh import EoHConfig\n\nconfig = EoHConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n\n    # \u8fdb\u5316\u53c2\u6570\n    max_generations=10,       # \u6700\u5927\u4ee3\u6570\n    pop_size=5,               # \u79cd\u7fa4\u5927\u5c0f\n    max_sample_nums=20,       # \u6bcf\u4ee3\u6700\u5927\u91c7\u6837\u6570\n    selection_num=2,          # \u4ea4\u53c9\u7684\u7236\u4ee3\u6570\u91cf\n\n    # \u7b97\u5b50\u63a7\u5236\n    use_e2_operator=True,     # \u4f7f\u7528 E2 \u7b97\u5b50\uff08\u4ea4\u53c9\uff09\n    use_m1_operator=True,     # \u4f7f\u7528 M1 \u7b97\u5b50\uff08\u53d8\u5f02\uff09\n    use_m2_operator=True,     # \u4f7f\u7528 M2 \u7b97\u5b50\uff08\u7b2c\u4e8c\u79cd\u53d8\u5f02\uff09\n\n    # \u5e76\u884c\u63a7\u5236\n    num_samplers=5,           # \u5e76\u884c\u91c7\u6837\u5668\u6570\u91cf\n    num_evaluators=5,         # \u5e76\u884c\u8bc4\u4f30\u5668\u6570\u91cf\n\n    # \u65e5\u5fd7\n    verbose=True\n)\n</code></pre>"},{"location":"zh/tutorials/advanced/configuration/#_6","title":"\u5173\u952e\u53c2\u6570","text":"<p>\u8fdb\u5316\uff1a - <code>max_generations</code> - \u4ee3\u6570 - <code>pop_size</code> - \u79cd\u7fa4\u5927\u5c0f\uff08\u901a\u5e38\u5c0f\u4e8e EvoEngineer\uff09 - <code>max_sample_nums</code> - \u6bcf\u4ee3\u91c7\u6837\u6570 - <code>selection_num</code> - \u4e3a\u4ea4\u53c9\u9009\u62e9\u7684\u7236\u4ee3\u6570</p> <p>\u9057\u4f20\u7b97\u5b50\uff1a - <code>use_e2_operator</code> - \u542f\u7528/\u7981\u7528\u4ea4\u53c9\u7b97\u5b50 - <code>use_m1_operator</code> - \u542f\u7528/\u7981\u7528\u7b2c\u4e00\u79cd\u53d8\u5f02\u7b97\u5b50 - <code>use_m2_operator</code> - \u542f\u7528/\u7981\u7528\u7b2c\u4e8c\u79cd\u53d8\u5f02\u7b97\u5b50</p>"},{"location":"zh/tutorials/advanced/configuration/#eoh_1","title":"\u4f55\u65f6\u4f7f\u7528 EoH","text":"<ul> <li>\u5f53\u60a8\u60f3\u8981\u663e\u5f0f\u63a7\u5236\u9057\u4f20\u7b97\u5b50\u65f6</li> <li>\u7528\u4e8e\u7814\u7a76\u6bd4\u8f83\u4e0d\u540c\u7684\u7b97\u5b50\u7ec4\u5408</li> <li>\u5f53\u4f20\u7edf\u8fdb\u5316\u7b97\u6cd5\u6982\u5ff5\u5f88\u91cd\u8981\u65f6</li> </ul>"},{"location":"zh/tutorials/advanced/configuration/#_7","title":"\u8c03\u4f18\u6307\u5357","text":""},{"location":"zh/tutorials/advanced/configuration/#_8","title":"\u79cd\u7fa4\u5927\u5c0f","text":"<p>\u5c0f\uff085-10\uff09\uff1a - \u4f18\u70b9\uff1a\u4ee3\u6570\u66f4\u5feb\uff0c\u6210\u672c\u66f4\u4f4e - \u7f3a\u70b9\uff1a\u591a\u6837\u6027\u8f83\u5c11\uff0c\u53ef\u80fd\u8fc7\u5feb\u6536\u655b - \u6700\u9002\u5408\uff1a\u7b80\u5355\u95ee\u9898\uff0c\u8d44\u6e90\u6709\u9650</p> <p>\u4e2d\u7b49\uff0810-20\uff09\uff1a - \u4f18\u70b9\uff1a\u901f\u5ea6\u548c\u591a\u6837\u6027\u7684\u826f\u597d\u5e73\u8861 - \u7f3a\u70b9\uff1a\u6ca1\u6709\u4e3b\u8981\u7f3a\u70b9 - \u6700\u9002\u5408\uff1a\u5927\u591a\u6570\u95ee\u9898\uff08\u63a8\u8350\u9ed8\u8ba4\u503c\uff09</p> <p>\u5927\uff0820+\uff09\uff1a - \u4f18\u70b9\uff1a\u6700\u5927\u591a\u6837\u6027\uff0c\u5f7b\u5e95\u63a2\u7d22 - \u7f3a\u70b9\uff1a\u8f83\u6162\uff0c\u6210\u672c\u66f4\u9ad8 - \u6700\u9002\u5408\uff1a\u590d\u6742\u95ee\u9898\uff0c\u7814\u7a76</p>"},{"location":"zh/tutorials/advanced/configuration/#_9","title":"\u5e76\u884c\u6267\u884c","text":"<pre><code>config = EvoEngineerConfig(\n    # ... \u5176\u4ed6\u53c2\u6570\n    num_samplers=4,      # \u5e76\u884c LLM \u8c03\u7528\n    num_evaluators=4,    # \u5e76\u884c\u8bc4\u4f30\n)\n</code></pre> <p>\u6307\u5357\uff1a - <code>num_samplers</code>\uff1a\u6839\u636e LLM API \u901f\u7387\u9650\u5236\u8bbe\u7f6e - <code>num_evaluators</code>\uff1a\u6839\u636e CPU/GPU \u53ef\u7528\u6027\u8bbe\u7f6e - \u4fdd\u5b88\u5730\u5f00\u59cb\uff082-4\uff09\uff0c\u5982\u679c\u8d44\u6e90\u5141\u8bb8\u5219\u589e\u52a0</p> <p>\u793a\u4f8b\u914d\u7f6e\uff1a</p> <pre><code># \u4fdd\u5b88\uff08\u4f4e\u8d44\u6e90\uff09\nnum_samplers=2\nnum_evaluators=2\n\n# \u5e73\u8861\uff08\u4e2d\u7b49\u8d44\u6e90\uff09\nnum_samplers=4\nnum_evaluators=4\n\n# \u6fc0\u8fdb\uff08\u9ad8\u8d44\u6e90\uff09\nnum_samplers=8\nnum_evaluators=8\n</code></pre>"},{"location":"zh/tutorials/advanced/configuration/#_10","title":"\u4ee3\u6570","text":"<p>\u5c11\u4ee3\u6570\uff085-10\uff09\uff1a - \u5feb\u901f\u5b9e\u9a8c - \u7b80\u5355\u95ee\u9898 - \u5feb\u901f\u539f\u578b</p> <p>\u4e2d\u7b49\u4ee3\u6570\uff0810-20\uff09\uff1a - \u5927\u591a\u6570\u95ee\u9898 - \u5e73\u8861\u63a2\u7d22 - \u63a8\u8350\u9ed8\u8ba4\u503c</p> <p>\u591a\u4ee3\u6570\uff0820+\uff09\uff1a - \u590d\u6742\u95ee\u9898 - \u7814\u7a76 - \u6700\u7ec8\u4f18\u5316\u8fd0\u884c</p>"},{"location":"zh/tutorials/advanced/configuration/#_11","title":"\u914d\u7f6e\u9884\u8bbe","text":""},{"location":"zh/tutorials/advanced/configuration/#_12","title":"\u5feb\u901f\u5b9e\u9a8c","text":"<pre><code>config = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5,\n    pop_size=5,\n    max_sample_nums=10,\n    num_samplers=2,\n    num_evaluators=2,\n    verbose=True\n)\n</code></pre> <p>\u7528\u4e8e\uff1a \u6d4b\u8bd5\u3001\u8c03\u8bd5\u3001\u5feb\u901f\u8fed\u4ee3</p>"},{"location":"zh/tutorials/advanced/configuration/#_13","title":"\u5e73\u8861\u6027\u80fd","text":"<pre><code>config = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=15,\n    pop_size=10,\n    max_sample_nums=20,\n    num_samplers=4,\n    num_evaluators=4,\n    verbose=True\n)\n</code></pre> <p>\u7528\u4e8e\uff1a \u5927\u591a\u6570\u751f\u4ea7\u7528\u4f8b</p>"},{"location":"zh/tutorials/advanced/configuration/#_14","title":"\u5f7b\u5e95\u641c\u7d22","text":"<pre><code>config = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=30,\n    pop_size=15,\n    max_sample_nums=30,\n    num_samplers=6,\n    num_evaluators=6,\n    verbose=True\n)\n</code></pre> <p>\u7528\u4e8e\uff1a \u7814\u7a76\u3001\u57fa\u51c6\u6d4b\u8bd5\u3001\u6700\u7ec8\u8fd0\u884c</p>"},{"location":"zh/tutorials/advanced/configuration/#_15","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u5b66\u4e60 \u7b97\u6cd5\u5185\u90e8 \u5206\u6790\u8fdb\u5316\u884c\u4e3a</li> <li>\u67e5\u770b \u8c03\u8bd5\u4e0e\u6027\u80fd\u5206\u6790 \u8fdb\u884c\u6027\u80fd\u4f18\u5316</li> <li>\u67e5\u9605 API \u53c2\u8003 \u83b7\u53d6\u5b8c\u6574\u7684\u53c2\u6570\u8be6\u60c5</li> </ul>"},{"location":"zh/tutorials/advanced/configuration/#_16","title":"\u8d44\u6e90","text":"<ul> <li>EvoEngineer \u8bba\u6587 - \u7b97\u6cd5\u8be6\u60c5</li> <li>FunSearch \u8bba\u6587 - \u5c9b\u5c7f\u6a21\u578b\u7406\u8bba</li> <li>EoH \u8bba\u6587 - \u542f\u53d1\u5f0f\u8fdb\u5316</li> </ul>"},{"location":"zh/tutorials/advanced/debugging/","title":"\u8c03\u8bd5\u4e0e\u6027\u80fd\u5206\u6790","text":"<p>\u8c03\u8bd5\u95ee\u9898\u5e76\u4f18\u5316\u8fdb\u5316\u5de5\u4f5c\u6d41\u7684\u6027\u80fd\u3002</p>"},{"location":"zh/tutorials/advanced/debugging/#_2","title":"\u542f\u7528\u8be6\u7ec6\u65e5\u5fd7","text":""},{"location":"zh/tutorials/advanced/debugging/#_3","title":"\u57fa\u672c\u8be6\u7ec6\u6a21\u5f0f","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineerConfig\n\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    verbose=True  # \u542f\u7528\u8be6\u7ec6\u65e5\u5fd7\n)\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n</code></pre> <p>\u8f93\u51fa\u793a\u4f8b\uff1a <pre><code>\u7b2c 1/10 \u4ee3:\n  - \u751f\u6210\u4e86 12 \u4e2a\u89e3\n  - \u6709\u6548\u89e3: 8\n  - \u6700\u4f73\u5206\u6570: 0.245\n  - \u5e73\u5747\u5206\u6570: 0.512\n  - \u4fdd\u7559\u7cbe\u82f1: 2\n\n\u7b2c 2/10 \u4ee3:\n  - \u751f\u6210\u4e86 12 \u4e2a\u89e3\n  - \u6709\u6548\u89e3: 10\n  - \u6700\u4f73\u5206\u6570: 0.189\n  - \u5e73\u5747\u5206\u6570: 0.431\n  - \u4fdd\u7559\u7cbe\u82f1: 2\n...\n</code></pre></p>"},{"location":"zh/tutorials/advanced/debugging/#_4","title":"\u4fdd\u5b58\u4e2d\u95f4\u89e3","text":""},{"location":"zh/tutorials/advanced/debugging/#_5","title":"\u4fdd\u5b58\u6240\u6709\u4ee3","text":"<pre><code>config = EvoEngineerConfig(\n    # ... \u5176\u4ed6\u53c2\u6570\n    save_all_generations=True  # \u4fdd\u5b58\u6bcf\u4ee3\u7684\u89e3\n)\n</code></pre> <p>\u76ee\u5f55\u7ed3\u6784\uff1a <pre><code>results/\n\u251c\u2500\u2500 generation_1/\n\u2502   \u251c\u2500\u2500 solution_1.py\n\u2502   \u251c\u2500\u2500 solution_2.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 generation_2/\n\u2502   \u251c\u2500\u2500 solution_1.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 ...\n\u2514\u2500\u2500 best_solution.py\n</code></pre></p> <p>\u8fd9\u5141\u8bb8\u60a8\uff1a - \u68c0\u67e5\u5931\u8d25\u7684\u89e3 - \u8c03\u8bd5\u8bc4\u4f30\u9519\u8bef - \u5206\u6790\u89e3\u7684\u8fdb\u5316 - \u4ece\u5d29\u6e83\u4e2d\u6062\u590d</p>"},{"location":"zh/tutorials/advanced/debugging/#llm","title":"\u68c0\u67e5 LLM \u4ea4\u4e92","text":""},{"location":"zh/tutorials/advanced/debugging/#llm_1","title":"\u542f\u7528 LLM \u65e5\u5fd7","text":"<pre><code>import logging\n\n# \u914d\u7f6e\u65e5\u5fd7\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('./results/llm_debug.log'),\n        logging.StreamHandler()\n    ]\n)\n\n# \u542f\u7528 LLM \u65e5\u5fd7\u8bb0\u5f55\u5668\nlogger = logging.getLogger('evotoolkit.llm')\nlogger.setLevel(logging.DEBUG)\n\n# \u73b0\u5728\u8fd0\u884c\u7b97\u6cd5 - \u6240\u6709 LLM \u4ea4\u4e92\u90fd\u5c06\u88ab\u8bb0\u5f55\nalgorithm.run()\n</code></pre> <p>\u65e5\u5fd7\u8f93\u51fa\u793a\u4f8b\uff1a <pre><code>2024-01-15 10:23:45 - evotoolkit.llm - DEBUG - \u53d1\u9001\u63d0\u793a\u5230 LLM:\n  --- \u63d0\u793a\u5f00\u59cb ---\n  You are an expert Python programmer...\n  --- \u63d0\u793a\u7ed3\u675f ---\n\n2024-01-15 10:23:52 - evotoolkit.llm - DEBUG - \u6536\u5230 LLM \u54cd\u5e94:\n  --- \u54cd\u5e94\u5f00\u59cb ---\n  def target_function(x):\n      return x ** 2 + 2 * x + 1\n  --- \u54cd\u5e94\u7ed3\u675f ---\n\n2024-01-15 10:23:52 - evotoolkit.llm - DEBUG - Token \u4f7f\u7528: 245 \u8f93\u5165, 67 \u8f93\u51fa\n</code></pre></p>"},{"location":"zh/tutorials/advanced/debugging/#_6","title":"\u4fdd\u5b58\u63d0\u793a\u548c\u54cd\u5e94","text":"<pre><code>class DebugInterface(EvoEngineerPythonInterface):\n    def __init__(self, task):\n        super().__init__(task)\n        self.prompt_history = []\n\n    def query_llm(self, prompt):\n        response = super().query_llm(prompt)\n\n        # \u4fdd\u5b58\u4ee5\u4f9b\u8c03\u8bd5\n        self.prompt_history.append({\n            'prompt': prompt,\n            'response': response,\n            'timestamp': time.time()\n        })\n\n        # \u4fdd\u5b58\u5230\u6587\u4ef6\n        with open('./results/llm_history.json', 'w') as f:\n            json.dump(self.prompt_history, f, indent=2)\n\n        return response\n</code></pre>"},{"location":"zh/tutorials/advanced/debugging/#_7","title":"\u6027\u80fd\u5206\u6790","text":""},{"location":"zh/tutorials/advanced/debugging/#_8","title":"\u65f6\u95f4\u5206\u6790","text":"<pre><code>import time\n\nstart_time = time.time()\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\nelapsed = time.time() - start_time\nprint(f\"\\n\u603b\u4f18\u5316\u65f6\u95f4: {elapsed:.2f} \u79d2\")\nprint(f\"\u6bcf\u4ee3\u65f6\u95f4: {elapsed / config.max_generations:.2f} \u79d2\")\n\n# \u8be6\u7ec6\u8ba1\u65f6\uff08\u5982\u679c\u53ef\u7528\uff09\nif hasattr(algorithm.run_state_dict, 'metadata'):\n    gen_times = algorithm.run_state_dict.metadata.get('generation_times', [])\n    for i, t in enumerate(gen_times):\n        print(f\"\u7b2c {i+1} \u4ee3: {t:.2f}\u79d2\")\n</code></pre>"},{"location":"zh/tutorials/advanced/debugging/#cprofile","title":"\u4f7f\u7528 cProfile \u8fdb\u884c\u8be6\u7ec6\u5206\u6790","text":"<pre><code>import cProfile\nimport pstats\nfrom pstats import SortKey\n\n# \u5206\u6790\u8fd0\u884c\nprofiler = cProfile.Profile()\nprofiler.enable()\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\nprofiler.disable()\n\n# \u4fdd\u5b58\u5e76\u5206\u6790\u7ed3\u679c\nstats = pstats.Stats(profiler)\nstats.sort_stats(SortKey.CUMULATIVE)\n\n# \u6253\u5370\u524d 20 \u4e2a\u6700\u8017\u65f6\u7684\u51fd\u6570\nprint(\"\\n\u524d 20 \u4e2a\u8017\u65f6\u51fd\u6570:\")\nstats.print_stats(20)\n\n# \u4fdd\u5b58\u5230\u6587\u4ef6\nwith open('./results/profile_stats.txt', 'w') as f:\n    stats = pstats.Stats(profiler, stream=f)\n    stats.sort_stats(SortKey.CUMULATIVE)\n    stats.print_stats()\n</code></pre>"},{"location":"zh/tutorials/advanced/debugging/#_9","title":"\u5185\u5b58\u5206\u6790","text":"<pre><code>import tracemalloc\n\n# \u5f00\u59cb\u5185\u5b58\u8ddf\u8e2a\ntracemalloc.start()\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# \u83b7\u53d6\u5185\u5b58\u4f7f\u7528\ncurrent, peak = tracemalloc.get_traced_memory()\nprint(f\"\\n\u5f53\u524d\u5185\u5b58\u4f7f\u7528: {current / 1024 / 1024:.2f} MB\")\nprint(f\"\u5cf0\u503c\u5185\u5b58\u4f7f\u7528: {peak / 1024 / 1024:.2f} MB\")\n\n# \u83b7\u53d6\u6700\u5927\u5185\u5b58\u5206\u914d\nsnapshot = tracemalloc.take_snapshot()\ntop_stats = snapshot.statistics('lineno')\n\nprint(\"\\n\u524d 10 \u4e2a\u5185\u5b58\u5206\u914d:\")\nfor stat in top_stats[:10]:\n    print(stat)\n\ntracemalloc.stop()\n</code></pre>"},{"location":"zh/tutorials/advanced/debugging/#_10","title":"\u5e38\u89c1\u8c03\u8bd5\u573a\u666f","text":""},{"location":"zh/tutorials/advanced/debugging/#_11","title":"\u95ee\u9898\uff1a\u89e3\u6ca1\u6709\u6539\u8fdb","text":"<p>\u8bca\u65ad\uff1a <pre><code># \u68c0\u67e5\u5206\u6570\u8fdb\u5c55\nscores = [s.evaluation_res.score for s in all_solutions if s.evaluation_res.valid]\nprint(f\"\u524d 5 \u4e2a\u5206\u6570: {scores[:5]}\")\nprint(f\"\u540e 5 \u4e2a\u5206\u6570: {scores[-5:]}\")\n\n# \u68c0\u67e5\u662f\u5426\u9677\u5165\u5c40\u90e8\u6700\u4f18\nif len(set(scores[-10:])) == 1:\n    print(\"\u8b66\u544a: \u5206\u6570\u6ca1\u6709\u53d8\u5316 - \u53ef\u80fd\u9677\u5165\u56f0\u5883\uff01\")\n</code></pre></p> <p>\u89e3\u51b3\u65b9\u6848\uff1a - \u589e\u52a0\u79cd\u7fa4\u591a\u6837\u6027\uff08\u66f4\u5927\u7684 <code>pop_size</code>\uff09 - \u589e\u52a0\u91c7\u6837\uff08\u66f4\u5927\u7684 <code>max_sample_nums</code>\uff09 - \u8c03\u6574 LLM \u6e29\u5ea6\uff08\u66f4\u9ad8\u4ee5\u83b7\u5f97\u66f4\u591a\u63a2\u7d22\uff09 - \u68c0\u67e5\u4efb\u52a1\u8bc4\u4f30\u662f\u5426\u6b63\u5e38\u5de5\u4f5c</p>"},{"location":"zh/tutorials/advanced/debugging/#_12","title":"\u95ee\u9898\uff1a\u8bb8\u591a\u65e0\u6548\u89e3","text":"<p>\u8bca\u65ad\uff1a <pre><code>valid_count = sum(1 for s in all_solutions if s.evaluation_res.valid)\ntotal_count = len(all_solutions)\nsuccess_rate = valid_count / total_count * 100\n\nprint(f\"\u6210\u529f\u7387: {success_rate:.1f}%\")\n\n# \u68c0\u67e5\u9519\u8bef\u6d88\u606f\nerrors = [s.evaluation_res.error_message for s in all_solutions if not s.evaluation_res.valid]\nfrom collections import Counter\nprint(\"\\n\u6700\u5e38\u89c1\u7684\u9519\u8bef:\")\nfor error, count in Counter(errors).most_common(5):\n    print(f\"  {count}\u6b21: {error[:100]}...\")\n</code></pre></p> <p>\u89e3\u51b3\u65b9\u6848\uff1a - \u6539\u8fdb\u63d0\u793a\u7684\u6e05\u6670\u5ea6 - \u5728\u63d0\u793a\u4e2d\u6dfb\u52a0\u66f4\u591a\u793a\u4f8b - \u653e\u5bbd\u4efb\u52a1\u7ea6\u675f - \u68c0\u67e5\u4efb\u52a1\u8bc4\u4f30\u903b\u8f91</p>"},{"location":"zh/tutorials/advanced/debugging/#_13","title":"\u95ee\u9898\uff1a\u6027\u80fd\u6162","text":"<p>\u8bca\u65ad\uff1a <pre><code>import time\n\n# \u8ba1\u65f6\u6bcf\u4e2a\u7ec4\u4ef6\nstart = time.time()\nalgorithm = EvoEngineer(config)\ninit_time = time.time() - start\n\nstart = time.time()\nalgorithm.run()\nrun_time = time.time() - start\n\nprint(f\"\u521d\u59cb\u5316: {init_time:.2f}\u79d2\")\nprint(f\"\u6267\u884c: {run_time:.2f}\u79d2\")\nprint(f\"\u6bcf\u4ee3: {run_time / config.max_generations:.2f}\u79d2\")\n</code></pre></p> <p>\u89e3\u51b3\u65b9\u6848\uff1a - \u589e\u52a0\u5e76\u884c\u5ea6\uff08<code>num_samplers</code>\u3001<code>num_evaluators</code>\uff09 - \u51cf\u5c11 <code>max_sample_nums</code> - \u4f7f\u7528\u66f4\u5feb\u7684 LLM \u6a21\u578b - \u4f18\u5316\u4efb\u52a1\u8bc4\u4f30\u4ee3\u7801</p>"},{"location":"zh/tutorials/advanced/debugging/#_14","title":"\u81ea\u5b9a\u4e49\u7b97\u6cd5\u5b9e\u73b0","text":"<p>\u5bf9\u4e8e\u60f3\u8981\u5b9e\u73b0\u81ea\u5df1\u8fdb\u5316\u7b97\u6cd5\u7684\u9ad8\u7ea7\u7528\u6237\uff1a</p> <pre><code>from evotoolkit.core import BaseMethod, BaseConfig, Solution\n\nclass MyCustomAlgorithm(BaseMethod):\n    \"\"\"\u81ea\u5b9a\u4e49\u8fdb\u5316\u7b97\u6cd5\u5b9e\u73b0\"\"\"\n\n    def __init__(self, config: BaseConfig):\n        super().__init__(config)\n        self.population = []\n\n    def run(self):\n        \"\"\"\u4e3b\u8fdb\u5316\u5faa\u73af\"\"\"\n        # \u521d\u59cb\u5316\u79cd\u7fa4\n        self.population = self.initialize_population()\n\n        for generation in range(self.config.max_generations):\n            print(f\"\\n\u7b2c {generation + 1}/{self.config.max_generations} \u4ee3\")\n\n            # \u4f7f\u7528 LLM \u751f\u6210\u65b0\u89e3\n            new_solutions = self.generate_solutions()\n\n            # \u8bc4\u4f30\u89e3\n            for solution in new_solutions:\n                eval_res = self.config.interface.task.evaluate_code(solution.sol_string)\n                solution.evaluation_res = eval_res\n\n            # \u66f4\u65b0\u79cd\u7fa4\n            self.population = self.select(self.population + new_solutions)\n\n            # \u8bb0\u5f55\u8fdb\u5ea6\n            valid_pop = [s for s in self.population if s.evaluation_res.valid]\n            if valid_pop:\n                best = max(valid_pop, key=lambda s: s.evaluation_res.score)\n                print(f\"  \u6700\u4f73\u5206\u6570: {best.evaluation_res.score:.4f}\")\n\n        # \u4fdd\u5b58\u7ed3\u679c\n        self.save_results()\n\n    def initialize_population(self):\n        \"\"\"\u751f\u6210\u521d\u59cb\u79cd\u7fa4\"\"\"\n        initial_solutions = []\n\n        # \u4f7f\u7528 LLM \u751f\u6210\u521d\u59cb\u89e3\n        for i in range(self.config.pop_size):\n            prompt = self.config.interface.get_init_prompt()\n            response = self.config.running_llm.query(prompt)\n\n            solution = Solution(sol_string=response)\n            eval_res = self.config.interface.task.evaluate_code(response)\n            solution.evaluation_res = eval_res\n\n            initial_solutions.append(solution)\n\n        return initial_solutions\n\n    def generate_solutions(self):\n        \"\"\"\u4e3a\u5f53\u524d\u4ee3\u751f\u6210\u65b0\u89e3\"\"\"\n        new_solutions = []\n\n        # \u793a\u4f8b\uff1a\u53d8\u5f02\n        for parent in self.population[:3]:  # \u53d6\u524d 3 \u540d\n            prompt = self.config.interface.get_mutation_prompt(parent)\n            response = self.config.running_llm.query(prompt)\n\n            solution = Solution(sol_string=response)\n            new_solutions.append(solution)\n\n        return new_solutions\n\n    def select(self, solutions):\n        \"\"\"\u4e3a\u4e0b\u4e00\u4ee3\u9009\u62e9\u6700\u4f73\u89e3\"\"\"\n        # \u8fc7\u6ee4\u6709\u6548\u89e3\n        valid = [s for s in solutions if s.evaluation_res.valid]\n\n        # \u6309\u5206\u6570\u6392\u5e8f\uff08\u8d8a\u9ad8\u8d8a\u597d\uff09\n        valid.sort(key=lambda s: s.evaluation_res.score, reverse=True)\n\n        # \u4fdd\u7559\u524d pop_size \u4e2a\u89e3\n        return valid[:self.config.pop_size]\n\n    def save_results(self):\n        \"\"\"\u4fdd\u5b58\u6700\u7ec8\u7ed3\u679c\"\"\"\n        best = max(self.population, key=lambda s: s.evaluation_res.score)\n\n        with open(f'{self.config.output_path}/best_solution.py', 'w') as f:\n            f.write(best.sol_string)\n\n        print(f\"\\n\u4f18\u5316\u5b8c\u6210\uff01\")\n        print(f\"\u6700\u4f73\u5206\u6570: {best.evaluation_res.score:.4f}\")\n</code></pre> <p>\u4f7f\u7528\uff1a <pre><code>algorithm = MyCustomAlgorithm(config)\nalgorithm.run()\n</code></pre></p>"},{"location":"zh/tutorials/advanced/debugging/#_15","title":"\u8c03\u8bd5\u68c0\u67e5\u6e05\u5355","text":"<p>\u5f53\u51fa\u73b0\u95ee\u9898\u65f6\uff0c\u68c0\u67e5\uff1a</p> <ul> <li> \u4efb\u52a1\u8bc4\u4f30\u51fd\u6570\u6b63\u5e38\u5de5\u4f5c</li> <li> LLM API \u6b63\u5728\u54cd\u5e94\uff08\u68c0\u67e5\u65e5\u5fd7\uff09</li> <li> \u63d0\u793a\u6e05\u6670\u4e14\u5305\u542b\u793a\u4f8b</li> <li> \u6b63\u5728\u751f\u6210\u89e3\uff08\u68c0\u67e5 <code>sol_history</code>\uff09</li> <li> \u5206\u6570\u8ba1\u7b97\u6b63\u786e</li> <li> \u914d\u7f6e\u53c2\u6570\u5408\u7406</li> <li> \u8d44\u6e90\u5145\u8db3\uff08API \u901f\u7387\u9650\u5236\u3001\u5185\u5b58\uff09</li> <li> \u8f93\u51fa\u76ee\u5f55\u53ef\u5199</li> </ul>"},{"location":"zh/tutorials/advanced/debugging/#_16","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u67e5\u770b \u7b97\u6cd5\u5185\u90e8 \u4e86\u89e3\u5206\u6790\u6280\u672f</li> <li>\u67e5\u770b \u914d\u7f6e \u8fdb\u884c\u53c2\u6570\u8c03\u4f18</li> <li>\u63a2\u7d22 \u4f4e\u7ea7 API \u83b7\u5f97\u66f4\u591a\u63a7\u5236</li> </ul>"},{"location":"zh/tutorials/advanced/debugging/#_17","title":"\u8d44\u6e90","text":"<ul> <li>Python \u65e5\u5fd7\u6587\u6863</li> <li>cProfile \u6587\u6863</li> <li>tracemalloc \u6587\u6863</li> <li>\u6027\u80fd\u5206\u6790\u6307\u5357</li> </ul>"},{"location":"zh/tutorials/advanced/internals/","title":"\u7b97\u6cd5\u5185\u90e8","text":"<p>\u8bbf\u95ee\u548c\u5206\u6790\u8fdb\u5316\u7b97\u6cd5\u7684\u5185\u90e8\u72b6\u6001\u3002</p>"},{"location":"zh/tutorials/advanced/internals/#_2","title":"\u6982\u8ff0","text":"<p>EvoToolkit \u7684\u4f4e\u7ea7 API \u63d0\u4f9b\u5bf9\u7b97\u6cd5\u5185\u90e8\u7684\u5b8c\u5168\u8bbf\u95ee\uff0c\u5141\u8bb8\u60a8\uff1a - \u68c0\u67e5\u8fdb\u5316\u5386\u53f2 - \u8bbf\u95ee\u89e3\u79cd\u7fa4 - \u63d0\u53d6\u6307\u6807\u548c\u7edf\u8ba1\u6570\u636e - \u7ed8\u5236\u8fdb\u5316\u8fdb\u7a0b</p>"},{"location":"zh/tutorials/advanced/internals/#_3","title":"\u8bbf\u95ee\u8fd0\u884c\u72b6\u6001","text":"<p>\u6240\u6709\u7b97\u6cd5\u5c06\u5176\u5185\u90e8\u72b6\u6001\u5b58\u50a8\u5728 <code>run_state_dict</code> \u4e2d\uff1a</p> <pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# \u8bbf\u95ee\u8fd0\u884c\u72b6\u6001\nrun_state = algorithm.run_state_dict\n\n# \u83b7\u53d6\u6240\u6709\u89e3\u5386\u53f2\nall_solutions = run_state.sol_history\n\n# \u83b7\u53d6\u5f53\u524d\u79cd\u7fa4\ncurrent_population = run_state.population\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_4","title":"\u68c0\u67e5\u8fdb\u5316\u5386\u53f2","text":""},{"location":"zh/tutorials/advanced/internals/#_5","title":"\u83b7\u53d6\u6240\u6709\u89e3","text":"<pre><code># \u6240\u6709\u751f\u6210\u8fc7\u7684\u89e3\uff08\u5305\u62ec\u65e0\u6548\u7684\uff09\nall_solutions = algorithm.run_state_dict.sol_history\n\nprint(f\"\u603b\u5171\u751f\u6210\u7684\u89e3: {len(all_solutions)}\")\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_6","title":"\u8fc7\u6ee4\u6709\u6548\u89e3","text":"<pre><code># \u4ec5\u6709\u6548\u89e3\nvalid_solutions = [\n    sol for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nprint(f\"\u6709\u6548\u89e3: {len(valid_solutions)}\")\nprint(f\"\u6210\u529f\u7387: {len(valid_solutions) / len(all_solutions) * 100:.1f}%\")\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_7","title":"\u83b7\u53d6\u5206\u6570\u5386\u53f2","text":"<pre><code># \u63d0\u53d6\u5206\u6570\uff08\u8d8a\u9ad8\u8d8a\u597d\uff09\nscore_history = [\n    sol.evaluation_res.score\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nprint(f\"\u6700\u4f73\u5206\u6570: {max(score_history)}\")\nprint(f\"\u5e73\u5747\u5206\u6570: {sum(score_history) / len(score_history):.4f}\")\nprint(f\"\u5206\u6570\u63d0\u5347: {max(score_history) - score_history[0]:.4f}\")\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_8","title":"\u83b7\u53d6\u6700\u4f73\u89e3","text":"<pre><code># \u65b9\u6cd5 1\uff1a\u4f7f\u7528\u5185\u7f6e\u8f85\u52a9\u51fd\u6570\nbest_solution = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n\n# \u65b9\u6cd5 2\uff1a\u624b\u52a8\u641c\u7d22\nbest_solution = max(\n    all_solutions,\n    key=lambda s: s.evaluation_res.score if s.evaluation_res.valid else float('-inf')\n)\n\nprint(f\"\u6700\u4f73\u5206\u6570: {best_solution.evaluation_res.score}\")\nprint(f\"\u6700\u4f73\u4ee3\u7801:\\n{best_solution.sol_string}\")\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_9","title":"\u89e3\u5bf9\u8c61\u7ed3\u6784","text":"<p>\u6bcf\u4e2a\u89e3\u5305\u542b\u8be6\u7ec6\u4fe1\u606f\uff1a</p> <pre><code>solution = all_solutions[0]\n\n# \u6838\u5fc3\u5c5e\u6027\nsolution.sol_string          # \u5b9e\u9645\u7684\u4ee3\u7801/\u89e3\u5b57\u7b26\u4e32\nsolution.evaluation_res      # \u8bc4\u4f30\u7ed3\u679c\u5bf9\u8c61\nsolution.other_info         # \u9644\u52a0\u5143\u6570\u636e\u5b57\u5178\n\n# \u8bc4\u4f30\u7ed3\u679c\neval_res = solution.evaluation_res\neval_res.valid              # \u5e03\u5c14\u503c\uff1a\u89e3\u662f\u5426\u6709\u6548\uff1f\neval_res.score              # \u6d6e\u70b9\u6570\uff1a\u9002\u5e94\u5ea6\u5206\u6570\uff08\u8d8a\u9ad8\u8d8a\u597d\uff09\neval_res.error_message      # \u5b57\u7b26\u4e32\uff1a\u5982\u679c\u65e0\u6548\u5219\u4e3a\u9519\u8bef\u4fe1\u606f\neval_res.metadata           # \u5b57\u5178\uff1a\u9644\u52a0\u8bc4\u4f30\u4fe1\u606f\n\n# \u793a\u4f8b\uff1a\u6253\u5370\u89e3\u7684\u8be6\u7ec6\u4fe1\u606f\nfor i, sol in enumerate(all_solutions[:5]):\n    print(f\"\\n\u89e3 {i+1}:\")\n    print(f\"  \u6709\u6548: {sol.evaluation_res.valid}\")\n    print(f\"  \u5206\u6570: {sol.evaluation_res.score:.4f}\")\n    if not sol.evaluation_res.valid:\n        print(f\"  \u9519\u8bef: {sol.evaluation_res.error_message}\")\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_10","title":"\u7ed8\u5236\u8fdb\u5316\u8fdb\u7a0b","text":""},{"location":"zh/tutorials/advanced/internals/#_11","title":"\u5206\u6570\u968f\u65f6\u95f4\u53d8\u5316","text":"<pre><code>import matplotlib.pyplot as plt\n\n# \u6309\u987a\u5e8f\u83b7\u53d6\u6709\u6548\u5206\u6570\nscores = [\n    sol.evaluation_res.score\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nplt.figure(figsize=(10, 6))\nplt.plot(scores, marker='o', alpha=0.6, linewidth=1, markersize=4)\nplt.xlabel('\u89e3\u7d22\u5f15', fontsize=12)\nplt.ylabel('\u5206\u6570\uff08\u8d8a\u9ad8\u8d8a\u597d\uff09', fontsize=12)\nplt.title('\u8fdb\u5316\u8fdb\u7a0b', fontsize=14)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('./results/evolution_progress.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_12","title":"\u6309\u4ee3\u6570\u7684\u6700\u4f73\u5206\u6570","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\n# \u6309\u4ee3\u6570\u5206\u7ec4\u89e3\ngenerations = {}\nfor sol in all_solutions:\n    if sol.evaluation_res.valid:\n        gen = sol.other_info.get('generation', 0)\n        if gen not in generations:\n            generations[gen] = []\n        generations[gen].append(sol.evaluation_res.score)\n\n# \u83b7\u53d6\u6bcf\u4ee3\u7684\u6700\u4f73\u5206\u6570\ngen_numbers = sorted(generations.keys())\nbest_scores = [max(generations[gen]) for gen in gen_numbers]\navg_scores = [np.mean(generations[gen]) for gen in gen_numbers]\n\nplt.figure(figsize=(10, 6))\nplt.plot(gen_numbers, best_scores, 'g-o', label='\u6700\u4f73\u5206\u6570', linewidth=2)\nplt.plot(gen_numbers, avg_scores, 'b--s', label='\u5e73\u5747\u5206\u6570', linewidth=2)\nplt.xlabel('\u4ee3\u6570', fontsize=12)\nplt.ylabel('\u5206\u6570', fontsize=12)\nplt.title('\u6309\u4ee3\u6570\u7684\u5206\u6570', fontsize=14)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('./results/score_by_generation.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_13","title":"\u6210\u529f\u7387\u5206\u6790","text":"<pre><code>import matplotlib.pyplot as plt\n\n# \u6309\u4ee3\u6570\u8ba1\u7b97\u6210\u529f\u7387\nsuccess_rates = []\nfor gen in gen_numbers:\n    total = len([s for s in all_solutions if s.other_info.get('generation') == gen])\n    valid = len(generations.get(gen, []))\n    success_rates.append(valid / total * 100 if total &gt; 0 else 0)\n\nplt.figure(figsize=(10, 6))\nplt.bar(gen_numbers, success_rates, alpha=0.7, color='steelblue')\nplt.xlabel('\u4ee3\u6570', fontsize=12)\nplt.ylabel('\u6210\u529f\u7387 (%)', fontsize=12)\nplt.title('\u6309\u4ee3\u6570\u7684\u89e3\u6709\u6548\u6027', fontsize=14)\nplt.ylim(0, 100)\nplt.grid(True, alpha=0.3, axis='y')\nplt.tight_layout()\nplt.savefig('./results/success_rate.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_14","title":"\u5206\u6790\u89e3\u7684\u591a\u6837\u6027","text":""},{"location":"zh/tutorials/advanced/internals/#_15","title":"\u4ee3\u7801\u957f\u5ea6\u5206\u5e03","text":"<pre><code>import matplotlib.pyplot as plt\n\n# \u83b7\u53d6\u4ee3\u7801\u957f\u5ea6\ncode_lengths = [\n    len(sol.sol_string)\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nplt.figure(figsize=(10, 6))\nplt.hist(code_lengths, bins=20, alpha=0.7, color='coral', edgecolor='black')\nplt.xlabel('\u4ee3\u7801\u957f\u5ea6\uff08\u5b57\u7b26\uff09', fontsize=12)\nplt.ylabel('\u9891\u7387', fontsize=12)\nplt.title('\u89e3\u4ee3\u7801\u957f\u5ea6\u5206\u5e03', fontsize=14)\nplt.grid(True, alpha=0.3, axis='y')\nplt.tight_layout()\nplt.savefig('./results/code_length_dist.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_16","title":"\u5206\u6570\u5206\u5e03","text":"<pre><code>import matplotlib.pyplot as plt\n\nscores = [\n    sol.evaluation_res.score\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nplt.figure(figsize=(10, 6))\nplt.hist(scores, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.xlabel('\u5206\u6570', fontsize=12)\nplt.ylabel('\u9891\u7387', fontsize=12)\nplt.title('\u5206\u6570\u5206\u5e03', fontsize=14)\nplt.axvline(max(scores), color='r', linestyle='--', linewidth=2, label=f'\u6700\u4f73: {max(scores):.4f}')\nplt.axvline(np.mean(scores), color='b', linestyle='--', linewidth=2, label=f'\u5e73\u5747: {np.mean(scores):.4f}')\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3, axis='y')\nplt.tight_layout()\nplt.savefig('./results/score_distribution.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_17","title":"\u63d0\u53d6\u6307\u6807","text":""},{"location":"zh/tutorials/advanced/internals/#_18","title":"\u7efc\u5408\u7edf\u8ba1","text":"<pre><code>import numpy as np\n\ndef compute_statistics(all_solutions):\n    \"\"\"\u8ba1\u7b97\u7efc\u5408\u8fdb\u5316\u7edf\u8ba1\u6570\u636e\"\"\"\n\n    valid_solutions = [s for s in all_solutions if s.evaluation_res.valid]\n    scores = [s.evaluation_res.score for s in valid_solutions]\n\n    stats = {\n        'total_solutions': len(all_solutions),\n        'valid_solutions': len(valid_solutions),\n        'success_rate': len(valid_solutions) / len(all_solutions) * 100,\n        'best_score': max(scores) if scores else None,\n        'worst_score': min(scores) if scores else None,\n        'mean_score': np.mean(scores) if scores else None,\n        'median_score': np.median(scores) if scores else None,\n        'std_score': np.std(scores) if scores else None,\n        'score_range': max(scores) - min(scores) if scores else None,\n    }\n\n    return stats\n\nstats = compute_statistics(all_solutions)\n\nprint(\"\u8fdb\u5316\u7edf\u8ba1:\")\nprint(f\"  \u603b\u89e3\u6570: {stats['total_solutions']}\")\nprint(f\"  \u6709\u6548\u89e3\u6570: {stats['valid_solutions']}\")\nprint(f\"  \u6210\u529f\u7387: {stats['success_rate']:.1f}%\")\nprint(f\"\\n\u5206\u6570\u7edf\u8ba1:\")\nprint(f\"  \u6700\u4f73: {stats['best_score']:.4f}\")\nprint(f\"  \u6700\u5dee: {stats['worst_score']:.4f}\")\nprint(f\"  \u5e73\u5747: {stats['mean_score']:.4f}\")\nprint(f\"  \u4e2d\u4f4d\u6570: {stats['median_score']:.4f}\")\nprint(f\"  \u6807\u51c6\u5dee: {stats['std_score']:.4f}\")\nprint(f\"  \u8303\u56f4: {stats['score_range']:.4f}\")\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#dataframe","title":"\u5bfc\u51fa\u5230 DataFrame","text":"<pre><code>import pandas as pd\n\n# \u5c06\u89e3\u8f6c\u6362\u4e3a DataFrame \u8fdb\u884c\u5206\u6790\ndata = []\nfor i, sol in enumerate(all_solutions):\n    data.append({\n        'index': i,\n        'valid': sol.evaluation_res.valid,\n        'score': sol.evaluation_res.score if sol.evaluation_res.valid else None,\n        'generation': sol.other_info.get('generation', -1),\n        'code_length': len(sol.sol_string),\n        'error': sol.evaluation_res.error_message if not sol.evaluation_res.valid else None\n    })\n\ndf = pd.DataFrame(data)\n\n# \u4fdd\u5b58\u5230 CSV\ndf.to_csv('./results/evolution_data.csv', index=False)\n\n# \u5feb\u901f\u5206\u6790\nprint(df.describe())\nprint(\"\\n\u6309\u4ee3\u6570\u7684\u5206\u6570:\")\nprint(df.groupby('generation')['score'].agg(['mean', 'max', 'count']))\n</code></pre>"},{"location":"zh/tutorials/advanced/internals/#_19","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u5b66\u4e60 \u8c03\u8bd5\u4e0e\u6027\u80fd\u5206\u6790 \u6765\u6392\u67e5\u95ee\u9898</li> <li>\u67e5\u770b \u4f4e\u7ea7 API \u83b7\u53d6\u66f4\u591a\u63a7\u5236\u9009\u9879</li> <li>\u67e5\u770b \u914d\u7f6e \u8fdb\u884c\u53c2\u6570\u8c03\u4f18</li> </ul>"},{"location":"zh/tutorials/advanced/internals/#_20","title":"\u8d44\u6e90","text":"<ul> <li>Matplotlib \u6587\u6863 - \u7ed8\u56fe\u5e93</li> <li>Pandas \u6587\u6863 - \u6570\u636e\u5206\u6790</li> <li>NumPy \u6587\u6863 - \u6570\u503c\u8ba1\u7b97</li> </ul>"},{"location":"zh/tutorials/advanced/low-level-api/","title":"\u4f4e\u7ea7 API","text":"<p>\u4e86\u89e3\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u4f7f\u7528\u4f4e\u7ea7 API \u6765\u6700\u5927\u5316\u63a7\u5236\u8fdb\u5316\u4f18\u5316\u3002</p>"},{"location":"zh/tutorials/advanced/low-level-api/#api-vs-api","title":"\u9ad8\u7ea7 API vs \u4f4e\u7ea7 API","text":""},{"location":"zh/tutorials/advanced/low-level-api/#api_1","title":"\u9ad8\u7ea7 API\uff08\u63a8\u8350\u5927\u591a\u6570\u7528\u6237\uff09","text":"<pre><code>import evotoolkit\n\n# \u7b80\u5355\u660e\u4e86\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre> <p>\u4f18\u70b9\uff1a - \u7b80\u5355\u660e\u4e86 - \u81ea\u52a8\u914d\u7f6e - \u5185\u7f6e\u6700\u4f73\u5b9e\u8df5 - \u66f4\u5c11\u7684\u4ee3\u7801\u7ef4\u62a4</p> <p>\u7f3a\u70b9\uff1a - \u5bf9\u5185\u90e8\u63a7\u5236\u8f83\u5c11 - \u81ea\u5b9a\u4e49\u80fd\u529b\u6709\u9650 - \u56fa\u5b9a\u7684\u5de5\u4f5c\u6d41\u7ed3\u6784</p> <p>\u6700\u9002\u5408\uff1a - \u5927\u591a\u6570\u4f18\u5316\u4efb\u52a1 - \u5feb\u901f\u539f\u578b\u5f00\u53d1 - \u6807\u51c6\u5de5\u4f5c\u6d41 - \u5feb\u901f\u5165\u95e8</p>"},{"location":"zh/tutorials/advanced/low-level-api/#api_2","title":"\u4f4e\u7ea7 API\uff08\u9ad8\u7ea7\u7528\u6237\uff09","text":"<pre><code>from evotoolkit.evo_method.evoengineer import EvoEngineer, EvoEngineerConfig\n\n# \u5b8c\u5168\u63a7\u5236\u914d\u7f6e\nconfig = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=8,\n    max_sample_nums=12,\n    num_samplers=4,  # \u5e76\u884c\u91c7\u6837\u5668\u6570\u91cf\n    num_evaluators=4,  # \u5e76\u884c\u8bc4\u4f30\u5668\u6570\u91cf\n    verbose=True\n)\n\n# \u521b\u5efa\u5e76\u8fd0\u884c\u7b97\u6cd5\nalgorithm = EvoEngineer(config)\nalgorithm.run()\n\n# \u8bbf\u95ee\u5185\u90e8\u72b6\u6001\nbest_solution = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\nall_solutions = algorithm.run_state_dict.sol_history\n</code></pre> <p>\u4f18\u70b9\uff1a - \u5b8c\u5168\u63a7\u5236\u53c2\u6570 - \u8bbf\u95ee\u5185\u90e8\u72b6\u6001 - \u81ea\u5b9a\u4e49\u5de5\u4f5c\u6d41\u96c6\u6210 - \u9ad8\u7ea7\u8c03\u8bd5\u80fd\u529b</p> <p>\u7f3a\u70b9\uff1a - \u4ee3\u7801\u66f4\u590d\u6742 - \u9700\u8981\u7b97\u6cd5\u77e5\u8bc6 - \u66f4\u591a\u7ef4\u62a4\u8d1f\u62c5 - \u5bb9\u6613\u914d\u7f6e\u9519\u8bef</p> <p>\u6700\u9002\u5408\uff1a - \u7814\u7a76\u548c\u5b9e\u9a8c - \u81ea\u5b9a\u4e49\u5de5\u4f5c\u6d41\u96c6\u6210 - \u6027\u80fd\u4f18\u5316 - \u7b97\u6cd5\u5f00\u53d1</p>"},{"location":"zh/tutorials/advanced/low-level-api/#_1","title":"\u4f7f\u7528\u4e0d\u540c\u7684\u7b97\u6cd5","text":""},{"location":"zh/tutorials/advanced/low-level-api/#funsearch","title":"FunSearch","text":"<pre><code>from evotoolkit.evo_method.funsearch import FunSearch, FunSearchConfig\n\nconfig = FunSearchConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_sample_nums=30,\n    programs_per_prompt=2,\n    num_islands=4,\n    max_population_size=1000,\n    num_samplers=5,\n    num_evaluators=5,\n    verbose=True\n)\n\nalgorithm = FunSearch(config)\nalgorithm.run()\n</code></pre> <p>\u6ce8\u610f\uff1a FunSearch \u4e0d\u4f7f\u7528 <code>max_generations</code>\u3002\u5b83\u57fa\u4e8e\u5c9b\u5c7f\u6a21\u578b\u6301\u7eed\u8fdb\u5316\u3002</p>"},{"location":"zh/tutorials/advanced/low-level-api/#eoh","title":"EoH (\u542f\u53d1\u5f0f\u8fdb\u5316)","text":"<pre><code>from evotoolkit.evo_method.eoh import EoH, EoHConfig\n\nconfig = EoHConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20,\n    selection_num=2,\n    use_e2_operator=True,  # \u4ea4\u53c9\n    use_m1_operator=True,  # \u53d8\u5f02 1\n    use_m2_operator=True,  # \u53d8\u5f02 2\n    num_samplers=5,\n    num_evaluators=5,\n    verbose=True\n)\n\nalgorithm = EoH(config)\nalgorithm.run()\n</code></pre>"},{"location":"zh/tutorials/advanced/low-level-api/#_2","title":"\u8bbf\u95ee\u7ed3\u679c","text":""},{"location":"zh/tutorials/advanced/low-level-api/#_3","title":"\u83b7\u53d6\u6700\u4f73\u89e3","text":"<pre><code>algorithm.run()\n\n# \u65b9\u6cd5 1\uff1a\u4f7f\u7528\u5185\u7f6e\u8f85\u52a9\u51fd\u6570\nbest_solution = algorithm._get_best_sol(algorithm.run_state_dict.sol_history)\n\n# \u65b9\u6cd5 2\uff1a\u624b\u52a8\u641c\u7d22\nall_solutions = algorithm.run_state_dict.sol_history\nvalid_solutions = [s for s in all_solutions if s.evaluation_res.valid]\nbest_solution = max(valid_solutions, key=lambda s: s.evaluation_res.score)\n\nprint(f\"\u6700\u4f73\u5206\u6570: {best_solution.evaluation_res.score}\")\nprint(f\"\u6700\u4f73\u4ee3\u7801:\\n{best_solution.sol_string}\")\n</code></pre>"},{"location":"zh/tutorials/advanced/low-level-api/#_4","title":"\u8bbf\u95ee\u8fdb\u5316\u5386\u53f2","text":"<pre><code># \u83b7\u53d6\u8fd0\u884c\u72b6\u6001\nrun_state = algorithm.run_state_dict\n\n# \u6240\u6709\u751f\u6210\u8fc7\u7684\u89e3\nall_solutions = run_state.sol_history\n\n# \u5f53\u524d\u79cd\u7fa4\ncurrent_population = run_state.population\n\n# \u5206\u6570\u8fdb\u5c55\nscores = [\n    sol.evaluation_res.score\n    for sol in all_solutions\n    if sol.evaluation_res.valid\n]\n\nprint(f\"\u603b\u89e3\u6570: {len(all_solutions)}\")\nprint(f\"\u6709\u6548\u89e3\u6570: {len(scores)}\")\nprint(f\"\u6700\u4f73\u5206\u6570: {max(scores)}\")\nprint(f\"\u5e73\u5747\u5206\u6570: {sum(scores) / len(scores)}\")\n</code></pre>"},{"location":"zh/tutorials/advanced/low-level-api/#_5","title":"\u81ea\u5b9a\u4e49\u5de5\u4f5c\u6d41\u96c6\u6210","text":""},{"location":"zh/tutorials/advanced/low-level-api/#_6","title":"\u68c0\u67e5\u70b9\u548c\u6062\u590d","text":"<pre><code>import pickle\n\n# \u8fd0\u884c\u51e0\u4ee3\nalgorithm = EvoEngineer(config)\nfor gen in range(5):\n    algorithm.run_one_generation()\n\n    # \u4fdd\u5b58\u68c0\u67e5\u70b9\n    with open(f'checkpoint_gen{gen}.pkl', 'wb') as f:\n        pickle.dump(algorithm.run_state_dict, f)\n\n# \u7a0d\u540e\uff1a\u4ece\u68c0\u67e5\u70b9\u6062\u590d\nwith open('checkpoint_gen4.pkl', 'rb') as f:\n    saved_state = pickle.load(f)\n\nalgorithm.run_state_dict = saved_state\nalgorithm.run()  # \u4ece\u4e0a\u6b21\u4e2d\u65ad\u5904\u7ee7\u7eed\n</code></pre>"},{"location":"zh/tutorials/advanced/low-level-api/#_7","title":"\u81ea\u5b9a\u4e49\u505c\u6b62\u51c6\u5219","text":"<pre><code>class CustomEvoEngineer(EvoEngineer):\n    def should_stop(self):\n        # \u5982\u679c\u627e\u5230\u5206\u6570 &gt; 0.95 \u7684\u89e3\u5c31\u505c\u6b62\n        best = self._get_best_sol(self.run_state_dict.sol_history)\n        if best and best.evaluation_res.score &gt; 0.95:\n            print(\"\u627e\u5230\u4f18\u79c0\u89e3\uff01\u63d0\u524d\u505c\u6b62\u3002\")\n            return True\n\n        # \u5426\u5219\u4f7f\u7528\u9ed8\u8ba4\u505c\u6b62\u51c6\u5219\n        return super().should_stop()\n\nalgorithm = CustomEvoEngineer(config)\nalgorithm.run()\n</code></pre>"},{"location":"zh/tutorials/advanced/low-level-api/#_8","title":"\u6df7\u5408\u7b97\u6cd5","text":"<pre><code># \u4ece EvoEngineer \u5f00\u59cb\u8fdb\u884c\u63a2\u7d22\nconfig1 = EvoEngineerConfig(\n    interface=interface,\n    output_path='./results/phase1',\n    running_llm=llm_api,\n    max_generations=5,\n    pop_size=10\n)\n\nalgo1 = EvoEngineer(config1)\nalgo1.run()\n\n# \u83b7\u53d6\u7b2c\u4e00\u9636\u6bb5\u7684\u6700\u4f73\u89e3\nbest_from_phase1 = sorted(\n    algo1.run_state_dict.sol_history,\n    key=lambda s: s.evaluation_res.score if s.evaluation_res.valid else float('-inf'),\n    reverse=True\n)[:3]\n\n# \u4f7f\u7528 FunSearch \u8fdb\u884c\u7cbe\u5316\nconfig2 = FunSearchConfig(\n    interface=interface,\n    output_path='./results/phase2',\n    running_llm=llm_api,\n    max_sample_nums=50\n)\n\nalgo2 = FunSearch(config2)\n# \u7528\u7b2c\u4e00\u9636\u6bb5\u7684\u89e3\u521d\u59cb\u5316\nalgo2.run_state_dict.population = best_from_phase1\nalgo2.run()\n</code></pre>"},{"location":"zh/tutorials/advanced/low-level-api/#_9","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u5b66\u4e60 \u7b97\u6cd5\u914d\u7f6e \u8fdb\u884c\u8be6\u7ec6\u7684\u53c2\u6570\u8c03\u4f18</li> <li>\u63a2\u7d22 \u7b97\u6cd5\u5185\u90e8 \u5206\u6790\u8fdb\u5316\u884c\u4e3a</li> <li>\u67e5\u770b \u8c03\u8bd5\u4e0e\u6027\u80fd\u5206\u6790 \u83b7\u53d6\u6545\u969c\u6392\u9664\u6280\u5de7</li> </ul>"},{"location":"zh/tutorials/advanced/low-level-api/#_10","title":"\u8d44\u6e90","text":"<ul> <li>API \u53c2\u8003 - \u5b8c\u6574\u7684 API \u6587\u6863</li> <li>\u67b6\u6784\u6307\u5357 - \u7406\u89e3\u5185\u90e8\u539f\u7406</li> </ul>"},{"location":"zh/tutorials/built-in/adversarial-attack/","title":"\u5bf9\u6297\u653b\u51fb\u6559\u7a0b","text":"<p>\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 LLM \u9a71\u52a8\u7684\u8fdb\u5316\u7b97\u6cd5\u6765\u53d1\u73b0\u6709\u6548\u7684\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\u3002</p> <p>\u5b66\u672f\u5f15\u7528</p> <p>\u5bf9\u6297\u653b\u51fb\u4efb\u52a1\u57fa\u4e8e L-AutoDA \u7814\u7a76\u3002\u5982\u679c\u60a8\u5728\u5b66\u672f\u5de5\u4f5c\u4e2d\u4f7f\u7528\u6b64\u529f\u80fd\uff0c\u8bf7\u5f15\u7528\uff1a</p> <pre><code>@inproceedings{10.1145/3638530.3664121,\n    author = {Guo, Ping and Liu, Fei and Lin, Xi and Zhao, Qingchuan and Zhang, Qingfu},\n    title = {L-AutoDA: Large Language Models for Automatically Evolving Decision-based Adversarial Attacks},\n    year = {2024},\n    isbn = {9798400704956},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3638530.3664121},\n    doi = {10.1145/3638530.3664121},\n    pages = {1846\u20131854},\n    numpages = {9},\n    keywords = {large language models, adversarial attacks, automated algorithm design, evolutionary algorithms},\n    location = {Melbourne, VIC, Australia},\n    series = {GECCO '24 Companion}\n}\n</code></pre> <p>\u5b8c\u6574\u793a\u4f8b\u4ee3\u7801</p> <p>\u672c\u6559\u7a0b\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u53ef\u8fd0\u884c\u793a\u4f8b\uff08\u70b9\u51fb\u67e5\u770b/\u4e0b\u8f7d\uff09\uff1a</p> <ul> <li> basic_example.py - \u4f7f\u7528\u6a21\u62df\u8bc4\u4f30\u7684\u57fa\u7840\u7528\u6cd5</li> <li> README.zh.md - \u793a\u4f8b\u6587\u6863\u548c\u4f7f\u7528\u6307\u5357</li> </ul> <p>\u672c\u5730\u8fd0\u884c\uff1a <pre><code>cd examples/adversarial_attack\npython basic_example.py\n</code></pre></p>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_2","title":"\u6982\u8ff0","text":"<p>\u672c\u6559\u7a0b\u6f14\u793a\uff1a</p> <ul> <li>\u521b\u5efa\u5bf9\u6297\u653b\u51fb\u4efb\u52a1</li> <li>\u4f7f\u7528 LLM \u9a71\u52a8\u7684\u8fdb\u5316\u7b97\u6cd5\u53d1\u73b0\u653b\u51fb\u7b97\u6cd5</li> <li>\u7406\u89e3 <code>draw_proposals</code> \u51fd\u6570</li> <li>\u5728\u795e\u7ecf\u7f51\u7edc\u4e0a\u8bc4\u4f30\u653b\u51fb</li> <li>\u81ea\u52a8\u8fdb\u5316\u6709\u6548\u7684\u9ed1\u76d2\u653b\u51fb</li> </ul>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_3","title":"\u5b89\u88c5","text":"<p>\u63a8\u8350\u4f7f\u7528 GPU</p> <p>\u4e3a\u83b7\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u5efa\u8bae\u5728\u5b89\u88c5 EvoToolkit \u4e4b\u524d\u5148\u5b89\u88c5\u652f\u6301 CUDA \u7684 PyTorch\u3002 \u6211\u4eec\u63a8\u8350\u4f7f\u7528 CUDA 12.9\uff08\u6700\u65b0\u7a33\u5b9a\u7248\uff09\u3002</p>"},{"location":"zh/tutorials/built-in/adversarial-attack/#1-pytorch-gpu","title":"\u6b65\u9aa4 1\uff1a\u5b89\u88c5 PyTorch\uff08\u652f\u6301 GPU\uff09","text":"<pre><code># CUDA 12.9\uff08\u63a8\u8350\uff09\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n\n# \u5176\u4ed6\u7248\u672c\u8bf7\u8bbf\u95ee\uff1ahttps://pytorch.org/get-started/locally/\n# CUDA 12.1\n# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n\n# \u4ec5 CPU\uff08\u4e0d\u63a8\u8350\uff0c\u6027\u80fd\u8f83\u6162\uff09\n# pip install torch torchvision\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#2-evotoolkit","title":"\u6b65\u9aa4 2\uff1a\u5b89\u88c5 EvoToolkit","text":"<pre><code>pip install evotoolkit[adversarial_attack]\n</code></pre> <p>\u8fd9\u5c06\u5b89\u88c5\uff1a</p> <ul> <li><code>timm</code> - PyTorch Image Models\uff08\u63d0\u4f9b\u6765\u81ea Hugging Face \u7684 CIFAR-10 \u9884\u8bad\u7ec3\u6a21\u578b\uff09</li> <li><code>foolbox</code> - \u5bf9\u6297\u653b\u51fb\u5e93</li> </ul> <p>\u524d\u7f6e\u6761\u4ef6\uff1a</p> <ul> <li>Python &gt;= 3.11</li> <li>PyTorch &gt;= 2.0\uff08\u5efa\u8bae\u5e26 CUDA \u652f\u6301\uff09</li> <li>LLM API \u8bbf\u95ee\u6743\u9650\uff08OpenAI\u3001Claude \u6216\u5176\u4ed6\u517c\u5bb9\u7684\u63d0\u4f9b\u5546\uff09</li> <li>\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u7684\u57fa\u7840\u7406\u89e3</li> </ul>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_4","title":"\u7406\u89e3\u5bf9\u6297\u653b\u51fb\u4efb\u52a1","text":""},{"location":"zh/tutorials/built-in/adversarial-attack/#_5","title":"\u4ec0\u4e48\u662f\u5bf9\u6297\u653b\u51fb\u4efb\u52a1\uff1f","text":"<p>\u5bf9\u6297\u653b\u51fb\u4efb\u52a1\u8fdb\u5316 \u63d0\u8bae\u751f\u6210\u7b97\u6cd5 \u6765\u521b\u5efa\u5bf9\u6297\u6837\u672c\uff0c\u4ee5\u6700\u5c0f\u7684\u6270\u52a8\u6b3a\u9a97\u795e\u7ecf\u7f51\u7edc\u3002</p> \u65b9\u9762 \u79d1\u5b66\u56de\u5f52 \u5bf9\u6297\u653b\u51fb \u89e3\u7c7b\u578b \u6570\u5b66\u65b9\u7a0b \u63d0\u8bae\u7b97\u6cd5 \u51fd\u6570\u540d\u79f0 <code>equation</code> <code>draw_proposals</code> \u8f93\u5165 \u6570\u636e + \u53c2\u6570 \u56fe\u50cf + \u566a\u58f0 + \u8d85\u53c2\u6570 \u8bc4\u4f30 \u9884\u6d4b\u7684 MSE \u5bf9\u6297\u6837\u672c\u7684 L2 \u8ddd\u79bb \u76ee\u6807 \u6700\u5c0f\u5316\u9884\u6d4b\u8bef\u5dee \u6700\u5c0f\u5316\u6270\u52a8"},{"location":"zh/tutorials/built-in/adversarial-attack/#_6","title":"\u4efb\u52a1\u7ec4\u4ef6","text":"<p>\u5bf9\u6297\u653b\u51fb\u4efb\u52a1\u9700\u8981\uff1a</p> <ul> <li>\u76ee\u6807\u6a21\u578b\uff1a\u8981\u653b\u51fb\u7684\u795e\u7ecf\u7f51\u7edc</li> <li>\u6d4b\u8bd5\u6570\u636e\uff1a\u7528\u4e8e\u751f\u6210\u5bf9\u6297\u6837\u672c\u7684\u56fe\u50cf</li> <li>\u653b\u51fb\u9884\u7b97\uff1a\u8fed\u4ee3/\u67e5\u8be2\u6b21\u6570</li> <li>\u8bc4\u4f30\u6307\u6807\uff1a\u539f\u59cb\u56fe\u50cf\u4e0e\u5bf9\u6297\u56fe\u50cf\u4e4b\u95f4\u7684 L2 \u8ddd\u79bb</li> </ul>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_7","title":"\u521b\u5efa\u60a8\u7684\u7b2c\u4e00\u4e2a\u5bf9\u6297\u653b\u51fb\u4efb\u52a1","text":""},{"location":"zh/tutorials/built-in/adversarial-attack/#1","title":"\u6b65\u9aa4 1\uff1a\u52a0\u8f7d\u76ee\u6807\u6a21\u578b\u548c\u6570\u636e","text":"<pre><code>import torch\nimport torch.nn as nn\nimport timm\nfrom torchvision import datasets, transforms\n\n# \u52a0\u8f7d CIFAR-10 \u9884\u8bad\u7ec3\u7684 ResNet18 \u6a21\u578b\uff08\u6765\u81ea Hugging Face Hub\uff09\n# \u8be5\u6a21\u578b\u5728 CIFAR-10 \u4e0a\u8fbe\u5230 94.98% \u51c6\u786e\u7387\n# CIFAR-10 \u7684 ResNet18 \u4f7f\u7528\u4fee\u6539\u8fc7\u7684\u67b6\u6784\uff083x3 conv1, \u79fb\u9664 maxpool\uff09\nbase_model = timm.create_model(\"resnet18\", num_classes=10, pretrained=False)\nbase_model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nbase_model.maxpool = nn.Identity()\n\n# \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\nbase_model.load_state_dict(\n    torch.hub.load_state_dict_from_url(\n        \"https://huggingface.co/edadaltocg/resnet18_cifar10/resolve/main/pytorch_model.bin\",\n        map_location=\"cpu\",\n        file_name=\"resnet18_cifar10.pth\"\n    )\n)\nbase_model.eval()\n\n# \u521b\u5efa\u5e26 Normalization \u7684\u6a21\u578b\u5305\u88c5\u5668\n# \u91cd\u8981\uff1aFoolbox \u9700\u8981\u8f93\u5165\u5728 [0, 1] \u8303\u56f4\uff0c\u6240\u4ee5 normalization \u5fc5\u987b\u5728\u6a21\u578b\u5185\u90e8\nclass NormalizedModel(nn.Module):\n    def __init__(self, model, mean, std):\n        super().__init__()\n        self.model = model\n        self.register_buffer('mean', torch.tensor(mean).view(1, 3, 1, 1))\n        self.register_buffer('std', torch.tensor(std).view(1, 3, 1, 1))\n\n    def forward(self, x):\n        # x \u5728 [0, 1] \u8303\u56f4\uff0c\u8fdb\u884c\u6807\u51c6\u5316\n        x_normalized = (x - self.mean) / self.std\n        return self.model(x_normalized)\n\nmodel = NormalizedModel(base_model,\n                        mean=[0.4914, 0.4822, 0.4465],\n                        std=[0.2471, 0.2435, 0.2616])\nmodel.eval()\n\nif torch.cuda.is_available():\n    model.cuda()\n\n# \u52a0\u8f7d CIFAR-10 \u6d4b\u8bd5\u96c6\uff08\u53ea\u505a ToTensor\uff0c\u4e0d\u505a Normalize\uff09\ntransform = transforms.Compose([\n    transforms.ToTensor(),  # \u8f6c\u6362\u5230 [0, 1] \u8303\u56f4\n])\ntest_set = datasets.CIFAR10(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transform\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_set,\n    batch_size=32,\n    shuffle=False\n)\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#2","title":"\u6b65\u9aa4 2\uff1a\u521b\u5efa\u4efb\u52a1\u5e76\u6d4b\u8bd5\u521d\u59cb\u89e3","text":"<pre><code>from evotoolkit.task.python_task import AdversarialAttackTask\n\n# \u521b\u5efa\u4efb\u52a1\ntask = AdversarialAttackTask(\n    model=model,\n    test_loader=test_loader,\n    attack_steps=1000,\n    n_test_samples=10,\n    use_mock=False\n)\n\n# \u83b7\u53d6\u521d\u59cb\u89e3\ninit_sol = task.make_init_sol_wo_other_info()\n\nprint(f\"\u521d\u59cb\u7b97\u6cd5:\")\nprint(init_sol.sol_string)\nprint(f\"\\n\u5f97\u5206: {init_sol.evaluation_res.score:.2f}\")\nprint(f\"\u5e73\u5747 L2 \u8ddd\u79bb: {init_sol.evaluation_res.additional_info['avg_distance']:.2f}\")\n</code></pre> <p>\u8f93\u51fa\uff1a <pre><code>\u521d\u59cb\u7b97\u6cd5:\nimport numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    \"\"\"\u57fa\u7ebf\u63d0\u8bae\u751f\u6210...\"\"\"\n    ...\n\n\u5f97\u5206: -2.34\n\u5e73\u5747 L2 \u8ddd\u79bb: 2.34\n</code></pre></p>"},{"location":"zh/tutorials/built-in/adversarial-attack/#3","title":"\u6b65\u9aa4 3\uff1a\u6d4b\u8bd5\u81ea\u5b9a\u4e49\u7b97\u6cd5","text":"<pre><code>custom_code = '''import numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    \"\"\"\u7b80\u5355\u7b97\u6cd5\uff1a\u5e26\u566a\u58f0\u5730\u5411\u539f\u59cb\u56fe\u50cf\u79fb\u52a8\u3002\"\"\"\n    org = org_img.flatten()\n    best = best_adv_img.flatten()\n    noise = std_normal_noise.flatten()\n\n    # \u5e26\u968f\u673a\u6270\u52a8\u5730\u5411\u539f\u59cb\u56fe\u50cf\u79fb\u52a8\n    direction = org - best\n    step = hyperparams[0] * 0.1\n    candidate = best + step * direction + step * noise * 0.5\n\n    return candidate.reshape(org_img.shape)\n'''\n\nresult = task.evaluate_code(custom_code)\nprint(f\"\u5f97\u5206: {result.score:.2f}\")\nprint(f\"\u5e73\u5747 L2 \u8ddd\u79bb: {result.additional_info['avg_distance']:.2f}\")\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#draw_proposals","title":"\u7406\u89e3 draw_proposals \u51fd\u6570","text":""},{"location":"zh/tutorials/built-in/adversarial-attack/#_8","title":"\u51fd\u6570\u7b7e\u540d","text":"<p>\u8fdb\u5316\u7684\u51fd\u6570\u5fc5\u987b\u5177\u6709\u4ee5\u4e0b\u786e\u5207\u7b7e\u540d\uff1a</p> <pre><code>def draw_proposals(\n    org_img: np.ndarray,         # \u539f\u59cb\u5e72\u51c0\u56fe\u50cf\n    best_adv_img: np.ndarray,    # \u5f53\u524d\u6700\u4f73\u5bf9\u6297\u6837\u672c\n    std_normal_noise: np.ndarray,# \u7528\u4e8e\u63a2\u7d22\u7684\u968f\u673a\u566a\u58f0\n    hyperparams: np.ndarray      # \u81ea\u9002\u5e94\u6b65\u957f\n) -&gt; np.ndarray:                 # \u65b0\u7684\u5019\u9009\u5bf9\u6297\u6837\u672c\n    \"\"\"\u751f\u6210\u65b0\u7684\u5019\u9009\u5bf9\u6297\u6837\u672c\u3002\"\"\"\n    ...\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_9","title":"\u8f93\u5165\u8be6\u60c5","text":"<p>org_img\uff08\u539f\u59cb\u56fe\u50cf\uff09\uff1a - \u5f62\u72b6\uff1aRGB \u56fe\u50cf\u4e3a <code>(3, H, W)</code>\uff08\u4f8b\u5982\uff0cCIFAR-10 \u4e3a <code>(3, 32, 32)</code>\uff09 - \u503c\uff1a<code>[0, 1]</code> \u5f52\u4e00\u5316\u7684\u50cf\u7d20\u503c - \u7528\u9014\uff1a\u6211\u4eec\u6b63\u5728\u653b\u51fb\u7684\u5e72\u51c0\u56fe\u50cf</p> <p>best_adv_img\uff08\u6700\u4f73\u5bf9\u6297\u6837\u672c\uff09\uff1a - \u5f62\u72b6\uff1a<code>(3, H, W)</code> - \u4e0e org_img \u76f8\u540c - \u503c\uff1a<code>[0, 1]</code> - \u7528\u9014\uff1a\u5f53\u524d\u6700\u4f73\u5bf9\u6297\u6837\u672c\uff08\u6b3a\u9a97\u6a21\u578b\uff0c\u6700\u63a5\u8fd1\u539f\u59cb\u56fe\u50cf\uff09</p> <p>std_normal_noise\uff08\u968f\u673a\u566a\u58f0\uff09\uff1a - \u5f62\u72b6\uff1a<code>(3, H, W)</code> - \u4e0e org_img \u76f8\u540c - \u503c\uff1a\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03 N(0, 1) \u91c7\u6837 - \u7528\u9014\uff1a\u4e3a\u63a2\u7d22\u63d0\u4f9b\u968f\u673a\u6027</p> <p>hyperparams\uff08\u81ea\u9002\u5e94\u53c2\u6570\uff09\uff1a - \u5f62\u72b6\uff1a<code>(1,)</code> - \u5355\u4e2a\u6807\u91cf\u503c - \u503c\uff1a\u901a\u5e38\u5728 <code>[0.5, 1.5]</code> \u8303\u56f4\u5185 - \u7528\u9014\uff1a\u627e\u5230\u5bf9\u6297\u6837\u672c\u65f6\u589e\u52a0\u7684\u81ea\u9002\u5e94\u6b65\u957f</p>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_10","title":"\u8fd4\u56de\u503c","text":"<p>\u5fc5\u987b\u8fd4\u56de\u4e00\u4e2a numpy \u6570\u7ec4\uff0c\u5177\u6709\uff1a - \u5f62\u72b6\uff1a<code>(3, H, W)</code> - \u4e0e org_img \u76f8\u540c - \u503c\uff1a\u4efb\u610f\uff08\u5c06\u81ea\u52a8\u88c1\u526a\u5230 <code>[0, 1]</code>\uff09 - \u7528\u9014\uff1a\u65b0\u7684\u5019\u9009\u5bf9\u6297\u6837\u672c</p>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_11","title":"\u7b97\u6cd5\u8bbe\u8ba1\u539f\u5219","text":"<p>1. \u5229\u7528\uff08\u4f18\u5316\uff09</p> <p>\u6cbf\u4ece org_img \u5230\u51b3\u7b56\u8fb9\u754c\u7684\u65b9\u5411\u79fb\u52a8\uff1a</p> <pre><code>direction = org_img - best_adv_img\ncandidate = best_adv_img + step_size * direction\n</code></pre> <p>2. \u63a2\u7d22\uff08\u53d1\u73b0\uff09</p> <p>\u6dfb\u52a0\u968f\u673a\u566a\u58f0\u4ee5\u53d1\u73b0\u65b0\u533a\u57df\uff1a</p> <pre><code>candidate = best_adv_img + noise_component\n</code></pre> <p>3. \u81ea\u9002\u5e94\u6b65\u957f</p> <p>\u4f7f\u7528 hyperparams \u5e73\u8861\u63a2\u7d22/\u5229\u7528\uff1a</p> <pre><code># hyperparams \u5728\u627e\u5230\u5bf9\u6297\u6837\u672c\u65f6\u589e\u52a0\nstep = hyperparams[0] * base_step_size\n</code></pre> <p>4. \u5b8c\u6574\u793a\u4f8b</p> <pre><code>import numpy as np\n\ndef draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    \"\"\"\u7ed3\u5408\u5e73\u884c\u548c\u5782\u76f4\u5206\u91cf\u3002\"\"\"\n    # \u5c55\u5e73\u4e3a\u5411\u91cf\n    org = org_img.flatten()\n    best = best_adv_img.flatten()\n    noise = std_normal_noise.flatten()\n\n    # \u8ba1\u7b97\u65b9\u5411\n    direction = org - best\n    direction_norm = np.linalg.norm(direction)\n\n    # \u5e73\u884c\u5206\u91cf\uff08\u671d\u5411\u539f\u59cb\u56fe\u50cf\uff09\n    noise_norm = np.linalg.norm(noise)\n    step_size = (noise_norm * hyperparams[0]) ** 2\n    d_parallel = step_size * direction\n\n    # \u5782\u76f4\u5206\u91cf\uff08\u63a2\u7d22\uff09\n    if direction_norm &gt; 1e-8:\n        dot_product = np.dot(direction, noise)\n        projection = (dot_product / direction_norm) * direction\n        d_perpendicular = (projection / direction_norm - direction_norm * noise) * hyperparams[0]\n    else:\n        d_perpendicular = noise * hyperparams[0]\n\n    # \u7ec4\u5408\n    candidate = best + d_parallel + d_perpendicular\n\n    return candidate.reshape(org_img.shape)\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_12","title":"\u8fd0\u884c\u8fdb\u5316\u4ee5\u53d1\u73b0\u653b\u51fb","text":""},{"location":"zh/tutorials/built-in/adversarial-attack/#1_1","title":"\u6b65\u9aa4 1\uff1a\u521b\u5efa\u63a5\u53e3","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools.llm import HttpsApi\n\n# \u521b\u5efa\u63a5\u53e3\ninterface = EvoEngineerPythonInterface(task)\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#2-llm","title":"\u6b65\u9aa4 2\uff1a\u914d\u7f6e LLM","text":"<pre><code>llm_api = HttpsApi(\n    api_url=\"api.openai.com\",  # \u4f60\u7684 API URL\n    key=\"your-api-key-here\",   # \u4f60\u7684 API \u5bc6\u94a5\n    model=\"gpt-4o\"\n)\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#3_1","title":"\u6b65\u9aa4 3\uff1a\u8fd0\u884c\u8fdb\u5316","text":"<pre><code>result = evotoolkit.solve(\n    interface=interface,\n    output_path='./attack_results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20\n)\n\nprint(f\"\u627e\u5230\u7684\u6700\u4f73\u7b97\u6cd5:\")\nprint(result.sol_string)\nprint(f\"\\n\u5e73\u5747 L2 \u8ddd\u79bb: {-result.evaluation_res.score:.2f}\")\n</code></pre> <p>\u5c1d\u8bd5\u4e0d\u540c\u7684\u7b97\u6cd5</p> <p>EvoToolkit \u652f\u6301\u591a\u79cd\u8fdb\u5316\u7b97\u6cd5\u7528\u4e8e\u5bf9\u6297\u653b\u51fb\uff1a</p> <pre><code># \u4f7f\u7528 EoH\nfrom evotoolkit.task.python_task import EoHPythonInterface\ninterface = EoHPythonInterface(task)\n\n# \u4f7f\u7528 FunSearch\nfrom evotoolkit.task.python_task import FunSearchPythonInterface\ninterface = FunSearchPythonInterface(task)\n\n# \u4f7f\u7528 EvoEngineer\uff08\u9ed8\u8ba4\uff09\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\ninterface = EvoEngineerPythonInterface(task)\n</code></pre> <p>\u7136\u540e\u4f7f\u7528\u76f8\u540c\u7684 <code>evotoolkit.solve()</code> \u8c03\u7528\u6765\u8fd0\u884c\u8fdb\u5316\u3002\u4e0d\u540c\u7684\u63a5\u53e3\u53ef\u80fd\u4f1a\u53d1\u73b0\u4e0d\u540c\u7684\u653b\u51fb\u7b56\u7565\u3002</p>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_13","title":"\u653b\u51fb\u8fdb\u5316\u793a\u4f8b","text":"<p>\u5728\u8fdb\u5316\u8fc7\u7a0b\u4e2d\uff0cLLM \u53d1\u73b0\u8d8a\u6765\u8d8a\u6709\u6548\u7684\u7b97\u6cd5\uff1a</p> <p>\u7b2c 1 \u4ee3\uff1a\u7b80\u5355\u57fa\u7ebf <pre><code>def draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    return best_adv_img + 0.01 * std_normal_noise\n# \u5e73\u5747 L2: 3.5\n</code></pre></p> <p>\u7b2c 3 \u4ee3\uff1a\u57fa\u4e8e\u65b9\u5411 <pre><code>def draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    direction = org_img - best_adv_img\n    return best_adv_img + hyperparams[0] * 0.1 * direction\n# \u5e73\u5747 L2: 2.1\n</code></pre></p> <p>\u7b2c 7 \u4ee3\uff1a\u590d\u6742\u7ec4\u5408 <pre><code>def draw_proposals(org_img, best_adv_img, std_normal_noise, hyperparams):\n    # \u7ed3\u5408\u591a\u4e2a\u7ec4\u4ef6\u7684\u590d\u6742\u7b97\u6cd5\n    ...\n# \u5e73\u5747 L2: 0.8\n</code></pre></p>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_14","title":"\u81ea\u5b9a\u4e49\u8fdb\u5316\u884c\u4e3a","text":"<p>\u8fdb\u5316\u653b\u51fb\u7684\u8d28\u91cf\u7531 \u8fdb\u5316\u65b9\u6cd5 \u53ca\u5176\u5185\u90e8\u7684 \u63d0\u793a\u8bbe\u8ba1 \u63a7\u5236\u3002\u8981\u6539\u8fdb\u7ed3\u679c\uff1a</p> <ul> <li>\u8c03\u6574\u63d0\u793a\uff1a\u7ee7\u627f\u73b0\u6709\u7684 Interface \u7c7b\u5e76\u81ea\u5b9a\u4e49 LLM \u63d0\u793a</li> <li>\u5f00\u53d1\u65b0\u7b97\u6cd5\uff1a\u521b\u5efa\u5168\u65b0\u7684\u8fdb\u5316\u7b56\u7565</li> </ul> <p>\u4e86\u89e3\u66f4\u591a</p> <p>\u8fd9\u4e9b\u662f\u9002\u7528\u4e8e\u6240\u6709\u4efb\u52a1\u7684\u901a\u7528\u6280\u672f\u3002\u6709\u5173\u8be6\u7ec6\u6559\u7a0b\uff0c\u8bf7\u53c2\u9605\uff1a</p> <ul> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u5982\u4f55\u4fee\u6539\u63d0\u793a\u548c\u5f00\u53d1\u65b0\u7b97\u6cd5</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u66f4\u591a\u9ad8\u7ea7\u914d\u7f6e\u9009\u9879</li> </ul> <p>\u5feb\u901f\u793a\u4f8b - \u5bf9\u6297\u653b\u51fb\u7684\u81ea\u5b9a\u4e49\u63d0\u793a\uff1a</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\n\nclass EvoEngineerCustomAttackInterface(EvoEngineerPythonInterface):\n    \"\"\"\u9488\u5bf9\u5bf9\u6297\u653b\u51fb\u8fdb\u5316\u4f18\u5316\u7684\u63a5\u53e3\u3002\"\"\"\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        \"\"\"\u81ea\u5b9a\u4e49\u53d8\u5f02\u63d0\u793a\u4ee5\u5f3a\u8c03\u653b\u51fb\u6709\u6548\u6027\u3002\"\"\"\n\n        if operator_name == \"mutation\":\n            task_description = self.task.get_base_task_description()\n            individual = selected_individuals[0]\n\n            prompt = f\"\"\"# \u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\u8fdb\u5316\n\n{task_description}\n\n## \u5f53\u524d\u6700\u4f73\u7b97\u6cd5\n**\u5e73\u5747 L2 \u8ddd\u79bb:** {-current_best_sol.evaluation_res.score:.2f}\n**\u7b97\u6cd5:** {current_best_sol.sol_string}\n\n## \u8981\u53d8\u5f02\u7684\u7b97\u6cd5\n**\u5e73\u5747 L2 \u8ddd\u79bb:** {-individual.evaluation_res.score:.2f}\n**\u7b97\u6cd5:** {individual.sol_string}\n\n## \u4f18\u5316\u6307\u5357\n\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u4e13\u6ce8\u4e8e\u6539\u8fdb\u7b97\u6cd5\uff1a\n- \u66f4\u597d\u5730\u5e73\u8861\u5229\u7528\uff08\u4f18\u5316\uff09\u548c\u63a2\u7d22\uff08\u53d1\u73b0\uff09\n- \u66f4\u6709\u6548\u5730\u4f7f\u7528\u81ea\u9002\u5e94 hyperparams\n- \u5de7\u5999\u7ec4\u5408\u65b9\u5411\u5411\u91cf\u548c\u566a\u58f0\n- \u6570\u503c\u7a33\u5b9a\u6027\u548c\u6548\u7387\n\n\u751f\u6210\u4e00\u4e2a\u6539\u8fdb\u7684 draw_proposals \u51fd\u6570\uff0c\u5b9e\u73b0\u66f4\u4f4e\u7684 L2 \u8ddd\u79bb\u3002\n\n## \u54cd\u5e94\u683c\u5f0f\uff1a\nname: [\u63cf\u8ff0\u6027\u540d\u79f0]\ncode:\n[\u60a8\u6539\u8fdb\u7684 draw_proposals \u51fd\u6570]\nthought: [\u66f4\u6539\u7684\u63a8\u7406]\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # \u5bf9\u5176\u4ed6\u7b97\u5b50\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u63a5\u53e3\ninterface = EvoEngineerCustomAttackInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./custom_results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_15","title":"\u7406\u89e3\u8bc4\u4f30","text":""},{"location":"zh/tutorials/built-in/adversarial-attack/#_16","title":"\u8bc4\u5206\u673a\u5236","text":"<ol> <li>\u653b\u51fb\u6267\u884c\uff1a\u5728\u6d4b\u8bd5\u6837\u672c\u4e0a\u8fd0\u884c\u8fdb\u5316\u7684\u7b97\u6cd5</li> <li>\u5bf9\u6297\u6837\u672c\u751f\u6210\uff1a\u4f7f\u7528 draw_proposals \u521b\u5efa\u5bf9\u6297\u6837\u672c</li> <li>\u8ddd\u79bb\u6d4b\u91cf\uff1a\u8ba1\u7b97\u4e0e\u539f\u59cb\u56fe\u50cf\u7684 L2 \u8ddd\u79bb</li> <li>\u9002\u5e94\u5ea6\u8ba1\u7b97\uff1a\u5f97\u5206 = -(\u5e73\u5747 L2 \u8ddd\u79bb)</li> </ol> <p>\u66f4\u4f4e\u7684 L2 \u8ddd\u79bb = \u66f4\u597d\u7684\u653b\u51fb = \u66f4\u9ad8\u7684\u5f97\u5206\uff08\u66f4\u4e0d\u8d1f\uff09</p>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_17","title":"\u8bc4\u4f30\u8f93\u51fa","text":"<pre><code>result = task.evaluate_code(algorithm_code)\n\nif result.valid:\n    print(f\"\u5f97\u5206: {result.score:.2f}\")  # \u8d1f L2 \u8ddd\u79bb\n    print(f\"\u5e73\u5747 L2: {result.additional_info['avg_distance']:.2f}\")\n    print(f\"\u653b\u51fb\u6b65\u6570: {result.additional_info['attack_steps']}\")\nelse:\n    print(f\"\u9519\u8bef: {result.additional_info['error']}\")\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_18","title":"\u7528\u4e8e\u6d4b\u8bd5\u7684\u6a21\u62df\u6a21\u5f0f","text":"<p>\u4f7f\u7528\u6a21\u62df\u6a21\u5f0f\u5728\u4e0d\u9700\u8981\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff1a</p> <pre><code># \u6a21\u62df\u6a21\u5f0f\u8fd4\u56de\u968f\u673a\u9002\u5e94\u5ea6\u7528\u4e8e\u6d4b\u8bd5\ntask = AdversarialAttackTask(\n    use_mock=True,\n    attack_steps=1000,\n    n_test_samples=10\n)\n\n# \u9002\u7528\u4e8e\uff1a\n# - \u6d4b\u8bd5\u4efb\u52a1\u8bbe\u7f6e\n# - \u8c03\u8bd5\u51fd\u6570\u683c\u5f0f\n# - \u7406\u89e3\u5de5\u4f5c\u6d41\u7a0b\n# - \u5f00\u53d1\u81ea\u5b9a\u4e49\u63a5\u53e3\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_19","title":"\u7528\u4f8b\u548c\u5e94\u7528","text":""},{"location":"zh/tutorials/built-in/adversarial-attack/#1_2","title":"1. \u9ed1\u76d2\u653b\u51fb\u53d1\u73b0","text":"<p>\u5728\u68af\u5ea6\u4e0d\u53ef\u7528\u7684\u9ed1\u76d2\u573a\u666f\u4e2d\u8fdb\u5316\u7b97\u6cd5\uff1a</p> <pre><code>task = AdversarialAttackTask(\n    model=black_box_model,\n    test_loader=test_loader,\n    attack_steps=5000,  # \u9ed1\u76d2\u9700\u8981\u66f4\u591a\u8fed\u4ee3\n    n_test_samples=50\n)\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#2_1","title":"2. \u9c81\u68d2\u6027\u8bc4\u4f30","text":"<p>\u901a\u8fc7\u8fdb\u5316\u5f3a\u653b\u51fb\u6765\u6d4b\u8bd5\u6a21\u578b\u9632\u5fa1\uff1a</p> <pre><code># \u52a0\u8f7d\u66f4\u9c81\u68d2\u7684\u6a21\u578b\uff08\u4f8b\u5982\uff0c\u5bf9\u6297\u8bad\u7ec3\u7684\u6a21\u578b\uff09\n# \u6ce8\u610f\uff1a\u9700\u8981\u60a8\u81ea\u5df1\u8bad\u7ec3\u6216\u83b7\u53d6\u9c81\u68d2\u6a21\u578b\nfrom torchvision import models\nmodel = models.resnet50(pretrained=True)  # \u6216\u60a8\u81ea\u5df1\u7684\u9c81\u68d2\u6a21\u578b\nmodel.eval()\n\ntask = AdversarialAttackTask(\n    model=model,\n    test_loader=test_loader,\n    attack_steps=10000,  # \u5f7b\u5e95\u8bc4\u4f30\n    n_test_samples=100\n)\n</code></pre> <p>\u5173\u4e8e\u9c81\u68d2\u6a21\u578b</p> <p>EvoToolkit \u4e0d\u518d\u4f9d\u8d56 robustbench \u5e93\u3002\u5982\u679c\u60a8\u9700\u8981\u6d4b\u8bd5\u9c81\u68d2\u6a21\u578b\uff0c\u8bf7\uff1a</p> <ul> <li>\u4f7f\u7528\u81ea\u5df1\u8bad\u7ec3\u7684\u5bf9\u6297\u9c81\u68d2\u6a21\u578b</li> <li>\u4ece\u5176\u4ed6\u6765\u6e90\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u9c81\u68d2\u6a21\u578b</li> <li>\u6216\u4f7f\u7528\u6807\u51c6\u6a21\u578b\u8fdb\u884c\u57fa\u7840\u6d4b\u8bd5</li> </ul>"},{"location":"zh/tutorials/built-in/adversarial-attack/#3_2","title":"3. \u8fc1\u79fb\u653b\u51fb\u5f00\u53d1","text":"<p>\u8fdb\u5316\u53ef\u8de8\u6a21\u578b\u8fc1\u79fb\u7684\u653b\u51fb\uff1a</p> <pre><code># \u5728\u66ff\u4ee3\u6a21\u578b\u4e0a\u8bad\u7ec3\nfrom torchvision import models\nsurrogate_model = models.resnet18(pretrained=True)\nsurrogate_model.eval()\n\ntask = AdversarialAttackTask(\n    model=surrogate_model,\n    test_loader=test_loader,\n    attack_steps=5000,\n    n_test_samples=50\n)\n\n# \u8fdb\u5316\u653b\u51fb\nresult = evotoolkit.solve(interface, ...)\n\n# \u5728\u76ee\u6807\u6a21\u578b\u4e0a\u6d4b\u8bd5\ntarget_model = models.resnet50(pretrained=True)  # \u4e0d\u540c\u67b6\u6784\ntarget_model.eval()\n# \u5728 target_model \u4e0a\u8bc4\u4f30\u8fdb\u5316\u7684\u7b97\u6cd5\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#4","title":"4. \u67e5\u8be2\u9ad8\u6548\u653b\u51fb","text":"<p>\u4f18\u5316\u5bf9\u76ee\u6807\u6a21\u578b\u7684\u6700\u5c11\u67e5\u8be2\uff1a</p> <pre><code>task = AdversarialAttackTask(\n    model=model,\n    test_loader=test_loader,\n    attack_steps=100,  # \u6709\u9650\u7684\u67e5\u8be2\n    n_test_samples=20\n)\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_20","title":"\u5b8c\u6574\u793a\u4f8b","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u5de5\u4f5c\u793a\u4f8b\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport timm\nimport evotoolkit\nfrom torchvision import datasets, transforms\nfrom evotoolkit.task.python_task import (\n    AdversarialAttackTask,\n    EvoEngineerPythonInterface\n)\nfrom evotoolkit.tools.llm import HttpsApi\n\n# 1. \u52a0\u8f7d CIFAR-10 \u9884\u8bad\u7ec3\u7684 ResNet18 \u6a21\u578b\nmodel = timm.create_model(\"resnet18\", num_classes=10, pretrained=False)\nmodel.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nmodel.maxpool = nn.Identity()\n\n# \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\nmodel.load_state_dict(\n    torch.hub.load_state_dict_from_url(\n        \"https://huggingface.co/edadaltocg/resnet18_cifar10/resolve/main/pytorch_model.bin\",\n        map_location=\"cpu\",\n        file_name=\"resnet18_cifar10.pth\"\n    )\n)\nmodel.eval()\n\nif torch.cuda.is_available():\n    model.cuda()\n\n# 2. \u51c6\u5907\u6d4b\u8bd5\u6570\u636e\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n                        std=[0.2471, 0.2435, 0.2616])\n])\ntest_set = datasets.CIFAR10(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transform\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_set, batch_size=32, shuffle=False\n)\n\n# 3. \u521b\u5efa\u4efb\u52a1\ntask = AdversarialAttackTask(\n    model=model,\n    test_loader=test_loader,\n    attack_steps=1000,\n    n_test_samples=10,\n    use_mock=False\n)\n\n# 4. \u914d\u7f6e LLM API\nllm_api = HttpsApi(\n    api_url=\"api.openai.com\",  # \u4f60\u7684 API URL\n    key=\"your-api-key-here\",   # \u4f60\u7684 API \u5bc6\u94a5\n    model=\"gpt-4o\"\n)\n\n# 5. \u521b\u5efa\u63a5\u53e3\ninterface = EvoEngineerPythonInterface(task)\n\n# 6. \u8fd0\u884c\u8fdb\u5316\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./attack_results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20\n)\n\n# 7. \u663e\u793a\u7ed3\u679c\nprint(f\"\u627e\u5230\u7684\u6700\u4f73\u653b\u51fb\u7b97\u6cd5:\")\nprint(result.sol_string)\nprint(f\"\\n\u5e73\u5747 L2 \u8ddd\u79bb: {-result.evaluation_res.score:.2f}\")\nprint(f\"\u653b\u51fb\u6b65\u6570: {result.evaluation_res.additional_info['attack_steps']}\")\n</code></pre>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_21","title":"\u4e0b\u4e00\u6b65","text":""},{"location":"zh/tutorials/built-in/adversarial-attack/#_22","title":"\u63a2\u7d22\u4e0d\u540c\u7684\u653b\u51fb\u573a\u666f","text":"<ul> <li>\u5c1d\u8bd5\u4e0d\u540c\u7684\u76ee\u6807\u6a21\u578b\uff08\u6807\u51c6 vs \u9c81\u68d2\uff09</li> <li>\u5b9e\u9a8c\u4e0d\u540c\u7684\u6570\u636e\u96c6\uff08CIFAR-10\u3001ImageNet\uff09</li> <li>\u6bd4\u8f83\u4e0d\u540c\u7684\u8fdb\u5316\u7b97\u6cd5</li> <li>\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u6d4b\u8bd5\u8fdb\u5316\u7684\u653b\u51fb</li> </ul>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_23","title":"\u81ea\u5b9a\u4e49\u548c\u6539\u8fdb\u8fdb\u5316","text":"<ul> <li>\u68c0\u67e5\u73b0\u6709 Interface \u7c7b\u4e2d\u7684\u63d0\u793a\u8bbe\u8ba1</li> <li>\u7ee7\u627f\u5e76\u91cd\u5199 Interface \u4ee5\u81ea\u5b9a\u4e49\u63d0\u793a</li> <li>\u4e3a\u4e0d\u540c\u7684\u653b\u51fb\u7c7b\u578b\u8bbe\u8ba1\u4e13\u95e8\u7684\u63d0\u793a</li> <li>\u5982\u6709\u9700\u8981\uff0c\u5f00\u53d1\u65b0\u7684\u8fdb\u5316\u7b97\u6cd5</li> </ul>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_24","title":"\u4e86\u89e3\u66f4\u591a","text":"<ul> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u6df1\u5165\u4e86\u89e3\u63d0\u793a\u81ea\u5b9a\u4e49</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u9ad8\u7ea7\u914d\u7f6e\u548c\u6280\u672f</li> <li>API \u53c2\u8003 - \u5b8c\u6574\u7684 API \u6587\u6863</li> <li>L-AutoDA \u8bba\u6587 - GECCO 2024</li> </ul>"},{"location":"zh/tutorials/built-in/adversarial-attack/#_25","title":"\u53c2\u8003\u6587\u732e","text":"<ul> <li>L-AutoDA: Large Language Models for Automatically Evolving Decision-based Adversarial Attacks (GECCO 2024)</li> <li>Foolbox: A Python toolbox to create adversarial examples</li> <li>PyTorch Models: Pretrained computer vision models (https://pytorch.org/vision/stable/models.html)</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/","title":"CUDA \u5185\u6838\u4f18\u5316\u6559\u7a0b","text":"<p>\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 LLM \u9a71\u52a8\u7684\u8fdb\u5316\u7b97\u6cd5\u6765\u4f18\u5316 CUDA \u5185\u6838\uff0c\u5728\u4fdd\u6301\u6b63\u786e\u6027\u7684\u540c\u65f6\u964d\u4f4e\u8fd0\u884c\u65f6\u95f4\u3002</p> <p>\u5b66\u672f\u5f15\u7528</p> <p>CUDA \u5185\u6838\u4f18\u5316\u4efb\u52a1\u57fa\u4e8e EvoEngineer \u7814\u7a76\u3002\u5982\u679c\u60a8\u5728\u5b66\u672f\u5de5\u4f5c\u4e2d\u4f7f\u7528\u6b64\u529f\u80fd\uff0c\u8bf7\u5f15\u7528\uff1a</p> <pre><code>@misc{guo2025evoengineermasteringautomatedcuda,\n    title={EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models},\n    author={Ping Guo and Chenyu Zhu and Siyuan Chen and Fei Liu and Xi Lin and Zhichao Lu and Qingfu Zhang},\n    year={2025},\n    eprint={2510.03760},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG},\n    url={https://arxiv.org/abs/2510.03760}\n}\n</code></pre> <p>\u5b8c\u6574\u793a\u4f8b\u4ee3\u7801</p> <p>\u672c\u6559\u7a0b\u63d0\u4f9b\u5b8c\u6574\u53ef\u8fd0\u884c\u7684\u793a\u4f8b\uff08\u70b9\u51fb\u67e5\u770b/\u4e0b\u8f7d\uff09\uff1a</p> <ul> <li> basic_example.py - \u57fa\u7840\u7528\u6cd5</li> <li> dataset_example.py - \u4f7f\u7528\u9884\u5b9a\u4e49\u6570\u636e\u96c6</li> <li> custom_prompt.py - \u81ea\u5b9a\u4e49\u63d0\u793a\u793a\u4f8b</li> <li> compare_algorithms.py - \u7b97\u6cd5\u5bf9\u6bd4</li> <li> README.zh.md - \u793a\u4f8b\u6587\u6863\u548c\u4f7f\u7528\u6307\u5357</li> </ul> <p>\u672c\u5730\u8fd0\u884c\uff1a <pre><code>cd examples/cuda_task\npython basic_example.py\n# \u6216\u4f7f\u7528\u9884\u5b9a\u4e49\u6570\u636e\u96c6\npython dataset_example.py\n</code></pre></p>"},{"location":"zh/tutorials/built-in/cuda-task/#_1","title":"\u6982\u8ff0","text":"<p>\u672c\u6559\u7a0b\u6f14\u793a\uff1a</p> <ul> <li>\u521b\u5efa CUDA \u5185\u6838\u4f18\u5316\u4efb\u52a1</li> <li>\u4f7f\u7528 LLM \u9a71\u52a8\u7684\u8fdb\u5316\u4f18\u5316\u5185\u6838\u8fd0\u884c\u65f6\u95f4</li> <li>\u81ea\u52a8\u9a8c\u8bc1\u5185\u6838\u6b63\u786e\u6027</li> <li>\u8fdb\u5316\u9ad8\u6027\u80fd GPU \u4ee3\u7801</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/#_2","title":"\u5b89\u88c5","text":"<p>\u63a8\u8350\u4f7f\u7528 GPU</p> <p>CUDA \u5185\u6838\u4f18\u5316\u9700\u8981 GPU \u548c PyTorch\u3002\u5728\u5b89\u88c5 EvoToolkit \u4e4b\u524d\u8bf7\u5148\u5b89\u88c5\u652f\u6301 CUDA \u7684 PyTorch\u3002 \u6211\u4eec\u63a8\u8350\u4f7f\u7528 CUDA 12.9\uff08\u6700\u65b0\u7a33\u5b9a\u7248\uff09\u3002</p>"},{"location":"zh/tutorials/built-in/cuda-task/#1-pytorch-gpu","title":"\u6b65\u9aa4 1\uff1a\u5b89\u88c5 PyTorch\uff08\u652f\u6301 GPU\uff09","text":"<pre><code># CUDA 12.9\uff08\u63a8\u8350 - \u7528\u4e8e\u81ea\u5b9a\u4e49\u4efb\u52a1\uff09\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n\n# \u5176\u4ed6\u7248\u672c\u8bf7\u8bbf\u95ee\uff1ahttps://pytorch.org/get-started/locally/\n# CUDA 12.1\n# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n\n# \u4ec5 CPU\uff08\u4e0d\u63a8\u8350\u7528\u4e8e CUDA \u4efb\u52a1\uff09\n# pip install torch torchvision\n</code></pre> <p>\u5173\u4e8e PyTorch \u7248\u672c</p> <p>\u6211\u4eec\u63a8\u8350\u5b89\u88c5\u6700\u65b0\u7684 CUDA 12.9 \u7248\u672c\u7528\u4e8e\u81ea\u5b9a\u4e49\u4efb\u52a1\u5f00\u53d1\u3002\u4f46\u8bf7\u6ce8\u610f\uff1a</p> <ul> <li>\u9884\u5b9a\u4e49\u6570\u636e\u96c6\uff1a\u6211\u4eec\u63d0\u4f9b\u7684\u793a\u4f8b\u6570\u636e\u96c6\u662f\u57fa\u4e8e CUDA 12.4 + PyTorch 2.4.0 \u6784\u5efa\u7684</li> <li>\u7248\u672c\u517c\u5bb9\u6027\uff1a\u4e0d\u540c PyTorch \u7248\u672c\u751f\u6210\u7684 CUDA \u4ee3\u7801\u53ef\u80fd\u4e0d\u540c\uff0c\u4f7f\u7528\u9884\u5b9a\u4e49\u6570\u636e\u96c6\u65f6\u5efa\u8bae\u5b89\u88c5\u5339\u914d\u7684 PyTorch \u7248\u672c</li> <li>\u81ea\u5b9a\u4e49\u4efb\u52a1\uff1a\u5982\u679c\u60a8\u521b\u5efa\u81ea\u5df1\u7684\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55 PyTorch \u7248\u672c</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/#2-evotoolkit","title":"\u6b65\u9aa4 2\uff1a\u5b89\u88c5 EvoToolkit","text":"<pre><code>pip install evotoolkit[cuda_engineering]\n</code></pre> <p>\u8fd9\u4f1a\u5b89\u88c5\uff1a</p> <ul> <li>Ninja\uff08\u9ad8\u6027\u80fd\u6784\u5efa\u7cfb\u7edf\uff09</li> <li>Portalocker\uff08\u8de8\u8fdb\u7a0b\u6587\u4ef6\u9501\uff09</li> <li>Psutil\uff08\u7cfb\u7edf\u548c\u8fdb\u7a0b\u5de5\u5177\uff09</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/#3-c","title":"\u6b65\u9aa4 3\uff1a\u5b89\u88c5 C++ \u7f16\u8bd1\u5668\uff08\u5fc5\u9700\uff09","text":"<p>\u5173\u952e\u524d\u7f6e\u6761\u4ef6\uff1aC++ \u7f16\u8bd1\u5668</p> <p>CUDA \u5185\u6838\u7f16\u8bd1\u9700\u8981 C++ \u7f16\u8bd1\u5668\uff01 \u5982\u679c\u7f3a\u5c11\u7f16\u8bd1\u5668\uff0c\u8fd0\u884c\u65f6\u4f1a\u62a5\u9519\uff1a <pre><code>Error checking compiler version for cl: [WinError 2] \u7cfb\u7edf\u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6587\u4ef6\u3002\n</code></pre></p>"},{"location":"zh/tutorials/built-in/cuda-task/#windows","title":"Windows \u7528\u6237","text":"<p>\u5fc5\u987b\u5b89\u88c5 Visual Studio \u53ca MSVC \u7f16\u8bd1\u5668\uff1a</p> <ol> <li>\u4e0b\u8f7d Visual Studio</li> <li>\u8bbf\u95ee\uff1ahttps://visualstudio.microsoft.com/downloads/</li> <li> <p>\u63a8\u8350\uff1aVisual Studio 2022 Community\uff08\u514d\u8d39\uff09</p> </li> <li> <p>\u5b89\u88c5\u65f6\u9009\u62e9\u5de5\u4f5c\u8d1f\u8f7d</p> </li> <li>\u52fe\u9009 \"\u4f7f\u7528 C++ \u7684\u684c\u9762\u5f00\u53d1\"\uff08Desktop development with C++\uff09</li> <li> <p>\u8fd9\u4f1a\u5b89\u88c5 MSVC \u7f16\u8bd1\u5668\u548c\u5fc5\u8981\u7684\u6784\u5efa\u5de5\u5177</p> </li> <li> <p>CUDA \u7248\u672c\u4e0e MSVC \u517c\u5bb9\u6027</p> </li> </ol> CUDA \u7248\u672c \u652f\u6301\u7684 Visual Studio \u7248\u672c \u652f\u6301\u7684 MSVC \u7248\u672c 12.9 VS 2022 (17.x)VS 2019 (16.x) MSVC 193xMSVC 192x 12.4 VS 2022 (17.x)VS 2019 (16.x) MSVC 193xMSVC 192x 12.1 VS 2022 (17.x)VS 2019 (16.x)VS 2017 (15.x) MSVC 193xMSVC 192xMSVC 191x <p>\u91cd\u8981\u8bf4\u660e</p> <ul> <li>Visual Studio 2017 \u5728 CUDA 12.5 \u88ab\u5f03\u7528\uff0c\u5728 12.9 \u5df2\u5b8c\u5168\u79fb\u9664\u652f\u6301</li> <li>\u4ece CUDA 12.0 \u5f00\u59cb\u4ec5\u652f\u6301 64 \u4f4d\u7f16\u8bd1\uff08\u4e0d\u518d\u652f\u6301 32 \u4f4d\uff09</li> <li>\u652f\u6301 C++14\uff08\u9ed8\u8ba4\uff09\u3001C++17 \u548c C++20</li> </ul> <ol> <li>\u9a8c\u8bc1\u7f16\u8bd1\u5668\u5b89\u88c5 <pre><code># \u6253\u5f00 \"x64 Native Tools Command Prompt for VS 2022\"\uff08\u4ece\u5f00\u59cb\u83dc\u5355\u627e\u5230\uff09\ncl\n\n# \u5e94\u8be5\u770b\u5230\u7c7b\u4f3c\u8f93\u51fa\uff1a\n# Microsoft (R) C/C++ Optimizing Compiler Version 19.39.xxxxx for x64\n</code></pre></li> </ol> <p>\u5982\u679c <code>cl</code> \u547d\u4ee4\u5728\u666e\u901a\u547d\u4ee4\u63d0\u793a\u7b26\u4e2d\u4e0d\u53ef\u7528\uff0c\u6709\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\uff1a</p> <p>\u65b9\u6848 A\uff1a\u4f7f\u7528 VS \u5f00\u53d1\u8005\u547d\u4ee4\u63d0\u793a\u7b26\uff08\u63a8\u8350\uff09    - \u4ece\u5f00\u59cb\u83dc\u5355\u641c\u7d22 \"x64 Native Tools Command Prompt for VS 2022\"    - \u5728\u6b64\u547d\u4ee4\u63d0\u793a\u7b26\u4e2d\u8fd0\u884c\u4f60\u7684 Python \u811a\u672c</p> <p>\u65b9\u6848 B\uff1a\u6dfb\u52a0\u5230\u7cfb\u7edf PATH\uff08\u6c38\u4e45\uff09 <pre><code># \u5c06 MSVC \u6dfb\u52a0\u5230\u7cfb\u7edf\u73af\u5883\u53d8\u91cf PATH\uff08\u793a\u4f8b\u8def\u5f84\uff0c\u6839\u636e\u5b9e\u9645\u5b89\u88c5\u4f4d\u7f6e\u8c03\u6574\uff09\n# C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.39.xxxxx\\bin\\Hostx64\\x64\n</code></pre></p>"},{"location":"zh/tutorials/built-in/cuda-task/#linuxubuntu","title":"Linux/Ubuntu \u7528\u6237","text":"<p>\u5b89\u88c5 GCC/G++ \u7f16\u8bd1\u5668\uff1a</p> <pre><code># Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install build-essential\n\n# \u9a8c\u8bc1\u5b89\u88c5\ngcc --version\ng++ --version\n\n# \u63a8\u8350\u7248\u672c\uff1aGCC 9.x \u6216\u66f4\u9ad8\n</code></pre> <p>CUDA \u7248\u672c\u4e0e GCC \u517c\u5bb9\u6027\uff1a</p> CUDA \u7248\u672c \u652f\u6301\u7684 GCC \u7248\u672c 12.9 GCC 9.x - 13.x 12.4 GCC 9.x - 13.x 12.1 GCC 9.x - 12.x <p>\u68c0\u67e5 CUDA \u4e0e\u7f16\u8bd1\u5668\u517c\u5bb9\u6027</p> <p>\u5982\u679c\u9047\u5230\u7f16\u8bd1\u9519\u8bef\uff0c\u8bf7\u68c0\u67e5\uff1a</p> <ol> <li>CUDA \u7248\u672c\uff1a<code>nvcc --version</code></li> <li>\u7f16\u8bd1\u5668\u7248\u672c\uff1aWindows \u7528 <code>cl</code>\uff0cLinux \u7528 <code>gcc --version</code></li> <li>\u786e\u8ba4\u7248\u672c\u5728\u4e0a\u8ff0\u517c\u5bb9\u6027\u8868\u683c\u8303\u56f4\u5185</li> </ol> <p>\u524d\u7f6e\u6761\u4ef6\u603b\u7ed3\uff1a</p> <ul> <li>\u2705 \u652f\u6301 CUDA \u7684 NVIDIA GPU</li> <li>\u2705 \u5df2\u5b89\u88c5 CUDA \u5de5\u5177\u5305\uff0812.1+ \u63a8\u8350\uff09</li> <li>\u2705 \u5df2\u5b89\u88c5\u517c\u5bb9\u7684 C++ \u7f16\u8bd1\u5668\uff08Windows: MSVC\uff0cLinux: GCC\uff09</li> <li>\u2705 PyTorch &gt;= 2.0\uff08\u652f\u6301 CUDA\uff09</li> <li>\u2705 CUDA \u7f16\u7a0b\u57fa\u7840\u77e5\u8bc6</li> <li>\u2705 \u719f\u6089\u5185\u6838\u4f18\u5316\u6982\u5ff5</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/#cuda_1","title":"\u7406\u89e3 CUDA \u4efb\u52a1","text":""},{"location":"zh/tutorials/built-in/cuda-task/#cuda_2","title":"\u4ec0\u4e48\u662f CUDA \u4efb\u52a1\uff1f","text":"<p>CUDA \u4efb\u52a1\u4f18\u5316 GPU \u5185\u6838\u4ee3\u7801\u4ee5\u6700\u5c0f\u5316\u8fd0\u884c\u65f6\u95f4\uff0c\u540c\u65f6\u786e\u4fdd\u6b63\u786e\u6027\u3002\u6846\u67b6\u4f1a\uff1a</p> <ol> <li>\u63a5\u6536\u4f60\u7684 Python \u51fd\u6570\u5b9e\u73b0</li> <li>\u8f6c\u6362\u4e3a\u51fd\u6570\u5f0f Python \u4ee3\u7801\uff08\u5982\u9700\u8981\uff09</li> <li>\u7ffb\u8bd1\u4e3a\u521d\u59cb CUDA \u5185\u6838</li> <li>\u8fdb\u5316\u5185\u6838\u4ee5\u63d0\u5347\u6027\u80fd</li> <li>\u5bf9\u7167 Python \u53c2\u8003\u9a8c\u8bc1\u6b63\u786e\u6027</li> </ol>"},{"location":"zh/tutorials/built-in/cuda-task/#_3","title":"\u4efb\u52a1\u7ec4\u4ef6","text":"<p>\u4e00\u4e2a CUDA \u4efb\u52a1\u9700\u8981\uff1a</p> <ul> <li>\u539f\u59cb Python \u4ee3\u7801 (<code>org_py_code</code>)\uff1a\u539f\u59cb PyTorch \u6a21\u578b\u4ee3\u7801\uff08\u53ef\u9009\uff0c\u53ef\u7559\u7a7a\uff09</li> <li>\u529f\u80fd\u6027 Python \u4ee3\u7801 (<code>func_py_code</code>)\uff1a\u63d0\u53d6\u7684\u529f\u80fd\u51fd\u6570\u5b9e\u73b0\uff0c\u7528\u4e8e\u6b63\u786e\u6027\u6bd4\u8f83\u548c\u6027\u80fd\u57fa\u51c6\u6d4b\u91cf</li> <li>CUDA \u4ee3\u7801 (<code>cuda_code</code>)\uff1a\u521d\u59cb CUDA \u5185\u6838\u5b9e\u73b0</li> <li>GPU \u4fe1\u606f\uff1aGPU \u7c7b\u578b\u548c CUDA \u7248\u672c</li> </ul> <p>\u5173\u4e8e org_py_code \u548c func_py_code</p> <ul> <li><code>func_py_code</code> \u5fc5\u987b\u63d0\u4f9b\uff0c\u662f\u5b9e\u9645\u7528\u4e8e CUDA \u6b63\u786e\u6027\u9a8c\u8bc1\u548c\u6027\u80fd\u5bf9\u6bd4\u7684 Python \u53c2\u8003\u5b9e\u73b0</li> <li>\u5982\u679c\u53ea\u6709 <code>org_py_code</code>\uff0c\u53ef\u4ee5\u4f7f\u7528 AI-CUDA-Engineer \u5de5\u4f5c\u6d41\uff08Stage 0\uff09\u8ba9 LLM \u5c06\u5176\u8f6c\u6362\u4e3a <code>func_py_code</code></li> <li><code>org_py_code</code> \u53ef\u4ee5\u7559\u7a7a\uff0c\u76f4\u63a5\u63d0\u4f9b <code>func_py_code</code>\uff08\u63a8\u8350\u7528\u4e8e\u8fdb\u5316\u4f18\u5316\uff09</li> </ul> <p>Windows \u7528\u6237\u5fc5\u8bfb\uff1a\u591a\u8fdb\u7a0b\u4fdd\u62a4</p> <p>CUDA \u4efb\u52a1\u8bc4\u4f30\u5668\u4f7f\u7528 multiprocessing \u6a21\u5757\u6267\u884c\u8d85\u65f6\u63a7\u5236\u3002\u5728 Windows \u4e0a\u8fd0\u884c\u65f6\uff0c\u5fc5\u987b\u4f7f\u7528 <code>if __name__ == '__main__':</code> \u4fdd\u62a4\u6240\u6709\u4e3b\u4ee3\u7801\uff0c\u5426\u5219\u4f1a\u5bfc\u81f4\u8fdb\u7a0b\u65e0\u9650\u9012\u5f52\u521b\u5efa\uff01</p> <p>\u9519\u8bef\u793a\u4f8b\uff08\u4f1a\u5bfc\u81f4 RuntimeError\uff09\uff1a <pre><code># \u274c \u9519\u8bef - \u6ca1\u6709\u4fdd\u62a4\nimport os\nfrom evotoolkit.task.cuda_engineering import CudaTask\n\nevaluator = Evaluator(temp_path)  # \u4f1a\u5728 Windows \u4e0a\u5d29\u6e83\uff01\ntask_info = CudaTaskInfoMaker.make_task_info(...)\n</code></pre></p> <p>\u6b63\u786e\u793a\u4f8b\uff1a <pre><code># \u2705 \u6b63\u786e - \u4f7f\u7528 if __name__ == '__main__': \u4fdd\u62a4\nimport os\nfrom evotoolkit.task.cuda_engineering import CudaTask\n\ndef main():\n    evaluator = Evaluator(temp_path)\n    task_info = CudaTaskInfoMaker.make_task_info(...)\n    # ... \u5176\u4ed6\u4ee3\u7801\n\nif __name__ == '__main__':\n    main()\n</code></pre></p> <p>\u4e3a\u4ec0\u4e48\u9700\u8981\u8fd9\u4e2a\u4fdd\u62a4\uff1f</p> <ul> <li>Windows \u4e0d\u652f\u6301 <code>fork</code>\uff0c\u53ea\u652f\u6301 <code>spawn</code> \u65b9\u5f0f\u542f\u52a8\u5b50\u8fdb\u7a0b</li> <li><code>spawn</code> \u4f1a\u91cd\u65b0\u5bfc\u5165\u4e3b\u6a21\u5757\u6765\u521b\u5efa\u5b50\u8fdb\u7a0b</li> <li>\u5982\u679c\u6ca1\u6709\u4fdd\u62a4\uff0c\u6bcf\u6b21\u5bfc\u5165\u90fd\u4f1a\u6267\u884c\u4e3b\u4ee3\u7801\uff0c\u5bfc\u81f4\u65e0\u9650\u9012\u5f52</li> </ul> <p>\u89c4\u5219\uff1a\u51e1\u662f\u8c03\u7528 CUDA \u4efb\u52a1\u8bc4\u4f30\u7684\u4ee3\u7801\uff0c\u90fd\u5fc5\u987b\u653e\u5728 <code>if __name__ == '__main__':</code> \u4fdd\u62a4\u5185\uff01</p>"},{"location":"zh/tutorials/built-in/cuda-task/#_4","title":"\u4f7f\u7528\u9884\u5b9a\u4e49\u6570\u636e\u96c6","text":"<p>EvoToolkit \u63d0\u4f9b\u4e86\u9884\u5b9a\u4e49\u7684 CUDA \u4f18\u5316\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u5e38\u89c1\u7684\u6df1\u5ea6\u5b66\u4e60\u64cd\u4f5c\u3002</p>"},{"location":"zh/tutorials/built-in/cuda-task/#_5","title":"\u4e0b\u8f7d\u6570\u636e\u96c6","text":"<p>\u6570\u636e\u96c6\u672a\u5305\u542b\u5728\u4e3b\u4ed3\u5e93\u4e2d\uff0c\u9700\u8981\u5355\u72ec\u4e0b\u8f7d\uff1a</p> <p>\u4e0b\u8f7d\u65b9\u5f0f\uff1a</p> <pre><code># \u65b9\u5f0f 1: \u4f7f\u7528 wget\ncd /path/to/evotool/project/root\nwget https://github.com/pgg3/evotoolkit/releases/download/data-v1.0.0/rtx4090_cu12_4_py311_torch_2_4_0.json\n\n# \u65b9\u5f0f 2: \u4f7f\u7528 curl\ncurl -L -O https://github.com/pgg3/evotoolkit/releases/download/data-v1.0.0/rtx4090_cu12_4_py311_torch_2_4_0.json\n</code></pre> <p>\u6570\u636e\u96c6\u4fe1\u606f\uff1a</p> <ul> <li>\u6587\u4ef6\u540d\uff1a <code>rtx4090_cu12_4_py311_torch_2_4_0.json</code></li> <li>\u5927\u5c0f\uff1a ~580 KB</li> <li>\u683c\u5f0f\uff1a JSON</li> <li>\u4f18\u5316\u76ee\u6807\uff1a RTX 4090 GPU + CUDA 12.4.1 + PyTorch 2.4.0</li> </ul> <p>\u6570\u636e\u96c6\u8bf4\u660e</p> <p>\u6b64\u6570\u636e\u96c6\u662f\u9488\u5bf9\u7279\u5b9a\u786c\u4ef6\u548c\u8f6f\u4ef6\u914d\u7f6e\u7684\u793a\u4f8b\u6570\u636e\u96c6\uff0c\u4e0d\u50cf scientific_regression \u4efb\u52a1\u90a3\u6837\u652f\u6301\u81ea\u52a8\u4e0b\u8f7d\u3002\u4f60\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u786c\u4ef6\u73af\u5883\u521b\u5efa\u7c7b\u4f3c\u7684\u6570\u636e\u96c6\u3002</p>"},{"location":"zh/tutorials/built-in/cuda-task/#_6","title":"\u52a0\u8f7d\u6570\u636e\u96c6","text":"<pre><code>import json\n\n# \u52a0\u8f7d\u9488\u5bf9 RTX 4090 + CUDA 12.4.1 + PyTorch 2.4.0 \u7684\u6570\u636e\u96c6\nwith open('rtx4090_cu12_4_py311_torch_2_4_0.json', 'r') as f:\n    dataset = json.load(f)\n\n# \u67e5\u770b\u53ef\u7528\u4efb\u52a1\nprint(f\"\u53ef\u7528\u4efb\u52a1\u6570\u91cf: {len(dataset)}\")\nprint(f\"\u4efb\u52a1\u5217\u8868: {list(dataset.keys())[:5]}...\")  # \u663e\u793a\u524d5\u4e2a\n\n# \u9009\u62e9\u4e00\u4e2a\u4efb\u52a1\ntask_name = \"10_3D_tensor_matrix_multiplication\"\ntask_data = dataset[task_name]\n\nprint(f\"\\n\u4efb\u52a1: {task_name}\")\nprint(f\"- org_py_code: {'\u5df2\u63d0\u4f9b' if task_data['org_py_code'] else '\u7a7a'}\")\nprint(f\"- func_py_code: {'\u5df2\u63d0\u4f9b' if task_data['func_py_code'] else '\u7a7a'}\")\nprint(f\"- cuda_code: {'\u5df2\u63d0\u4f9b' if task_data['cuda_code'] else '\u7a7a'}\")\n</code></pre> <p>\u6570\u636e\u96c6\u5305\u542b\u7684\u4efb\u52a1\u7c7b\u578b\uff1a</p> <ul> <li>\u77e9\u9635\u4e58\u6cd5\u53d8\u4f53\uff083D\u30014D \u5f20\u91cf\uff0c\u5bf9\u89d2\u77e9\u9635\uff0c\u5bf9\u79f0\u77e9\u9635\u7b49\uff09</li> <li>\u6fc0\u6d3b\u51fd\u6570\uff08ReLU\u3001Sigmoid\u3001Tanh\u3001GELU \u7b49\uff09</li> <li>\u635f\u5931\u51fd\u6570\uff08CrossEntropy\u3001HingeLoss \u7b49\uff09</li> <li>\u5f52\u4e00\u5316\u5c42\uff08LayerNorm\u3001BatchNorm \u7b49\uff09</li> <li>\u6ce8\u610f\u529b\u673a\u5236\u548c Transformer \u7ec4\u4ef6</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/#_7","title":"\u4ece\u6570\u636e\u96c6\u521b\u5efa\u4efb\u52a1","text":"<pre><code>from evotoolkit.task.cuda_engineering import CudaTask, CudaTaskInfoMaker\nfrom evotoolkit.task.cuda_engineering.evaluator import Evaluator\nimport tempfile\nimport os\n\n\ndef main():\n    # \u914d\u7f6e CUDA \u73af\u5883\u53d8\u91cf\uff08\u8fd0\u884c\u524d\u5fc5\u987b\u8bbe\u7f6e\uff09\n    # Windows: \u8bbe\u7f6e\u4e3a\u4f60\u7684 CUDA \u5b89\u88c5\u8def\u5f84\n    os.environ[\"CUDA_HOME\"] = \"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.4\"\n    # Linux/Ubuntu: \u901a\u5e38\u4e3a\u9ed8\u8ba4\u8def\u5f84\n    # os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n\n    # \u6307\u5b9a GPU \u67b6\u6784\u4ee5\u8282\u7701\u7f16\u8bd1\u65f6\u95f4\uff08\u6839\u636e\u4f60\u7684 GPU \u8bbe\u7f6e\uff09\n    # RTX 4090: 8.9, RTX 3090: 8.6, V100: 7.0\n    os.environ['TORCH_CUDA_ARCH_LIST'] = \"8.9\"\n\n    # \u4f7f\u7528\u6570\u636e\u96c6\u4e2d\u7684\u4efb\u52a1\u6570\u636e\n    task_data = dataset[\"10_3D_tensor_matrix_multiplication\"]\n\n    # \u521b\u5efa\u8bc4\u4f30\u5668\u548c\u4efb\u52a1\n    temp_path = tempfile.mkdtemp()\n    evaluator = Evaluator(temp_path)\n\n    task_info = CudaTaskInfoMaker.make_task_info(\n        evaluator=evaluator,\n        gpu_type=\"RTX 4090\",\n        cuda_version=\"12.4.1\",\n        org_py_code=task_data[\"org_py_code\"],      # \u53ef\u4e3a\u7a7a\n        func_py_code=task_data[\"func_py_code\"],    # \u529f\u80fd\u6027\u5b9e\u73b0\n        cuda_code=task_data[\"cuda_code\"],          # \u521d\u59cb CUDA \u5185\u6838\n        fake_mode=False\n    )\n\n    task = CudaTask(data=task_info, temp_path=temp_path, fake_mode=False)\n    print(f\"\u4efb\u52a1\u5df2\u521b\u5efa\uff0c\u521d\u59cb\u8fd0\u884c\u65f6\u95f4: {task.task_info['cuda_info']['runtime']:.4f} ms\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"zh/tutorials/built-in/cuda-task/#_8","title":"\u793a\u4f8b\uff1a\u4ece\u5934\u521b\u5efa\u77e9\u9635\u4e58\u6cd5\u4f18\u5316\u4efb\u52a1","text":"<p>\u5982\u679c\u4f60\u60f3\u4ece\u5934\u521b\u5efa\u81ea\u5df1\u7684 CUDA \u4f18\u5316\u4efb\u52a1\uff1a</p>"},{"location":"zh/tutorials/built-in/cuda-task/#1-python","title":"\u6b65\u9aa4 1\uff1a\u51c6\u5907 Python \u51fd\u6570","text":"<p>func_py_code \u683c\u5f0f\u8981\u6c42</p> <p><code>func_py_code</code> \u5fc5\u987b\u5305\u542b\u4ee5\u4e0b\u7ec4\u4ef6\uff1a</p> <ol> <li><code>module_fn</code> \u51fd\u6570\uff1a\u6838\u5fc3\u529f\u80fd\u5b9e\u73b0</li> <li><code>Model</code> \u7c7b\uff1a\u7ee7\u627f <code>nn.Module</code>\uff0c\u5176 <code>forward</code> \u65b9\u6cd5\u63a5\u53d7 <code>fn=module_fn</code> \u53c2\u6570</li> <li><code>get_inputs()</code> \u51fd\u6570\uff1a\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\u6570\u636e</li> <li><code>get_init_inputs()</code> \u51fd\u6570\uff1a\u751f\u6210\u521d\u59cb\u5316\u8f93\u5165\uff08\u901a\u5e38\u4e3a\u7a7a\u5217\u8868\uff09</li> </ol> <p>\u8fd9\u79cd\u8bbe\u8ba1\u5141\u8bb8 CUDA \u5185\u6838\u901a\u8fc7\u4f20\u5165\u4e0d\u540c\u7684 <code>fn</code> \u66ff\u6362 <code>module_fn</code>\uff0c\u4ece\u800c\u8fdb\u884c\u6b63\u786e\u6027\u9a8c\u8bc1\u3002</p> <pre><code># \u8981\u4f18\u5316\u7684\u539f\u59cb\u51fd\u6570\uff08\u53ef\u9009\uff09\norg_py_code = '''\nimport torch\n\ndef matmul(A, B):\n    \"\"\"\u4f7f\u7528 PyTorch \u7684\u77e9\u9635\u4e58\u6cd5\u3002\"\"\"\n    return torch.matmul(A, B)\n'''\n\n# \u529f\u80fd\u6027\u5b9e\u73b0\u7248\u672c\uff08\u7528\u4e8e\u6b63\u786e\u6027\u6bd4\u8f83\u548c\u6027\u80fd\u57fa\u51c6\uff09\nfunc_py_code = '''\nimport torch\nimport torch.nn as nn\n\ndef module_fn(A: torch.Tensor, B: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\u529f\u80fd\u6027\u77e9\u9635\u4e58\u6cd5\u5b9e\u73b0\u3002\"\"\"\n    return torch.matmul(A, B)\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n    def forward(self, A, B, fn=module_fn):\n        return fn(A, B)\n\nM = 1024\nK = 2048\nN = 1024\n\ndef get_inputs():\n    A = torch.randn(M, K)\n    B = torch.randn(K, N)\n    return [A, B]\n\ndef get_init_inputs():\n    return []\n'''\n</code></pre>"},{"location":"zh/tutorials/built-in/cuda-task/#2-cuda","title":"\u6b65\u9aa4 2\uff1a\u521b\u5efa\u521d\u59cb CUDA \u5185\u6838","text":"<pre><code># \u521d\u59cb CUDA \u5b9e\u73b0\uff08\u6734\u7d20\u7248\u672c\uff09\ncuda_code = '''\n#include &lt;torch/extension.h&gt;\n#include &lt;cuda_runtime.h&gt;\n\n__global__ void matmul_kernel(float* A, float* B, float* C,\n                               int M, int N, int K) {\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (row &lt; M &amp;&amp; col &lt; N) {\n        float sum = 0.0f;\n        for (int k = 0; k &lt; K; k++) {\n            sum += A[row * K + k] * B[k * N + col];\n        }\n        C[row * N + col] = sum;\n    }\n}\n\ntorch::Tensor matmul_cuda(torch::Tensor A, torch::Tensor B) {\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n\n    auto C = torch::zeros({M, N}, A.options());\n\n    dim3 threads(16, 16);\n    dim3 blocks((N + 15) / 16, (M + 15) / 16);\n\n    matmul_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(\n        A.data_ptr&lt;float&gt;(),\n        B.data_ptr&lt;float&gt;(),\n        C.data_ptr&lt;float&gt;(),\n        M, N, K\n    );\n\n    return C;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &amp;matmul_cuda, \"Matrix multiplication (CUDA)\");\n}\n'''\n</code></pre>"},{"location":"zh/tutorials/built-in/cuda-task/#3-cuda","title":"\u6b65\u9aa4 3\uff1a\u521b\u5efa CUDA \u4efb\u52a1","text":"<pre><code>from evotoolkit.task.cuda_engineering import CudaTask, CudaTaskInfoMaker\nfrom evotoolkit.task.cuda_engineering.evaluator import Evaluator\nimport tempfile\nimport os\n\n\ndef main():\n    # \u914d\u7f6e CUDA \u73af\u5883\u53d8\u91cf\uff08\u8fd0\u884c\u524d\u5fc5\u987b\u8bbe\u7f6e\uff09\n    # Windows: \u8bbe\u7f6e\u4e3a\u4f60\u7684 CUDA \u5b89\u88c5\u8def\u5f84\n    os.environ[\"CUDA_HOME\"] = \"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.4\"\n    # Linux/Ubuntu: \u901a\u5e38\u4e3a\u9ed8\u8ba4\u8def\u5f84\n    # os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n\n    # \u6307\u5b9a GPU \u67b6\u6784\u4ee5\u8282\u7701\u7f16\u8bd1\u65f6\u95f4\n    # RTX 4090: 8.9, RTX 3090: 8.6, V100: 7.0\n    os.environ['TORCH_CUDA_ARCH_LIST'] = \"8.9\"\n\n    # \u521b\u5efa\u8bc4\u4f30\u5668\n    temp_path = tempfile.mkdtemp()\n    evaluator = Evaluator(temp_path)\n\n    # \u521b\u5efa\u4efb\u52a1\u4fe1\u606f\n    task_info = CudaTaskInfoMaker.make_task_info(\n        evaluator=evaluator,\n        gpu_type=\"RTX 4090\",\n        cuda_version=\"12.4.1\",\n        org_py_code=org_py_code,\n        func_py_code=func_py_code,\n        cuda_code=cuda_code,\n        fake_mode=False  # \u8bbe\u4e3a True \u53ef\u5728\u65e0 GPU \u60c5\u51b5\u4e0b\u6d4b\u8bd5\n    )\n\n    # \u521b\u5efa\u4efb\u52a1\n    task = CudaTask(\n        data=task_info,\n        temp_path=temp_path,\n        fake_mode=False\n    )\n\n    print(f\"GPU \u7c7b\u578b: {task.task_info['gpu_type']}\")\n    print(f\"CUDA \u7248\u672c: {task.task_info['cuda_version']}\")\n    print(f\"\u521d\u59cb\u8fd0\u884c\u65f6\u95f4: {task.task_info['cuda_info']['runtime']:.4f} ms\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>\u8f93\u51fa\uff1a <pre><code>GPU \u7c7b\u578b: RTX 4090\nCUDA \u7248\u672c: 12.4.1\n\u521d\u59cb\u8fd0\u884c\u65f6\u95f4: 2.3456 ms\n</code></pre></p>"},{"location":"zh/tutorials/built-in/cuda-task/#4","title":"\u6b65\u9aa4 4\uff1a\u6d4b\u8bd5\u521d\u59cb\u89e3\u51b3\u65b9\u6848","text":"<pre><code>def main():\n    # ... (\u524d\u9762\u7684\u6b65\u9aa4 3 \u4ee3\u7801)\n\n    # \u83b7\u53d6\u521d\u59cb\u89e3\u51b3\u65b9\u6848\n    init_sol = task.make_init_sol_wo_other_info()\n\n    print(\"\u521d\u59cb\u5185\u6838\u4fe1\u606f\uff1a\")\n    print(f\"\u8fd0\u884c\u65f6\u95f4: {-init_sol.evaluation_res.score:.4f} ms\")\n    print(f\"\u5f97\u5206: {init_sol.evaluation_res.score:.6f}\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>\u7406\u89e3\u8bc4\u4f30\uff1a</p> <ul> <li>\u5f97\u5206\uff1a\u8d1f\u7684\u8fd0\u884c\u65f6\u95f4\uff08\u8d8a\u9ad8\u8d8a\u597d\uff0c\u6240\u4ee5\u66f4\u5feb\u7684\u5185\u6838\u5f97\u5206\u66f4\u9ad8\uff09</li> <li>\u8fd0\u884c\u65f6\u95f4\uff1a\u5185\u6838\u6267\u884c\u65f6\u95f4\uff08\u6beb\u79d2\uff09</li> <li>\u6b63\u786e\u6027\uff1a\u81ea\u52a8\u5bf9\u7167 Python \u53c2\u8003\u9a8c\u8bc1</li> <li>\u6027\u80fd\u5206\u6790\u5b57\u7b26\u4e32\uff1aCUDA \u5206\u6790\u5668\u8f93\u51fa\uff0c\u663e\u793a\u74f6\u9888</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/#5-evoengineer","title":"\u6b65\u9aa4 5\uff1a\u4f7f\u7528 EvoEngineer \u8fd0\u884c\u8fdb\u5316","text":"<p>\u5b8c\u6574\u4ee3\u7801\u793a\u4f8b</p> <p>\u4ee5\u4e0b\u4ee3\u7801\u5047\u8bbe\u4f60\u5df2\u7ecf\u5b8c\u6210\u4e86\u524d\u9762\u7684\u6b65\u9aa4\uff08\u6b65\u9aa4 1-4\uff09\uff0c\u5e76\u4e14 <code>task</code> \u5bf9\u8c61\u5df2\u7ecf\u521b\u5efa\u3002\u5982\u679c\u9700\u8981\u5b8c\u6574\u7684\u53ef\u8fd0\u884c\u4ee3\u7801\uff0c\u8bf7\u53c2\u8003 basic_example.py\u3002</p> <pre><code>import os\nimport evotoolkit\nfrom evotoolkit.task.cuda_engineering import EvoEngineerFullCudaInterface\nfrom evotoolkit.tools.llm import HttpsApi\n\n\ndef main():\n    # === \u524d\u9762\u7684\u6b65\u9aa4\uff08\u6b65\u9aa4 1-4\uff09===\n    # \u8fd9\u91cc\u5e94\u8be5\u5305\u542b\u524d\u9762\u6b65\u9aa4\u4e2d\u7684\u4ee3\u7801\uff1a\n    # - \u5b9a\u4e49 org_py_code, func_py_code, cuda_code\n    # - \u521b\u5efa evaluator \u548c task_info\n    # - \u521b\u5efa task \u5bf9\u8c61\n    # \u5b8c\u6574\u4ee3\u7801\u8bf7\u53c2\u8003 basic_example.py\n\n    # \u8bbe\u7f6e CUDA \u73af\u5883\u53d8\u91cf\uff08CUDA \u5185\u6838\u7f16\u8bd1\u5fc5\u9700\uff09\n    # CUDA_HOME: CUDA \u5b89\u88c5\u76ee\u5f55\u8def\u5f84\n    os.environ.setdefault(\"CUDA_HOME\", \"/usr/local/cuda\")\n    # TORCH_CUDA_ARCH_LIST: GPU \u8ba1\u7b97\u80fd\u529b\uff08\u4f8b\u5982 RTX 4090 \u4e3a \"8.9\"\uff09\n    os.environ.setdefault(\"TORCH_CUDA_ARCH_LIST\", \"8.9\")\n\n    # \u521b\u5efa\u63a5\u53e3\uff08\u4f7f\u7528\u524d\u9762\u6b65\u9aa4\u521b\u5efa\u7684 task \u5bf9\u8c61\uff09\n    interface = EvoEngineerFullCudaInterface(task)\n\n    # \u914d\u7f6e LLM API\n    # \u8bbe\u7f6e LLM_API_URL \u548c LLM_API_KEY \u73af\u5883\u53d8\u91cf\n    llm_api = HttpsApi(\n        api_url=os.environ.get(\"LLM_API_URL\", \"https://api.openai.com/v1/chat/completions\"),\n        key=os.environ.get(\"LLM_API_KEY\", \"your-api-key-here\"),\n        model=\"gpt-4o\"\n    )\n\n    # \u8fd0\u884c\u8fdb\u5316\n    result = evotoolkit.solve(\n        interface=interface,\n        output_path='./cuda_optimization_results',\n        running_llm=llm_api,\n        max_generations=10,\n        pop_size=5,\n        max_sample_nums=20\n    )\n\n    print(f\"\u627e\u5230\u6700\u4f73\u5185\u6838\uff01\")\n    print(f\"\u8fd0\u884c\u65f6\u95f4: {-result.evaluation_res.score:.4f} ms\")\n    print(f\"\u52a0\u901f\u6bd4: {task.task_info['cuda_info']['runtime'] / (-result.evaluation_res.score):.2f}x\")\n    print(f\"\\n\u4f18\u5316\u540e\u7684\u5185\u6838\uff1a\\n{result.sol_string}\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>\u5c1d\u8bd5\u5176\u4ed6\u7b97\u6cd5</p> <p>EvoToolkit \u652f\u6301\u591a\u79cd CUDA \u4f18\u5316\u8fdb\u5316\u7b97\u6cd5\uff1a</p> <pre><code># \u4f7f\u7528 EoH\nfrom evotoolkit.task.cuda_engineering import EoHCudaInterface\ninterface = EoHCudaInterface(task)\n\n# \u4f7f\u7528 FunSearch\nfrom evotoolkit.task.cuda_engineering import FunSearchCudaInterface\ninterface = FunSearchCudaInterface(task)\n\n# \u4f7f\u7528 EvoEngineer \u6d1e\u5bdf\u6a21\u5f0f\nfrom evotoolkit.task.cuda_engineering import EvoEngineerInsightCudaInterface\ninterface = EvoEngineerInsightCudaInterface(task)\n\n# \u4f7f\u7528 EvoEngineer \u81ea\u7531\u6a21\u5f0f\nfrom evotoolkit.task.cuda_engineering import EvoEngineerFreeCudaInterface\ninterface = EvoEngineerFreeCudaInterface(task)\n</code></pre> <p>\u7136\u540e\u4f7f\u7528\u76f8\u540c\u7684 <code>evotoolkit.solve()</code> \u8c03\u7528\u8fd0\u884c\u8fdb\u5316\u3002\u4e0d\u540c\u7684\u63a5\u53e3\u53ef\u80fd\u5728\u4e0d\u540c\u7684\u5185\u6838\u4e0a\u8868\u73b0\u66f4\u597d\u3002</p>"},{"location":"zh/tutorials/built-in/cuda-task/#_9","title":"\u81ea\u5b9a\u4e49\u8fdb\u5316\u884c\u4e3a","text":"<p>\u8fdb\u5316\u8fc7\u7a0b\u7684\u8d28\u91cf\u4e3b\u8981\u7531 \u8fdb\u5316\u65b9\u6cd5 \u53ca\u5176\u5185\u90e8\u7684 \u63d0\u793a\u8bbe\u8ba1 \u63a7\u5236\u3002\u5982\u679c\u60f3\u63d0\u5347\u7ed3\u679c\uff1a</p> <ul> <li>\u8c03\u6574\u63d0\u793a\uff1a\u7ee7\u627f\u73b0\u6709\u7684 Interface \u7c7b\u5e76\u81ea\u5b9a\u4e49 LLM \u63d0\u793a</li> <li>\u5f00\u53d1\u65b0\u7b97\u6cd5\uff1a\u521b\u5efa\u5168\u65b0\u7684\u8fdb\u5316\u7b56\u7565\u548c\u7b97\u5b50</li> </ul> <p>\u4e86\u89e3\u66f4\u591a</p> <p>\u8fd9\u4e9b\u662f\u9002\u7528\u4e8e\u6240\u6709\u4efb\u52a1\u7684\u901a\u7528\u6280\u672f\u3002\u8be6\u7ec6\u6559\u7a0b\u8bf7\u53c2\u89c1\uff1a</p> <ul> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u5982\u4f55\u4fee\u6539\u63d0\u793a\u548c\u5f00\u53d1\u65b0\u7b97\u6cd5</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u66f4\u591a\u9ad8\u7ea7\u914d\u7f6e\u9009\u9879</li> </ul> <p>\u5feb\u901f\u793a\u4f8b - \u4e3a CUDA \u4f18\u5316\u81ea\u5b9a\u4e49\u63d0\u793a\uff1a</p> <pre><code>from evotoolkit.task.cuda_engineering import EvoEngineerFullCudaInterface\n\nclass OptimizedCudaInterface(EvoEngineerFullCudaInterface):\n    \"\"\"\u4e3a\u5185\u5b58\u53d7\u9650\u5185\u6838\u4f18\u5316\u7684\u63a5\u53e3\u3002\"\"\"\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        \"\"\"\u81ea\u5b9a\u4e49\u53d8\u5f02\u63d0\u793a\u4ee5\u5f3a\u8c03\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u3002\"\"\"\n\n        if operator_name == \"mutation\":\n            task_description = self.task.get_base_task_description()\n            individual = selected_individuals[0]\n\n            prompt = f\"\"\"# CUDA \u5185\u6838\u4f18\u5316 - \u5185\u5b58\u4f18\u5316\u91cd\u70b9\n{task_description}\n\n## \u5f53\u524d\u6700\u4f73\n**\u540d\u79f0\uff1a** {current_best_sol.other_info['name']}\n**\u8fd0\u884c\u65f6\u95f4\uff1a** {-current_best_sol.evaluation_res.score:.5f} \u6beb\u79d2\n\n## \u5f85\u53d8\u5f02\u5185\u6838\n**\u540d\u79f0\uff1a** {individual.other_info['name']}\n**\u8fd0\u884c\u65f6\u95f4\uff1a** {-individual.evaluation_res.score:.5f} \u6beb\u79d2\n\n## \u4f18\u5316\u91cd\u70b9\n\u91cd\u70b9\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff1a\n- \u4f7f\u7528\u5171\u4eab\u5185\u5b58\u51cf\u5c11\u5168\u5c40\u5185\u5b58\u8bbf\u95ee\n- \u5b9e\u73b0\u5185\u5b58\u5408\u5e76\u4ee5\u63d0\u9ad8\u5e26\u5bbd\n- \u8003\u8651\u5185\u5b58 bank \u51b2\u7a81\n- \u4f7f\u7528\u9002\u5f53\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff08\u7eb9\u7406\u5185\u5b58\u3001\u5e38\u91cf\u5185\u5b58\uff09\n\n\u751f\u6210\u4e00\u4e2a\u51cf\u5c11\u5185\u5b58\u74f6\u9888\u7684\u6539\u8fdb\u5185\u6838\u3002\n\n## \u54cd\u5e94\u683c\u5f0f\uff1a\nname: [\u63cf\u8ff0\u6027\u540d\u79f0]\ncode:\n```cpp\n[\u60a8\u7684 CUDA \u5185\u6838\u5b9e\u73b0]\n```\nthought: [\u5185\u5b58\u4f18\u5316\u7406\u7531]\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # \u5176\u4ed6\u7b97\u5b50\u4f7f\u7528\u9ed8\u8ba4\u63d0\u793a\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u63a5\u53e3\ninterface = OptimizedCudaInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre> <p>\u5173\u4e8e EvoEngineer \u7b97\u5b50</p> <p>EvoEngineer \u4f7f\u7528\u4e09\u4e2a\u7b97\u5b50\uff1ainit\uff08\u521d\u59cb\u5316\uff09\u3001mutation\uff08\u53d8\u5f02\uff09\u3001crossover\uff08\u4ea4\u53c9\uff09\u3002 \u7236\u7c7b <code>EvoEngineerFullCudaInterface</code> \u5df2\u7ecf\u5b9a\u4e49\u4e86\u8fd9\u4e9b\u7b97\u5b50\u548c\u9ed8\u8ba4\u63d0\u793a\u3002 \u4f60\u53ea\u9700\u91cd\u5199 <code>get_operator_prompt()</code> \u6765\u81ea\u5b9a\u4e49\u7279\u5b9a\u7b97\u5b50\u7684\u63d0\u793a - \u5176\u4ed6\u7b97\u5b50\u4f1a\u81ea\u52a8\u4f7f\u7528\u9ed8\u8ba4\u5b9e\u73b0\u3002</p> <p>\u5b8c\u6574\u7684\u81ea\u5b9a\u4e49\u6559\u7a0b\u548c\u66f4\u591a\u793a\u4f8b\uff0c\u8bf7\u53c2\u89c1 \u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5\u3002</p>"},{"location":"zh/tutorials/built-in/cuda-task/#_10","title":"\u7406\u89e3\u8bc4\u4f30","text":""},{"location":"zh/tutorials/built-in/cuda-task/#_11","title":"\u8bc4\u5206\u673a\u5236","text":"<ol> <li>\u6b63\u786e\u6027\u9a8c\u8bc1\uff1aCUDA \u5185\u6838\u8f93\u51fa\u4e0e Python \u53c2\u8003\u5b9e\u73b0\u8fdb\u884c\u6bd4\u8f83</li> <li>\u8fd0\u884c\u65f6\u6d4b\u91cf\uff1a\u4f7f\u7528 CUDA \u4e8b\u4ef6\u548c\u5206\u6790\u5de5\u5177\u6d4b\u91cf\u5185\u6838\u6267\u884c\u65f6\u95f4</li> <li>\u9002\u5e94\u5ea6\uff1a\u8d1f\u7684\u8fd0\u884c\u65f6\u95f4\uff08\u8d8a\u9ad8\u8d8a\u597d\uff0c\u6240\u4ee5\u8d8a\u4f4e\u7684\u8fd0\u884c\u65f6\u95f4 = \u8d8a\u9ad8\u7684\u9002\u5e94\u5ea6\uff09</li> </ol>"},{"location":"zh/tutorials/built-in/cuda-task/#_12","title":"\u8bc4\u4f30\u8f93\u51fa","text":"<pre><code>result = task.evaluate_code(candidate_cuda_code)\n\nif result.valid:\n    print(f\"\u5f97\u5206: {result.score}\")                                    # \u8d8a\u9ad8\u8d8a\u597d\n    print(f\"\u8fd0\u884c\u65f6\u95f4: {-result.score:.4f} ms\")                        # \u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\n    print(f\"\u6027\u80fd\u5206\u6790: {result.additional_info['prof_string']}\")       # CUDA \u5206\u6790\u5668\u8f93\u51fa\nelse:\n    if result.additional_info['compilation_error']:\n        print(f\"\u7f16\u8bd1\u9519\u8bef: {result.additional_info['error_msg']}\")\n    elif result.additional_info['comparison_error']:\n        print(f\"\u6b63\u786e\u6027\u9519\u8bef: {result.additional_info['error_msg']}\")\n</code></pre>"},{"location":"zh/tutorials/built-in/cuda-task/#_13","title":"\u7528\u4e8e\u6d4b\u8bd5\u7684\u5047\u6a21\u5f0f","text":"<p>\u4f60\u53ef\u4ee5\u4f7f\u7528\u5047\u6a21\u5f0f\u5728\u65e0 GPU \u7684\u60c5\u51b5\u4e0b\u6d4b\u8bd5\uff1a</p> <pre><code>def main():\n    task_info = CudaTaskInfoMaker.make_task_info(\n        evaluator=evaluator,\n        gpu_type=\"RTX 4090\",\n        cuda_version=\"12.4.1\",\n        org_py_code=org_py_code,\n        func_py_code=func_py_code,\n        cuda_code=cuda_code,\n        fake_mode=True  # \u8df3\u8fc7\u5b9e\u9645 CUDA \u8bc4\u4f30\n    )\n\n    task = CudaTask(data=task_info, fake_mode=True)\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"zh/tutorials/built-in/cuda-task/#qa","title":"\u5e38\u89c1\u95ee\u9898\uff08Q&amp;A\uff09","text":""},{"location":"zh/tutorials/built-in/cuda-task/#q-_get_vc_env-is-private","title":"Q: \u8fd0\u884c\u65f6\u51fa\u73b0 <code>_get_vc_env is private</code> \u8b66\u544a\u600e\u4e48\u529e\uff1f","text":"<p>\u95ee\u9898\u63cf\u8ff0\uff1a</p> <p>\u5728 Windows \u4e0a\u7f16\u8bd1 CUDA \u6269\u5c55\u65f6\uff0c\u53ef\u80fd\u4f1a\u770b\u5230\u4ee5\u4e0b\u8b66\u544a\uff1a</p> <pre><code>UserWarning: _get_vc_env is private; find an alternative (pypa/distutils#340)\n</code></pre> <p>\u539f\u56e0\u5206\u6790\uff1a</p> <p>\u8fd9\u662f setuptools/distutils \u5728 Windows \u4e0a\u68c0\u6d4b MSVC \u7f16\u8bd1\u5668\u65f6\u7684\u517c\u5bb9\u6027\u8b66\u544a\u3002\u5177\u4f53\u539f\u56e0\uff1a</p> <ul> <li>CUDA \u6269\u5c55\u7f16\u8bd1\u9700\u8981 Visual Studio C++ \u7f16\u8bd1\u5668\uff08MSVC\uff09</li> <li>setuptools \u8c03\u7528\u4e86\u5185\u90e8\u51fd\u6570 <code>_get_vc_env()</code> \u6765\u83b7\u53d6\u7f16\u8bd1\u5668\u73af\u5883</li> <li>Python \u6b63\u5728\u5c06 distutils \u8fc1\u79fb\u5230 setuptools\uff0c\u8fc7\u7a0b\u4e2d\u4e00\u4e9b\u5185\u90e8 API \u6807\u8bb0\u4e3a\u79c1\u6709</li> </ul> <p>\u5f71\u54cd\u7a0b\u5ea6\uff1a</p> <ul> <li>\u26a0\ufe0f \u8fd9\u53ea\u662f\u4e00\u4e2a UserWarning\uff0c\u4e0d\u5f71\u54cd\u7a0b\u5e8f\u8fd0\u884c</li> <li>\u2705 \u4e0d\u5f71\u54cd CUDA \u5185\u6838\u7f16\u8bd1</li> <li>\u2705 \u4e0d\u5f71\u54cd\u4f18\u5316\u7ed3\u679c</li> </ul> <p>\u89e3\u51b3\u65b9\u6848\uff1a</p> <p>\u65b9\u6848 1\uff1a\u8fc7\u6ee4\u8b66\u544a\uff08\u63a8\u8350\uff09</p> <p>\u5728\u811a\u672c\u5f00\u5934\u6dfb\u52a0\u8b66\u544a\u8fc7\u6ee4\uff1a</p> <pre><code>import warnings\nwarnings.filterwarnings('ignore', category=UserWarning, module='setuptools')\n\n# \u6216\u8005\u66f4\u7cbe\u786e\u5730\u8fc7\u6ee4\nwarnings.filterwarnings('ignore', message='.*_get_vc_env is private.*')\n\n# \u7136\u540e\u5bfc\u5165\u5176\u4ed6\u6a21\u5757\nfrom evotoolkit.task.cuda_engineering import CudaTask\n# ...\n</code></pre> <p>\u65b9\u6848 2\uff1a\u5347\u7ea7 setuptools</p> <p>\u5c1d\u8bd5\u5347\u7ea7\u5230\u6700\u65b0\u7248\u672c\uff08\u53ef\u80fd\u5df2\u4fee\u590d\u6b64\u95ee\u9898\uff09\uff1a</p> <pre><code>pip install --upgrade setuptools\n</code></pre> <p>\u65b9\u6848 3\uff1a\u5ffd\u7565</p> <p>\u5982\u679c\u4e0d\u4ecb\u610f\u770b\u5230\u8b66\u544a\uff0c\u53ef\u4ee5\u76f4\u63a5\u5ffd\u7565\u3002\u8fd9\u4e2a\u8b66\u544a\u4e0d\u4f1a\u5f71\u54cd\u529f\u80fd\uff0c\u53ea\u662f\u63d0\u9192\u5f00\u53d1\u8005\u5185\u90e8 API \u53ef\u80fd\u5728\u672a\u6765\u7248\u672c\u4e2d\u6539\u53d8\u3002</p>"},{"location":"zh/tutorials/built-in/cuda-task/#q-windows-if-__name__-__main__","title":"Q: \u4e3a\u4ec0\u4e48\u5728 Windows \u4e0a\u5fc5\u987b\u4f7f\u7528 <code>if __name__ == '__main__':</code> \u4fdd\u62a4\uff1f","text":"<p>\u539f\u56e0\uff1a</p> <ul> <li>Windows \u4e0d\u652f\u6301 <code>fork</code> \u8fdb\u7a0b\u521b\u5efa\u65b9\u5f0f\uff0c\u53ea\u652f\u6301 <code>spawn</code></li> <li><code>spawn</code> \u65b9\u5f0f\u4f1a\u91cd\u65b0\u5bfc\u5165\u4e3b\u6a21\u5757\u6765\u521b\u5efa\u5b50\u8fdb\u7a0b</li> <li>CUDA \u4efb\u52a1\u8bc4\u4f30\u5668\u4f7f\u7528 <code>multiprocessing</code> \u6a21\u5757\u8fdb\u884c\u8d85\u65f6\u63a7\u5236</li> <li>\u5982\u679c\u6ca1\u6709\u4fdd\u62a4\uff0c\u6bcf\u6b21\u5bfc\u5165\u90fd\u4f1a\u6267\u884c\u4e3b\u4ee3\u7801\uff0c\u5bfc\u81f4\u65e0\u9650\u9012\u5f52\u521b\u5efa\u8fdb\u7a0b</li> </ul> <p>\u6b63\u786e\u793a\u4f8b\uff1a</p> <pre><code>from evotoolkit.task.cuda_engineering import CudaTask\n\ndef main():\n    evaluator = Evaluator(temp_path)\n    task = CudaTask(...)\n    # \u6240\u6709\u4efb\u52a1\u4ee3\u7801\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>\u9519\u8bef\u793a\u4f8b\uff08\u4f1a\u5d29\u6e83\uff09\uff1a</p> <pre><code>from evotoolkit.task.cuda_engineering import CudaTask\n\n# \u274c \u76f4\u63a5\u5728\u6a21\u5757\u7ea7\u522b\u6267\u884c\nevaluator = Evaluator(temp_path)  # \u4f1a\u5bfc\u81f4 RuntimeError\n</code></pre>"},{"location":"zh/tutorials/built-in/cuda-task/#_14","title":"\u4e0b\u4e00\u6b65","text":""},{"location":"zh/tutorials/built-in/cuda-task/#_15","title":"\u63a2\u7d22\u4e0d\u540c\u7684\u4f18\u5316\u7b56\u7565","text":"<ul> <li>\u5c1d\u8bd5\u4e0d\u540c\u7684\u8fdb\u5316\u7b97\u6cd5\uff08EvoEngineer \u53d8\u4f53\u3001EoH\u3001FunSearch\uff09</li> <li>\u6bd4\u8f83\u4e0d\u540c\u63a5\u53e3\u7684\u7ed3\u679c</li> <li>\u5206\u6790\u6027\u80fd\u5206\u6790\u4ee5\u8bc6\u522b\u74f6\u9888</li> <li>\u5b9e\u9a8c\u4e0d\u540c\u7684\u5185\u6838\u6a21\u5f0f\uff08\u5206\u5757\u3001\u5171\u4eab\u5185\u5b58\u7b49\uff09</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/#_16","title":"\u81ea\u5b9a\u4e49\u548c\u6539\u8fdb\u8fdb\u5316\u8fc7\u7a0b","text":"<ul> <li>\u68c0\u67e5\u73b0\u6709 Interface \u7c7b\u4e2d\u7684\u63d0\u793a\u8bbe\u8ba1</li> <li>\u7ee7\u627f\u5e76\u91cd\u5199 Interface \u4ee5\u81ea\u5b9a\u4e49\u63d0\u793a</li> <li>\u4e3a\u4e0d\u540c\u7684\u4f18\u5316\u76ee\u6807\u8bbe\u8ba1\u4e13\u95e8\u7684\u63d0\u793a\uff08\u5185\u5b58\u53d7\u9650\u3001\u8ba1\u7b97\u53d7\u9650\u7b49\uff09</li> <li>\u5982\u6709\u9700\u8981\uff0c\u5f00\u53d1\u5168\u65b0\u7684\u8fdb\u5316\u7b97\u6cd5</li> </ul>"},{"location":"zh/tutorials/built-in/cuda-task/#_17","title":"\u4e86\u89e3\u66f4\u591a","text":"<ul> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u6df1\u5165\u4e86\u89e3\u63d0\u793a\u81ea\u5b9a\u4e49\u548c\u7b97\u6cd5\u5f00\u53d1</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u9ad8\u7ea7\u914d\u7f6e\u548c\u6280\u5de7</li> <li>API \u53c2\u8003 - \u5b8c\u6574\u7684 API \u6587\u6863</li> <li>\u5f00\u53d1\u6587\u6863 - \u8d21\u732e\u65b0\u65b9\u6cd5\u548c\u529f\u80fd</li> </ul>"},{"location":"zh/tutorials/built-in/prompt-engineering/","title":"\u63d0\u793a\u8bcd\u5de5\u7a0b\u6559\u7a0b","text":"<p>\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 LLM \u9a71\u52a8\u7684\u8fdb\u5316\u7b97\u6cd5\u6765\u4f18\u5316\u63d0\u793a\u8bcd\u6a21\u677f\uff0c\u4ee5\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002</p> <p>\u5b66\u672f\u5f15\u7528</p> <p>\u5982\u679c\u60a8\u5728\u7814\u7a76\u4e2d\u4f7f\u7528 EvoToolkit\uff0c\u8bf7\u5f15\u7528\uff1a</p> <pre><code>@article{guo2025evotoolkit,\ntitle={evotoolkit: A Unified LLM-Driven Evolutionary Framework for Generalized Solution Search},\nauthor={Guo, Ping and Zhang, Qingfu},\njournal={arXiv preprint arXiv:XXXX.XXXXX},\nyear={2025},\nnote={Submitted to arXiv}\n}\n</code></pre> <p>\u5b8c\u6574\u793a\u4f8b\u4ee3\u7801</p> <p>\u672c\u6559\u7a0b\u63d0\u4f9b\u5b8c\u6574\u53ef\u8fd0\u884c\u7684\u793a\u4f8b\uff08\u70b9\u51fb\u67e5\u770b/\u4e0b\u8f7d\uff09\uff1a</p> <ul> <li> basic_example.py - \u4f7f\u7528 mock LLM \u7684\u57fa\u7840\u7528\u6cd5</li> <li> README.zh.md - \u793a\u4f8b\u6587\u6863\u548c\u4f7f\u7528\u6307\u5357\uff08\u4e2d\u6587\u7248\uff09</li> </ul> <p>\u672c\u5730\u8fd0\u884c\uff1a <pre><code>cd examples/prompt_optimization\npython basic_example.py\n</code></pre></p>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_2","title":"\u6982\u8ff0","text":"<p>\u672c\u6559\u7a0b\u6f14\u793a\uff1a</p> <ul> <li>\u521b\u5efa\u63d0\u793a\u8bcd\u4f18\u5316\u4efb\u52a1</li> <li>\u4f7f\u7528 LLM \u9a71\u52a8\u7684\u8fdb\u5316\u6539\u8fdb\u63d0\u793a\u8bcd\u6a21\u677f</li> <li>\u5728\u7279\u5b9a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u6d4b\u8bd5\u63d0\u793a\u8bcd</li> <li>\u81ea\u52a8\u8fdb\u5316\u9ad8\u8d28\u91cf\u63d0\u793a\u8bcd</li> </ul>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_3","title":"\u5b89\u88c5","text":"<p>\u5b89\u88c5 EvoToolkit\uff1a</p> <pre><code>pip install evotoolkit\n</code></pre> <p>\u524d\u7f6e\u6761\u4ef6\uff1a</p> <ul> <li>Python &gt;= 3.11</li> <li>LLM API \u8bbf\u95ee\u6743\u9650\uff08OpenAI\u3001Claude \u6216\u5176\u4ed6\u517c\u5bb9\u63d0\u4f9b\u5546\uff09</li> <li>\u63d0\u793a\u8bcd\u5de5\u7a0b\u57fa\u7840\u77e5\u8bc6</li> </ul>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_4","title":"\u7406\u89e3\u63d0\u793a\u8bcd\u4f18\u5316\u4efb\u52a1","text":""},{"location":"zh/tutorials/built-in/prompt-engineering/#_5","title":"\u4ec0\u4e48\u662f\u63d0\u793a\u8bcd\u4f18\u5316\u4efb\u52a1\uff1f","text":"<p>\u63d0\u793a\u8bcd\u4f18\u5316\u4efb\u52a1\u901a\u8fc7\u8fdb\u5316 \u5b57\u7b26\u4e32\u6a21\u677f \u6765\u6700\u5927\u5316\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002\u4e0e\u8fdb\u5316\u4ee3\u7801\u7684 Python \u4efb\u52a1\u4e0d\u540c\uff0c\u63d0\u793a\u8bcd\u4efb\u52a1\u76f4\u63a5\u8fdb\u5316\u63d0\u793a\u8bcd\u6587\u672c\u3002</p> \u65b9\u9762 Python \u4efb\u52a1 \u63d0\u793a\u8bcd\u4efb\u52a1 \u89e3\u51b3\u65b9\u6848\u7c7b\u578b Python \u4ee3\u7801 \u5b57\u7b26\u4e32\u6a21\u677f \u8fdb\u5316\u76ee\u6807 \u51fd\u6570/\u7b97\u6cd5 \u63d0\u793a\u8bcd\u6587\u672c \u8bc4\u4f30\u65b9\u5f0f \u6267\u884c\u4ee3\u7801 \u7528 LLM \u6d4b\u8bd5\u6a21\u677f \u793a\u4f8b <code>def func(x): return x**2</code> <code>\"\u6c42\u89e3\uff1a{question}\\n\u7b54\u6848\uff1a\"</code>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_6","title":"\u4efb\u52a1\u7ec4\u4ef6","text":"<p>\u4e00\u4e2a\u63d0\u793a\u8bcd\u4f18\u5316\u4efb\u52a1\u9700\u8981\uff1a</p> <ul> <li>\u6d4b\u8bd5\u7528\u4f8b\uff1a\u7528\u4e8e\u8bc4\u4f30\u7684\u95ee\u7b54\u5bf9</li> <li>\u6a21\u677f\u8bed\u6cd5\uff1a\u5305\u542b <code>{question}</code> \u5360\u4f4d\u7b26\u7684\u5b57\u7b26\u4e32</li> <li>LLM API\uff1a\u7528\u4e8e\u6d4b\u8bd5\u63d0\u793a\u8bcd\u6a21\u677f\uff08\u6216\u4f7f\u7528 mock \u6a21\u5f0f\uff09</li> <li>\u8bc4\u4f30\u6307\u6807\uff1a\u5728\u6d4b\u8bd5\u7528\u4f8b\u4e0a\u7684\u51c6\u786e\u7387</li> </ul>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_7","title":"\u521b\u5efa\u4f60\u7684\u7b2c\u4e00\u4e2a\u63d0\u793a\u8bcd\u4efb\u52a1","text":""},{"location":"zh/tutorials/built-in/prompt-engineering/#1","title":"\u6b65\u9aa4 1\uff1a\u5b9a\u4e49\u6d4b\u8bd5\u7528\u4f8b","text":"<p>\u521b\u5efa\u5305\u542b\u95ee\u9898\u548c\u9884\u671f\u7b54\u6848\u7684\u6d4b\u8bd5\u7528\u4f8b\uff1a</p> <pre><code>test_cases = [\n    {\"question\": \"2+2\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"4\"},\n    {\"question\": \"5*3\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"15\"},\n    {\"question\": \"10-7\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"3\"},\n    {\"question\": \"12/4\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"3\"},\n    {\"question\": \"7+8\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"15\"},\n]\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#2","title":"\u6b65\u9aa4 2\uff1a\u521b\u5efa\u4efb\u52a1","text":"<pre><code>from evotoolkit.task import PromptOptimizationTask\nfrom evotoolkit.tools.llm import HttpsApi\n\n# \u914d\u7f6e LLM API\nllm_api = HttpsApi(\n    api_url=\"your_api_url\",  # \u4f8b\u5982: \"ai.api.example.com\"\n    key=\"your_api_key\",       # \u4f60\u7684 API \u5bc6\u94a5\n    model=\"gpt-4o\"\n)\n\ntask = PromptOptimizationTask(\n    test_cases=test_cases,\n    llm_api=llm_api,\n    use_mock=False\n)\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#3","title":"\u6b65\u9aa4 3\uff1a\u6d4b\u8bd5\u521d\u59cb\u6a21\u677f","text":"<pre><code># \u83b7\u53d6\u521d\u59cb\u89e3\u51b3\u65b9\u6848\ninit_sol = task.make_init_sol_wo_other_info()\n\nprint(f\"\u521d\u59cb\u6a21\u677f\uff1a{init_sol.sol_string}\")\nprint(f\"\u51c6\u786e\u7387\uff1a{init_sol.evaluation_res.score:.2%}\")\nprint(f\"\u6b63\u786e\u6570\uff1a{init_sol.evaluation_res.additional_info['correct']}/{init_sol.evaluation_res.additional_info['total']}\")\n</code></pre> <p>\u8f93\u51fa\uff1a <pre><code>\u521d\u59cb\u6a21\u677f\uff1a\"\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff1a{question}\"\n\u51c6\u786e\u7387\uff1a100.00%\n\u6b63\u786e\u6570\uff1a5/5\n</code></pre></p>"},{"location":"zh/tutorials/built-in/prompt-engineering/#4","title":"\u6b65\u9aa4 4\uff1a\u6d4b\u8bd5\u81ea\u5b9a\u4e49\u6a21\u677f","text":"<pre><code># \u6d4b\u8bd5\u4f60\u81ea\u5df1\u7684\u6a21\u677f\ncustom_template = \"\u89e3\u7b54\u8fd9\u9053\u6570\u5b66\u9898\uff0c\u53ea\u7ed9\u51fa\u6570\u5b57\uff1a{question}\"\nresult = task.evaluate_code(custom_template)\n\nprint(f\"\u81ea\u5b9a\u4e49\u6a21\u677f\uff1a{custom_template}\")\nprint(f\"\u51c6\u786e\u7387\uff1a{result.score:.2%}\")\nprint(f\"\u6b63\u786e\u6570\uff1a{result.additional_info['correct']}/{result.additional_info['total']}\")\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_8","title":"\u8fd0\u884c\u8fdb\u5316\u4ee5\u4f18\u5316\u63d0\u793a\u8bcd","text":""},{"location":"zh/tutorials/built-in/prompt-engineering/#1_1","title":"\u6b65\u9aa4 1\uff1a\u521b\u5efa\u63a5\u53e3","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task import EvoEngineerStringInterface\n\n# \u521b\u5efa\u63a5\u53e3\ninterface = EvoEngineerStringInterface(task)\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#2_1","title":"\u6b65\u9aa4 2\uff1a\u8fd0\u884c\u8fdb\u5316","text":"<pre><code># \u4f7f\u7528 LLM \u8fd0\u884c\u8fdb\u5316\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./prompt_results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20\n)\n\nprint(f\"\u627e\u5230\u7684\u6700\u4f73\u6a21\u677f\uff1a{result.sol_string}\")\nprint(f\"\u51c6\u786e\u7387\uff1a{result.evaluation_res.score:.2%}\")\n</code></pre> <p>\u5c1d\u8bd5\u4e0d\u540c\u7684\u7b97\u6cd5</p> <p>EvoToolkit \u652f\u6301\u591a\u79cd\u63d0\u793a\u8bcd\u4f18\u5316\u7684\u8fdb\u5316\u7b97\u6cd5\uff1a</p> <pre><code># \u4f7f\u7528 EoH\nfrom evotoolkit.task import EoHStringInterface\ninterface = EoHStringInterface(task)\n\n# \u4f7f\u7528 FunSearch\nfrom evotoolkit.task import FunSearchStringInterface\ninterface = FunSearchStringInterface(task)\n\n# \u4f7f\u7528 EvoEngineer\uff08\u9ed8\u8ba4\uff09\nfrom evotoolkit.task import EvoEngineerStringInterface\ninterface = EvoEngineerStringInterface(task)\n</code></pre> <p>\u7136\u540e\u4f7f\u7528\u76f8\u540c\u7684 <code>evotoolkit.solve()</code> \u8c03\u7528\u8fd0\u884c\u8fdb\u5316\u3002\u4e0d\u540c\u7684\u63a5\u53e3\u53ef\u80fd\u5728\u4e0d\u540c\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\u3002</p>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_9","title":"\u7406\u89e3\u6a21\u677f\u683c\u5f0f","text":""},{"location":"zh/tutorials/built-in/prompt-engineering/#_10","title":"\u6709\u6548\u7684\u6a21\u677f","text":"<p>\u63d0\u793a\u8bcd\u6a21\u677f\u5fc5\u987b\u5305\u542b <code>{question}</code> \u5360\u4f4d\u7b26\uff1a</p> <pre><code># \u2705 \u597d\u7684\u6a21\u677f\n\"\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff1a{question}\"\n\"\u89e3\u7b54\u8fd9\u9053\u6570\u5b66\u9898\uff1a{question}\\n\u53ea\u7ed9\u51fa\u6570\u5b57\u3002\"\n\"\u95ee\u9898\uff1a{question}\\n\u9010\u6b65\u601d\u8003\u5e76\u53ea\u63d0\u4f9b\u6700\u7ec8\u7b54\u6848\u3002\"\n\"\u8ba9\u6211\u4eec\u6765\u89e3\u51b3\uff1a{question}\\n\u9996\u5148\uff0c\u5206\u6790\u95ee\u9898...\"\n\n# \u274c \u9519\u8bef\u7684\u6a21\u677f\uff08\u7f3a\u5c11\u5360\u4f4d\u7b26\uff09\n\"\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\"     # \u6ca1\u6709 {question} \u5360\u4f4d\u7b26\n\"\u7b54\u6848\uff1a42\"         # \u6ca1\u6709 {question} \u5360\u4f4d\u7b26\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_11","title":"\u6a21\u677f\u8fdb\u5316\u793a\u4f8b","text":"<p>\u5728\u8fdb\u5316\u8fc7\u7a0b\u4e2d\uff0cLLM \u751f\u6210\u6539\u8fdb\u7684\u6a21\u677f\uff1a</p> <pre><code># \u7b2c 1 \u4ee3\n\"\u7b54\u6848\uff1a{question}\"\n# \u51c6\u786e\u7387\uff1a60%\n\n# \u7b2c 3 \u4ee3\n\"\u89e3\u7b54\u8fd9\u9053\u6570\u5b66\u9898\uff1a{question}\\n\u53ea\u63d0\u4f9b\u6570\u5b57\u7b54\u6848\u3002\"\n# \u51c6\u786e\u7387\uff1a85%\n\n# \u7b2c 7 \u4ee3\n\"\u8ba1\u7b97\uff1a{question}\\n\u53ea\u663e\u793a\u6700\u7ec8\u6570\u5b57\uff0c\u65e0\u9700\u89e3\u91ca\u3002\"\n# \u51c6\u786e\u7387\uff1a100%\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_12","title":"\u7528\u4f8b\u548c\u5e94\u7528","text":""},{"location":"zh/tutorials/built-in/prompt-engineering/#1_2","title":"1. \u6570\u5b66\u95ee\u9898\u6c42\u89e3","text":"<pre><code>test_cases = [\n    {\"question\": \"15 * 7 \u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"105\"},\n    {\"question\": \"144 / 12 \u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"12\"},\n    # ...\n]\n\ntask = PromptOptimizationTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#2_2","title":"2. \u6587\u672c\u5206\u7c7b","text":"<pre><code>test_cases = [\n    {\"question\": \"\u8fd9\u90e8\u7535\u5f71\u592a\u68d2\u4e86\uff01\", \"expected\": \"\u6b63\u9762\"},\n    {\"question\": \"\u8fd9\u90e8\u7535\u5f71\u592a\u7cdf\u7cd5\u4e86\uff01\", \"expected\": \"\u8d1f\u9762\"},\n    {\"question\": \"\u6211\u559c\u6b22\u8fd9\u90e8\u7535\u5f71\uff01\", \"expected\": \"\u6b63\u9762\"},\n    # ...\n]\n\ntask = PromptOptimizationTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#3_1","title":"3. \u4fe1\u606f\u63d0\u53d6","text":"<pre><code>test_cases = [\n    {\"question\": \"\u63d0\u53d6\u65e5\u671f\uff1a\u4f1a\u8bae\u5728 2024-03-15 \u4e3e\u884c\", \"expected\": \"2024-03-15\"},\n    {\"question\": \"\u63d0\u53d6\u65e5\u671f\uff1a\u6211\u4eec\u5c06\u5728 2024 \u5e74 3 \u6708 20 \u65e5\u89c1\u9762\", \"expected\": \"2024-03-20\"},\n    # ...\n]\n\ntask = PromptOptimizationTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#4_1","title":"4. \u7ffb\u8bd1\u4efb\u52a1","text":"<pre><code>test_cases = [\n    {\"question\": \"\u7ffb\u8bd1\u6210\u82f1\u6587\uff1a\u4f60\u597d\", \"expected\": \"Hello\"},\n    {\"question\": \"\u7ffb\u8bd1\u6210\u82f1\u6587\uff1a\u8c22\u8c22\", \"expected\": \"Thank you\"},\n    # ...\n]\n\ntask = PromptOptimizationTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_13","title":"\u81ea\u5b9a\u4e49\u8fdb\u5316\u884c\u4e3a","text":"<p>\u8fdb\u5316\u63d0\u793a\u8bcd\u7684\u8d28\u91cf\u4e3b\u8981\u7531 \u8fdb\u5316\u65b9\u6cd5 \u53ca\u5176\u5185\u90e8\u7684 \u63d0\u793a\u8bbe\u8ba1 \u63a7\u5236\u3002\u5982\u679c\u60f3\u63d0\u5347\u7ed3\u679c\uff1a</p> <ul> <li>\u8c03\u6574\u63d0\u793a\uff1a\u7ee7\u627f\u73b0\u6709\u7684 Interface \u7c7b\u5e76\u81ea\u5b9a\u4e49 LLM \u63d0\u793a</li> <li>\u5f00\u53d1\u65b0\u7b97\u6cd5\uff1a\u521b\u5efa\u5168\u65b0\u7684\u8fdb\u5316\u7b56\u7565</li> </ul> <p>\u4e86\u89e3\u66f4\u591a</p> <p>\u8fd9\u4e9b\u662f\u9002\u7528\u4e8e\u6240\u6709\u4efb\u52a1\u7684\u901a\u7528\u6280\u672f\u3002\u8be6\u7ec6\u6559\u7a0b\u8bf7\u53c2\u89c1\uff1a</p> <ul> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u5982\u4f55\u4fee\u6539\u63d0\u793a\u548c\u5f00\u53d1\u65b0\u7b97\u6cd5</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u66f4\u591a\u9ad8\u7ea7\u914d\u7f6e\u9009\u9879</li> </ul> <p>\u5feb\u901f\u793a\u4f8b - \u4e3a\u63d0\u793a\u8bcd\u4f18\u5316\u81ea\u5b9a\u4e49\u63d0\u793a\uff1a</p> <pre><code>from evotoolkit.task import EvoEngineerStringInterface\n\nclass CustomPromptInterface(EvoEngineerStringInterface):\n    \"\"\"\u4f18\u5316\u63d0\u793a\u8bcd\u6a21\u677f\u8fdb\u5316\u7684\u63a5\u53e3\u3002\"\"\"\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        \"\"\"\u81ea\u5b9a\u4e49\u53d8\u5f02\u63d0\u793a\u4ee5\u5f3a\u8c03\u6e05\u6670\u5ea6\u548c\u7ed3\u6784\u3002\"\"\"\n\n        if operator_name == \"mutation\":\n            task_description = self.task.get_base_task_description()\n            individual = selected_individuals[0]\n\n            prompt = f\"\"\"# \u63d0\u793a\u8bcd\u6a21\u677f\u4f18\u5316\n\n{task_description}\n\n## \u5f53\u524d\u6700\u4f73\u6a21\u677f\n**\u51c6\u786e\u7387\uff1a** {current_best_sol.evaluation_res.score:.2%}\n**\u6a21\u677f\uff1a** {current_best_sol.sol_string}\n\n## \u5f85\u53d8\u5f02\u6a21\u677f\n**\u51c6\u786e\u7387\uff1a** {individual.evaluation_res.score:.2%}\n**\u6a21\u677f\uff1a** {individual.sol_string}\n\n## \u4f18\u5316\u6307\u5357\n\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u6539\u8fdb\u6a21\u677f\uff1a\n- \u6dfb\u52a0\u6e05\u6670\u7684\u6307\u4ee4\n- \u660e\u786e\u6307\u5b9a\u8f93\u51fa\u683c\u5f0f\n- \u5305\u542b\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\u6216\u793a\u4f8b\n- \u4f7f\u7528\u6070\u5f53\u7684\u8bed\u6c14\u548c\u98ce\u683c\n- \u786e\u4fdd\u4fdd\u7559 {{question}} \u5360\u4f4d\u7b26\n\n\u751f\u6210\u4e00\u4e2a\u63d0\u9ad8\u51c6\u786e\u7387\u7684\u6539\u8fdb\u6a21\u677f\u3002\n\n## \u54cd\u5e94\u683c\u5f0f\uff1a\nname: [\u63cf\u8ff0\u6027\u540d\u79f0]\ncode:\n[\u5305\u542b {{question}} \u5360\u4f4d\u7b26\u7684\u6539\u8fdb\u6a21\u677f]\nthought: [\u4fee\u6539\u7406\u7531]\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # \u5176\u4ed6\u7b97\u5b50\u4f7f\u7528\u9ed8\u8ba4\u5b9e\u73b0\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u63a5\u53e3\ninterface = CustomPromptInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./custom_results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_14","title":"\u7406\u89e3\u8bc4\u4f30","text":""},{"location":"zh/tutorials/built-in/prompt-engineering/#_15","title":"\u8bc4\u5206\u673a\u5236","text":"<ol> <li>\u6a21\u677f\u6d4b\u8bd5\uff1a\u6bcf\u4e2a\u6a21\u677f\u5728\u6240\u6709\u6d4b\u8bd5\u7528\u4f8b\u4e0a\u8fdb\u884c\u6d4b\u8bd5</li> <li>LLM \u54cd\u5e94\uff1aLLM \u4f7f\u7528\u6a21\u677f\u751f\u6210\u7b54\u6848</li> <li>\u7b54\u6848\u68c0\u67e5\uff1a\u54cd\u5e94\u4e0e\u9884\u671f\u7b54\u6848\u8fdb\u884c\u6bd4\u8f83</li> <li>\u51c6\u786e\u7387\u8ba1\u7b97\uff1a\u5f97\u5206 = (\u6b63\u786e\u7b54\u6848\u6570) / (\u603b\u6d4b\u8bd5\u7528\u4f8b\u6570)</li> </ol>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_16","title":"\u8bc4\u4f30\u8f93\u51fa","text":"<pre><code>result = task.evaluate_code(template)\n\nif result.valid:\n    print(f\"\u51c6\u786e\u7387\uff1a{result.score:.2%}\")\n    print(f\"\u6b63\u786e\u6570\uff1a{result.additional_info['correct']}/{result.additional_info['total']}\")\n    print(f\"\u8be6\u60c5\uff1a{result.additional_info['details']}\")\nelse:\n    print(f\"\u9519\u8bef\uff1a{result.additional_info['error_msg']}\")\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#mock","title":"\u7528\u4e8e\u6d4b\u8bd5\u7684 Mock \u6a21\u5f0f","text":"<p>\u4f7f\u7528 mock \u6a21\u5f0f\u6d4b\u8bd5\u800c\u65e0\u9700 LLM API \u6210\u672c\uff1a</p> <pre><code># Mock \u6a21\u5f0f\u603b\u662f\u8fd4\u56de\u6b63\u786e\u7b54\u6848\u7528\u4e8e\u6d4b\u8bd5\ntask = PromptOptimizationTask(\n    test_cases=test_cases,\n    use_mock=True  # \u4e0d\u8fdb\u884c\u5b9e\u9645\u7684 LLM \u8c03\u7528\n)\n\n# \u9002\u7528\u4e8e\uff1a\n# - \u6d4b\u8bd5\u4efb\u52a1\u8bbe\u7f6e\n# - \u8c03\u8bd5\u6a21\u677f\u683c\u5f0f\n# - \u7406\u89e3\u5de5\u4f5c\u6d41\u7a0b\n# - \u5f00\u53d1\u81ea\u5b9a\u4e49\u63a5\u53e3\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_17","title":"\u81ea\u5b9a\u4e49\u8bc4\u4f30\u903b\u8f91","text":"<p>\u5bf9\u4e8e\u4e13\u95e8\u7684\u4efb\u52a1\uff0c\u4f60\u53ef\u4ee5\u81ea\u5b9a\u4e49\u7b54\u6848\u68c0\u67e5\uff1a</p> <pre><code>from evotoolkit.task import PromptOptimizationTask\n\nclass CustomPromptTask(PromptOptimizationTask):\n    \"\"\"\u5177\u6709\u4e13\u95e8\u7b54\u6848\u68c0\u67e5\u7684\u81ea\u5b9a\u4e49\u4efb\u52a1\u3002\"\"\"\n\n    def _check_answer(self, response: str, expected: str) -&gt; bool:\n        \"\"\"\u81ea\u5b9a\u4e49\u8bc4\u4f30\u903b\u8f91\u3002\"\"\"\n        # \u793a\u4f8b\uff1a\u4e0d\u533a\u5206\u5927\u5c0f\u5199\u7684\u6bd4\u8f83\n        return response.strip().lower() == expected.strip().lower()\n\n        # \u793a\u4f8b\uff1a\u6a21\u7cca\u5339\u914d\n        # from difflib import SequenceMatcher\n        # similarity = SequenceMatcher(None, response, expected).ratio()\n        # return similarity &gt; 0.8\n\n        # \u793a\u4f8b\uff1a\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\n        # import re\n        # return bool(re.search(expected, response))\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u4efb\u52a1\ntest_cases = [\n    {\"question\": \"\u6cd5\u56fd\u7684\u9996\u90fd\u662f\uff1f\", \"expected\": \"\u5df4\u9ece\"},\n    # \"\u5df4\u9ece\"\u3001\"PARIS\"\u3001\"paris\" \u90fd\u88ab\u63a5\u53d7\n]\n\ntask = CustomPromptTask(test_cases=test_cases, llm_api=llm_api)\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_18","title":"\u5b8c\u6574\u793a\u4f8b","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u5de5\u4f5c\u793a\u4f8b\uff1a</p> <pre><code>import evotoolkit\nfrom evotoolkit.task import PromptOptimizationTask, EvoEngineerStringInterface\nfrom evotoolkit.tools.llm import HttpsApi\n\n# 1. \u5b9a\u4e49\u6d4b\u8bd5\u7528\u4f8b\ntest_cases = [\n    {\"question\": \"2+2\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"4\"},\n    {\"question\": \"5*3\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"15\"},\n    {\"question\": \"10-7\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"3\"},\n    {\"question\": \"12/4\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"3\"},\n    {\"question\": \"7+8\u7b49\u4e8e\u591a\u5c11\uff1f\", \"expected\": \"15\"},\n]\n\n# 2. \u914d\u7f6e LLM API\nllm_api = HttpsApi(\n    api_url=\"your_api_url\",  # \u4f8b\u5982: \"ai.api.example.com\"\n    key=\"your_api_key\",       # \u4f60\u7684 API \u5bc6\u94a5\n    model=\"gpt-4o\"\n)\n\n# 3. \u521b\u5efa\u4efb\u52a1\ntask = PromptOptimizationTask(\n    test_cases=test_cases,\n    llm_api=llm_api,\n    use_mock=False\n)\n\n# 4. \u521b\u5efa\u63a5\u53e3\ninterface = EvoEngineerStringInterface(task)\n\n# 5. \u8fd0\u884c\u8fdb\u5316\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./prompt_optimization_results',\n    running_llm=llm_api,\n    max_generations=10,\n    pop_size=5,\n    max_sample_nums=20\n)\n\n# 6. \u663e\u793a\u7ed3\u679c\nprint(f\"\u627e\u5230\u7684\u6700\u4f73\u6a21\u677f\uff1a\")\nprint(f\"  {result.sol_string}\")\nprint(f\"\u51c6\u786e\u7387\uff1a{result.evaluation_res.score:.2%}\")\nprint(f\"\u6b63\u786e\u6570\uff1a{result.evaluation_res.additional_info['correct']}/{result.evaluation_res.additional_info['total']}\")\n</code></pre>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_19","title":"\u4e0b\u4e00\u6b65","text":""},{"location":"zh/tutorials/built-in/prompt-engineering/#_20","title":"\u63a2\u7d22\u4e0d\u540c\u7684\u4f18\u5316\u7b56\u7565","text":"<ul> <li>\u5c1d\u8bd5\u4e0d\u540c\u7684\u8fdb\u5316\u7b97\u6cd5\uff08EvoEngineer \u53d8\u4f53\u3001EoH\u3001FunSearch\uff09</li> <li>\u6bd4\u8f83\u4e0d\u540c\u63a5\u53e3\u7684\u7ed3\u679c</li> <li>\u5b9e\u9a8c\u4e0d\u540c\u7684\u6d4b\u8bd5\u7528\u4f8b\u96c6</li> <li>\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e0a\u6d4b\u8bd5</li> </ul>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_21","title":"\u81ea\u5b9a\u4e49\u548c\u6539\u8fdb\u8fdb\u5316\u8fc7\u7a0b","text":"<ul> <li>\u68c0\u67e5\u73b0\u6709 Interface \u7c7b\u4e2d\u7684\u63d0\u793a\u8bbe\u8ba1</li> <li>\u7ee7\u627f\u5e76\u91cd\u5199 Interface \u4ee5\u81ea\u5b9a\u4e49\u63d0\u793a</li> <li>\u4e3a\u4e0d\u540c\u7684\u4efb\u52a1\u7c7b\u578b\u8bbe\u8ba1\u4e13\u95e8\u7684\u63d0\u793a</li> <li>\u5982\u6709\u9700\u8981\uff0c\u5f00\u53d1\u5168\u65b0\u7684\u8fdb\u5316\u7b97\u6cd5</li> </ul>"},{"location":"zh/tutorials/built-in/prompt-engineering/#_22","title":"\u4e86\u89e3\u66f4\u591a","text":"<ul> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u6df1\u5165\u4e86\u89e3\u63d0\u793a\u81ea\u5b9a\u4e49\u548c\u7b97\u6cd5\u5f00\u53d1</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u9ad8\u7ea7\u914d\u7f6e\u548c\u6280\u5de7</li> <li>API \u53c2\u8003 - \u5b8c\u6574\u7684 API \u6587\u6863</li> <li>\u5f00\u53d1\u6587\u6863 - \u8d21\u732e\u65b0\u65b9\u6cd5\u548c\u529f\u80fd</li> </ul>"},{"location":"zh/tutorials/built-in/scientific-regression/","title":"\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b","text":"<p>\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 LLM \u9a71\u52a8\u7684\u8fdb\u5316\u4ece\u771f\u5b9e\u79d1\u5b66\u6570\u636e\u96c6\u4e2d\u53d1\u73b0\u6570\u5b66\u65b9\u7a0b\u3002</p> <p>\u5b66\u672f\u5f15\u7528</p> <p>\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4efb\u52a1\u548c\u6570\u636e\u96c6\u57fa\u4e8e CoEvo \u7814\u7a76\u3002\u5982\u679c\u60a8\u5728\u5b66\u672f\u5de5\u4f5c\u4e2d\u4f7f\u7528\u6b64\u529f\u80fd\uff0c\u8bf7\u5f15\u7528\uff1a</p> <pre><code>@misc{guo2024coevocontinualevolutionsymbolic,\n    title={CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models},\n    author={Ping Guo and Qingfu Zhang and Xi Lin},\n    year={2024},\n    eprint={2412.18890},\n    archivePrefix={arXiv},\n    primaryClass={cs.AI},\n    url={https://arxiv.org/abs/2412.18890}\n}\n</code></pre> <p>\u5b8c\u6574\u793a\u4f8b\u4ee3\u7801</p> <p>\u672c\u6559\u7a0b\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u53ef\u8fd0\u884c\u793a\u4f8b\uff08\u70b9\u51fb\u67e5\u770b/\u4e0b\u8f7d\uff09\uff1a</p> <ul> <li> basic_example.py - \u57fa\u7840\u793a\u4f8b</li> <li> custom_prompt.py - \u81ea\u5b9a\u4e49 prompt \u793a\u4f8b</li> <li> compare_algorithms.py - \u5bf9\u6bd4\u4e0d\u540c\u7b97\u6cd5</li> <li> README.zh.md - \u793a\u4f8b\u8bf4\u660e\u548c\u8fd0\u884c\u6307\u5357</li> </ul> <p>\u672c\u5730\u8fd0\u884c\uff1a <pre><code>cd examples/scientific_regression\npython basic_example.py\n</code></pre></p>"},{"location":"zh/tutorials/built-in/scientific-regression/#_2","title":"\u6982\u8ff0","text":"<p>\u672c\u6559\u7a0b\u6f14\u793a\uff1a</p> <ul> <li>\u52a0\u8f7d\u79d1\u5b66\u6570\u636e\u96c6\u7528\u4e8e\u7b26\u53f7\u56de\u5f52</li> <li>\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u6570\u5b66\u65b9\u7a0b</li> <li>\u81ea\u52a8\u4f18\u5316\u65b9\u7a0b\u53c2\u6570</li> <li>\u8fdb\u5316\u590d\u6742\u7684\u79d1\u5b66\u6a21\u578b</li> </ul>"},{"location":"zh/tutorials/built-in/scientific-regression/#_3","title":"\u5b89\u88c5","text":"<p>\u5b89\u88c5\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4f9d\u8d56\uff1a</p> <pre><code>pip install evotoolkit[scientific_regression]\n</code></pre> <p>\u8fd9\u4f1a\u5b89\u88c5\uff1a</p> <ul> <li>SciPy\uff08\u7528\u4e8e\u53c2\u6570\u4f18\u5316\uff09</li> <li>Pandas\uff08\u7528\u4e8e\u6570\u636e\u52a0\u8f7d\uff09</li> </ul> <p>\u524d\u7f6e\u77e5\u8bc6\uff1a</p> <ul> <li>\u57fa\u672c\u4e86\u89e3\u7b26\u53f7\u56de\u5f52\u6982\u5ff5</li> <li>\u719f\u6089 NumPy \u548c SciPy \u4f7f\u7528</li> </ul>"},{"location":"zh/tutorials/built-in/scientific-regression/#_4","title":"\u51c6\u5907\u6570\u636e\u96c6","text":"<p>EvoToolkit \u652f\u6301 \u61d2\u4e0b\u8f7d - \u9996\u6b21\u4f7f\u7528\u65f6\u81ea\u52a8\u4e0b\u8f7d\u6570\u636e\u96c6\u5230\u9ed8\u8ba4\u4f4d\u7f6e\u3002</p> <p>\u53ef\u7528\u6570\u636e\u96c6\uff1a</p> <ul> <li>bactgrow: \u5927\u80a0\u6746\u83cc\u7ec6\u83cc\u751f\u957f\u7387\u9884\u6d4b\uff084\u8f93\u5165\uff1a\u79cd\u7fa4\u3001\u5e95\u7269\u3001\u6e29\u5ea6\u3001pH\uff09</li> <li>oscillator1: \u963b\u5c3c\u975e\u7ebf\u6027\u632f\u8361\u5668\u52a0\u901f\u5ea6\uff082\u8f93\u5165\uff1a\u4f4d\u7f6e\u3001\u901f\u5ea6\uff09</li> <li>oscillator2: \u963b\u5c3c\u975e\u7ebf\u6027\u632f\u8361\u5668\u53d8\u4f532\uff082\u8f93\u5165\uff1a\u4f4d\u7f6e\u3001\u901f\u5ea6\uff09</li> <li>stressstrain: \u94dd\u68d2\u5e94\u529b\u9884\u6d4b\uff082\u8f93\u5165\uff1a\u5e94\u53d8\u3001\u6e29\u5ea6\uff09</li> </ul> <p>\u81ea\u5b9a\u4e49\u6570\u636e\u76ee\u5f55\uff1a</p> <pre><code># \u5728\u4efb\u52a1\u4e2d\u6307\u5b9a\u6570\u636e\u76ee\u5f55\uff08\u63a8\u8350\uff09\ntask = ScientificRegressionTask(\n    dataset_name=\"bactgrow\",\n    data_dir='./my_data'  # \u9996\u6b21\u8fd0\u884c\u65f6\u81ea\u52a8\u4e0b\u8f7d\u5230\u6b64\u76ee\u5f55\n)\n</code></pre>"},{"location":"zh/tutorials/built-in/scientific-regression/#_5","title":"\u793a\u4f8b\uff1a\u7ec6\u83cc\u751f\u957f\u5efa\u6a21","text":""},{"location":"zh/tutorials/built-in/scientific-regression/#1","title":"\u6b65\u9aa4 1: \u521b\u5efa\u4efb\u52a1","text":"<pre><code>from evotoolkit.task.python_task.scientific_regression import ScientificRegressionTask\n\n# \u4e3a\u7ec6\u83cc\u751f\u957f\u6570\u636e\u96c6\u521b\u5efa\u4efb\u52a1\ntask = ScientificRegressionTask(\n    dataset_name=\"bactgrow\",\n    max_params=10,          # \u53ef\u4f18\u5316\u53c2\u6570\u6570\u91cf\n    timeout_seconds=60.0    # \u6bcf\u6b21\u8bc4\u4f30\u8d85\u65f6\u65f6\u95f4\n)\n\nprint(f\"\u6570\u636e\u96c6: {task.dataset_name}\")\nprint(f\"\u8bad\u7ec3\u96c6\u5927\u5c0f: {task.task_info['train_size']}\")\nprint(f\"\u6d4b\u8bd5\u96c6\u5927\u5c0f: {task.task_info['test_size']}\")\n</code></pre> <p>\u8f93\u51fa: <pre><code>\u6570\u636e\u96c6: bactgrow\n\u8bad\u7ec3\u96c6\u5927\u5c0f: 7500\n\u6d4b\u8bd5\u96c6\u5927\u5c0f: 2500\n\u8f93\u5165\u6570\u91cf: 4\n</code></pre></p>"},{"location":"zh/tutorials/built-in/scientific-regression/#2","title":"\u6b65\u9aa4 2: \u7406\u89e3\u4efb\u52a1","text":"<p>\u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u4efb\u52a1\u7684\u76ee\u6807\u662f \u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u6570\u5b66\u65b9\u7a0b \u3002\u5bf9\u4e8e\u7ec6\u83cc\u751f\u957f\u6570\u636e\u96c6\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230\u4e00\u4e2a\u51fd\u6570\u6765\u9884\u6d4b\u751f\u957f\u7387\u3002</p> <p>\u51fd\u6570\u7b7e\u540d\uff1a <code>equation(b, s, temp, pH, params) -&gt; growth_rate</code></p> <p>\u8f93\u5165\u53d8\u91cf\uff1a</p> <ul> <li><code>b</code>: \u79cd\u7fa4\u5bc6\u5ea6</li> <li><code>s</code>: \u5e95\u7269\u6d53\u5ea6</li> <li><code>temp</code>: \u6e29\u5ea6</li> <li><code>pH</code>: pH \u503c</li> <li><code>params</code>: \u53ef\u4f18\u5316\u5e38\u6570\u6570\u7ec4 (params[0] \u5230 params[9])</li> </ul> <p>\u8bc4\u4f30\u6d41\u7a0b\uff1a</p> <ol> <li>\u60a8\u63d0\u4f9b\u65b9\u7a0b\u7684\u7ed3\u6784\uff08\u5982 <code>params[0] * s / (params[1] + s)</code>\uff09</li> <li>\u6846\u67b6\u4f7f\u7528 <code>scipy.optimize.minimize</code> \u81ea\u52a8\u4f18\u5316\u53c2\u6570\u503c</li> <li>\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8ba1\u7b97 MSE\uff08\u5747\u65b9\u8bef\u5dee\uff09\u4f5c\u4e3a\u9002\u5e94\u5ea6\uff08\u8d8a\u4f4e\u8d8a\u597d\uff09</li> </ol>"},{"location":"zh/tutorials/built-in/scientific-regression/#3","title":"\u6b65\u9aa4 3: \u4f7f\u7528\u521d\u59cb\u89e3\u6d4b\u8bd5","text":"<pre><code># \u83b7\u53d6\u521d\u59cb\u89e3\uff08\u7b80\u5355\u7ebf\u6027\u6a21\u578b\uff09\ninit_sol = task.make_init_sol_wo_other_info()\n\nprint(\"\u521d\u59cb\u89e3\u4ee3\u7801:\")\nprint(init_sol.sol_string)\n\n# \u8bc4\u4f30\u5b83\nresult = task.evaluate_code(init_sol.sol_string)\nprint(f\"\u5f97\u5206: {result.score:.6f}\")\nprint(f\"\u6d4b\u8bd5 MSE: {result.additional_info['test_mse']:.6f}\")\n</code></pre> <p>\u8f93\u51fa: <pre><code>\u521d\u59cb\u89e3\u4ee3\u7801:\nimport numpy as np\n\ndef equation(b, s, temp, pH, params):\n    \"\"\"\u7ebf\u6027\u57fa\u51c6\u6a21\u578b\u3002\"\"\"\n    return params[0] * b + params[1] * s + params[2] * temp + params[3] * pH + params[4]\n\n\u5f97\u5206: 0.017200\n\u6d4b\u8bd5 MSE: 0.017200\n</code></pre></p>"},{"location":"zh/tutorials/built-in/scientific-regression/#4","title":"\u6b65\u9aa4 4: \u5c1d\u8bd5\u81ea\u5b9a\u4e49\u521d\u59cb\u89e3","text":"<p>\u60a8\u53ef\u4ee5\u63d0\u4f9b\u81ea\u5b9a\u4e49\u7684\u521d\u59cb\u65b9\u7a0b\u4f5c\u4e3a\u8fdb\u5316\u7684\u8d77\u70b9\u3002\u4f8b\u5982\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u751f\u7269\u5b66\u673a\u5236\u7684\u590d\u6742\u6a21\u578b\uff1a</p> <pre><code>custom_code = '''import numpy as np\n\ndef equation(b, s, temp, pH, params):\n    \"\"\"\u5177\u6709\u751f\u7269\u5b66\u673a\u5236\u7684\u975e\u7ebf\u6027\u7ec6\u83cc\u751f\u957f\u6a21\u578b\u3002\"\"\"\n\n    # Monod \u65b9\u7a0b\u7528\u4e8e\u5e95\u7269\u9650\u5236\n    growth_rate = params[0] * s / (params[1] + s)\n\n    # \u9ad8\u65af\u6e29\u5ea6\u6548\u5e94\n    optimal_temp = params[4]\n    temp_effect = params[2] * np.exp(-params[3] * (temp - optimal_temp)**2)\n\n    # \u9ad8\u65af pH \u6548\u5e94\n    optimal_pH = params[7]\n    pH_effect = params[5] * np.exp(-params[6] * (pH - optimal_pH)**2)\n\n    # \u5e26\u73af\u5883\u5bb9\u91cf\u7684 logistic \u751f\u957f\n    carrying_capacity = params[9]\n    density_limit = params[8] * (1 - b / carrying_capacity)\n\n    return growth_rate * temp_effect * pH_effect * density_limit\n'''\n\nresult = task.evaluate_code(custom_code)\nprint(f\"\u81ea\u5b9a\u4e49\u6a21\u578b\u5f97\u5206: {result.score:.6f}\")\nprint(f\"\u6d4b\u8bd5 MSE: {result.additional_info['test_mse']:.6f}\")\n</code></pre> <p>\u8f93\u51fa: <pre><code>\u81ea\u5b9a\u4e49\u6a21\u578b\u5f97\u5206: 0.021515\n\u6d4b\u8bd5 MSE: 0.021515\n</code></pre></p> <p>\u5173\u4e8e\u521d\u59cb\u89e3</p> <p>\u6ce8\u610f\uff1a\u5728\u8fd9\u91cc\u7f16\u5199\u7684\u4efb\u4f55\u81ea\u5b9a\u4e49\u65b9\u7a0b\u53ea\u662f\u4f5c\u4e3a \u521d\u59cb\u5316\u89e3\u3002\u8fdb\u5316\u7b97\u6cd5\u5c06\u4f7f\u7528 LLM \u4ece\u8fd9\u4e2a\u8d77\u70b9\u5f00\u59cb\u751f\u6210\u548c\u6539\u8fdb\u65b9\u7a0b\u3002\u6700\u7ec8\u7684\u8fdb\u5316\u7ed3\u679c\u53d6\u51b3\u4e8e\u6240\u9009\u7684\u8fdb\u5316\u65b9\u6cd5\u53ca\u5176\u5185\u90e8 prompt \u8bbe\u8ba1\u3002</p>"},{"location":"zh/tutorials/built-in/scientific-regression/#5-evoengineer","title":"\u6b65\u9aa4 5: \u4f7f\u7528 EvoEngineer \u8fd0\u884c\u8fdb\u5316","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools.llm import HttpsApi\nimport os\n\n# \u4e3a EvoEngineer \u521b\u5efa\u63a5\u53e3\ninterface = EvoEngineerPythonInterface(task)\n\n# \u914d\u7f6e LLM API\nllm_api = HttpsApi(\n    api_url=\"https://api.openai.com/v1/chat/completions\",\n    key=\"your-api-key-here\",\n    model=\"gpt-4o\"\n)\n\n# \u8fd0\u884c\u8fdb\u5316\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./scientific_regression_results',\n    running_llm=llm_api,\n    max_generations=5,\n    pop_size=10\n)\n\nprint(f\"\u627e\u5230\u6700\u4f73\u89e3\uff01\")\nprint(f\"\u5f97\u5206: {result['best_solution'].evaluation_res.score:.6f}\")\nprint(f\"\u4ee3\u7801:\\n{result['best_solution'].sol_string}\")\n</code></pre> <p>\u5c1d\u8bd5\u5176\u4ed6\u7b97\u6cd5</p> <p>EvoToolkit \u652f\u6301\u591a\u79cd\u8fdb\u5316\u7b97\u6cd5\u3002\u53ea\u9700\u66f4\u6362 Interface \u5373\u53ef\uff1a</p> <pre><code># \u4f7f\u7528 EoH\nfrom evotoolkit.task.python_task import EoHPythonInterface\ninterface = EoHPythonInterface(task)\n\n# \u4f7f\u7528 FunSearch\nfrom evotoolkit.task.python_task import FunSearchPythonInterface\ninterface = FunSearchPythonInterface(task)\n</code></pre> <p>\u7136\u540e\u4f7f\u7528\u76f8\u540c\u7684 <code>evotoolkit.solve()</code> \u8c03\u7528\u8fd0\u884c\u8fdb\u5316\u3002\u4e0d\u540c\u7b97\u6cd5\u53ef\u80fd\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u540c\uff0c\u5efa\u8bae\u591a\u5c1d\u8bd5\u5bf9\u6bd4\u3002</p>"},{"location":"zh/tutorials/built-in/scientific-regression/#_6","title":"\u81ea\u5b9a\u4e49\u8fdb\u5316\u884c\u4e3a","text":"<p>\u8fdb\u5316\u8fc7\u7a0b\u7684\u8d28\u91cf\u4e3b\u8981\u7531 \u8fdb\u5316\u65b9\u6cd5 \u53ca\u5176\u5185\u90e8 prompt \u8bbe\u8ba1 \u63a7\u5236\u3002\u5982\u679c\u60a8\u60f3\u6539\u8fdb\u7ed3\u679c\uff1a</p> <ul> <li>\u8c03\u6574 prompt: \u7ee7\u627f\u73b0\u6709 Interface \u7c7b\u5e76\u81ea\u5b9a\u4e49 LLM prompt</li> <li>\u5f00\u53d1\u65b0\u7b97\u6cd5: \u521b\u5efa\u5168\u65b0\u7684\u8fdb\u5316\u7b56\u7565\u548c\u64cd\u4f5c\u7b26</li> </ul> <p>\u6df1\u5165\u5b66\u4e60</p> <p>\u8fd9\u4e9b\u662f\u9002\u7528\u4e8e\u6240\u6709\u4efb\u52a1\u7684\u901a\u7528\u6280\u672f\u3002\u8be6\u7ec6\u6559\u7a0b\u8bf7\u53c2\u9605\uff1a</p> <ul> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u5982\u4f55\u4fee\u6539 prompt \u548c\u5f00\u53d1\u65b0\u7b97\u6cd5</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u66f4\u591a\u9ad8\u7ea7\u914d\u7f6e\u9009\u9879</li> </ul> <p>\u5feb\u901f\u793a\u4f8b - \u4e3a\u79d1\u5b66\u56de\u5f52\u81ea\u5b9a\u4e49 prompt:</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\n\nclass ScientificRegressionInterface(EvoEngineerPythonInterface):\n    \"\"\"\u9488\u5bf9\u79d1\u5b66\u65b9\u7a0b\u53d1\u73b0\u4f18\u5316\u7684 Interface\uff0c\u4e3a mutation \u7b97\u5b50\u81ea\u5b9a\u4e49 prompt\"\"\"\n\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        \"\"\"\u81ea\u5b9a\u4e49 mutation \u7b97\u5b50\u7684 prompt\uff0c\u5f3a\u8c03\u7269\u7406/\u751f\u7269\u5b66\u539f\u7406\"\"\"\n\n        if operator_name == \"mutation\":\n            task_description = self.task.get_base_task_description()\n            prompt = f\"\"\"\u4f60\u662f\u4e00\u4e2a\u79d1\u5b66\u65b9\u7a0b\u53d1\u73b0\u4e13\u5bb6\u3002\n\n\u4efb\u52a1: {task_description}\n\n\u5f53\u524d\u6700\u4f73\u65b9\u7a0b (\u5f97\u5206: {current_best_sol.evaluation_res.score:.5f}):\n{current_best_sol.sol_string}\n\n\u8981\u6c42: \u751f\u6210\u6539\u8fdb\u7684\u65b9\u7a0b\uff0c\u5fc5\u987b\u57fa\u4e8e\u5df2\u77e5\u7269\u7406/\u751f\u7269\u5b66\u539f\u7406\uff08\u5982Monod\u65b9\u7a0b\u3001Arrhenius\u65b9\u7a0b\u7b49\uff09\u3002\n\u786e\u4fdd\u6570\u503c\u7a33\u5b9a\u6027\u548c\u6a21\u578b\u7b80\u6d01\u6027\u3002\n\n\u8f93\u51fa\u683c\u5f0f:\n- name: \u65b9\u7a0b\u540d\u79f0\n- code: Python\u4ee3\u7801\n- thought: \u6539\u8fdb\u601d\u8def\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # init \u548c crossover \u7b97\u5b50\u4f7f\u7528\u7236\u7c7b\u7684\u9ed8\u8ba4 prompt\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49 Interface\ninterface = ScientificRegressionInterface(task)\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=5\n)\n</code></pre> <p>\u5173\u4e8e EvoEngineer \u7684\u7b97\u5b50</p> <p>EvoEngineer \u4f7f\u7528\u4e09\u4e2a\u7b97\u5b50\uff1ainit\uff08\u521d\u59cb\u5316\uff09\u3001mutation\uff08\u53d8\u5f02\uff09\u3001crossover\uff08\u4ea4\u53c9\uff09\u3002 \u7236\u7c7b <code>EvoEngineerPythonInterface</code> \u5df2\u7ecf\u5b9a\u4e49\u4e86\u8fd9\u4e9b\u7b97\u5b50\u548c\u9ed8\u8ba4 prompt\u3002 \u4f60\u53ea\u9700\u91cd\u5199 <code>get_operator_prompt()</code> \u6765\u81ea\u5b9a\u4e49\u7279\u5b9a\u7b97\u5b50\u7684 prompt\uff0c\u5176\u4ed6\u7b97\u5b50\u4f1a\u81ea\u52a8\u4f7f\u7528\u9ed8\u8ba4\u5b9e\u73b0\u3002</p> <p>\u5b8c\u6574\u7684\u81ea\u5b9a\u4e49\u6559\u7a0b\u548c\u66f4\u591a\u793a\u4f8b\uff0c\u8bf7\u53c2\u9605 \u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5\u3002</p>"},{"location":"zh/tutorials/built-in/scientific-regression/#_7","title":"\u7406\u89e3\u8bc4\u4f30","text":""},{"location":"zh/tutorials/built-in/scientific-regression/#_8","title":"\u8bc4\u5206\u5de5\u4f5c\u539f\u7406","text":"<ol> <li>\u53c2\u6570\u4f18\u5316: \u901a\u8fc7\u4f7f\u7528 BFGS \u65b9\u6cd5\u7684 <code>scipy.optimize.minimize</code> \u4f18\u5316\u53c2\u6570\u6765\u8bc4\u4f30\u65b9\u7a0b\u7ed3\u6784</li> <li>MSE \u8ba1\u7b97: \u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5747\u65b9\u8bef\u5dee</li> <li>\u9002\u5e94\u5ea6: \u8d1f MSE\uff08\u8d8a\u9ad8\u8d8a\u597d\uff0c\u56e0\u6b64\u8d8a\u4f4e\u7684 MSE = \u8d8a\u9ad8\u7684\u9002\u5e94\u5ea6\uff09</li> </ol>"},{"location":"zh/tutorials/built-in/scientific-regression/#_9","title":"\u8bc4\u4f30\u8f93\u51fa","text":"<pre><code>result = task.evaluate_code(code)\n\nif result.valid:\n    print(f\"\u5f97\u5206: {result.score}\")                           # \u8d8a\u9ad8\u8d8a\u597d\n    print(f\"\u8bad\u7ec3 MSE: {result.additional_info['train_mse']}\")  # \u8bad\u7ec3\u6570\u636e\u4e0a\n    print(f\"\u6d4b\u8bd5 MSE: {result.additional_info['test_mse']}\")    # \u6d4b\u8bd5\u6570\u636e\u4e0a\uff08\u7528\u4e8e\u9002\u5e94\u5ea6\uff09\nelse:\n    print(f\"\u9519\u8bef: {result.additional_info['error']}\")\n</code></pre>"},{"location":"zh/tutorials/built-in/scientific-regression/#_10","title":"\u4e0b\u4e00\u6b65","text":""},{"location":"zh/tutorials/built-in/scientific-regression/#_11","title":"\u63a2\u7d22\u4e0d\u540c\u7684\u4efb\u52a1\u548c\u65b9\u6cd5","text":"<ul> <li>\u5c1d\u8bd5\u4e0d\u540c\u7684\u6570\u636e\u96c6\uff08oscillator1\u3001oscillator2\u3001stressstrain\uff09</li> <li>\u6bd4\u8f83\u4e0d\u540c\u8fdb\u5316\u65b9\u6cd5\uff08EvoEngineer\u3001EoH\u3001FunSearch\uff09\u7684\u7ed3\u679c</li> <li>\u53ef\u89c6\u5316\u9884\u6d4b\u4e0e\u771f\u5b9e\u503c</li> </ul>"},{"location":"zh/tutorials/built-in/scientific-regression/#_12","title":"\u81ea\u5b9a\u4e49\u548c\u6539\u8fdb\u8fdb\u5316\u8fc7\u7a0b","text":"<ul> <li>\u68c0\u67e5\u73b0\u6709 Interface \u7c7b\u7684 prompt \u8bbe\u8ba1</li> <li>\u7ee7\u627f\u5e76\u91cd\u5199 Interface \u6765\u81ea\u5b9a\u4e49 prompt</li> <li>\u4e3a\u4e0d\u540c\u64cd\u4f5c\u7b26\uff08init/mutation/crossover\uff09\u8bbe\u8ba1\u4e13\u95e8\u7684 prompt</li> <li>\u5982\u6709\u9700\u8981\uff0c\u5f00\u53d1\u5168\u65b0\u7684\u8fdb\u5316\u7b97\u6cd5</li> </ul>"},{"location":"zh/tutorials/built-in/scientific-regression/#_13","title":"\u66f4\u591a\u5b66\u4e60\u8d44\u6e90","text":"<ul> <li>\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5 - \u6df1\u5165\u5b66\u4e60 prompt \u81ea\u5b9a\u4e49\u548c\u7b97\u6cd5\u5f00\u53d1</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u8fdb\u9636\u914d\u7f6e\u548c\u6280\u5de7</li> <li>API \u53c2\u8003 - \u5b8c\u6574\u7684 API \u6587\u6863</li> <li>\u5f00\u53d1\u6587\u6863 - \u8d21\u732e\u65b0\u65b9\u6cd5\u548c\u7279\u6027</li> </ul>"},{"location":"zh/tutorials/customization/custom-task/","title":"\u81ea\u5b9a\u4e49\u4efb\u52a1\u6559\u7a0b","text":"<p>\u5b66\u4e60\u5982\u4f55\u5728 EvoToolkit \u4e2d\u521b\u5efa\u81ea\u5df1\u7684\u4f18\u5316\u4efb\u52a1\u3002</p>"},{"location":"zh/tutorials/customization/custom-task/#_2","title":"\u6982\u8ff0","text":"<p>\u672c\u6559\u7a0b\u5c06\u5411\u60a8\u5c55\u793a\u5982\u4f55\uff1a</p> <ul> <li>\u6269\u5c55 <code>PythonTask</code> \u57fa\u7c7b</li> <li>\u5b9e\u73b0\u81ea\u5b9a\u4e49\u8bc4\u4f30\u903b\u8f91</li> <li>\u5c06\u81ea\u5b9a\u4e49\u4efb\u52a1\u4e0e\u8fdb\u5316\u7b97\u6cd5\u4e00\u8d77\u4f7f\u7528</li> </ul> <p>\u5b8c\u6574\u793a\u4f8b\u4ee3\u7801</p> <p>\u672c\u6559\u7a0b\u63d0\u4f9b\u5b8c\u6574\u53ef\u8fd0\u884c\u7684\u793a\u4f8b\uff08\u70b9\u51fb\u67e5\u770b/\u4e0b\u8f7d\uff09\uff1a</p> <ul> <li> my_custom_task.py - \u5b8c\u6574\u7684\u81ea\u5b9a\u4e49\u4efb\u52a1\u793a\u4f8b</li> </ul> <p>\u672c\u5730\u8fd0\u884c\uff1a <pre><code>cd examples/custom_task\npython my_custom_task.py\n</code></pre></p>"},{"location":"zh/tutorials/customization/custom-task/#_3","title":"\u524d\u7f6e\u6761\u4ef6","text":"<ul> <li>\u5b8c\u6210 \u79d1\u5b66\u7b26\u53f7\u56de\u5f52\u6559\u7a0b</li> <li>\u7406\u89e3 Python \u7c7b\u548c\u7ee7\u627f</li> </ul>"},{"location":"zh/tutorials/customization/custom-task/#_4","title":"\u521b\u5efa\u81ea\u5b9a\u4e49\u4efb\u52a1","text":""},{"location":"zh/tutorials/customization/custom-task/#1","title":"\u6b65\u9aa4 1: \u5b9a\u4e49\u4efb\u52a1\u7c7b","text":"<pre><code>from evotoolkit.task.python_task import PythonTask\nfrom evotoolkit.core import Solution, EvaluationResult\nimport numpy as np\n\nclass MyOptimizationTask(PythonTask):\n    \"\"\"\u7279\u5b9a\u95ee\u9898\u4f18\u5316\u7684\u81ea\u5b9a\u4e49\u4efb\u52a1\"\"\"\n\n    def __init__(self, data, target, timeout_seconds=30.0):\n        \"\"\"\n        \u4f7f\u7528\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u6570\u636e\u521d\u59cb\u5316\u4efb\u52a1\n\n        Args:\n            data: \u8f93\u5165\u6570\u636e\uff08NumPy \u6570\u7ec4\uff09\n            target: \u76ee\u6807\u8f93\u51fa\u503c\uff08NumPy \u6570\u7ec4\uff09\n            timeout_seconds: \u4ee3\u7801\u6267\u884c\u8d85\u65f6\u65f6\u95f4\uff08\u79d2\uff09\n        \"\"\"\n        self.target = target\n        super().__init__(data, timeout_seconds)\n\n    def _process_data(self, data):\n        \"\"\"\u5904\u7406\u8f93\u5165\u6570\u636e\u5e76\u521b\u5efa task_info\"\"\"\n        self.data = data\n        self.task_info = {\n            'data_size': len(data),\n            'description': '\u51fd\u6570\u8fd1\u4f3c\u4efb\u52a1'\n        }\n\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"\u8bc4\u4f30\u5019\u9009\u4ee3\u7801\u5e76\u8fd4\u56de\u8bc4\u4f30\u7ed3\u679c\"\"\"\n        # 1. \u6267\u884c\u4ee3\u7801\n        namespace = {'np': np}\n        exec(candidate_code, namespace)\n\n        # 2. \u68c0\u67e5\u51fd\u6570\u662f\u5426\u5b58\u5728\n        if 'my_function' not in namespace:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': 'Function \"my_function\" not found'}\n            )\n\n        evolved_func = namespace['my_function']\n\n        # 3. \u8ba1\u7b97\u9002\u5e94\u5ea6\uff08score \u8d8a\u9ad8\u8d8a\u597d\uff09\n        predictions = np.array([evolved_func(x) for x in self.data])\n        mse = np.mean((predictions - self.target) ** 2)\n        score = -mse  # \u8d1f MSE\uff0c\u8d8a\u9ad8\u8d8a\u597d\n\n        return EvaluationResult(\n            valid=True,\n            score=score,\n            additional_info={'mse': mse}\n        )\n\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"\u83b7\u53d6\u4efb\u52a1\u63cf\u8ff0\u4f9b prompt \u751f\u6210\u4f7f\u7528\"\"\"\n        return \"\"\"\u4f60\u662f\u51fd\u6570\u8fd1\u4f3c\u4e13\u5bb6\u3002\n\n\u4efb\u52a1\uff1a\u521b\u5efa\u4e00\u4e2a\u51fd\u6570 my_function(x)\uff0c\u4f7f\u5176\u8f93\u51fa\u5c3d\u53ef\u80fd\u63a5\u8fd1\u76ee\u6807\u503c\u3002\n\n\u8981\u6c42\uff1a\n- \u5b9a\u4e49\u51fd\u6570 my_function(x: float) -&gt; float\n- \u4f7f\u7528\u6570\u5b66\u8fd0\u7b97\uff1a+, -, *, /, **, np.exp, np.log, np.sin, np.cos \u7b49\n- \u786e\u4fdd\u6570\u503c\u7a33\u5b9a\u6027\n\n\u793a\u4f8b\u4ee3\u7801\uff1a\n    import numpy as np\n\n    def my_function(x):\n        return np.sin(x)\n\"\"\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"\u521b\u5efa\u521d\u59cb\u89e3\"\"\"\n        initial_code = '''import numpy as np\n\ndef my_function(x):\n    \"\"\"\u7b80\u5355\u7ebf\u6027\u51fd\u6570\u4f5c\u4e3a\u57fa\u7ebf\"\"\"\n    return x\n'''\n        eval_res = self.evaluate_code(initial_code)\n        return Solution(\n            sol_string=initial_code,\n            evaluation_res=eval_res\n        )\n</code></pre> <p>\u5173\u952e\u70b9\uff1a</p> <ul> <li>\u7ee7\u627f <code>PythonTask</code> \u800c\u4e0d\u662f\u76f4\u63a5\u7ee7\u627f <code>BaseTask</code></li> <li>\u5b9e\u73b0 <code>_evaluate_code_impl()</code> \u8fd4\u56de <code>EvaluationResult</code> \u5bf9\u8c61</li> <li>\u5b9e\u73b0 <code>get_base_task_description()</code> \u63d0\u4f9b\u4efb\u52a1\u63cf\u8ff0</li> <li>\u5b9e\u73b0 <code>make_init_sol_wo_other_info()</code> \u521b\u5efa\u521d\u59cb\u89e3</li> <li>\u4f7f\u7528 <code>_process_data()</code> \u8bbe\u7f6e <code>task_info</code></li> <li><code>score</code> \u8d8a\u9ad8\u8d8a\u597d\uff08\u4f7f\u7528\u8d1f MSE\uff09</li> </ul>"},{"location":"zh/tutorials/customization/custom-task/#2","title":"\u6b65\u9aa4 2: \u4f7f\u7528\u81ea\u5b9a\u4e49\u4efb\u52a1","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.tools.llm import HttpsApi\nimport numpy as np\nimport os\n\n# \u521b\u5efa\u4efb\u52a1\u5b9e\u4f8b\ndata = np.linspace(0, 10, 50)\ntarget = np.sin(data)  # \u76ee\u6807\uff1a\u8fd1\u4f3c\u6b63\u5f26\u51fd\u6570\n\ntask = MyOptimizationTask(data, target)\n\n# \u521b\u5efa\u63a5\u53e3\ninterface = EvoEngineerPythonInterface(task)\n\n# \u8bbe\u7f6e LLM\nllm_api = HttpsApi(\n    api_url=os.environ.get(\"LLM_API_URL\", \"https://api.openai.com/v1/chat/completions\"),\n    key=os.environ.get(\"LLM_API_KEY\", \"your-api-key-here\"),\n    model=\"gpt-4o\"\n)\n\n# \u6c42\u89e3\nresult = evotoolkit.solve(\n    interface=interface,\n    output_path='./results/custom_task',\n    running_llm=llm_api,\n    max_generations=10\n)\n\nprint(f\"\u6700\u4f73\u5f97\u5206: {result.evaluation_res.score:.4f}\")\nprint(f\"\u6700\u4f73 MSE: {result.evaluation_res.additional_info['mse']:.4f}\")\n</code></pre>"},{"location":"zh/tutorials/customization/custom-task/#_5","title":"\u793a\u4f8b\uff1a\u5b57\u7b26\u4e32\u5339\u914d\u4efb\u52a1","text":"<pre><code>from evotoolkit.task.python_task import PythonTask\nfrom evotoolkit.core import Solution, EvaluationResult\n\nclass StringMatchTask(PythonTask):\n    \"\"\"\u8fdb\u5316\u751f\u6210\u76ee\u6807\u5b57\u7b26\u4e32\u7684\u51fd\u6570\u7684\u4efb\u52a1\"\"\"\n\n    def __init__(self, target_string, timeout_seconds=30.0):\n        self.target = target_string\n        super().__init__(data={'target': target_string}, timeout_seconds=timeout_seconds)\n\n    def _process_data(self, data):\n        \"\"\"\u5904\u7406\u8f93\u5165\u6570\u636e\"\"\"\n        self.data = data\n        self.task_info = {\n            'target': self.target,\n            'target_length': len(self.target)\n        }\n\n    def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n        \"\"\"\u8bc4\u4f30\u4ee3\u7801\"\"\"\n        namespace = {}\n        exec(candidate_code, namespace)\n\n        if 'generate_string' not in namespace:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': 'Function \"generate_string\" not found'}\n            )\n\n        try:\n            generated = namespace['generate_string']()\n            # \u7f16\u8f91\u8ddd\u79bb\u8d8a\u5c0f\u8d8a\u597d\uff0c\u6240\u4ee5\u7528\u8d1f\u503c\u4f5c\u4e3a score\n            distance = self.levenshtein_distance(generated, self.target)\n            score = -distance  # \u8d8a\u9ad8\u8d8a\u597d\n\n            return EvaluationResult(\n                valid=True,\n                score=score,\n                additional_info={'distance': distance, 'generated': generated}\n            )\n        except Exception as e:\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': str(e)}\n            )\n\n    def levenshtein_distance(self, s1, s2):\n        \"\"\"\u8ba1\u7b97 Levenshtein \u7f16\u8f91\u8ddd\u79bb\"\"\"\n        if len(s1) &lt; len(s2):\n            return self.levenshtein_distance(s2, s1)\n        if len(s2) == 0:\n            return len(s1)\n\n        previous_row = range(len(s2) + 1)\n        for i, c1 in enumerate(s1):\n            current_row = [i + 1]\n            for j, c2 in enumerate(s2):\n                insertions = previous_row[j + 1] + 1\n                deletions = current_row[j] + 1\n                substitutions = previous_row[j] + (c1 != c2)\n                current_row.append(min(insertions, deletions, substitutions))\n            previous_row = current_row\n\n        return previous_row[-1]\n\n    def get_base_task_description(self) -&gt; str:\n        \"\"\"\u4efb\u52a1\u63cf\u8ff0\"\"\"\n        return f\"\"\"\u4f60\u662f\u5b57\u7b26\u4e32\u751f\u6210\u4e13\u5bb6\u3002\n\n\u4efb\u52a1\uff1a\u521b\u5efa\u4e00\u4e2a\u51fd\u6570 generate_string()\uff0c\u751f\u6210\u76ee\u6807\u5b57\u7b26\u4e32 \"{self.target}\"\u3002\n\n\u8981\u6c42\uff1a\n- \u5b9a\u4e49\u51fd\u6570 generate_string() -&gt; str\n- \u51fd\u6570\u5e94\u8fd4\u56de\u4e0e\u76ee\u6807\u5b57\u7b26\u4e32\u5c3d\u53ef\u80fd\u63a5\u8fd1\u7684\u5b57\u7b26\u4e32\n\n\u793a\u4f8b\u4ee3\u7801\uff1a\n    def generate_string():\n        return \"Hello, World!\"\n\"\"\"\n\n    def make_init_sol_wo_other_info(self) -&gt; Solution:\n        \"\"\"\u521b\u5efa\u521d\u59cb\u89e3\"\"\"\n        initial_code = f'''def generate_string():\n    \"\"\"\u521d\u59cb\u7b80\u5355\u5b9e\u73b0\"\"\"\n    return \"\"\n'''\n        eval_res = self.evaluate_code(initial_code)\n        return Solution(\n            sol_string=initial_code,\n            evaluation_res=eval_res\n        )\n</code></pre> <p>\u7528\u6cd5:</p> <pre><code>task = StringMatchTask(\"Hello, EvoToolkit!\")\ninterface = EvoEngineerPythonInterface(task)\nresult = evotoolkit.solve(interface, './results', llm_api)\nprint(f\"\u751f\u6210\u7684\u5b57\u7b26\u4e32: {result.evaluation_res.additional_info['generated']}\")\n</code></pre>"},{"location":"zh/tutorials/customization/custom-task/#_6","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"zh/tutorials/customization/custom-task/#1_1","title":"1. \u5065\u58ee\u7684\u9519\u8bef\u5904\u7406","text":"<pre><code>def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n    \"\"\"\u5728 _evaluate_code_impl \u4e2d\u5b9e\u73b0\u5065\u58ee\u7684\u9519\u8bef\u5904\u7406\"\"\"\n    try:\n        # \u6267\u884c\u548c\u8bc4\u4f30\u903b\u8f91\n        namespace = {}\n        exec(candidate_code, namespace)\n        # ... \u8bc4\u4f30\u903b\u8f91 ...\n\n        return EvaluationResult(\n            valid=True,\n            score=score,\n            additional_info={}\n        )\n    except SyntaxError as e:\n        return EvaluationResult(\n            valid=False,\n            score=float('-inf'),\n            additional_info={'error': f'Syntax error: {str(e)}'}\n        )\n    except Exception as e:\n        return EvaluationResult(\n            valid=False,\n            score=float('-inf'),\n            additional_info={'error': f'Evaluation error: {str(e)}'}\n        )\n</code></pre> <p>\u6ce8\u610f\uff1a PythonTask \u7684\u7236\u7c7b\u65b9\u6cd5 <code>evaluate_code()</code> \u5df2\u7ecf\u63d0\u4f9b\u4e86\u8d85\u65f6\u63a7\u5236\uff0c\u5728\u6784\u9020\u51fd\u6570\u4e2d\u8bbe\u7f6e <code>timeout_seconds</code> \u53c2\u6570\u5373\u53ef\u3002</p>"},{"location":"zh/tutorials/customization/custom-task/#2_1","title":"2. \u9a8c\u8bc1\u89e3\u8f93\u51fa","text":"<pre><code>def _evaluate_code_impl(self, candidate_code: str) -&gt; EvaluationResult:\n    \"\"\"\u9a8c\u8bc1\u51fd\u6570\u8f93\u51fa\u7684\u7c7b\u578b\u548c\u8303\u56f4\"\"\"\n    namespace = {}\n    exec(candidate_code, namespace)\n\n    evolved_func = namespace['my_function']\n    result = evolved_func(test_input)\n\n    # \u9a8c\u8bc1\u7c7b\u578b\n    if not isinstance(result, (int, float, np.ndarray)):\n        return EvaluationResult(\n            valid=False,\n            score=float('-inf'),\n            additional_info={'error': 'Invalid output type'}\n        )\n\n    # \u9a8c\u8bc1\u8303\u56f4\n    if isinstance(result, np.ndarray):\n        if np.any(np.isnan(result)) or np.any(np.isinf(result)):\n            return EvaluationResult(\n                valid=False,\n                score=float('-inf'),\n                additional_info={'error': 'Output contains NaN or Inf'}\n            )\n\n    # \u8ba1\u7b97\u9002\u5e94\u5ea6\n    score = -abs(result - expected)  # \u8d1f\u8bef\u5dee\uff0c\u8d8a\u9ad8\u8d8a\u597d\n    return EvaluationResult(valid=True, score=score, additional_info={})\n</code></pre>"},{"location":"zh/tutorials/customization/custom-task/#3-task_info","title":"3. \u4f7f\u7528 task_info \u5b58\u50a8\u4efb\u52a1\u5143\u6570\u636e","text":"<pre><code>def _process_data(self, data):\n    \"\"\"\u5728 task_info \u4e2d\u5b58\u50a8\u91cd\u8981\u7684\u4efb\u52a1\u5143\u6570\u636e\"\"\"\n    self.data = data\n    self.task_info = {\n        'data_size': len(data),\n        'input_dim': data.shape[1] if len(data.shape) &gt; 1 else 1,\n        'description': '\u81ea\u5b9a\u4e49\u4f18\u5316\u4efb\u52a1',\n        'metric': 'MSE',\n        # \u5176\u4ed6\u6709\u7528\u7684\u5143\u6570\u636e...\n    }\n</code></pre>"},{"location":"zh/tutorials/customization/custom-task/#_7","title":"\u9ad8\u7ea7\uff1a\u81ea\u5b9a\u4e49\u63a5\u53e3","text":"<p>\u5982\u679c\u60a8\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u63a7\u5236\uff0c\u53ef\u4ee5\u4e3a\u4e0d\u540c\u7684\u8fdb\u5316\u65b9\u6cd5\u81ea\u5b9a\u4e49\u63a5\u53e3\uff08Interface\uff09\u3002\u4e0d\u540c\u7684\u65b9\u6cd5\uff08\u5982 EvoEngineer\u3001FunSearch\u3001EoH\uff09\u6709\u5404\u81ea\u7684\u63a5\u53e3\u5b9e\u73b0\uff0c\u5b83\u4eec\u63a7\u5236\u7740 prompt \u751f\u6210\u3001LLM \u54cd\u5e94\u89e3\u6790\u7b49\u884c\u4e3a\u3002</p> <p>\u5982\u9700\u4e86\u89e3\u5982\u4f55\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5\u548c\u63a5\u53e3\uff0c\u8bf7\u53c2\u9605 \u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5\u6559\u7a0b\u3002</p>"},{"location":"zh/tutorials/customization/custom-task/#_8","title":"\u5b8c\u6574\u793a\u4f8b","text":"<p>\u53c2\u89c1 <code>examples/custom_task/my_custom_task.py</code> \u83b7\u53d6\u5b8c\u6574\u7684\u53ef\u8fd0\u884c\u793a\u4f8b\u3002</p>"},{"location":"zh/tutorials/customization/custom-task/#_9","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u5c1d\u8bd5 CUDA \u4efb\u52a1\u6559\u7a0b \u8fdb\u884c GPU \u4f18\u5316</li> <li>\u63a2\u7d22 \u9ad8\u7ea7\u7528\u6cd5 \u4e86\u89e3\u4f4e\u7ea7 API</li> <li>\u67e5\u770b API \u53c2\u8003 \u4e86\u89e3 Task \u7c7b\u8be6\u60c5</li> </ul>"},{"location":"zh/tutorials/customization/customizing-evolution/","title":"\u81ea\u5b9a\u4e49\u8fdb\u5316\u65b9\u6cd5","text":"<p>\u5b66\u4e60\u5982\u4f55\u901a\u8fc7\u4fee\u6539 prompt \u6216\u5f00\u53d1\u5168\u65b0\u7b97\u6cd5\u6765\u81ea\u5b9a\u4e49 EvoToolkit \u4e2d\u7684\u8fdb\u5316\u884c\u4e3a\u3002</p>"},{"location":"zh/tutorials/customization/customizing-evolution/#_2","title":"\u6982\u8ff0","text":"<p>EvoToolkit \u4e2d\u8fdb\u5316\u4f18\u5316\u7684\u8d28\u91cf\u7531\u4ee5\u4e0b\u56e0\u7d20\u63a7\u5236\uff1a</p> <ol> <li>\u8fdb\u5316\u65b9\u6cd5\uff1a\u7b97\u6cd5\u6846\u67b6\uff08EvoEngineer\u3001EoH\u3001FunSearch\uff09</li> <li>Interface\uff1a\u4efb\u52a1\u4e0e\u65b9\u6cd5\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u5305\u542b prompt \u903b\u8f91</li> <li>Prompts\uff1a\u53d1\u9001\u7ed9 LLM \u7684\u6307\u4ee4\uff0c\u7528\u4e8e\u5f15\u5bfc\u89e3\u7684\u751f\u6210</li> </ol> <p>\u672c\u6559\u7a0b\u6db5\u76d6\u4e24\u4e2a\u5c42\u6b21\u7684\u81ea\u5b9a\u4e49\uff1a</p> <ul> <li>\u7ea7\u522b 1\uff1a\u81ea\u5b9a\u4e49 prompt - \u7ee7\u627f\u73b0\u6709 Interface \u5e76\u4fee\u6539 prompt\uff08\u63a8\u8350\uff09</li> <li>\u7ea7\u522b 2\uff1a\u5f00\u53d1\u65b0\u7b97\u6cd5 - \u521b\u5efa\u5168\u65b0\u7684\u8fdb\u5316\u7b56\u7565\uff08\u9ad8\u7ea7\uff09</li> </ul>"},{"location":"zh/tutorials/customization/customizing-evolution/#1-prompt","title":"\u7ea7\u522b 1\uff1a\u81ea\u5b9a\u4e49 Prompt","text":""},{"location":"zh/tutorials/customization/customizing-evolution/#11-interface","title":"1.1 \u7406\u89e3 Interface","text":"<p>\u6bcf\u4e2a\u8fdb\u5316\u65b9\u6cd5\u4f7f\u7528\u4e00\u4e2a Interface \u7c7b\uff0c\u5b83\u8d1f\u8d23\uff1a</p> <ul> <li>\u5b9a\u4e49\u64cd\u4f5c\u7b26\uff08init\u3001mutation\u3001crossover \u7b49\uff09</li> <li>\u901a\u8fc7 <code>get_operator_prompt()</code> \u4e3a\u6bcf\u4e2a\u64cd\u4f5c\u7b26\u751f\u6210 LLM prompt</li> <li>\u5c06 LLM \u54cd\u5e94\u89e3\u6790\u4e3a\u89e3\u51b3\u65b9\u6848</li> </ul> <p>\u53ef\u7528\u7684 Interface\uff1a</p> Interface \u65b9\u6cd5 \u63cf\u8ff0 <code>EvoEngineerPythonInterface</code> EvoEngineer Python \u4efb\u52a1\u7684\u4e3b\u8981 LLM \u9a71\u52a8\u7b97\u6cd5 <code>EoHPythonInterface</code> EoH Python \u4efb\u52a1\u7684\u542f\u53d1\u5f0f\u8fdb\u5316 <code>FunSearchPythonInterface</code> FunSearch Python \u4efb\u52a1\u7684\u51fd\u6570\u641c\u7d22 <code>EvoEngineerCUDAInterface</code> EvoEngineer CUDA \u4ee3\u7801\u8fdb\u5316"},{"location":"zh/tutorials/customization/customizing-evolution/#12-prompt","title":"1.2 \u68c0\u67e5\u73b0\u6709 Prompt","text":"<p>\u5728\u81ea\u5b9a\u4e49\u4e4b\u524d\uff0c\u5148\u67e5\u770b\u73b0\u6709 Interface \u5982\u4f55\u751f\u6210 prompt\uff1a</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\nimport inspect\n\n# \u521b\u5efa\u4e00\u4e2a interface\ninterface = EvoEngineerPythonInterface(task)\n\n# \u67e5\u770b prompt \u751f\u6210\u65b9\u6cd5\u7684\u6e90\u7801\nprint(inspect.getsource(interface.get_operator_prompt))\n</code></pre> <p>\u8fd9\u53ef\u4ee5\u8ba9\u60a8\u770b\u5230\uff1a</p> <ul> <li>prompt \u4e2d\u5305\u542b\u4e86\u54ea\u4e9b\u4fe1\u606f</li> <li>prompt \u7684\u7ed3\u6784\u662f\u600e\u6837\u7684</li> <li>LLM \u9700\u8981\u9075\u5faa\u4ec0\u4e48\u683c\u5f0f</li> </ul>"},{"location":"zh/tutorials/customization/customizing-evolution/#13-interface","title":"1.3 \u521b\u5efa\u81ea\u5b9a\u4e49 Interface","text":"<p>\u8981\u81ea\u5b9a\u4e49 prompt\uff0c\u4ece\u73b0\u6709 Interface \u7ee7\u627f\u5e76\u91cd\u5199 <code>get_operator_prompt()</code>\uff1a</p> <pre><code>from evotoolkit.task.python_task import EvoEngineerPythonInterface\nfrom evotoolkit.core import Solution\nfrom typing import List\n\nclass CustomInterface(EvoEngineerPythonInterface):\n    \"\"\"\u5e26\u6709\u4fee\u6539\u8fc7\u7684 prompt \u7684\u81ea\u5b9a\u4e49 Interface\"\"\"\n\n    def get_operator_prompt(self, operator_name: str,\n                           selected_individuals: List[Solution],\n                           current_best_sol: Solution,\n                           random_thoughts: List[str],\n                           **kwargs) -&gt; List[dict]:\n        \"\"\"\u91cd\u5199\u6b64\u65b9\u6cd5\u6765\u81ea\u5b9a\u4e49\u4efb\u4f55\u64cd\u4f5c\u7b26\u7684 prompt\"\"\"\n\n        # \u83b7\u53d6\u57fa\u7840\u4efb\u52a1\u63cf\u8ff0\n        task_description = self.task.get_base_task_description()\n\n        if operator_name == \"mutation\":\n            # \u81ea\u5b9a\u4e49\u53d8\u5f02 prompt\n            prompt = f\"\"\"\u4f60\u662f\u4e00\u4e2a\u4e13\u5bb6\u4f18\u5316\u5668\u3002\n\u5f53\u524d\u6700\u4f73\u89e3\u5f97\u5206: {current_best_sol.evaluation_res.score:.5f}\n\n\u4f60\u7684\u4efb\u52a1: {task_description}\n\n\u5f53\u524d\u4ee3\u7801:\n{current_best_sol.sol_string}\n\n\u901a\u8fc7\u5e94\u7528\u53d8\u5f02\u751f\u6210\u6539\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\u3002\n\u91cd\u70b9\u5173\u6ce8: [\u5728\u6b64\u6dfb\u52a0\u60a8\u7684\u81ea\u5b9a\u4e49\u8981\u6c42]\n\n\u683c\u5f0f:\n- name: \u63cf\u8ff0\u6027\u540d\u79f0\n- code: [\u5b8c\u6574\u4ee3\u7801]\n- thought: [\u63a8\u7406\u8fc7\u7a0b]\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        elif operator_name == \"crossover\":\n            # \u81ea\u5b9a\u4e49\u4ea4\u53c9 prompt\n            parent1, parent2 = selected_individuals[0], selected_individuals[1]\n            prompt = f\"\"\"\u7ed3\u5408\u8fd9\u4e24\u4e2a\u89e3\u51b3\u65b9\u6848...\n\u7236\u4ee3 1 (\u5f97\u5206 {parent1.evaluation_res.score:.5f}):\n{parent1.sol_string}\n\n\u7236\u4ee3 2 (\u5f97\u5206 {parent2.evaluation_res.score:.5f}):\n{parent2.sol_string}\n\n\u521b\u5efa\u4e00\u4e2a\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u540e\u4ee3...\n\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n\n        # \u5176\u4ed6\u64cd\u4f5c\u7b26\u4f7f\u7528\u9ed8\u8ba4\u5b9e\u73b0\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n\n# \u4f7f\u7528\u60a8\u7684\u81ea\u5b9a\u4e49 Interface\ncustom_interface = CustomInterface(task)\nresult = evotoolkit.solve(\n    interface=custom_interface,\n    output_path='./custom_results',\n    running_llm=llm_api,\n    max_generations=10\n)\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#14-prompt","title":"1.4 Prompt \u5de5\u7a0b\u6700\u4f73\u5b9e\u8df5","text":"<p>\u81ea\u5b9a\u4e49 prompt \u65f6\uff1a</p>"},{"location":"zh/tutorials/customization/customizing-evolution/#141","title":"1.4.1 \u660e\u786e\u8981\u6c42","text":"<pre><code># \u6a21\u7cca\nprompt = \"\u6539\u8fdb\u8fd9\u6bb5\u4ee3\u7801\"\n\n# \u660e\u786e\nprompt = \"\"\"\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u6539\u8fdb\u4ee3\u7801:\n1. \u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\n2. \u4fdd\u6301\u6570\u503c\u7a33\u5b9a\u6027\n3. \u786e\u4fdd\u8fb9\u754c\u60c5\u51b5\u7684\u6b63\u786e\u6027\"\"\"\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#142","title":"1.4.2 \u63d0\u4f9b\u4e0a\u4e0b\u6587\u548c\u793a\u4f8b","text":"<pre><code>prompt = f\"\"\"\u4efb\u52a1: {task_description}\n\n\u597d\u7684\u505a\u6cd5:\n- \u4f7f\u7528\u5411\u91cf\u5316\u7684 NumPy \u64cd\u4f5c\n- \u5c3d\u53ef\u80fd\u907f\u514d\u5faa\u73af\n- \u5904\u7406\u8fb9\u754c\u60c5\u51b5\uff08\u7a7a\u6570\u7ec4\u3001\u96f6\u503c\uff09\n\n\u4e0d\u597d\u7684\u505a\u6cd5:\n- \u5bf9\u5927\u6570\u7ec4\u4f7f\u7528\u663e\u5f0f Python \u5faa\u73af\n- \u4e0d\u68c0\u67e5\u96f6\u503c\u5c31\u8fdb\u884c\u9664\u6cd5\n\n\u5f53\u524d\u4ee3\u7801:\n{current_best_sol.sol_string}\n\n\u751f\u6210\u6539\u8fdb\u7248\u672c...\"\"\"\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#143","title":"1.4.3 \u878d\u5165\u9886\u57df\u77e5\u8bc6","text":"<pre><code># \u5bf9\u4e8e\u79d1\u5b66\u56de\u5f52\nprompt = \"\"\"\u57fa\u4e8e\u5df2\u77e5\u7684\u7269\u7406/\u751f\u7269\u5b66\u539f\u7406\u5efa\u7acb\u65b9\u7a0b:\n- Monod \u65b9\u7a0b\u7528\u4e8e\u5e95\u7269\u9650\u5236: \u03bc = \u03bcmax * S / (Ks + S)\n- Arrhenius \u65b9\u7a0b\u7528\u4e8e\u6e29\u5ea6: k = A * exp(-Ea / RT)\n- Logistic \u589e\u957f\u7528\u4e8e\u79cd\u7fa4\u52a8\u529b\u5b66\n...\"\"\"\n\n# \u5bf9\u4e8e CUDA \u4f18\u5316\nprompt = \"\"\"\u5e94\u7528 GPU \u4f18\u5316\u6280\u672f:\n- \u5408\u5e76\u5185\u5b58\u8bbf\u95ee\n- \u5bf9\u9891\u7e41\u8bbf\u95ee\u7684\u6570\u636e\u4f7f\u7528\u5171\u4eab\u5185\u5b58\n- \u6700\u5c0f\u5316\u5206\u652f\u5206\u6b67\n...\"\"\"\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#144","title":"1.4.4 \u6839\u636e\u64cd\u4f5c\u7b26\u7c7b\u578b\u81ea\u5b9a\u4e49","text":"<p>\u4e0d\u540c\u7684\u64cd\u4f5c\u7b26\u53d7\u76ca\u4e8e\u4e0d\u540c\u7684 prompt\uff1a</p> <pre><code>def get_operator_prompt(self, operator_name, ...):\n    if operator_name == \"init\":\n        # \u521d\u59cb\u63a2\u7d22 - \u9f13\u52b1\u591a\u6837\u6027\n        prompt = \"\u63a2\u7d22\u591a\u6837\u5316\u7684\u89e3\u51b3\u65b9\u6848\u65b9\u6cd5...\"\n\n    elif operator_name == \"mutation\":\n        # \u5c40\u90e8\u641c\u7d22 - \u5c0f\u7684\u6539\u8fdb\n        prompt = \"\u5bf9\u5f53\u524d\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u6e10\u8fdb\u5f0f\u6539\u8fdb...\"\n\n    elif operator_name == \"crossover\":\n        # \u7ec4\u5408\u7279\u5f81 - \u91cd\u7ec4\n        prompt = \"\u7ed3\u5408\u4e24\u4e2a\u7236\u4ee3\u89e3\u51b3\u65b9\u6848\u7684\u4f18\u52bf...\"\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#2","title":"\u7ea7\u522b 2\uff1a\u5f00\u53d1\u65b0\u7b97\u6cd5","text":"<p>\u9ad8\u7ea7\u4e3b\u9898</p> <p>\u672c\u8282\u9762\u5411\u5e0c\u671b\u5b9e\u73b0\u5168\u65b0\u8fdb\u5316\u7b56\u7565\u7684\u7528\u6237\u3002\u5927\u591a\u6570\u7528\u6237\u5e94\u8be5\u4ece\u7ea7\u522b 1\uff08\u81ea\u5b9a\u4e49 prompt\uff09\u5f00\u59cb\uff0c\u8fd9\u901a\u5e38\u5df2\u7ecf\u8db3\u591f\u3002</p>"},{"location":"zh/tutorials/customization/customizing-evolution/#21","title":"2.1 \u4f55\u65f6\u5f00\u53d1\u65b0\u7b97\u6cd5","text":"<p>\u5728\u4ee5\u4e0b\u60c5\u51b5\u4e0b\u8003\u8651\u5f00\u53d1\u65b0\u7b97\u6cd5\uff1a</p> <ul> <li>\u73b0\u6709\u7b97\u6cd5\uff08EvoEngineer\u3001EoH\u3001FunSearch\uff09\u4e0d\u9002\u5408\u60a8\u7684\u95ee\u9898\u7ed3\u6784</li> <li>\u60a8\u6709\u7279\u5b9a\u9886\u57df\u7684\u8fdb\u5316\u7b56\u7565</li> <li>\u60a8\u60f3\u7814\u7a76\u65b0\u7684 LLM \u9a71\u52a8\u4f18\u5316\u65b9\u6cd5</li> <li>\u60a8\u9700\u8981\u5b8c\u5168\u4e0d\u540c\u7684\u8fdb\u5316\u6d41\u7a0b\u6216\u9009\u62e9\u673a\u5236</li> </ul>"},{"location":"zh/tutorials/customization/customizing-evolution/#22","title":"2.2 \u7b97\u6cd5\u67b6\u6784","text":"<p>EvoToolkit \u4f7f\u7528\u4e09\u5c42\u67b6\u6784\u6765\u5b9e\u73b0\u65b0\u7b97\u6cd5\uff1a</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \u7b2c 1 \u5c42\uff1a\u7b97\u6cd5\u7c7b (Algorithm)            \u2502\n\u2502  - \u7ee7\u627f Method \u57fa\u7c7b                     \u2502\n\u2502  - \u5b9e\u73b0 run() \u65b9\u6cd5\uff08\u8fdb\u5316\u4e3b\u5faa\u73af\uff09        \u2502\n\u2502  - \u5b9a\u4e49 Config \u7c7b\uff08\u7b97\u6cd5\u914d\u7f6e\uff09           \u2502\n\u2502  \u4f4d\u7f6e\uff1aevo_method/your_algorithm/       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \u7b2c 2 \u5c42\uff1a\u901a\u7528 Interface \u57fa\u7c7b           \u2502\n\u2502  - \u5fc5\u9700\u65b9\u6cd5\uff1amake_init_sol()            \u2502\n\u2502  -          parse_response()            \u2502\n\u2502  - \u5176\u4ed6\u65b9\u6cd5\uff1a\u7531\u7b97\u6cd5\u9700\u6c42\u51b3\u5b9a             \u2502\n\u2502  \u4f4d\u7f6e\uff1acore/method_interface/           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \u7b2c 3 \u5c42\uff1a\u4efb\u52a1\u4e13\u7528 Interface            \u2502\n\u2502  - \u7ee7\u627f\u901a\u7528 Interface \u57fa\u7c7b              \u2502\n\u2502  - \u5b9e\u73b0\u7279\u5b9a\u4efb\u52a1\u7c7b\u578b\u7684\u5177\u4f53\u903b\u8f91           \u2502\n\u2502  \u4f4d\u7f6e\uff1atask/*/method_interface/         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Interface \u8bbe\u8ba1\u7684\u7075\u6d3b\u6027</p> <p>\u6838\u5fc3\u8981\u6c42\uff1a <code>BaseMethodInterface</code> \u53ea\u5f3a\u5236\u8981\u6c42\u4e24\u4e2a\u65b9\u6cd5\uff1a</p> <ul> <li><code>make_init_sol()</code> - \u521b\u5efa\u521d\u59cb\u89e3</li> <li><code>parse_response(response_str)</code> - \u89e3\u6790 LLM \u54cd\u5e94</li> </ul> <p>\u7b97\u6cd5\u7279\u5b9a\u65b9\u6cd5\uff1a \u5176\u4ed6\u6240\u6709\u65b9\u6cd5\u90fd\u7531\u60a8\u7684\u7b97\u6cd5\u9700\u6c42\u51b3\u5b9a\uff1a</p> <ul> <li>\u57fa\u4e8e\u64cd\u4f5c\u7b26\uff08\u5982 EvoEngineer\uff09\uff1a<code>get_init_operators()</code>, <code>get_offspring_operators()</code>, <code>get_operator_prompt()</code></li> <li>\u8fed\u4ee3\u5f0f\uff08\u5982 FunSearch\uff09\uff1a<code>generate_evolution_prompt()</code></li> <li>\u60a8\u7684\u8bbe\u8ba1\uff1a\u5b9a\u4e49\u4efb\u4f55\u60a8\u7684\u7b97\u6cd5\u9700\u8981\u7684\u65b9\u6cd5</li> </ul> <p>\u73b0\u6709\u7b97\u6cd5\u793a\u4f8b\uff1a</p> <ul> <li>EvoEngineer\uff1a<code>evo_method/evoengineer/evoengineer.py</code> (\u7b2c1\u5c42) \u2192 <code>core/method_interface/evoengineer_interface.py</code> (\u7b2c2\u5c42) \u2192 <code>task/python_task/method_interface/evoengineer_interface.py</code> (\u7b2c3\u5c42)</li> <li>EoH\uff1a<code>evo_method/eoh/</code> \u2192 <code>core/method_interface/eoh_interface.py</code> \u2192 <code>task/python_task/method_interface/eoh_interface.py</code></li> <li>FunSearch\uff1a<code>evo_method/funsearch/</code> \u2192 <code>core/method_interface/funsearch_interface.py</code> \u2192 <code>task/python_task/method_interface/funsearch_interface.py</code></li> </ul>"},{"location":"zh/tutorials/customization/customizing-evolution/#23","title":"2.3 \u521b\u5efa\u65b0\u7b97\u6cd5","text":""},{"location":"zh/tutorials/customization/customizing-evolution/#1-1","title":"\u6b65\u9aa4 1\uff1a\u521b\u5efa\u7b97\u6cd5\u7c7b (\u7b2c 1 \u5c42)","text":"<p>\u7b97\u6cd5\u7c7b\u8d1f\u8d23\u5b9e\u73b0\u8fdb\u5316\u4e3b\u5faa\u73af\u548c\u79cd\u7fa4\u7ba1\u7406\uff1a</p> <pre><code>from evotoolkit.core import Method, BaseConfig, Solution\nfrom evotoolkit.tools.llm import HttpsApi\nfrom typing import List\n\nclass MyAlgorithmConfig(BaseConfig):\n    \"\"\"\u7b97\u6cd5\u914d\u7f6e\u7c7b\"\"\"\n    def __init__(\n        self,\n        interface,  # Interface \u5b9e\u4f8b\n        output_path: str,\n        running_llm: HttpsApi,\n        max_generations: int = 10,\n        pop_size: int = 5,\n        offspring_per_generation: int = 3,\n        temperature: float = 1.0,\n        **kwargs\n    ):\n        super().__init__(interface, output_path, verbose=kwargs.get('verbose', True))\n        self.running_llm = running_llm\n        self.max_generations = max_generations\n        self.pop_size = pop_size\n        self.offspring_per_generation = offspring_per_generation\n        self.temperature = temperature\n\n\nclass MyAlgorithm(Method):\n    \"\"\"\u6211\u7684\u81ea\u5b9a\u4e49\u8fdb\u5316\u7b97\u6cd5 - \u7b80\u5355\u7684\u8fed\u4ee3\u5f0f\u8fdb\u5316\"\"\"\n\n    def __init__(self, config: MyAlgorithmConfig):\n        super().__init__(config)\n        self.config = config\n\n    def run(self):\n        \"\"\"\u4e3b\u8fdb\u5316\u5faa\u73af - \u5b9e\u73b0\u60a8\u7684\u8fdb\u5316\u7b56\u7565\"\"\"\n        self.verbose_title(\"MY ALGORITHM STARTED\")\n\n        # 1. \u521d\u59cb\u5316\uff1a\u521b\u5efa\u521d\u59cb\u89e3\n        if len(self.run_state_dict.sol_history) == 0:\n            init_sol = self._get_init_sol()\n            self.run_state_dict.sol_history.append(init_sol)\n            self.run_state_dict.population.append(init_sol)\n            self._save_run_state_dict()\n\n        # 2. \u4e3b\u8fdb\u5316\u5faa\u73af\n        while self.run_state_dict.generation &lt; self.config.max_generations:\n            self.verbose_info(f\"Generation {self.run_state_dict.generation}\")\n\n            current_best = max(self.run_state_dict.population,\n                             key=lambda s: s.evaluation_res.score)\n\n            # \u751f\u6210\u65b0\u7684\u5019\u9009\u89e3\n            for i in range(self.config.offspring_per_generation):\n                # \u751f\u6210 prompt\n                messages = self.config.interface.generate_evolution_prompt(\n                    current_best=current_best,\n                    population=self.run_state_dict.population,\n                    generation=self.run_state_dict.generation\n                )\n\n                # \u8c03\u7528 LLM\n                response, usage = self.config.running_llm.get_response(messages)\n\n                # \u89e3\u6790\u54cd\u5e94\n                new_sol = self.config.interface.parse_response(response)\n\n                # \u6dfb\u52a0\u5230\u5386\u53f2\u548c\u79cd\u7fa4\n                if new_sol.evaluation_res.valid:\n                    self.run_state_dict.sol_history.append(new_sol)\n                    self.run_state_dict.population.append(new_sol)\n\n            # \u79cd\u7fa4\u7ba1\u7406\uff1a\u4fdd\u7559\u6700\u4f18\u7684\u4e2a\u4f53\n            self.run_state_dict.population.sort(\n                key=lambda s: s.evaluation_res.score, reverse=True\n            )\n            self.run_state_dict.population = \\\n                self.run_state_dict.population[:self.config.pop_size]\n\n            self.run_state_dict.generation += 1\n            self._save_run_state_dict()\n\n        # 3. \u6807\u8bb0\u5b8c\u6210\n        self.run_state_dict.is_done = True\n        self._save_run_state_dict()\n</code></pre> <p>\u6587\u4ef6\u4f4d\u7f6e\uff1a \u60a8\u53ef\u4ee5\u5c06\u7b97\u6cd5\u6587\u4ef6\u653e\u5728\u4efb\u4f55\u4f4d\u7f6e\u3002\u5982\u679c\u8981\u8d21\u732e\u5230 EvoToolkit \u5e93\uff0c\u5efa\u8bae\u653e\u5728 <code>src/evotool/evo_method/my_algorithm/</code> \u76ee\u5f55\u4e0b\u3002</p>"},{"location":"zh/tutorials/customization/customizing-evolution/#2-interface-2","title":"\u6b65\u9aa4 2\uff1a\u521b\u5efa\u901a\u7528 Interface \u57fa\u7c7b (\u7b2c 2 \u5c42)","text":"<p>\u901a\u7528 Interface \u5b9a\u4e49\u7b97\u6cd5\u9700\u8981\u7684\u6838\u5fc3\u65b9\u6cd5\u3002\u91cd\u8981\uff1a <code>BaseMethodInterface</code> \u53ea\u8981\u6c42\u5b9e\u73b0\u4e24\u4e2a\u6838\u5fc3\u65b9\u6cd5\uff1a</p> <ul> <li><code>make_init_sol()</code> - \u521b\u5efa\u521d\u59cb\u89e3</li> <li><code>parse_response(response_str: str)</code> - \u89e3\u6790 LLM \u54cd\u5e94</li> </ul> <p>\u5176\u4ed6\u65b9\u6cd5\u5b8c\u5168\u7531\u60a8\u7684\u7b97\u6cd5\u9700\u6c42\u51b3\u5b9a\u3002 \u4e0d\u540c\u7b97\u6cd5\u6709\u4e0d\u540c\u7684\u7ed3\u6784\uff1a</p> <ul> <li>\u57fa\u4e8e\u64cd\u4f5c\u7b26\u7684\u7b97\u6cd5\uff08\u5982 EvoEngineer\uff09\uff1a\u9700\u8981 <code>get_init_operators()</code>, <code>get_offspring_operators()</code>, <code>get_operator_prompt()</code></li> <li>\u8fed\u4ee3\u5f0f\u7b97\u6cd5\uff08\u5982 FunSearch\uff09\uff1a\u53ef\u80fd\u53ea\u9700\u8981 <code>generate_evolution_prompt()</code></li> <li>\u60a8\u7684\u7b97\u6cd5\uff1a\u5b9a\u4e49\u4efb\u4f55\u60a8\u9700\u8981\u7684\u65b9\u6cd5</li> </ul> <p>\u793a\u4f8b\uff1a\u7b80\u5355\u7684\u8fed\u4ee3\u5f0f Interface</p> <pre><code>from abc import abstractmethod\nfrom typing import List\nfrom evotoolkit.core import Solution, BaseTask\nfrom evotoolkit.core.method_interface import BaseMethodInterface\n\nclass MyAlgorithmInterface(BaseMethodInterface):\n    \"\"\"\u6211\u7684\u7b97\u6cd5\u7684\u901a\u7528 Interface \u57fa\u7c7b\"\"\"\n\n    def __init__(self, task: BaseTask):\n        super().__init__(task)\n\n    def make_init_sol(self) -&gt; Solution:\n        \"\"\"\u521b\u5efa\u521d\u59cb\u89e3\uff08\u5fc5\u9700\uff09\"\"\"\n        init_sol = self.task.make_init_sol_wo_other_info()\n        init_sol.other_info = {'generation': 0}\n        return init_sol\n\n    @abstractmethod\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"\u89e3\u6790 LLM \u54cd\u5e94\uff08\u5fc5\u9700\uff09\"\"\"\n        pass\n\n    @abstractmethod\n    def generate_evolution_prompt(\n        self,\n        current_best: Solution,\n        population: List[Solution],\n        generation: int\n    ) -&gt; List[dict]:\n        \"\"\"\n        \u4e3a\u5f53\u524d\u4ee3\u751f\u6210\u8fdb\u5316 prompt\uff08\u7b97\u6cd5\u7279\u5b9a\u65b9\u6cd5\uff09\n\n        Args:\n            current_best: \u5f53\u524d\u6700\u4f18\u89e3\n            population: \u5f53\u524d\u79cd\u7fa4\n            generation: \u5f53\u524d\u4ee3\u6570\n\n        Returns:\n            List[dict]: LLM \u6d88\u606f\u5217\u8868\n        \"\"\"\n        pass\n</code></pre> <p>\u6587\u4ef6\u4f4d\u7f6e\uff1a \u60a8\u53ef\u4ee5\u5c06 Interface \u6587\u4ef6\u653e\u5728\u4efb\u4f55\u4f4d\u7f6e\u3002\u5982\u679c\u8981\u8d21\u732e\u5230 EvoToolkit \u5e93\uff0c\u5efa\u8bae\u653e\u5728 <code>src/evotool/core/method_interface/my_algorithm_interface.py</code>\u3002</p> <p>\u8bbe\u8ba1\u539f\u5219</p> <ul> <li>\u5fc5\u9700\u65b9\u6cd5\uff1a\u53ea\u6709 <code>make_init_sol()</code> \u548c <code>parse_response()</code> \u662f\u5fc5\u9700\u7684</li> <li>\u81ea\u5b9a\u4e49\u65b9\u6cd5\uff1a\u6839\u636e\u7b97\u6cd5\u7684\u8fdb\u5316\u7b56\u7565\u6dfb\u52a0\u4efb\u4f55\u9700\u8981\u7684\u65b9\u6cd5</li> <li>\u7075\u6d3b\u6027\uff1a\u4e0d\u8981\u53d7\u9650\u4e8e\u73b0\u6709\u7b97\u6cd5\u7684\u7ed3\u6784\uff0c\u8bbe\u8ba1\u6700\u9002\u5408\u60a8\u95ee\u9898\u7684\u63a5\u53e3</li> </ul>"},{"location":"zh/tutorials/customization/customizing-evolution/#3-interface-3","title":"\u6b65\u9aa4 3\uff1a\u521b\u5efa\u4efb\u52a1\u4e13\u7528 Interface (\u7b2c 3 \u5c42)","text":"<p>\u4e3a\u7279\u5b9a\u4efb\u52a1\u7c7b\u578b\u5b9e\u73b0\u5177\u4f53\u903b\u8f91\uff1a</p> <pre><code>from evotoolkit.core import MyAlgorithmInterface, Solution\nfrom evotoolkit.task.python_task import PythonTask\nfrom typing import List\nimport re\n\nclass MyAlgorithmPythonInterface(MyAlgorithmInterface):\n    \"\"\"\u9488\u5bf9 Python \u4efb\u52a1\u7684 Interface \u5b9e\u73b0\"\"\"\n\n    def __init__(self, task: PythonTask):\n        super().__init__(task)\n\n    def parse_response(self, response_str: str) -&gt; Solution:\n        \"\"\"\u4ece LLM \u54cd\u5e94\u4e2d\u89e3\u6790 Python \u4ee3\u7801\"\"\"\n        # \u63d0\u53d6 Python \u4ee3\u7801\u5757\n        code_match = re.search(r'```python\\n(.*?)\\n```', response_str, re.DOTALL)\n        if code_match:\n            code = code_match.group(1)\n        else:\n            code = response_str\n\n        # \u8bc4\u4f30\u4ee3\u7801\n        eval_res = self.task.evaluate_code(code)\n\n        return Solution(\n            sol_string=code,\n            evaluation_res=eval_res,\n            other_info={'raw_response': response_str}\n        )\n\n    def generate_evolution_prompt(\n        self,\n        current_best: Solution,\n        population: List[Solution],\n        generation: int\n    ) -&gt; List[dict]:\n        \"\"\"\u4e3a\u5f53\u524d\u4ee3\u751f\u6210\u8fdb\u5316 prompt\"\"\"\n\n        task_description = self.task.get_base_task_description()\n\n        # \u6784\u5efa prompt\n        prompt = f\"\"\"\u4f60\u662f\u8fdb\u5316\u4f18\u5316\u4e13\u5bb6\u3002\n\n\u4efb\u52a1\u63cf\u8ff0\uff1a\n{task_description}\n\n\u5f53\u524d\u6700\u4f18\u89e3 (\u5f97\u5206: {current_best.evaluation_res.score:.5f}):\n{current_best.sol_string}\n\n\u5f53\u524d\u4ee3\u6570: {generation}\n\n\u8bf7\u6539\u8fdb\u8fd9\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u751f\u6210\u4e00\u4e2a\u6027\u80fd\u66f4\u597d\u7684\u7248\u672c\u3002\u5173\u6ce8\uff1a\n- \u7b97\u6cd5\u6548\u7387\u548c\u51c6\u786e\u6027\n- \u6570\u503c\u7a33\u5b9a\u6027\n- \u8fb9\u754c\u60c5\u51b5\u5904\u7406\n\n\u8bf7\u63d0\u4f9b\u6539\u8fdb\u7684 Python \u4ee3\u7801\u3002\"\"\"\n\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre> <p>\u6587\u4ef6\u4f4d\u7f6e\uff1a \u60a8\u53ef\u4ee5\u5c06\u4efb\u52a1\u4e13\u7528 Interface \u6587\u4ef6\u653e\u5728\u4efb\u4f55\u4f4d\u7f6e\u3002\u5982\u679c\u8981\u8d21\u732e\u5230 EvoToolkit \u5e93\uff0c\u5efa\u8bae\u653e\u5728 <code>src/evotool/task/python_task/method_interface/my_algorithm_interface.py</code>\u3002</p> <p>Prompt \u4e2d\u7684\u4ee3\u7801\u5757</p> <p>\u5728 prompt \u5b57\u7b26\u4e32\u4e2d\u5f15\u7528\u4ee3\u7801\u65f6\uff0c\u76f4\u63a5\u63d2\u5165\u4ee3\u7801\u6587\u672c\u5373\u53ef\uff0c\u4e0d\u8981\u4f7f\u7528 markdown \u4ee3\u7801\u5757\u6807\u8bb0\u3002LLM \u80fd\u591f\u7406\u89e3\u4ee3\u7801\u7ed3\u6784\uff0c\u800c markdown \u6807\u8bb0\u53ef\u80fd\u5bfc\u81f4\u6df7\u6dc6\u3002</p>"},{"location":"zh/tutorials/customization/customizing-evolution/#4","title":"\u6b65\u9aa4 4\uff1a\u4f7f\u7528\u60a8\u7684\u65b0\u7b97\u6cd5","text":"<pre><code>import evotoolkit\nfrom evotoolkit.task.python_task import MyAlgorithmPythonInterface\nfrom evotoolkit.tools.llm import HttpsApi\nimport os\n\n# \u521b\u5efa\u4efb\u52a1\ntask = MyTask(...)\n\n# \u521b\u5efa\u4efb\u52a1\u4e13\u7528 Interface\ninterface = MyAlgorithmPythonInterface(task)\n\n# \u914d\u7f6e LLM\nllm_api = HttpsApi(\n    api_url=os.environ.get(\"LLM_API_URL\"),\n    key=os.environ.get(\"LLM_API_KEY\"),\n    model=\"gpt-4o\"\n)\n\n# \u4f7f\u7528 evotoolkit.solve() \u4f1a\u81ea\u52a8\u627e\u5230\u5bf9\u5e94\u7684\u7b97\u6cd5\u7c7b\n# \u6216\u8005\u624b\u52a8\u521b\u5efa\uff1a\nfrom evotoolkit.evo_method.my_algorithm import MyAlgorithm, MyAlgorithmConfig\n\nconfig = MyAlgorithmConfig(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    max_generations=20,\n    temperature=0.8  # \u60a8\u7684\u81ea\u5b9a\u4e49\u53c2\u6570\n)\n\nalgorithm = MyAlgorithm(config)\nalgorithm.run()\n\n# \u83b7\u53d6\u6700\u4f73\u89e3\nbest_sol = algorithm.run_state_dict.get_best_solution()\nprint(f\"Best score: {best_sol.evaluation_res.score}\")\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#5","title":"\u6b65\u9aa4 5\uff1a\u6ce8\u518c\u7b97\u6cd5\uff08\u53ef\u9009\uff09","text":"<p>\u5982\u679c\u5e0c\u671b\u7b97\u6cd5\u80fd\u88ab <code>evotoolkit.solve()</code> \u81ea\u52a8\u8bc6\u522b\uff0c\u9700\u8981\u6ce8\u518c\uff1a</p> <pre><code>from evotoolkit.registry import register_algorithm\n\n@register_algorithm(\"my_algorithm\", config=MyAlgorithmConfig)\nclass MyAlgorithm(Method):\n    # ...\n</code></pre> <p>\u7136\u540e\u53ef\u4ee5\u8fd9\u6837\u4f7f\u7528\uff1a</p> <pre><code>result = evotoolkit.solve(\n    interface=interface,\n    output_path='./results',\n    running_llm=llm_api,\n    algorithm=\"my_algorithm\",  # \u6307\u5b9a\u7b97\u6cd5\u540d\u79f0\n    max_generations=20\n)\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#24","title":"2.4 \u5b66\u4e60\u73b0\u6709\u7b97\u6cd5\u5b9e\u73b0","text":"<p>\u5728\u5b9e\u73b0\u60a8\u81ea\u5df1\u7684\u7b97\u6cd5\u4e4b\u524d\uff0c\u5efa\u8bae\u7814\u7a76\u73b0\u6709\u7b97\u6cd5\u7684\u6e90\u4ee3\u7801\uff1a</p> <p>\u63a8\u8350\u9605\u8bfb\u987a\u5e8f\uff1a</p> <ol> <li>EvoEngineer \u7b97\u6cd5\uff08\u6700\u5b8c\u6574\u7684\u793a\u4f8b\uff09</li> <li>\u7b97\u6cd5\u7c7b\uff1a<code>src/evotool/evo_method/evoengineer/evoengineer.py</code></li> <li>Config\uff1a<code>src/evotool/evo_method/evoengineer/run_config.py</code></li> <li>\u901a\u7528 Interface\uff1a<code>src/evotool/core/method_interface/evoengineer_interface.py</code></li> <li> <p>Python Interface\uff1a<code>src/evotool/task/python_task/method_interface/evoengineer_interface.py</code></p> </li> <li> <p>EoH \u7b97\u6cd5\uff08\u66f4\u7b80\u5355\u7684\u793a\u4f8b\uff09</p> </li> <li>\u7b97\u6cd5\u7c7b\uff1a<code>src/evotool/evo_method/eoh/</code></li> <li>\u901a\u7528 Interface\uff1a<code>src/evotool/core/method_interface/eoh_interface.py</code></li> <li> <p>Python Interface\uff1a<code>src/evotool/task/python_task/method_interface/eoh_interface.py</code></p> </li> <li> <p>FunSearch \u7b97\u6cd5\uff08\u4e0d\u540c\u7684\u8fdb\u5316\u7b56\u7565\uff09</p> </li> <li>\u7b97\u6cd5\u7c7b\uff1a<code>src/evotool/evo_method/funsearch/</code></li> <li>\u901a\u7528 Interface\uff1a<code>src/evotool/core/method_interface/funsearch_interface.py</code></li> </ol> <p>\u5173\u952e\u8981\u70b9\uff1a</p> <ul> <li>\u7b97\u6cd5\u7c7b\u7684 <code>run()</code> \u65b9\u6cd5\u5b9a\u4e49\u4e3b\u8fdb\u5316\u5faa\u73af</li> <li>Interface \u7684 <code>get_operator_prompt()</code> \u63a7\u5236 LLM \u4ea4\u4e92</li> <li>Config \u7c7b\u7ba1\u7406\u7b97\u6cd5\u8d85\u53c2\u6570</li> <li><code>_apply_operators_parallel()</code> \u5b9e\u73b0\u5e76\u884c\u8bc4\u4f30</li> <li><code>_manage_population_size()</code> \u7ba1\u7406\u79cd\u7fa4\u5927\u5c0f</li> </ul>"},{"location":"zh/tutorials/customization/customizing-evolution/#_3","title":"\u7279\u5b9a\u4efb\u52a1\u7684\u81ea\u5b9a\u4e49\u793a\u4f8b","text":""},{"location":"zh/tutorials/customization/customizing-evolution/#31","title":"3.1 \u79d1\u5b66\u56de\u5f52","text":"<pre><code>class ScientificInterface(EvoEngineerPythonInterface):\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        if operator_name == \"mutation\":\n            prompt = f\"\"\"\u4f60\u662f\u4e00\u4e2a\u7269\u7406\u5b66\u5bb6/\u751f\u7269\u5b66\u5bb6\uff0c\u6b63\u5728\u53d1\u73b0\u65b9\u7a0b\u3002\n\n\u5f53\u524d\u65b9\u7a0b (MSE: {current_best_sol.evaluation_res.score:.6f}):\n{current_best_sol.sol_string}\n\n\u4f7f\u7528\u5df2\u5efa\u7acb\u7684\u539f\u7406:\n- Monod: \u03bc = \u03bcmax * S / (Ks + S)\n- Arrhenius: k = A * exp(-Ea / RT)\n- Michaelis-Menten \u52a8\u529b\u5b66\n- Logistic \u589e\u957f\n\n\u7ea6\u675f:\n- \u786e\u4fdd\u91cf\u7eb2\u4e00\u81f4\u6027\n- \u907f\u514d\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\n- \u4fdd\u6301\u6a21\u578b\u7b80\u6d01\n\n\u751f\u6210\u6539\u8fdb\u7684\u65b9\u7a0b...\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#32-cuda","title":"3.2 CUDA \u4f18\u5316","text":"<pre><code>class CUDAInterface(EvoEngineerCUDAInterface):\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        if operator_name == \"mutation\":\n            prompt = f\"\"\"\u4f60\u662f\u4e00\u4e2a GPU \u4f18\u5316\u4e13\u5bb6\u3002\n\n\u5f53\u524d CUDA kernel (\u65f6\u95f4: {current_best_sol.evaluation_res.score:.3f}ms):\n{current_best_sol.sol_string}\n\n\u5e94\u7528\u4f18\u5316:\n- \u5408\u5e76\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\n- \u5bf9\u4e34\u65f6\u6570\u636e\u4f7f\u7528\u5171\u4eab\u5185\u5b58\n- \u51cf\u5c11 bank \u51b2\u7a81\n- \u6700\u5c0f\u5316\u7ebf\u7a0b\u5206\u6b67\n- \u4f18\u5316 block/grid \u7ef4\u5ea6\n\n\u751f\u6210\u4f18\u5316\u7684 kernel...\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#33","title":"3.3 \u63d0\u793a\u8bcd\u5de5\u7a0b","text":"<pre><code>class PromptOptimizationInterface(EvoEngineerPythonInterface):\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n        if operator_name == \"mutation\":\n            prompt = f\"\"\"\u4f60\u662f LLM \u63d0\u793a\u8bcd\u5de5\u7a0b\u4e13\u5bb6\u3002\n\n\u5f53\u524d prompt (\u5f97\u5206: {current_best_sol.evaluation_res.score:.3f}):\n{current_best_sol.sol_string}\n\n\u6539\u8fdb\u7b56\u7565:\n- \u6dfb\u52a0\u6e05\u6670\u7684\u6307\u4ee4\u548c\u7ed3\u6784\n- \u63d0\u4f9b\u76f8\u5173\u793a\u4f8b\n- \u6307\u5b9a\u8f93\u51fa\u683c\u5f0f\n- \u5305\u542b\u7ea6\u675f\u548c\u6307\u5bfc\u65b9\u9488\n- \u4f7f\u7528\u9002\u5f53\u7684\u8bed\u6c14\u548c\u98ce\u683c\n\n\u751f\u6210\u6539\u8fdb\u7684 prompt...\"\"\"\n            return [{\"role\": \"user\", \"content\": prompt}]\n        return super().get_operator_prompt(operator_name, selected_individuals,\n                                          current_best_sol, random_thoughts, **kwargs)\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#_4","title":"\u6d4b\u8bd5\u548c\u8c03\u8bd5","text":""},{"location":"zh/tutorials/customization/customizing-evolution/#41-prompt","title":"4.1 \u8bb0\u5f55 Prompt","text":"<p>\u8981\u67e5\u770b\u53d1\u9001\u7ed9 LLM \u7684 prompt\uff1a</p> <pre><code>class DebugInterface(EvoEngineerPythonInterface):\n    def get_operator_prompt(self, operator_name, selected_individuals,\n                           current_best_sol, random_thoughts, **kwargs):\n\n        prompts = super().get_operator_prompt(operator_name, selected_individuals,\n                                             current_best_sol, random_thoughts, **kwargs)\n\n        # \u8bb0\u5f55 prompt \u4ee5\u8fdb\u884c\u8c03\u8bd5\n        print(f\"\\n{'='*60}\")\n        print(f\"\u64cd\u4f5c\u7b26: {operator_name}\")\n        print(f\"PROMPT:\\n{prompts[0]['content']}\")\n        print(f\"{'='*60}\\n\")\n\n        return prompts\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#42-interface","title":"4.2 \u9a8c\u8bc1\u81ea\u5b9a\u4e49 Interface","text":"<p>\u5728\u8fd0\u884c\u5b8c\u6574\u8fdb\u5316\u4e4b\u524d\uff0c\u6d4b\u8bd5\u60a8\u7684 Interface\uff1a</p> <pre><code># \u521b\u5efa interface\ninterface = CustomInterface(task)\n\n# \u83b7\u53d6\u521d\u59cb\u89e3\ninit_sol = task.make_init_sol_wo_other_info()\n\n# \u6d4b\u8bd5\u6bcf\u4e2a\u64cd\u4f5c\u7b26\u7684 prompt \u751f\u6210\nfor op in interface.get_offspring_operators():\n    prompts = interface.get_operator_prompt(\n        operator_name=op.name,\n        selected_individuals=[init_sol],\n        current_best_sol=init_sol,\n        random_thoughts=[]\n    )\n    print(f\"\u64cd\u4f5c\u7b26 {op.name}:\")\n    print(prompts[0]['content'][:200] + \"...\")\n    print()\n</code></pre>"},{"location":"zh/tutorials/customization/customizing-evolution/#_5","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u5b9e\u9a8c\uff1a\u5c1d\u8bd5\u4e0d\u540c\u7684 prompt \u98ce\u683c\uff0c\u770b\u770b\u54ea\u79cd\u6548\u679c\u6700\u597d</li> <li>\u5206\u6790\uff1a\u6bd4\u8f83\u4e0d\u540c\u81ea\u5b9a\u4e49\u65b9\u6848\u7684\u7ed3\u679c</li> <li>\u5206\u4eab\uff1a\u8003\u8651\u5c06\u6210\u529f\u7684\u81ea\u5b9a\u4e49\u65b9\u6848\u8d21\u732e\u7ed9\u9879\u76ee</li> </ul> <p>\u76f8\u5173\u6587\u6863\uff1a</p> <ul> <li>\u79d1\u5b66\u56de\u5f52\u6559\u7a0b - \u5e94\u7528\u793a\u4f8b</li> <li>CUDA \u4efb\u52a1\u6559\u7a0b - GPU \u4ee3\u7801\u4f18\u5316</li> <li>\u9ad8\u7ea7\u7528\u6cd5 - \u66f4\u591a\u914d\u7f6e\u9009\u9879</li> <li>API \u53c2\u8003 - \u5b8c\u6574\u7684 Interface API \u6587\u6863</li> <li>\u8d21\u732e\u6307\u5357 - \u5206\u4eab\u60a8\u7684\u81ea\u5b9a\u4e49\u65b9\u6cd5</li> </ul>"}]}